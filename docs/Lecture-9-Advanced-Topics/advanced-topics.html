<!DOCTYPE html>
<html lang="en"><head>
<script src="advanced-topics_files/libs/clipboard/clipboard.min.js"></script>
<script src="advanced-topics_files/libs/quarto-html/tabby.min.js"></script>
<script src="advanced-topics_files/libs/quarto-html/popper.min.js"></script>
<script src="advanced-topics_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="advanced-topics_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="advanced-topics_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="advanced-topics_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.1.251">

  <meta name="author" content="Dr Patrick Laub">
  <title>Advanced Topics &amp; Revision</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="advanced-topics_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="advanced-topics_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #1f1c1b;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #1f1c1b; } /* Normal */
    code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
    code span.an { color: #ca60ca; } /* Annotation */
    code span.at { color: #0057ae; } /* Attribute */
    code span.bn { color: #b08000; } /* BaseN */
    code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
    code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #924c9d; } /* Char */
    code span.cn { color: #aa5500; } /* Constant */
    code span.co { color: #898887; } /* Comment */
    code span.cv { color: #0095ff; } /* CommentVar */
    code span.do { color: #607880; } /* Documentation */
    code span.dt { color: #0057ae; } /* DataType */
    code span.dv { color: #b08000; } /* DecVal */
    code span.er { color: #bf0303; text-decoration: underline; } /* Error */
    code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
    code span.fl { color: #b08000; } /* Float */
    code span.fu { color: #644a9b; } /* Function */
    code span.im { color: #ff5500; } /* Import */
    code span.in { color: #b08000; } /* Information */
    code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
    code span.op { color: #ca60ca; } /* Operator */
    code span.ot { color: #006e28; } /* Other */
    code span.pp { color: #006e28; } /* Preprocessor */
    code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
    code span.sc { color: #3daee9; } /* SpecialChar */
    code span.ss { color: #ff5500; } /* SpecialString */
    code span.st { color: #bf0303; } /* String */
    code span.va { color: #0057ae; } /* Variable */
    code span.vs { color: #bf0303; } /* VerbatimString */
    code span.wa { color: #bf0303; } /* Warning */
  </style>
  <link rel="stylesheet" href="advanced-topics_files/libs/revealjs/dist/theme/quarto.css" id="theme">
  <link href="advanced-topics_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="advanced-topics_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="advanced-topics_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="advanced-topics_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="advanced-topics_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="advanced-topics_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="advanced-topics_files/libs/quarto-diagram/mermaid.min.js"></script>
  <script src="advanced-topics_files/libs/quarto-diagram/mermaid-init.js"></script>
  <link href="advanced-topics_files/libs/quarto-diagram/mermaid.css" rel="stylesheet">
</head>
<body class="quarto-light">
<div class="line right"></div>
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="unsw-yellow-shape.png" data-background-size="contain !important" class="center">
  <h1 class="title">Advanced Topics &amp; Revision</h1>
  <p class="subtitle">ACTL3143/5111: Deep Learning for Actuaries</p>
  <p class="author">Dr Patrick Laub</p>
  <p class="date">Week 10</p>
</section>

<section>
<section id="section" class="title-slide slide level1 center">
<h1></h1>
<h2>
Lecture Outline
</h2>
<p><br></p>
<ul>
<li>Dissecting <code>model.fit</code></li>
<li>Object oriented programming &amp; PyTorch</li>
<li>Generative adversarial networks</li>
<li>Exam preparation</li>
</ul>
<p><br><br><br></p>
</section>
<section id="announcements" class="slide level2">
<h2>Announcements</h2>
<ul>
<li>Previous StoryWall was quite successful.</li>
<li>Young Data Analytics Working Group podcast opportunity.</li>
<li>Project marks will go on Moodle next week.</li>
<li>Final Story Wall is due <strong>this Friday at noon</strong>.</li>
</ul>
</section>
<section id="exam-details" class="slide level2">
<h2>Exam details</h2>
<ul>
<li>Thursday 18th Aug 2 pm - 4 pm (14:00-16:00)</li>
<li>Exam is a Moodle quiz</li>
<li>Open book (if you see “No Exam Materials permitted” just ignore it)</li>
<li>Link at the top of the Moodle page for the course</li>
<li>Exam open for 2 hours, but <strong>you have 1.5 hours</strong> to complete</li>
<li>Complete the IT preparation checklist (MFA, speed test, read policies)</li>
</ul>
</section>
<section id="dall-e-2" class="slide level2">
<h2>DALL-E 2</h2>

<img data-src="dall-e-2-teddy-bears-on-moon.jpeg" class="r-stretch quarto-figure-center"><p class="caption">DALL-E 2 example: “Teddy bears working on new AI research on the moon in the 1980s”</p><div class="footer">
<p>Source: OpenAI, <a href="https://openai.com/dall-e-2/">DALL-E 2</a>.</p>
</div>
</section>
<section id="dall-e-2-beta" class="slide level2 smaller">
<h2>DALL-E 2 Beta</h2>
<p><em>A painting of a penguin in a library studying a textbook while eating sushi and drinking a strawberry milkshake</em></p>
<div class="columns">
<div class="column">
<p><img data-src="DALL-E/DALL·E%202022-07-28%2008.55.22%20-%20A%20painting%20of%20a%20penguin%20in%20a%20library%20studying%20a%20textbook%20while%20eating%20sushi%20and%20drinking%20a%20strawberry%20milkshake%20.png"></p>
</div><div class="column">
<p><img data-src="DALL-E/DALL·E%202022-07-28%2008.55.28%20-%20A%20painting%20of%20a%20penguin%20in%20a%20library%20studying%20a%20textbook%20while%20eating%20sushi%20and%20drinking%20a%20strawberry%20milkshake%20.png"></p>
</div>
</div>
</section>
<section id="dall-e-2-beta-ii" class="slide level2 smaller">
<h2>DALL-E 2 Beta II</h2>
<p><em>A painting of a penguin in a library studying a textbook while eating sushi and drinking a strawberry milkshake</em></p>
<div class="columns">
<div class="column">
<p><img data-src="DALL-E/DALL·E%202022-07-28%2008.55.34%20-%20A%20painting%20of%20a%20penguin%20in%20a%20library%20studying%20a%20textbook%20while%20eating%20sushi%20and%20drinking%20a%20strawberry%20milkshake%20.png"></p>
</div><div class="column">
<p><img data-src="DALL-E/DALL·E%202022-07-28%2008.55.40%20-%20A%20painting%20of%20a%20penguin%20in%20a%20library%20studying%20a%20textbook%20while%20eating%20sushi%20and%20drinking%20a%20strawberry%20milkshake%20.png"></p>
</div>
</div>
</section>
<section id="load-packages" class="slide level2" data-visibility="uncounted">
<h2>Load packages</h2>
<p><br></p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers</span>
<span id="cb1-7"><a href="#cb1-7"></a></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="op">%</span>load_ext watermark</span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="op">%</span>watermark <span class="op">-</span>p matplotlib,numpy,pandas,tensorflow</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>matplotlib: 3.5.2
numpy     : 1.21.5
pandas    : 1.4.4
tensorflow: 2.8.0
</code></pre>
</div>
</div>
</section>
<section id="load-mnist-dataset" class="slide level2">
<h2>Load MNIST dataset</h2>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>(X_train, y_train), (X_test, y_test) <span class="op">=</span> keras.datasets.mnist.load_data()</span>
<span id="cb3-2"><a href="#cb3-2"></a>X_train <span class="op">=</span> X_train.astype(<span class="st">"float32"</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb3-3"><a href="#cb3-3"></a>X_test <span class="op">=</span> X_test.astype(<span class="st">"float32"</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb3-4"><a href="#cb3-4"></a></span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="co"># Reserve 10,000 samples for validation.</span></span>
<span id="cb3-6"><a href="#cb3-6"></a>X_val <span class="op">=</span> X_train[<span class="op">-</span><span class="dv">10000</span>:]</span>
<span id="cb3-7"><a href="#cb3-7"></a>y_val <span class="op">=</span> y_train[<span class="op">-</span><span class="dv">10000</span>:]</span>
<span id="cb3-8"><a href="#cb3-8"></a>X_train <span class="op">=</span> X_train[:<span class="op">-</span><span class="dv">10000</span>]</span>
<span id="cb3-9"><a href="#cb3-9"></a>y_train <span class="op">=</span> y_train[:<span class="op">-</span><span class="dv">10000</span>]</span>
<span id="cb3-10"><a href="#cb3-10"></a></span>
<span id="cb3-11"><a href="#cb3-11"></a><span class="co"># Prepare the training dataset.</span></span>
<span id="cb3-12"><a href="#cb3-12"></a>batch_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb3-13"><a href="#cb3-13"></a>train_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((X_train, y_train))</span>
<span id="cb3-14"><a href="#cb3-14"></a><span class="co"># train_dataset = train_dataset.shuffle(buffer_size=1024)</span></span>
<span id="cb3-15"><a href="#cb3-15"></a>train_dataset <span class="op">=</span> train_dataset.batch(batch_size)</span>
<span id="cb3-16"><a href="#cb3-16"></a></span>
<span id="cb3-17"><a href="#cb3-17"></a><span class="co"># Prepare the validation dataset.</span></span>
<span id="cb3-18"><a href="#cb3-18"></a>val_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((X_val, y_val))</span>
<span id="cb3-19"><a href="#cb3-19"></a>val_dataset <span class="op">=</span> val_dataset.batch(batch_size)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="a-basic-mnist-model" class="slide level2">
<h2>A basic MNIST model</h2>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">def</span> build_model(seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb4-2"><a href="#cb4-2"></a>  tf.random.set_seed(seed)</span>
<span id="cb4-3"><a href="#cb4-3"></a>  <span class="cf">return</span> keras.Sequential([</span>
<span id="cb4-4"><a href="#cb4-4"></a>    layers.Flatten(input_shape<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>)),</span>
<span id="cb4-5"><a href="#cb4-5"></a>    layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb4-6"><a href="#cb4-6"></a>    layers.Dense(<span class="dv">10</span>)</span>
<span id="cb4-7"><a href="#cb4-7"></a>  ])</span>
<span id="cb4-8"><a href="#cb4-8"></a></span>
<span id="cb4-9"><a href="#cb4-9"></a>firstModel <span class="op">=</span> build_model()</span>
<span id="cb4-10"><a href="#cb4-10"></a>firstModel.summary(print_fn<span class="op">=</span>skip_empty)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"
_________________________________________________________________
Layer (type)                Output Shape              Param #
=================================================================
flatten (Flatten)           (None, 784)               0
dense (Dense)               (None, 128)               100480
dense_1 (Dense)             (None, 10)                1290
=================================================================
Total params: 101,770
Trainable params: 101,770
Non-trainable params: 0
_________________________________________________________________</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section></section>
<section>
<section id="dissecting-model.fit" class="title-slide slide level1 center" data-background-image="unsw-yellow-shape.png" data-visibility="uncounted">
<h1>Dissecting <code>model.fit</code></h1>
<br>
<center>
<blockquote class="twitter-tweet" data-theme="light">
<p lang="en" dir="ltr">
Spoiler: it's going to be a 20-lines Python script that calls model.fіt()<a href="https://t.co/AqLZSQ0kwD">https://t.co/AqLZSQ0kwD</a>
</p>
— François Chollet (<span class="citation" data-cites="fchollet">@fchollet</span>) <a href="https://twitter.com/fchollet/status/1518702623892799488?ref_src=twsrc%5Etfw">April 25, 2022</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<div class="footer">
<p>Source: <a href="https://twitter.com/fchollet/status/1518702623892799488?s=20&amp;t=RZyyrUzgI5VhGfq730ynBg">Twitter</a></p>
</div>
</section>
<section id="fitting-like-normal" class="slide level2">
<h2>Fitting like normal</h2>
<p>Specify fitting requirements.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>epochs <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb6-2"><a href="#cb6-2"></a>lr <span class="op">=</span> <span class="fl">1e-2</span></span>
<span id="cb6-3"><a href="#cb6-3"></a>optimizer <span class="op">=</span> keras.optimizers.SGD(learning_rate<span class="op">=</span>lr)</span>
<span id="cb6-4"><a href="#cb6-4"></a>loss_fn <span class="op">=</span> keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Create a model &amp; run <code>model.fit</code>.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a>firstModel <span class="op">=</span> build_model()</span>
<span id="cb7-2"><a href="#cb7-2"></a>firstModel.<span class="bu">compile</span>(optimizer, loss_fn)</span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="op">%</span>time firstFit <span class="op">=</span> firstModel.fit(train_dataset, epochs<span class="op">=</span>epochs, <span class="op">\</span></span>
<span id="cb7-4"><a href="#cb7-4"></a>        validation_data<span class="op">=</span>val_dataset, verbose<span class="op">=</span><span class="dv">0</span>)<span class="op">;</span></span>
<span id="cb7-5"><a href="#cb7-5"></a>firstFit.history[<span class="st">"loss"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 2.05 s, sys: 382 ms, total: 2.43 s
Wall time: 1.3 s</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>[0.973278820514679, 0.455027312040329]</code></pre>
</div>
</div>
</section>
<section id="going-through-the-epochs" class="slide level2">
<h2>Going through the epochs</h2>
<p>Create a new model:</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb10-2"><a href="#cb10-2"></a>model.<span class="bu">compile</span>(optimizer, loss_fn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Repeatedly call <code>model.fit</code>:</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="co"># Go through all the training data multiple times.</span></span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb11-3"><a href="#cb11-3"></a>    model.fit(train_dataset, epochs<span class="op">=</span><span class="dv">1</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-warning callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Warning</strong></p>
</div>
<div class="callout-content">
<p>Reusing the same optimiser works here because SGD is stateless. In contrast, RMSprop &amp; Adam have internal state (e.g.&nbsp;to calculate/store momentum).</p>
</div>
</div>
</div>
</section>
<section id="are-they-exactly-the-same" class="slide level2">
<h2>Are they <em>exactly</em> the same?</h2>
<div class="columns">
<div class="column">
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>firstModel.layers[<span class="op">-</span><span class="dv">1</span>].get_weights()[<span class="dv">0</span>][:<span class="dv">3</span>,:<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>array([[ 0.0982, -0.0743,  0.2274],
       [-0.1007,  0.0848, -0.2163],
       [-0.2138, -0.197 ,  0.035 ]], dtype=float32)</code></pre>
</div>
</div>
</div><div class="column">
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a>model.layers[<span class="op">-</span><span class="dv">1</span>].get_weights()[<span class="dv">0</span>][:<span class="dv">3</span>,:<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>array([[ 0.0982, -0.0743,  0.2274],
       [-0.1007,  0.0848, -0.2163],
       [-0.2138, -0.197 ,  0.035 ]], dtype=float32)</code></pre>
</div>
</div>
</div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a><span class="kw">def</span> same_last_layer(model1, model2):</span>
<span id="cb16-2"><a href="#cb16-2"></a>    weights1 <span class="op">=</span> model1.layers[<span class="op">-</span><span class="dv">1</span>].get_weights()[<span class="dv">0</span>]</span>
<span id="cb16-3"><a href="#cb16-3"></a>    weights2 <span class="op">=</span> model2.layers[<span class="op">-</span><span class="dv">1</span>].get_weights()[<span class="dv">0</span>]</span>
<span id="cb16-4"><a href="#cb16-4"></a>    <span class="cf">return</span> np.<span class="bu">max</span>(np.<span class="bu">abs</span>(weights1 <span class="op">-</span> weights2)) <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb16-5"><a href="#cb16-5"></a></span>
<span id="cb16-6"><a href="#cb16-6"></a>same_last_layer(firstModel, model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>True</code></pre>
</div>
</div>
</section>
<section id="going-through-the-batches" class="slide level2">
<h2>Going through the batches</h2>
<p>Create a new model:</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb18-2"><a href="#cb18-2"></a>model.<span class="bu">compile</span>(optimizer, loss_fn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Repeatedly call <code>train_on_batch</code>:</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a><span class="co"># Go through all the training data multiple times.</span></span>
<span id="cb19-2"><a href="#cb19-2"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb19-3"><a href="#cb19-3"></a></span>
<span id="cb19-4"><a href="#cb19-4"></a>    <span class="co"># Go through the entire training dataset in batches.</span></span>
<span id="cb19-5"><a href="#cb19-5"></a>    <span class="cf">for</span> (X_batch_train, y_batch_train) <span class="kw">in</span> train_dataset:</span>
<span id="cb19-6"><a href="#cb19-6"></a></span>
<span id="cb19-7"><a href="#cb19-7"></a>        <span class="co"># Update weights &amp; biases to make this batch's predictions better.</span></span>
<span id="cb19-8"><a href="#cb19-8"></a>        model.train_on_batch(X_batch_train, y_batch_train)</span>
<span id="cb19-9"><a href="#cb19-9"></a></span>
<span id="cb19-10"><a href="#cb19-10"></a><span class="bu">print</span>(same_last_layer(firstModel, model))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="what-is-model.fit-really-doing" class="slide level2">
<h2>What is <code>model.fit()</code> really doing?</h2>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a><span class="op">%%</span>time</span>
<span id="cb21-2"><a href="#cb21-2"></a>model <span class="op">=</span> build_model() <span class="co"># No model.compile!</span></span>
<span id="cb21-3"><a href="#cb21-3"></a></span>
<span id="cb21-4"><a href="#cb21-4"></a><span class="co"># Go through all the training data multiple times.</span></span>
<span id="cb21-5"><a href="#cb21-5"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb21-6"><a href="#cb21-6"></a>    <span class="co"># Go through the entire training dataset in batches.</span></span>
<span id="cb21-7"><a href="#cb21-7"></a>    <span class="cf">for</span> (X_batch_train, y_batch_train) <span class="kw">in</span> train_dataset:</span>
<span id="cb21-8"><a href="#cb21-8"></a>        <span class="co"># Calculate the loss, while keeping track of gradients.</span></span>
<span id="cb21-9"><a href="#cb21-9"></a>        <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb21-10"><a href="#cb21-10"></a>            y_pred <span class="op">=</span> model(X_batch_train, training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-11"><a href="#cb21-11"></a>            loss_value <span class="op">=</span> loss_fn(y_batch_train, y_pred)</span>
<span id="cb21-12"><a href="#cb21-12"></a></span>
<span id="cb21-13"><a href="#cb21-13"></a>        <span class="co"># Calculate the gradients &amp; take a SGD step.</span></span>
<span id="cb21-14"><a href="#cb21-14"></a>        grads <span class="op">=</span> tape.gradient(loss_value, model.trainable_weights)</span>
<span id="cb21-15"><a href="#cb21-15"></a>        optimizer.apply_gradients(<span class="bu">zip</span>(grads, model.trainable_weights))</span>
<span id="cb21-16"><a href="#cb21-16"></a></span>
<span id="cb21-17"><a href="#cb21-17"></a><span class="bu">print</span>(same_last_layer(firstModel, model))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True
CPU times: user 3.56 s, sys: 331 ms, total: 3.89 s
Wall time: 3.01 s</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="what-about-optimizer-stuff" class="slide level2">
<h2>What about <code>optimizer</code> stuff?</h2>
<p><span class="math display">\[
\boldsymbol{\theta}_i = \boldsymbol{\theta}_{i-1} - \eta \nabla \text{LossOnBatch} \\
\]</span></p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb23-2"><a href="#cb23-2"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb23-3"><a href="#cb23-3"></a>    <span class="cf">for</span> (X_batch_train, y_batch_train) <span class="kw">in</span> train_dataset:</span>
<span id="cb23-4"><a href="#cb23-4"></a>        <span class="co"># Calculate the loss, while keeping track of gradients.</span></span>
<span id="cb23-5"><a href="#cb23-5"></a>        <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb23-6"><a href="#cb23-6"></a>            y_pred <span class="op">=</span> model(X_batch_train, training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-7"><a href="#cb23-7"></a>            loss_value <span class="op">=</span> loss_fn(y_batch_train, y_pred)</span>
<span id="cb23-8"><a href="#cb23-8"></a></span>
<span id="cb23-9"><a href="#cb23-9"></a>        <span class="co"># Calculate the gradients &amp; take a SGD step.</span></span>
<span id="cb23-10"><a href="#cb23-10"></a>        grads <span class="op">=</span> tape.gradient(loss_value, model.trainable_weights)</span>
<span id="cb23-11"><a href="#cb23-11"></a>        <span class="cf">for</span> grad, weight <span class="kw">in</span> <span class="bu">zip</span>(grads, model.trainable_weights):</span>
<span id="cb23-12"><a href="#cb23-12"></a>            <span class="co"># Take a small negative step in the direction of the gradient.</span></span>
<span id="cb23-13"><a href="#cb23-13"></a>            weight.assign(weight <span class="op">-</span> lr <span class="op">*</span> grad) </span>
<span id="cb23-14"><a href="#cb23-14"></a></span>
<span id="cb23-15"><a href="#cb23-15"></a><span class="bu">print</span>(same_last_layer(firstModel, model))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="inspecting-the-gradients" class="slide level2">
<h2>Inspecting the gradients</h2>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a>grads</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>[&lt;tf.Tensor: shape=(784, 128), dtype=float32, numpy=
 array([[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)&gt;,
 &lt;tf.Tensor: shape=(128,), dtype=float32, numpy=
 array([ 3.0360e-02, -3.0921e-02,  1.2238e-02,  1.7940e-03,  1.3904e-02,
         1.9477e-03,  3.3881e-02,  2.9056e-02,  2.5945e-02,  4.2920e-02,
         1.7383e-02, -3.8926e-02,  2.5133e-02, -3.1567e-03, -1.0122e-02,
        -1.1740e-02,  9.4486e-03, -2.3212e-02, -3.2686e-03,  2.9088e-03,
         7.8852e-03,  9.4453e-03, -1.7209e-02, -1.6564e-02, -2.1614e-02,
         4.4864e-02,  0.0000e+00,  4.2568e-02, -1.6856e-02,  0.0000e+00,
         1.7898e-02,  1.2590e-02, -4.1752e-02,  4.2497e-02,  5.1698e-02,
         1.3341e-02, -1.1867e-02, -1.2916e-02, -2.9950e-03,  2.5390e-02,
        -1.5389e-02, -2.0011e-02, -4.7447e-03,  7.1656e-03,  2.9904e-02,
        -3.9028e-02,  2.4499e-02, -1.8957e-02,  7.0073e-02, -4.6733e-03,
        -6.2825e-02, -1.1439e-02,  2.7188e-03, -3.5783e-02, -6.5961e-03,
        -2.5142e-02,  0.0000e+00,  1.2887e-02, -3.5036e-02,  6.9635e-02,
         2.0950e-02,  4.1346e-02, -2.3510e-02,  1.2610e-02,  6.8104e-03,
         0.0000e+00,  4.1232e-03, -3.6927e-04,  2.8907e-03, -2.5114e-02,
        -1.6823e-02, -9.1659e-03, -3.2145e-04,  1.1823e-02,  4.5568e-03,
         2.0118e-02,  3.6144e-02,  2.1522e-02, -6.2480e-04, -1.0185e-02,
        -3.9899e-03,  3.2229e-02, -2.8387e-02, -2.4063e-02,  3.9055e-02,
         8.1349e-03,  0.0000e+00,  2.1982e-03,  6.5691e-03,  1.1468e-02,
        -7.3067e-02, -3.5447e-02,  4.1712e-02,  0.0000e+00,  0.0000e+00,
        -1.2898e-02, -7.6021e-02, -4.8762e-03, -2.2640e-03, -5.4343e-03,
        -1.4178e-02, -5.3009e-02,  5.9933e-03, -1.6995e-02, -7.1337e-03,
        -2.4793e-02,  3.4487e-03,  8.7715e-03,  4.2343e-03, -7.9992e-03,
        -3.0582e-02,  6.7091e-03, -2.3130e-02, -6.9053e-05,  8.7078e-03,
        -6.9982e-03, -2.4844e-04, -1.1759e-03,  2.2047e-02,  3.2849e-02,
         4.1823e-02,  7.4070e-02,  3.9271e-02, -9.8804e-03,  0.0000e+00,
        -3.4394e-03,  3.5277e-02,  3.6637e-02], dtype=float32)&gt;,
 &lt;tf.Tensor: shape=(128, 10), dtype=float32, numpy=
 array([[-8.2953e-02,  1.1690e-03,  1.3262e-01, ...,  4.3149e-03,
          3.7797e-02,  1.9627e-02],
        [-3.4308e-02,  2.3726e-03,  5.8461e-02, ...,  2.9720e-03,
          8.9332e-03,  4.8369e-03],
        [-8.2968e-02,  3.7370e-03,  6.4873e-02, ...,  1.1627e-04,
         -4.0694e-03,  1.1197e-02],
        ...,
        [-3.3582e-02,  2.2347e-03,  2.7756e-02, ..., -1.9675e-03,
         -9.1139e-03,  1.4606e-02],
        [-7.5606e-02,  4.6353e-03,  3.9845e-02, ...,  2.5930e-03,
         -1.5467e-02,  1.3436e-02],
        [-1.0268e-01,  5.5425e-03,  1.1661e-01, ...,  2.8978e-03,
         -1.6526e-02,  2.3900e-02]], dtype=float32)&gt;,
 &lt;tf.Tensor: shape=(10,), dtype=float32, numpy=
 array([-0.0911,  0.0039,  0.0746, -0.0119, -0.0295, -0.0706,  0.1077,
         0.0018, -0.0024,  0.0175], dtype=float32)&gt;]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a>[np.mean(np.<span class="bu">abs</span>(grad.numpy())) <span class="cf">for</span> grad <span class="kw">in</span> grads]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>[0.003485533, 0.01930479, 0.029289845, 0.041103397]</code></pre>
</div>
</div>
</section>
<section id="calculating-training-losses" class="slide level2">
<h2>Calculating training losses</h2>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a>firstFit.history[<span class="st">"loss"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>[0.973278820514679, 0.455027312040329]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb31-2"><a href="#cb31-2"></a></span>
<span id="cb31-3"><a href="#cb31-3"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb31-4"><a href="#cb31-4"></a>    loss_history <span class="op">=</span> []</span>
<span id="cb31-5"><a href="#cb31-5"></a>    <span class="cf">for</span> (X_batch_train, y_batch_train) <span class="kw">in</span> train_dataset:</span>
<span id="cb31-6"><a href="#cb31-6"></a>        <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb31-7"><a href="#cb31-7"></a>            y_pred <span class="op">=</span> model(X_batch_train, training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb31-8"><a href="#cb31-8"></a>            loss_value <span class="op">=</span> loss_fn(y_batch_train, y_pred)</span>
<span id="cb31-9"><a href="#cb31-9"></a>            loss_history.append(loss_value.numpy())</span>
<span id="cb31-10"><a href="#cb31-10"></a></span>
<span id="cb31-11"><a href="#cb31-11"></a>        grads <span class="op">=</span> tape.gradient(loss_value, model.trainable_weights)</span>
<span id="cb31-12"><a href="#cb31-12"></a>        optimizer.apply_gradients(<span class="bu">zip</span>(grads, model.trainable_weights))</span>
<span id="cb31-13"><a href="#cb31-13"></a></span>
<span id="cb31-14"><a href="#cb31-14"></a>    <span class="bu">print</span>(<span class="ss">f"[Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">] Loss avg </span><span class="sc">{</span>np<span class="sc">.</span>mean(loss_history)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Epoch 0] Loss avg 0.9733172059059143</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[Epoch 1] Loss avg 0.4553719162940979</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="calculating-validation-losses" class="slide level2">
<h2>Calculating validation losses</h2>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1"></a>firstFit.history[<span class="st">"val_loss"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>[0.48505955934524536, 0.3652433753013611]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb36-2"><a href="#cb36-2"></a>model.<span class="bu">compile</span>(optimizer, loss_fn)</span>
<span id="cb36-3"><a href="#cb36-3"></a></span>
<span id="cb36-4"><a href="#cb36-4"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb36-5"><a href="#cb36-5"></a>    model.fit(train_dataset, epochs<span class="op">=</span><span class="dv">1</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb36-6"><a href="#cb36-6"></a></span>
<span id="cb36-7"><a href="#cb36-7"></a>    val_losses <span class="op">=</span> []</span>
<span id="cb36-8"><a href="#cb36-8"></a>    <span class="cf">for</span> (X_batch_val, y_batch_val) <span class="kw">in</span> val_dataset:</span>
<span id="cb36-9"><a href="#cb36-9"></a>        y_pred <span class="op">=</span> model(X_batch_val)</span>
<span id="cb36-10"><a href="#cb36-10"></a>        val_losses.append(loss_fn(y_batch_val, y_pred))</span>
<span id="cb36-11"><a href="#cb36-11"></a></span>
<span id="cb36-12"><a href="#cb36-12"></a>    <span class="bu">print</span>(<span class="ss">f"[Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">] Val loss avg </span><span class="sc">{</span>np<span class="sc">.</span>mean(val_losses)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Epoch 0] Val loss avg 0.48449423909187317</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[Epoch 1] Val loss avg 0.3643719255924225</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="comparable-training-val.-losses" class="slide level2">
<h2>Comparable training &amp; val. losses</h2>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1"></a><span class="bu">print</span>(firstFit.history[<span class="st">"loss"</span>])</span>
<span id="cb39-2"><a href="#cb39-2"></a><span class="bu">print</span>(firstFit.history[<span class="st">"val_loss"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.973278820514679, 0.455027312040329]
[0.48505955934524536, 0.3652433753013611]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb41-2"><a href="#cb41-2"></a>model.<span class="bu">compile</span>(optimizer, loss_fn)</span>
<span id="cb41-3"><a href="#cb41-3"></a></span>
<span id="cb41-4"><a href="#cb41-4"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb41-5"><a href="#cb41-5"></a>    model.fit(train_dataset, epochs<span class="op">=</span><span class="dv">1</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb41-6"><a href="#cb41-6"></a></span>
<span id="cb41-7"><a href="#cb41-7"></a>    <span class="co"># Now the epoch is over and the model isn't being updated,</span></span>
<span id="cb41-8"><a href="#cb41-8"></a>    <span class="co"># calculate the losses on train and validation data.</span></span>
<span id="cb41-9"><a href="#cb41-9"></a>    train_loss <span class="op">=</span> model.evaluate(train_dataset, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb41-10"><a href="#cb41-10"></a>    val_loss <span class="op">=</span> model.evaluate(val_dataset, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb41-11"><a href="#cb41-11"></a>    <span class="bu">print</span>(<span class="ss">f"[Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">] Train loss </span><span class="sc">{</span>train_loss<span class="sc">}</span><span class="ss"> Val loss </span><span class="sc">{</span>val_loss<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Epoch 0] Train loss 0.53240567445755 Val loss 0.48505955934524536</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[Epoch 1] Train loss 0.4036087989807129 Val loss 0.3652433753013611</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="how-to-use-losses" class="slide level2">
<h2>How to use losses</h2>
<p>A common strategy is to:</p>
<ol type="1">
<li>Keep fitting bigger and bigger models until training error is <span class="math inline">\(\approx 0\)</span>. <em>This will likely produce a huge error on the validation set, called generalisation error, due to overfitting</em>.</li>
<li>Apply regularisation/dropout/early stopping to reduce the generalisation error.</li>
<li>Watch out for <em>overfitting the validation set</em> by looking at the test loss.</li>
</ol>
</section>
<section id="what-is-this-with-syntax" class="slide level2">
<h2>What is this <code>with</code> syntax?</h2>
<p>Example, opening a file:</p>
<div class="columns">
<div class="column">
<p>Most basic way is:</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1"></a>f <span class="op">=</span> <span class="bu">open</span>(<span class="st">"haiku1.txt"</span>, <span class="st">"r"</span>)</span>
<span id="cb44-2"><a href="#cb44-2"></a><span class="bu">print</span>(f.read())</span>
<span id="cb44-3"><a href="#cb44-3"></a>f.close()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Chaos reigns within.
Reflect, repent, and reboot.
Order shall return.</code></pre>
</div>
</div>
</div><div class="column">
<p>Instead, use:</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">"haiku2.txt"</span>, <span class="st">"r"</span>) <span class="im">as</span> f:</span>
<span id="cb46-2"><a href="#cb46-2"></a>    <span class="bu">print</span>(f.read())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The Web site you seek
Cannot be located, but
Countless more exist.</code></pre>
</div>
</div>
</div>
</div>
<div class="footer">
<p>Haikus from http://www.libertybasicuniversity.com/lbnews/nl107/haiku.htm</p>
</div>
</section>
<section id="what-is-gradienttape" class="slide level2">
<h2>What is <code>GradientTape()</code>?</h2>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1"></a>x <span class="op">=</span> tf.Variable(<span class="fl">3.0</span>)</span>
<span id="cb48-2"><a href="#cb48-2"></a></span>
<span id="cb48-3"><a href="#cb48-3"></a><span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb48-4"><a href="#cb48-4"></a>  y <span class="op">=</span> x<span class="op">**</span><span class="dv">2</span></span>
<span id="cb48-5"><a href="#cb48-5"></a></span>
<span id="cb48-6"><a href="#cb48-6"></a>dy_dx <span class="op">=</span> tape.gradient(y, x)</span>
<span id="cb48-7"><a href="#cb48-7"></a>dy_dx.numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>6.0</code></pre>
</div>
</div>
<div class="footer">
<p>Source: Tensorflow (2022), <a href="https://www.tensorflow.org/guide/autodiff">Introduction to gradients and automatic differentiation</a>, Tensorflow docs.</p>
</div>
</section></section>
<section>
<section id="computation-graphs-automatic-differentiation" class="title-slide slide level1 center" data-background-image="unsw-yellow-shape.png" data-visibility="uncounted">
<h1>Computation Graphs &amp; Automatic Differentiation</h1>

</section>
<section id="compile-using-graph-mode" class="slide level2">
<h2>Compile using graph mode</h2>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb50-2"><a href="#cb50-2"></a></span>
<span id="cb50-3"><a href="#cb50-3"></a><span class="at">@tf.function</span></span>
<span id="cb50-4"><a href="#cb50-4"></a><span class="kw">def</span> train_step(X, y):</span>
<span id="cb50-5"><a href="#cb50-5"></a>    <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb50-6"><a href="#cb50-6"></a>        y_pred <span class="op">=</span> model(X, training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb50-7"><a href="#cb50-7"></a>        loss_value <span class="op">=</span> loss_fn(y, y_pred)</span>
<span id="cb50-8"><a href="#cb50-8"></a>    grads <span class="op">=</span> tape.gradient(loss_value, model.trainable_weights)</span>
<span id="cb50-9"><a href="#cb50-9"></a>    optimizer.apply_gradients(<span class="bu">zip</span>(grads, model.trainable_weights))</span>
<span id="cb50-10"><a href="#cb50-10"></a>    <span class="cf">return</span> loss_value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1"></a><span class="op">%%</span>time</span>
<span id="cb51-2"><a href="#cb51-2"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb51-3"><a href="#cb51-3"></a>    <span class="cf">for</span> (X_batch_train, y_batch_train) <span class="kw">in</span> train_dataset:</span>
<span id="cb51-4"><a href="#cb51-4"></a>        loss_value <span class="op">=</span> train_step(X_batch_train, y_batch_train)</span>
<span id="cb51-5"><a href="#cb51-5"></a><span class="bu">print</span>(same_last_layer(firstModel, model))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True
CPU times: user 1.59 s, sys: 312 ms, total: 1.9 s
Wall time: 992 ms</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="example-computational-graph" class="slide level2">
<h2>Example computational graph</h2>

<img data-src="Geron-mlst_0901-blur.png" class="r-stretch quarto-figure-center"><p class="caption">Each basic equation is broken down to its core components.</p><div class="footer">
<p>Source: Aurélien Géron (2017), <em>Hands-On Machine Learning with Scikit-Learn &amp; TensorFlow</em>, 1st Edition, Figure 9.1 (<strong>redacted</strong>).</p>
</div>
</section>
<section id="why" class="slide level2">
<h2>Why?</h2>

<img data-src="Geron-mlst_0902-blur.png" class="r-stretch quarto-figure-center"><p class="caption">Tensorflow figures out the smartest way to evaluate your equations.</p><div class="footer">
<p>Source: Aurélien Géron (2017), <em>Hands-On Machine Learning with Scikit-Learn &amp; TensorFlow</em>, 1st Edition, Figure 9.2 (<strong>redacted</strong>).</p>
</div>
</section>
<section id="example-linear-regression" class="slide level2">
<h2>Example: linear regression</h2>
<p><span class="math display">\[
\hat{y}(x) = w x + b
\]</span></p>
<p>For some observation <span class="math inline">\(\{ x_i, y_i \}\)</span>, the (MSE) loss is</p>
<p><span class="math display">\[
\text{Loss}_i = (\hat{y}(x_i) - y_i)^2
\]</span></p>
<p>For a batch of the first <span class="math inline">\(n\)</span> observations the loss is</p>
<p><span class="math display">\[
\text{Loss}_{1:n} = \frac{1}{n} \sum_{i=1}^n (\hat{y}(x_i) - y_i)^2
\]</span></p>
</section>
<section id="derivatives" class="slide level2">
<h2>Derivatives</h2>
<p>Since <span class="math inline">\(\hat{y}(x) = w x + b\)</span>,</p>
<p><span class="math display">\[
\frac{\partial \hat{y}(x)}{\partial w} = x \text{ and }
\frac{\partial \hat{y}(x)}{\partial b} = 1 .
\]</span></p>
<p>As <span class="math inline">\(\text{Loss}_i = (\hat{y}(x_i) - y_i)^2\)</span>, we know <span class="math display">\[
\frac{\partial \text{Loss}_i}{\partial \hat{y}(x_i) } = 2 (\hat{y}(x_i) - y_i) .
\]</span></p>
</section>
<section id="chain-rule" class="slide level2">
<h2>Chain rule</h2>
<p><span class="math display">\[
\frac{\partial \text{Loss}_i}{\partial \hat{y}(x_i) } = 2 (\hat{y}(x_i) - y_i), \,\,
\frac{\partial \hat{y}(x)}{\partial w} = x , \, \text{ and } \,
\frac{\partial \hat{y}(x)}{\partial b} = 1 .
\]</span></p>
<p>Putting this together, we have</p>
<p><span class="math display">\[
\frac{\partial \text{Loss}_i}{\partial w}
= \frac{\partial \text{Loss}_i}{\partial \hat{y}(x_i) }
  \times \frac{\partial \hat{y}(x_i)}{\partial w}
= 2 (\hat{y}(x_i) - y_i) \, x_i
\]</span></p>
<p>and <span class="math display">\[
\frac{\partial \text{Loss}_i}{\partial b}
= \frac{\partial \text{Loss}_i}{\partial \hat{y}(x_i) }
  \times \frac{\partial \hat{y}(x_i)}{\partial b}
= 2 (\hat{y}(x_i) - y_i) .
\]</span></p>
</section>
<section id="backpropagation" class="slide level2">
<h2>Backpropagation</h2>
<div class="columns">
<div class="column">
<iframe width="560" height="560" src="https://www.youtube.com/embed/Ilg3gGewQ5U" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</div><div class="column">
<iframe width="560" height="560" src="https://www.youtube.com/embed/tIeHLnjs5U8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</div>
</div>
</section>
<section id="linear-regression-graph" class="slide level2">
<h2>Linear regression graph</h2>
<p><br></p>
<div class="cell" data-reveal="true" data-fig-width="10">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-1">%%{init: {'themeVariables': {'edgeLabelBackground': 'white', 'fontSize': '25px'}}}%%
graph LR
    x[x]:::data --&gt; times(( &lt;sup&gt;.&lt;/sup&gt; ))
    w[w]:::param --&gt; times
    times --&gt;|z| plus(( + ))
    b[b]:::param --&gt; plus
    plus --&gt;|yp| minus(( - ))
    y[y]:::data --&gt; minus
    minus --&gt; loss[loss]
    
    classDef data fill:aqua,stroke-width:0px
    classDef param fill:lightGreen,stroke-width:0px
    style loss fill:white,stroke-width:0px
</pre>
<div id="mermaid-tooltip-1" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="forward-pass" class="slide level2">
<h2>Forward pass</h2>
<p><br><br></p>
<div class="cell" data-reveal="true" data-fig-width="10">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-2">%%{init: {'themeVariables': { 'edgeLabelBackground': 'white', 'fontSize': '25px'}}}%%
graph LR
    x[x = 2]:::data --&gt; times(( &lt;sup&gt;.&lt;/sup&gt; ))
    w[w = 3]:::param --&gt; times
    times --&gt;|z = 6| plus(( + ))
    b[b = 1]:::param --&gt; plus
    plus --&gt;|yp = 7| minus(( - ))
    y[y = 4]:::data --&gt; minus
    minus --&gt; loss[loss = 3]
    
    classDef data fill:aqua,stroke-width:0px
    classDef param fill:lightGreen,stroke-width:0px
    style loss fill:white,stroke-width:0px
</pre>
<div id="mermaid-tooltip-2" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="backward-pass" class="slide level2">
<h2>Backward pass</h2>
<div class="cell" data-reveal="true" data-fig-width="10">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-3">%%{init: {'themeVariables': { 'edgeLabelBackground': 'white', 'fontSize': '25px'}}}%%
graph LR
    x[x = 2]:::data --- times(( &lt;sup&gt;.&lt;/sup&gt; ))
    w[w = 3]:::param ---|"grad(z, w) = 2"| times
    times ---|"z=6&lt;br&gt;grad(yp, z) = 1"| plus(( + ))
    b[b = 1]:::param ---|"grad(yp, b) = 1"| plus
    plus ---|"yp = 7&lt;br&gt;grad(loss, yp) = 1"| minus(( - ))
    y[y = 4]:::data --- minus
    minus --- loss[loss = 3]
    
    classDef data fill:aqua,stroke-width:0px
    classDef param fill:lightGreen,stroke-width:0px
    style loss fill:white,stroke-width:0px
</pre>
<div id="mermaid-tooltip-3" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
<div class="fragment">
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1"></a>x <span class="op">=</span> tf.constant(<span class="fl">2.0</span>)<span class="op">;</span> y <span class="op">=</span> tf.constant(<span class="fl">4.0</span>)</span>
<span id="cb53-2"><a href="#cb53-2"></a>w <span class="op">=</span> tf.Variable(<span class="fl">3.0</span>)<span class="op">;</span> b <span class="op">=</span> tf.Variable(<span class="fl">1.0</span>)</span>
<span id="cb53-3"><a href="#cb53-3"></a><span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb53-4"><a href="#cb53-4"></a>  yp <span class="op">=</span> w<span class="op">*</span>x <span class="op">+</span> b</span>
<span id="cb53-5"><a href="#cb53-5"></a>  loss <span class="op">=</span> tf.<span class="bu">abs</span>(yp <span class="op">-</span> y)</span>
<span id="cb53-6"><a href="#cb53-6"></a>tape.gradient(loss, [w, b])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>[&lt;tf.Tensor: shape=(), dtype=float32, numpy=2.0&gt;,
 &lt;tf.Tensor: shape=(), dtype=float32, numpy=1.0&gt;]</code></pre>
</div>
</div>
</div>
</section>
<section id="thats-it" class="slide level2">
<h2>That’s it</h2>
<blockquote>
<p>And with that, you just saw backpropagation in action! Backpropagation is simply the application of the chain rule to a computation graph. There’s nothing more to it. Backpropagation starts with the final loss value and works backward from the top layers to the bottom layers, computing the contribution that each parameter had in the loss value. That’s where the name “backpropagation” comes from: we “back propagate” the loss contributions of different nodes in a computation graph.</p>
</blockquote>
<div class="footer">
<p>Source: François Chollet (2021), <em>Deep Learning with Python</em>, Second Edition, Chapter 2.</p>
</div>
</section>
<section id="batch-gradient-descent" class="slide level2">
<h2>Batch gradient descent</h2>
<p>For the first <span class="math inline">\(n\)</span> observations <span class="math inline">\(\text{Loss}_{1:n} = \frac{1}{n} \sum_{i=1}^n \text{Loss}_i\)</span> so</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial \text{Loss}_{1:n}}{\partial w}
&amp;= \frac{1}{n} \sum_{i=1}^n \frac{\partial \text{Loss}_{i}}{\partial w}
= \frac{1}{n} \sum_{i=1}^n \frac{\partial \text{Loss}_{i}}{\hat{y}(x_i)} \frac{\partial \hat{y}(x_i)}{\partial w} \\
&amp;= \frac{1}{n} \sum_{i=1}^n 2 (\hat{y}(x_i) - y_i) \, x_i .
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial \text{Loss}_{1:n}}{\partial b}
&amp;= \frac{1}{n} \sum_{i=1}^n \frac{\partial \text{Loss}_{i}}{\partial b}
= \frac{1}{n} \sum_{i=1}^n \frac{\partial \text{Loss}_{i}}{\hat{y}(x_i)} \frac{\partial \hat{y}(x_i)}{\partial b} \\
&amp;= \frac{1}{n} \sum_{i=1}^n 2 (\hat{y}(x_i) - y_i) .
\end{aligned}
\]</span></p>
</section>
<section id="bespoke-derivatives-vs.-autodiff" class="slide level2">
<h2>Bespoke derivatives vs.&nbsp;autodiff</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1"></a>w <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> b <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb55-2"><a href="#cb55-2"></a>y_pred <span class="op">=</span> w <span class="op">*</span> x <span class="op">+</span> b</span>
<span id="cb55-3"><a href="#cb55-3"></a>loss <span class="op">=</span> (y_pred <span class="op">-</span> y) <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb55-4"><a href="#cb55-4"></a></span>
<span id="cb55-5"><a href="#cb55-5"></a>dL_dw <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (y_pred <span class="op">-</span> y) <span class="op">*</span> x</span>
<span id="cb55-6"><a href="#cb55-6"></a>dL_db <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (y_pred <span class="op">-</span> y)</span>
<span id="cb55-7"><a href="#cb55-7"></a></span>
<span id="cb55-8"><a href="#cb55-8"></a>nabla <span class="op">=</span> [dL_dw.mean(), dL_db.mean()]</span>
<span id="cb55-9"><a href="#cb55-9"></a><span class="bu">print</span>(np.array(nabla))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[-14.6942  -6.005 ]</code></pre>
</div>
</div>
</div><div class="column" style="width:40%;">
<div class="cell" data-execution_count="32">
<div class="cell-output cell-output-display" data-execution_count="32">

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
      <th>dL/dw</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>0.99</td>
      <td>-1.98</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>3.00</td>
      <td>-12.02</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.0</td>
      <td>5.01</td>
      <td>-30.09</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1"></a>w <span class="op">=</span> tf.Variable(<span class="fl">0.0</span>)<span class="op">;</span> b <span class="op">=</span> tf.Variable(<span class="fl">0.0</span>)</span>
<span id="cb57-2"><a href="#cb57-2"></a>x <span class="op">=</span> tf.constant(x)<span class="op">;</span> y <span class="op">=</span> tf.constant(y)</span>
<span id="cb57-3"><a href="#cb57-3"></a></span>
<span id="cb57-4"><a href="#cb57-4"></a><span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb57-5"><a href="#cb57-5"></a>  y_pred <span class="op">=</span> w <span class="op">*</span> x <span class="op">+</span> b</span>
<span id="cb57-6"><a href="#cb57-6"></a>  loss <span class="op">=</span> tf.reduce_mean((y_pred <span class="op">-</span> y) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb57-7"><a href="#cb57-7"></a></span>
<span id="cb57-8"><a href="#cb57-8"></a>dL_dw, dL_db <span class="op">=</span> tape.gradient(loss, [w, b])</span>
<span id="cb57-9"><a href="#cb57-9"></a><span class="bu">print</span>(np.array([dL_dw, dL_db]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[-14.6942  -6.005 ]</code></pre>
</div>
</div>
</section>
<section id="the-magic-of-autodiff" class="slide level2">
<h2>The magic of autodiff</h2>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1"></a><span class="im">from</span> tensorflow.keras.metrics <span class="im">import</span> mean_squared_error <span class="im">as</span> mse</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="columns">
<div class="column">
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1"></a><span class="op">%%</span>timeit</span>
<span id="cb60-2"><a href="#cb60-2"></a>y_pred <span class="op">=</span> w<span class="op">*</span>x <span class="op">+</span> b</span>
<span id="cb60-3"><a href="#cb60-3"></a>res <span class="op">=</span> y_pred <span class="op">-</span> y</span>
<span id="cb60-4"><a href="#cb60-4"></a>dL_db <span class="op">=</span> tf.reduce_mean(<span class="dv">2</span><span class="op">*</span>res)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>63.2 ms ± 364 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1"></a><span class="op">%%</span>timeit</span>
<span id="cb62-2"><a href="#cb62-2"></a><span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb62-3"><a href="#cb62-3"></a>  loss <span class="op">=</span> mse(y, w<span class="op">*</span>x <span class="op">+</span> b)</span>
<span id="cb62-4"><a href="#cb62-4"></a>tape.gradient(loss, b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>163 ms ± 414 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</div><div class="column">
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1"></a><span class="op">%%</span>timeit</span>
<span id="cb64-2"><a href="#cb64-2"></a>res <span class="op">=</span> (w<span class="op">*</span>x <span class="op">+</span> b) <span class="op">-</span> y</span>
<span id="cb64-3"><a href="#cb64-3"></a>dL_dw <span class="op">=</span> tf.reduce_mean(<span class="dv">2</span><span class="op">*</span>res<span class="op">*</span>x)</span>
<span id="cb64-4"><a href="#cb64-4"></a>dL_db <span class="op">=</span> tf.reduce_mean(<span class="dv">2</span><span class="op">*</span>res)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>98.9 ms ± 1.39 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1"></a><span class="op">%%</span>timeit</span>
<span id="cb66-2"><a href="#cb66-2"></a><span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb66-3"><a href="#cb66-3"></a>  loss <span class="op">=</span> mse(y, w<span class="op">*</span>x <span class="op">+</span> b)</span>
<span id="cb66-4"><a href="#cb66-4"></a>tape.gradient(loss, [w, b])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>163 ms ± 242 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="object-oriented-programming" class="title-slide slide level1 center" data-background-image="unsw-yellow-shape.png" data-visibility="uncounted">
<h1>Object-oriented programming</h1>

</section>
<section id="remember-this-class" class="slide level2">
<h2>Remember this class?</h2>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1"></a>COURSE_CREDITS <span class="op">=</span> {<span class="st">"ACTL3143"</span>: <span class="dv">6</span>, <span class="st">"ACTL5001"</span>: <span class="dv">12</span>}</span>
<span id="cb68-2"><a href="#cb68-2"></a></span>
<span id="cb68-3"><a href="#cb68-3"></a><span class="kw">class</span> Student:</span>
<span id="cb68-4"><a href="#cb68-4"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, name, zID, grades):</span>
<span id="cb68-5"><a href="#cb68-5"></a>    <span class="va">self</span>.name <span class="op">=</span> name</span>
<span id="cb68-6"><a href="#cb68-6"></a>    <span class="va">self</span>.zID <span class="op">=</span> zID</span>
<span id="cb68-7"><a href="#cb68-7"></a>    <span class="va">self</span>.grades <span class="op">=</span> grades</span>
<span id="cb68-8"><a href="#cb68-8"></a></span>
<span id="cb68-9"><a href="#cb68-9"></a>  <span class="kw">def</span> wam(<span class="va">self</span>):</span>
<span id="cb68-10"><a href="#cb68-10"></a>    <span class="co">"""</span></span>
<span id="cb68-11"><a href="#cb68-11"></a><span class="co">    Calculate the weighted average mark for this student.</span></span>
<span id="cb68-12"><a href="#cb68-12"></a><span class="co">    """</span></span>
<span id="cb68-13"><a href="#cb68-13"></a>    total_credits <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb68-14"><a href="#cb68-14"></a>    total_grade <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb68-15"><a href="#cb68-15"></a>    <span class="cf">for</span> course, grade <span class="kw">in</span> <span class="va">self</span>.grades.items():</span>
<span id="cb68-16"><a href="#cb68-16"></a>      total_credits <span class="op">+=</span> COURSE_CREDITS[course]</span>
<span id="cb68-17"><a href="#cb68-17"></a>      total_grade <span class="op">+=</span> grade <span class="op">*</span> COURSE_CREDITS[course]</span>
<span id="cb68-18"><a href="#cb68-18"></a>    <span class="cf">return</span> total_grade <span class="op">/</span> total_credits</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="calling-the-wam-method" class="slide level2">
<h2>Calling the <code>wam</code> method</h2>
<p>Now every student object can calculate its own WAM.</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1"></a>don <span class="op">=</span> Student(<span class="st">"Don Quixote"</span>, <span class="dv">111222</span>,</span>
<span id="cb69-2"><a href="#cb69-2"></a>    {<span class="st">"ACTL3143"</span>: <span class="dv">100</span>, <span class="st">"ACTL5001"</span>: <span class="dv">50</span>})</span>
<span id="cb69-3"><a href="#cb69-3"></a></span>
<span id="cb69-4"><a href="#cb69-4"></a>zhuge <span class="op">=</span> Student(<span class="st">"Zhuge Liang"</span>, <span class="dv">123456</span>, </span>
<span id="cb69-5"><a href="#cb69-5"></a>    {<span class="st">"ACTL3143"</span>: <span class="dv">100</span>, <span class="st">"ACTL5001"</span>: <span class="dv">100</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1"></a>don.wam()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>66.66666666666667</code></pre>
</div>
</div>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1"></a>zhuge.wam()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>100.0</code></pre>
</div>
</div>
</section>
<section id="customising-an-existing-class" class="slide level2">
<h2>Customising an existing class</h2>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1"></a><span class="kw">class</span> PhDStudent(Student):</span>
<span id="cb74-2"><a href="#cb74-2"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, name, zID, grades, supervisor):</span>
<span id="cb74-3"><a href="#cb74-3"></a>    <span class="bu">super</span>().<span class="fu">__init__</span>(name, zID, grades)</span>
<span id="cb74-4"><a href="#cb74-4"></a>    <span class="va">self</span>.supervisor <span class="op">=</span> supervisor</span>
<span id="cb74-5"><a href="#cb74-5"></a>    <span class="va">self</span>.timeTillGraduation <span class="op">=</span> np.inf</span>
<span id="cb74-6"><a href="#cb74-6"></a>    <span class="va">self</span>.chanceToFindFreeFood <span class="op">=</span> <span class="fl">0.999</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1"></a>mei <span class="op">=</span> PhDStudent(<span class="st">"Mei Changsu"</span>, <span class="dv">123456</span>, </span>
<span id="cb75-2"><a href="#cb75-2"></a>    {<span class="st">"ACTL3143"</span>: <span class="dv">100</span>, <span class="st">"ACTL5001"</span>: <span class="dv">100</span>},</span>
<span id="cb75-3"><a href="#cb75-3"></a>    <span class="st">"Lin Chen"</span>)</span>
<span id="cb75-4"><a href="#cb75-4"></a></span>
<span id="cb75-5"><a href="#cb75-5"></a>mei.supervisor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>'Lin Chen'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1"></a>mei.wam()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>100.0</code></pre>
</div>
</div>
</section>
<section id="example-monte-carlo-dropout" class="slide level2">
<h2>Example: Monte Carlo dropout</h2>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1"></a>tf.random.set_seed(<span class="dv">42</span>)</span>
<span id="cb79-2"><a href="#cb79-2"></a>model <span class="op">=</span> keras.Sequential([</span>
<span id="cb79-3"><a href="#cb79-3"></a>    layers.Flatten(input_shape<span class="op">=</span>[<span class="dv">28</span>, <span class="dv">28</span>]),</span>
<span id="cb79-4"><a href="#cb79-4"></a>    layers.Dropout(rate<span class="op">=</span><span class="fl">0.2</span>),</span>
<span id="cb79-5"><a href="#cb79-5"></a>    layers.Dense(<span class="dv">300</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb79-6"><a href="#cb79-6"></a>    layers.Dropout(rate<span class="op">=</span><span class="fl">0.2</span>),</span>
<span id="cb79-7"><a href="#cb79-7"></a>    layers.Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb79-8"><a href="#cb79-8"></a>    layers.Dropout(rate<span class="op">=</span><span class="fl">0.2</span>),</span>
<span id="cb79-9"><a href="#cb79-9"></a>    layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">"softmax"</span>)</span>
<span id="cb79-10"><a href="#cb79-10"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="columns">
<div class="column">
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1"></a>model.predict(X_train[[<span class="dv">0</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>array([[0.23, 0.16, 0.05, 0.05, 0.05, 0.16, 0.11, 0.05, 0.07, 0.07]],
      dtype=float32)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1"></a>model(X_train[[<span class="dv">0</span>]], training<span class="op">=</span><span class="va">True</span>).numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>array([[0.18, 0.15, 0.04, 0.06, 0.05, 0.31, 0.03, 0.04, 0.08, 0.06]],
      dtype=float32)</code></pre>
</div>
</div>
</div><div class="column">
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1"></a>model.predict(X_train[[<span class="dv">0</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>array([[0.23, 0.16, 0.05, 0.05, 0.05, 0.16, 0.11, 0.05, 0.07, 0.07]],
      dtype=float32)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1"></a>model(X_train[[<span class="dv">0</span>]], training<span class="op">=</span><span class="va">True</span>).numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>array([[0.15, 0.19, 0.04, 0.06, 0.05, 0.12, 0.12, 0.04, 0.09, 0.14]],
      dtype=float32)</code></pre>
</div>
</div>
</div>
</div>
</section>
<section id="custom-mcdropout-layer" class="slide level2">
<h2>Custom <code>MCDropout</code> layer</h2>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1"></a><span class="kw">class</span> MCDropout(layers.Dropout):</span>
<span id="cb88-2"><a href="#cb88-2"></a>  <span class="kw">def</span> call(<span class="va">self</span>, inputs):</span>
<span id="cb88-3"><a href="#cb88-3"></a>    <span class="cf">return</span> <span class="bu">super</span>().call(inputs, training<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1"></a>tf.random.set_seed(<span class="dv">42</span>)</span>
<span id="cb89-2"><a href="#cb89-2"></a>model <span class="op">=</span> keras.Sequential([</span>
<span id="cb89-3"><a href="#cb89-3"></a>    layers.Flatten(input_shape<span class="op">=</span>[<span class="dv">28</span>, <span class="dv">28</span>]),</span>
<span id="cb89-4"><a href="#cb89-4"></a>    MCDropout(rate<span class="op">=</span><span class="fl">0.2</span>),</span>
<span id="cb89-5"><a href="#cb89-5"></a>    layers.Dense(<span class="dv">300</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb89-6"><a href="#cb89-6"></a>    MCDropout(rate<span class="op">=</span><span class="fl">0.2</span>),</span>
<span id="cb89-7"><a href="#cb89-7"></a>    layers.Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb89-8"><a href="#cb89-8"></a>    MCDropout(rate<span class="op">=</span><span class="fl">0.2</span>),</span>
<span id="cb89-9"><a href="#cb89-9"></a>    layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">"softmax"</span>)</span>
<span id="cb89-10"><a href="#cb89-10"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="columns">
<div class="column">
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1"></a>model.predict(X_train[[<span class="dv">0</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>array([[0.28, 0.13, 0.04, 0.03, 0.03, 0.23, 0.1 , 0.06, 0.05, 0.05]],
      dtype=float32)</code></pre>
</div>
</div>
</div><div class="column">
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1"></a>model.predict(X_train[[<span class="dv">0</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>array([[0.11, 0.19, 0.04, 0.07, 0.04, 0.19, 0.07, 0.07, 0.12, 0.1 ]],
      dtype=float32)</code></pre>
</div>
</div>
</div>
</div>
<div class="footer">
<p>Source: Aurélien Géron (2019), <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>, 2nd Edition, p.&nbsp;370 &amp; p.&nbsp;367</p>
</div>
</section>
<section id="encouraging-callbacks" class="slide level2">
<h2>Encouraging callbacks</h2>
<p><a href="https://github.com/keras-team/keras/blob/v2.9.0/keras/callbacks.py#L575-L881">Callback</a> is a Keras class that is meant to be subclassed.</p>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1"></a><span class="kw">class</span> EncouragingCallback(keras.callbacks.Callback):</span>
<span id="cb94-2"><a href="#cb94-2"></a>  <span class="kw">def</span> on_epoch_end(<span class="va">self</span>, epoch, logs):</span>
<span id="cb94-3"><a href="#cb94-3"></a>    phrases <span class="op">=</span> [<span class="st">"Great work!"</span>, <span class="st">"Nearly there"</span>, <span class="st">"加油"</span>]</span>
<span id="cb94-4"><a href="#cb94-4"></a>    encourage <span class="op">=</span> phrases[epoch<span class="op">%</span><span class="bu">len</span>(phrases)]</span>
<span id="cb94-5"><a href="#cb94-5"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">: loss=</span><span class="sc">{</span>logs[<span class="st">'loss'</span>]<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>encourage<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb95-2"><a href="#cb95-2"></a>model.<span class="bu">compile</span>(optimizer, loss_fn)</span>
<span id="cb95-3"><a href="#cb95-3"></a>ec <span class="op">=</span> EncouragingCallback()</span>
<span id="cb95-4"><a href="#cb95-4"></a>model <span class="op">=</span> model.fit(train_dataset, epochs<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb95-5"><a href="#cb95-5"></a>        callbacks <span class="op">=</span> [ec], verbose<span class="op">=</span><span class="dv">0</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0: loss=0.973278820514679, Great work!</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1: loss=0.455027312040329, Nearly there</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 2: loss=0.37771159410476685, 加油</code></pre>
</div>
</div>
<div class="footer">
<p>Inspired by: Aurélien Géron (2019), <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>, 2nd Edition, Chapter 10.</p>
</div>
</section>
<section id="keras-tuner" class="slide level2">
<h2>Keras-tuner</h2>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1"></a><span class="im">import</span> keras_tuner <span class="im">as</span> kt</span>
<span id="cb99-2"><a href="#cb99-2"></a></span>
<span id="cb99-3"><a href="#cb99-3"></a><span class="kw">def</span> build_model(hp):</span>
<span id="cb99-4"><a href="#cb99-4"></a>  numHidden <span class="op">=</span> hp.Int(<span class="st">"units"</span>, min_value<span class="op">=</span><span class="dv">32</span>, max_value<span class="op">=</span><span class="dv">512</span>, step<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb99-5"><a href="#cb99-5"></a>  model <span class="op">=</span> keras.Sequential([</span>
<span id="cb99-6"><a href="#cb99-6"></a>    layers.Flatten(),</span>
<span id="cb99-7"><a href="#cb99-7"></a>    layers.Dense(numHidden, <span class="st">"relu"</span>),</span>
<span id="cb99-8"><a href="#cb99-8"></a>    layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">"softmax"</span>)</span>
<span id="cb99-9"><a href="#cb99-9"></a>  ])</span>
<span id="cb99-10"><a href="#cb99-10"></a>  model.<span class="bu">compile</span>(<span class="st">"adam"</span>, <span class="st">"sparse_categorical_crossentropy"</span>,</span>
<span id="cb99-11"><a href="#cb99-11"></a>      metrics<span class="op">=</span>[<span class="st">"accuracy"</span>])</span>
<span id="cb99-12"><a href="#cb99-12"></a>  <span class="cf">return</span> model</span>
<span id="cb99-13"><a href="#cb99-13"></a></span>
<span id="cb99-14"><a href="#cb99-14"></a>tuner <span class="op">=</span> kt.RandomSearch(build_model, objective<span class="op">=</span><span class="st">"val_accuracy"</span>,</span>
<span id="cb99-15"><a href="#cb99-15"></a>    max_trials<span class="op">=</span><span class="dv">3</span>, seed<span class="op">=</span><span class="dv">42</span>, project_name<span class="op">=</span><span class="st">"optimise-num-hidden-units"</span>)</span>
<span id="cb99-16"><a href="#cb99-16"></a>tuner.search(X_train, y_train, epochs<span class="op">=</span><span class="dv">2</span>, validation_data<span class="op">=</span>(X_val, y_val))</span>
<span id="cb99-17"><a href="#cb99-17"></a>tuner.get_best_hyperparameters()[<span class="dv">0</span>].get(<span class="st">"units"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>352</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Invernizzi et al.&nbsp;(2021), <a href="https://keras.io/guides/keras_tuner/getting_started/">Getting started with KerasTuner</a>, Keras docs.</p>
</div>
</section>
<section id="tune-fitting-hyperparameters" class="slide level2">
<h2>Tune fitting hyperparameters</h2>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1"></a><span class="kw">class</span> MyHyperModel(kt.HyperModel):</span>
<span id="cb101-2"><a href="#cb101-2"></a>  <span class="kw">def</span> build(<span class="va">self</span>, hp):</span>
<span id="cb101-3"><a href="#cb101-3"></a>    numHidden <span class="op">=</span> hp.Int(<span class="st">"units"</span>, min_value<span class="op">=</span><span class="dv">32</span>, max_value<span class="op">=</span><span class="dv">512</span>, step<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb101-4"><a href="#cb101-4"></a>    model <span class="op">=</span> keras.Sequential([</span>
<span id="cb101-5"><a href="#cb101-5"></a>      layers.Flatten(),</span>
<span id="cb101-6"><a href="#cb101-6"></a>      layers.Dense(numHidden, <span class="st">"relu"</span>),</span>
<span id="cb101-7"><a href="#cb101-7"></a>      layers.Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">"softmax"</span>)</span>
<span id="cb101-8"><a href="#cb101-8"></a>    ])</span>
<span id="cb101-9"><a href="#cb101-9"></a>    model.<span class="bu">compile</span>(<span class="st">"adam"</span>, <span class="st">"sparse_categorical_crossentropy"</span>,</span>
<span id="cb101-10"><a href="#cb101-10"></a>        metrics<span class="op">=</span>[<span class="st">"accuracy"</span>])</span>
<span id="cb101-11"><a href="#cb101-11"></a>    <span class="cf">return</span> model</span>
<span id="cb101-12"><a href="#cb101-12"></a></span>
<span id="cb101-13"><a href="#cb101-13"></a>  <span class="kw">def</span> fit(<span class="va">self</span>, hp, model, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb101-14"><a href="#cb101-14"></a>    batchSize <span class="op">=</span> hp.Int(<span class="st">"batchSize"</span>, min_value<span class="op">=</span><span class="dv">32</span>, max_value<span class="op">=</span><span class="dv">512</span>, step<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb101-15"><a href="#cb101-15"></a>    <span class="cf">return</span> model.fit(<span class="op">*</span>args, batch_size <span class="op">=</span> batchSize, <span class="op">**</span>kwargs)</span>
<span id="cb101-16"><a href="#cb101-16"></a></span>
<span id="cb101-17"><a href="#cb101-17"></a>tuner <span class="op">=</span> kt.RandomSearch(MyHyperModel(), objective<span class="op">=</span><span class="st">"val_accuracy"</span>,</span>
<span id="cb101-18"><a href="#cb101-18"></a>  max_trials<span class="op">=</span><span class="dv">3</span>, seed<span class="op">=</span><span class="dv">123</span>, project_name<span class="op">=</span><span class="st">"optimise-batch-size"</span>)</span>
<span id="cb101-19"><a href="#cb101-19"></a>tuner.search(X_train, y_train, epochs<span class="op">=</span><span class="dv">2</span>, validation_data<span class="op">=</span>(X_val, y_val))</span>
<span id="cb101-20"><a href="#cb101-20"></a>tuner.get_best_hyperparameters()[<span class="dv">0</span>].get(<span class="st">"batchSize"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>64</code></pre>
</div>
</div>
<div class="footer">
<p>Source code for <a href="https://github.com/keras-team/keras-tuner/blob/1.1.3/keras_tuner/engine/hypermodel.py#L17">keras-tuner.HyperModel</a>.</p>
</div>
</section></section>
<section>
<section id="pytorch" class="title-slide slide level1 center" data-background-image="unsw-yellow-shape.png" data-visibility="uncounted">
<h1>PyTorch</h1>

</section>
<section id="why-1" class="slide level2">
<h2>Why?</h2>

<img data-src="pytorch-papers-of-total.svg" class="r-stretch quarto-figure-center"><p class="caption">Fraction of ML papers using PyTorch.</p><div class="footer">
<p>Source: Horace He (2022), <a href="http://horace.io/pytorch-vs-tensorflow/">pytorch-vs-tensorflow</a>.</p>
</div>
</section>
<section id="load-up-fashionmnist" class="slide level2">
<h2>Load up FashionMNIST</h2>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1"></a><span class="im">import</span> torch</span>
<span id="cb103-2"><a href="#cb103-2"></a><span class="im">import</span> torchvision</span>
<span id="cb103-3"><a href="#cb103-3"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb103-4"><a href="#cb103-4"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb103-5"><a href="#cb103-5"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb103-6"><a href="#cb103-6"></a><span class="op">%</span>watermark <span class="op">-</span>p torch,torchvision</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch      : 1.12.1
torchvision: 0.13.1
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1"></a>training_data <span class="op">=</span> torchvision.datasets.FashionMNIST(</span>
<span id="cb105-2"><a href="#cb105-2"></a>    root<span class="op">=</span><span class="st">"data"</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb105-3"><a href="#cb105-3"></a>    transform<span class="op">=</span>torchvision.transforms.ToTensor())</span>
<span id="cb105-4"><a href="#cb105-4"></a></span>
<span id="cb105-5"><a href="#cb105-5"></a>test_data <span class="op">=</span> torchvision.datasets.FashionMNIST(</span>
<span id="cb105-6"><a href="#cb105-6"></a>    root<span class="op">=</span><span class="st">"data"</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb105-7"><a href="#cb105-7"></a>    transform<span class="op">=</span>torchvision.transforms.ToTensor())</span>
<span id="cb105-8"><a href="#cb105-8"></a></span>
<span id="cb105-9"><a href="#cb105-9"></a>classes <span class="op">=</span> [</span>
<span id="cb105-10"><a href="#cb105-10"></a>    <span class="st">"T-shirt/top"</span>, <span class="st">"Trouser"</span>, <span class="st">"Pullover"</span>, <span class="st">"Dress"</span>, <span class="st">"Coat"</span>, </span>
<span id="cb105-11"><a href="#cb105-11"></a>    <span class="st">"Sandal"</span>, <span class="st">"Shirt"</span>, <span class="st">"Sneaker"</span>, <span class="st">"Bag"</span>, <span class="st">"Ankle boot"</span>,</span>
<span id="cb105-12"><a href="#cb105-12"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="footer">
<p>Adapted from: PyTorch (2022), <a href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html">Quickstart</a>, PyTorch docs.</p>
</div>
</section>
<section id="take-a-look-at-the-data" class="slide level2">
<h2>Take a look at the data</h2>
<div class="columns">
<div class="column" style="width:33%;">
<div class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1"></a>x, y <span class="op">=</span> training_data[<span class="dv">5</span>]</span>
<span id="cb106-2"><a href="#cb106-2"></a>plt.imshow(x[<span class="dv">0</span>])</span>
<span id="cb106-3"><a href="#cb106-3"></a>plt.title(classes[y])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img data-src="advanced-topics_files/figure-revealjs/cell-64-output-1.png"></p>
</div>
</div>
</div><div class="column" style="width:33%;">
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1"></a>x, y <span class="op">=</span> training_data[<span class="dv">25</span>]</span>
<span id="cb107-2"><a href="#cb107-2"></a>plt.imshow(x[<span class="dv">0</span>])</span>
<span id="cb107-3"><a href="#cb107-3"></a>plt.title(classes[y])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img data-src="advanced-topics_files/figure-revealjs/cell-65-output-1.png"></p>
</div>
</div>
</div><div class="column" style="width:33%;">
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1"></a>x, y <span class="op">=</span> training_data[<span class="dv">30</span>]</span>
<span id="cb108-2"><a href="#cb108-2"></a>plt.imshow(x[<span class="dv">0</span>])</span>
<span id="cb108-3"><a href="#cb108-3"></a>plt.title(classes[y])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img data-src="advanced-topics_files/figure-revealjs/cell-66-output-1.png"></p>
</div>
</div>
</div>
</div>
<div class="footer">
<p>Adapted from: PyTorch (2022), <a href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html">Quickstart</a>, PyTorch docs.</p>
</div>
</section>
<section id="batch-up-the-data" class="slide level2">
<h2>Batch up the data</h2>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1"></a>batch_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb109-2"><a href="#cb109-2"></a></span>
<span id="cb109-3"><a href="#cb109-3"></a><span class="co"># Create data loaders.</span></span>
<span id="cb109-4"><a href="#cb109-4"></a>train_dataloader <span class="op">=</span> DataLoader(training_data, batch_size<span class="op">=</span>batch_size)</span>
<span id="cb109-5"><a href="#cb109-5"></a>test_dataloader <span class="op">=</span> DataLoader(test_data, batch_size<span class="op">=</span>batch_size)</span>
<span id="cb109-6"><a href="#cb109-6"></a></span>
<span id="cb109-7"><a href="#cb109-7"></a><span class="cf">for</span> X, y <span class="kw">in</span> test_dataloader:</span>
<span id="cb109-8"><a href="#cb109-8"></a>    <span class="bu">print</span>(<span class="ss">f"Shape of X [N, C, H, W]: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb109-9"><a href="#cb109-9"></a>    <span class="bu">print</span>(<span class="ss">f"Shape of y: </span><span class="sc">{</span>y<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>y<span class="sc">.</span>dtype<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb109-10"><a href="#cb109-10"></a>    <span class="cf">break</span></span>
<span id="cb109-11"><a href="#cb109-11"></a></span>
<span id="cb109-12"><a href="#cb109-12"></a><span class="co"># Get cpu or gpu device for training.</span></span>
<span id="cb109-13"><a href="#cb109-13"></a>device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span> <span class="co"># Normally..</span></span>
<span id="cb109-14"><a href="#cb109-14"></a>device <span class="op">=</span> <span class="st">"mps"</span> <span class="co"># But I'm on a Mac.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])
Shape of y: torch.Size([64]) torch.int64</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: PyTorch (2022), <a href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html">Quickstart</a>, PyTorch docs.</p>
</div>
</section>
<section id="make-a-sequential-model" class="slide level2">
<h2>Make a sequential model</h2>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1"></a>torch.manual_seed(<span class="dv">0</span>)</span>
<span id="cb111-2"><a href="#cb111-2"></a>model <span class="op">=</span> nn.Sequential(</span>
<span id="cb111-3"><a href="#cb111-3"></a>            nn.Flatten(),</span>
<span id="cb111-4"><a href="#cb111-4"></a>            nn.Linear(<span class="dv">28</span><span class="op">*</span><span class="dv">28</span>, <span class="dv">512</span>),</span>
<span id="cb111-5"><a href="#cb111-5"></a>            nn.ReLU(),</span>
<span id="cb111-6"><a href="#cb111-6"></a>            nn.Linear(<span class="dv">512</span>, <span class="dv">512</span>),</span>
<span id="cb111-7"><a href="#cb111-7"></a>            nn.ReLU(),</span>
<span id="cb111-8"><a href="#cb111-8"></a>            nn.Linear(<span class="dv">512</span>, <span class="dv">10</span>)</span>
<span id="cb111-9"><a href="#cb111-9"></a>        )</span>
<span id="cb111-10"><a href="#cb111-10"></a>model <span class="op">=</span> model.to(device)</span>
<span id="cb111-11"><a href="#cb111-11"></a><span class="bu">print</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
  (1): Linear(in_features=784, out_features=512, bias=True)
  (2): ReLU()
  (3): Linear(in_features=512, out_features=512, bias=True)
  (4): ReLU()
  (5): Linear(in_features=512, out_features=10, bias=True)
)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1"></a>epochs <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb113-2"><a href="#cb113-2"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb113-3"><a href="#cb113-3"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">1e-3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="run-a-train-loop" class="slide level2">
<h2>Run a train loop</h2>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1"></a><span class="op">%%</span>time</span>
<span id="cb114-2"><a href="#cb114-2"></a>model.train()</span>
<span id="cb114-3"><a href="#cb114-3"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(epochs):    </span>
<span id="cb114-4"><a href="#cb114-4"></a>    <span class="cf">for</span> X, y <span class="kw">in</span> train_dataloader:</span>
<span id="cb114-5"><a href="#cb114-5"></a>        X, y <span class="op">=</span> X.to(device), y.to(device)</span>
<span id="cb114-6"><a href="#cb114-6"></a></span>
<span id="cb114-7"><a href="#cb114-7"></a>        <span class="co"># Compute prediction error</span></span>
<span id="cb114-8"><a href="#cb114-8"></a>        pred <span class="op">=</span> model(X)</span>
<span id="cb114-9"><a href="#cb114-9"></a>        loss <span class="op">=</span> loss_fn(pred, y)</span>
<span id="cb114-10"><a href="#cb114-10"></a></span>
<span id="cb114-11"><a href="#cb114-11"></a>        <span class="co"># Backpropagation</span></span>
<span id="cb114-12"><a href="#cb114-12"></a>        optimizer.zero_grad()</span>
<span id="cb114-13"><a href="#cb114-13"></a>        loss.backward()</span>
<span id="cb114-14"><a href="#cb114-14"></a>        optimizer.step()</span>
<span id="cb114-15"><a href="#cb114-15"></a></span>
<span id="cb114-16"><a href="#cb114-16"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>t<span class="sc">}</span><span class="ss"> Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0 Loss: 2.158100128173828</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1 Loss: 1.9045133590698242</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 2 Loss: 1.5597727298736572
CPU times: user 10.3 s, sys: 5.91 s, total: 16.2 s
Wall time: 11.2 s</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: PyTorch (2022), <a href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html">Quickstart</a>, PyTorch docs.</p>
</div>
</section>
<section id="far-more-common-to-subclass" class="slide level2">
<h2>Far more common to subclass</h2>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1"></a><span class="kw">class</span> NeuralNetwork(nn.Module):</span>
<span id="cb118-2"><a href="#cb118-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb118-3"><a href="#cb118-3"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb118-4"><a href="#cb118-4"></a>        <span class="va">self</span>.linear1 <span class="op">=</span> nn.Linear(<span class="dv">28</span><span class="op">*</span><span class="dv">28</span>, <span class="dv">512</span>)</span>
<span id="cb118-5"><a href="#cb118-5"></a>        <span class="va">self</span>.linear2 <span class="op">=</span> nn.Linear(<span class="dv">512</span>, <span class="dv">512</span>)</span>
<span id="cb118-6"><a href="#cb118-6"></a>        <span class="va">self</span>.linear3 <span class="op">=</span> nn.Linear(<span class="dv">512</span>, <span class="dv">10</span>)</span>
<span id="cb118-7"><a href="#cb118-7"></a>        </span>
<span id="cb118-8"><a href="#cb118-8"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb118-9"><a href="#cb118-9"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.linear1(x.flatten(<span class="dv">1</span>)))</span>
<span id="cb118-10"><a href="#cb118-10"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.linear2(x))</span>
<span id="cb118-11"><a href="#cb118-11"></a>        <span class="cf">return</span> <span class="va">self</span>.linear3(x)</span>
<span id="cb118-12"><a href="#cb118-12"></a>        </span>
<span id="cb118-13"><a href="#cb118-13"></a>torch.manual_seed(<span class="dv">0</span>)</span>
<span id="cb118-14"><a href="#cb118-14"></a>classyModel <span class="op">=</span> NeuralNetwork().to(device)</span>
<span id="cb118-15"><a href="#cb118-15"></a>classyModel</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>NeuralNetwork(
  (linear1): Linear(in_features=784, out_features=512, bias=True)
  (linear2): Linear(in_features=512, out_features=512, bias=True)
  (linear3): Linear(in_features=512, out_features=10, bias=True)
)</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: PyTorch (2022), <a href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html">Quickstart</a>, PyTorch docs.</p>
</div>
</section>
<section id="evaluate-the-fit" class="slide level2">
<h2>Evaluate the fit</h2>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb120-2"><a href="#cb120-2"></a></span>
<span id="cb120-3"><a href="#cb120-3"></a>num_correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb120-4"><a href="#cb120-4"></a>test_size <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb120-5"><a href="#cb120-5"></a><span class="cf">for</span> X, y <span class="kw">in</span> test_dataloader:</span>
<span id="cb120-6"><a href="#cb120-6"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb120-7"><a href="#cb120-7"></a>        pred <span class="op">=</span> model(X.to(device))</span>
<span id="cb120-8"><a href="#cb120-8"></a>        num_correct <span class="op">+=</span> torch.<span class="bu">sum</span>(y.to(device) <span class="op">==</span> pred.argmax(<span class="dv">1</span>)).item()</span>
<span id="cb120-9"><a href="#cb120-9"></a>        test_size <span class="op">+=</span> <span class="bu">len</span>(y)</span>
<span id="cb120-10"><a href="#cb120-10"></a></span>
<span id="cb120-11"><a href="#cb120-11"></a><span class="bu">print</span>(<span class="ss">f"Test accuracy: </span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>num_correct<span class="op">/</span>test_size<span class="sc">:.2f}</span><span class="ss">%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Test accuracy: 61.30%</code></pre>
</div>
</div>
</section>
<section id="predict-new-data" class="slide level2">
<h2>Predict new data</h2>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1"></a>X, y <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(test_dataloader))</span>
<span id="cb122-2"><a href="#cb122-2"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb122-3"><a href="#cb122-3"></a>    pred <span class="op">=</span> model(X.to(device))</span>
<span id="cb122-4"><a href="#cb122-4"></a></span>
<span id="cb122-5"><a href="#cb122-5"></a>predictedClasses <span class="op">=</span> [classes[ind] <span class="cf">for</span> ind <span class="kw">in</span> pred.argmax(<span class="dv">1</span>)]</span>
<span id="cb122-6"><a href="#cb122-6"></a>actualClasses <span class="op">=</span> [classes[ind] <span class="cf">for</span> ind <span class="kw">in</span> y]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="columns">
<div class="column" style="width:33%;">
<div class="cell" data-execution_count="73">
<div class="cell-output cell-output-display">
<p><img data-src="advanced-topics_files/figure-revealjs/cell-74-output-1.png"></p>
</div>
</div>
</div><div class="column" style="width:33%;">
<div class="cell" data-execution_count="74">
<div class="cell-output cell-output-display">
<p><img data-src="advanced-topics_files/figure-revealjs/cell-75-output-1.png"></p>
</div>
</div>
</div><div class="column" style="width:33%;">
<div class="cell" data-execution_count="75">
<div class="cell-output cell-output-display">
<p><img data-src="advanced-topics_files/figure-revealjs/cell-76-output-1.png"></p>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="variational-autoencoders" class="title-slide slide level1 center" data-background-image="unsw-yellow-shape.png" data-visibility="uncounted">
<h1>Variational Autoencoders</h1>

</section>
<section id="variational-autoencoder" class="slide level2">
<h2>Variational autoencoder</h2>
<aside class="notes">
<p>A slightly different sample from the distribution in the latent space will be decoded to a slightly different image. The stochasticity of this process improves robustness and forces the latent space to encode meaningful representation everywhere: every point in the latent space is decoded to a valid output. So the latent spaces of VAEs are continuous and highly-structured.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>

<img data-src="chollet-VAE-blur.png" class="r-stretch quarto-figure-center"><p class="caption">Schematic of a variational autoencoder.</p><div class="footer">
<p>Source: François Chollet (2021), <em>Deep Learning with Python</em>, Second Edition, Figure 12.17 (<strong>redacted</strong>).</p>
</div>
</section>
<section id="vae-schematic-process" class="slide level2">
<h2>VAE schematic process</h2>

<img data-src="chollet-VAEcode-blur.png" class="r-stretch quarto-figure-center"><p class="caption">Keras code for a VAE.</p><div class="footer">
<p>Source: François Chollet (2021), <em>Deep Learning with Python</em>, Second Edition, Unnumbered listing in Chapter 12 (<strong>redacted</strong>).</p>
</div>
</section>
<section id="focus-on-the-decoder" class="slide level2">
<h2>Focus on the decoder</h2>

<img data-src="chollet-latentspace-blur.png" class="r-stretch quarto-figure-center"><p class="caption">Sampling new artificial images from the latent space.</p><div class="footer">
<p>Source: François Chollet (2021), <em>Deep Learning with Python</em>, Second Edition, Figure 12.13 (<strong>redacted</strong>).</p>
</div>
</section>
<section id="exploring-the-mnist-latent-space" class="slide level2">
<h2>Exploring the MNIST latent space</h2>

<img data-src="chollet-VAEdecoded-blur.png" class="r-stretch quarto-figure-center"><p class="caption">Example of MNIST-like images generated from the latent space.</p><div class="footer">
<p>Source: François Chollet (2021), <em>Deep Learning with Python</em>, Second Edition, Figure 12.18 (<strong>redacted</strong>).</p>
</div>
</section></section>
<section>
<section id="generative-adversarial-networks" class="title-slide slide level1 center" data-background-image="unsw-yellow-shape.png" data-visibility="uncounted">
<h1>Generative Adversarial Networks</h1>

</section>
<section id="gan-faces" class="slide level2">
<h2>GAN faces</h2>
<div class="columns">
<div class="column">
<p><img data-src="fakeface1.jpeg"></p>
</div><div class="column">
<p><img data-src="fakeface2.jpeg"></p>
</div>
</div>
<p>Try out <a href="https://www.whichfaceisreal.com">https://www.whichfaceisreal.com</a>.</p>
<div class="footer">
<p>Source: <a href="https://thispersondoesnotexist.com">https://thispersondoesnotexist.com</a>.</p>
</div>
</section>
<section id="gan-structure" class="slide level2">
<h2>GAN structure</h2>

<img data-src="gan-diagram.png" class="r-stretch quarto-figure-center"><p class="caption">A schematic of a generative adversarial network.</p><div class="footer">
<p>Source: Thales Silva (2018), <a href="https://www.freecodecamp.org/news/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394">An intuitive introduction to Generative Adversarial Networks (GANs)</a>, freeCodeCamp.</p>
</div>
</section>
<section id="gan-intuition" class="slide level2">
<h2>GAN intuition</h2>
<p><img data-src="google-devs-bad_gan.svg"> <img data-src="google-devs-ok_gan.svg"> <img data-src="google-devs-good_gan.svg"></p>
<div class="footer">
<p>Source: Google Developers, <a href="https://developers.google.com/machine-learning/gan/gan_structure">Overview of GAN Structure</a>, Google Machine Learning Education.</p>
</div>
</section>
<section id="stylegan2-ada" class="slide level2">
<h2>StyleGAN2-ADA</h2>
<p><br></p>
<p>Training times on V100s (1024x1024 resolution):</p>
<table>
<colgroup>
<col style="width: 6%">
<col style="width: 22%">
<col style="width: 20%">
<col style="width: 12%">
<col style="width: 16%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">GPUs</th>
<th style="text-align: center;">1000 kimg</th>
<th style="text-align: center;">25000 kimg</th>
<th style="text-align: center;">sec / kimg</th>
<th style="text-align: center;">GPU mem</th>
<th style="text-align: center;">CPU mem</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1d 20h</td>
<td style="text-align: center;">46d 03h</td>
<td style="text-align: center;">158</td>
<td style="text-align: center;">8.1 GB</td>
<td style="text-align: center;">5.3 GB</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">23h 09m</td>
<td style="text-align: center;">24d 02h</td>
<td style="text-align: center;">83</td>
<td style="text-align: center;">8.6 GB</td>
<td style="text-align: center;">11.9 GB</td>
</tr>
<tr class="odd">
<td style="text-align: center;">4</td>
<td style="text-align: center;">11h 36m</td>
<td style="text-align: center;">12d 02h</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">8.4 GB</td>
<td style="text-align: center;">21.9 GB</td>
</tr>
<tr class="even">
<td style="text-align: center;">8</td>
<td style="text-align: center;">5h 54m</td>
<td style="text-align: center;">6d 03h</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">8.3 GB</td>
<td style="text-align: center;">44.7 GB</td>
</tr>
</tbody>
</table>
<div class="footer">
<p>Source: NVIDIA’s Github, <a href="https://github.com/NVlabs/stylegan2-ada-pytorch/">StyleGAN2-ADA — Official PyTorch implementation</a>.</p>
</div>
</section>
<section id="discriminator" class="slide level2">
<h2>Discriminator</h2>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1"></a>lrelu <span class="op">=</span> layers.LeakyReLU(alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb123-2"><a href="#cb123-2"></a></span>
<span id="cb123-3"><a href="#cb123-3"></a>discriminator <span class="op">=</span> keras.Sequential([</span>
<span id="cb123-4"><a href="#cb123-4"></a>    keras.Input(shape<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)),</span>
<span id="cb123-5"><a href="#cb123-5"></a>    layers.Conv2D(<span class="dv">64</span>, <span class="dv">3</span>, strides<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">"same"</span>, activation<span class="op">=</span>lrelu),</span>
<span id="cb123-6"><a href="#cb123-6"></a>    layers.Conv2D(<span class="dv">128</span>, <span class="dv">3</span>, strides<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">"same"</span>, activation<span class="op">=</span>lrelu),</span>
<span id="cb123-7"><a href="#cb123-7"></a>    layers.GlobalMaxPooling2D(),</span>
<span id="cb123-8"><a href="#cb123-8"></a>    layers.Dense(<span class="dv">1</span>)])</span>
<span id="cb123-9"><a href="#cb123-9"></a></span>
<span id="cb123-10"><a href="#cb123-10"></a>discriminator.summary(print_fn<span class="op">=</span>skip_empty)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_15"
_________________________________________________________________
Layer (type)                Output Shape              Param #
=================================================================
conv2d (Conv2D)             (None, 14, 14, 64)        640
conv2d_1 (Conv2D)           (None, 7, 7, 128)         73856
global_max_pooling2d (Globa  (None, 128)              0
lMaxPooling2D)
dense_32 (Dense)            (None, 1)                 129
=================================================================
Total params: 74,625
Trainable params: 74,625
Non-trainable params: 0
_________________________________________________________________</code></pre>
</div>
</div>
</section>
<section id="generator" class="slide level2">
<h2>Generator</h2>
<div class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1"></a>latent_dim <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb125-2"><a href="#cb125-2"></a>generator <span class="op">=</span> keras.Sequential([</span>
<span id="cb125-3"><a href="#cb125-3"></a>    layers.Dense(<span class="dv">7</span> <span class="op">*</span> <span class="dv">7</span> <span class="op">*</span> <span class="dv">128</span>, input_dim<span class="op">=</span>latent_dim, activation<span class="op">=</span>lrelu),</span>
<span id="cb125-4"><a href="#cb125-4"></a>    layers.Reshape((<span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">128</span>)),</span>
<span id="cb125-5"><a href="#cb125-5"></a>    layers.Conv2DTranspose(<span class="dv">128</span>, <span class="dv">4</span>, strides<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">"same"</span>, activation<span class="op">=</span>lrelu),</span>
<span id="cb125-6"><a href="#cb125-6"></a>    layers.Conv2DTranspose(<span class="dv">128</span>, <span class="dv">4</span>, strides<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="st">"same"</span>, activation<span class="op">=</span>lrelu),</span>
<span id="cb125-7"><a href="#cb125-7"></a>    layers.Conv2D(<span class="dv">1</span>, <span class="dv">7</span>, padding<span class="op">=</span><span class="st">"same"</span>, activation<span class="op">=</span><span class="st">"sigmoid"</span>)])</span>
<span id="cb125-8"><a href="#cb125-8"></a>generator.summary(print_fn<span class="op">=</span>skip_empty)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_16"
_________________________________________________________________
Layer (type)                Output Shape              Param #
=================================================================
dense_33 (Dense)            (None, 6272)              809088
reshape (Reshape)           (None, 7, 7, 128)         0
conv2d_transpose (Conv2DTra  (None, 14, 14, 128)      262272
nspose)
conv2d_transpose_1 (Conv2DT  (None, 28, 28, 128)      262272
ranspose)
conv2d_2 (Conv2D)           (None, 28, 28, 1)         6273
=================================================================
Total params: 1,339,905
Trainable params: 1,339,905
Non-trainable params: 0
_________________________________________________________________</code></pre>
</div>
</div>
</section>
<section id="advanced-image-layers" class="slide level2 smaller">
<h2>Advanced image layers</h2>
<div class="absolute" style="top: 120px; left: 250px; ">
<p>Conv2D</p>
</div>
<div class="absolute" style="top: 270px; left: 60px; ">
<p>GlobalMaxPool2D</p>
</div>
<div class="absolute" style="top: 270px; right: 100px; ">
<p>Conv2DTranspose</p>
</div>
<p><img data-src="2d_global_max_pooling_pa1.png" class="absolute" style="left: 0px; bottom: 0px; width: 550px; "></p>
<p><img data-src="conv2d.gif" class="absolute" style="top: 75px; left: 350px; width: 300px; "></p>
<p><img data-src="conv2dTranspose.gif" class="absolute" style="bottom: 0px; right: 50px; width: 300px; "></p>
<div class="footer">
<p>Sources: Pröve (2017), <a href="https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d">An Introduction to different Types of Convolutions in Deep Learning</a>, and Peltarion Knowledge Center, <a href="https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/global-max-pooling-2d">Global max pooling 2D</a>.</p>
</div>
</section>
<section id="train-step" class="slide level2">
<h2>Train step</h2>
<div class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1"></a><span class="co"># Separate optimisers for discriminator and generator.</span></span>
<span id="cb127-2"><a href="#cb127-2"></a>d_optimizer <span class="op">=</span> keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">0.0003</span>)</span>
<span id="cb127-3"><a href="#cb127-3"></a>g_optimizer <span class="op">=</span> keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">0.0004</span>)</span>
<span id="cb127-4"><a href="#cb127-4"></a></span>
<span id="cb127-5"><a href="#cb127-5"></a><span class="co"># Instantiate a loss function.</span></span>
<span id="cb127-6"><a href="#cb127-6"></a>loss_fn <span class="op">=</span> keras.losses.BinaryCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb127-7"><a href="#cb127-7"></a></span>
<span id="cb127-8"><a href="#cb127-8"></a><span class="at">@tf.function</span></span>
<span id="cb127-9"><a href="#cb127-9"></a><span class="kw">def</span> train_step(real_images):</span>
<span id="cb127-10"><a href="#cb127-10"></a>  <span class="co"># Sample random points in the latent space</span></span>
<span id="cb127-11"><a href="#cb127-11"></a>  random_latent_vectors <span class="op">=</span> tf.random.normal(shape<span class="op">=</span>(batch_size, latent_dim))</span>
<span id="cb127-12"><a href="#cb127-12"></a>  <span class="co"># Decode them to fake images</span></span>
<span id="cb127-13"><a href="#cb127-13"></a>  generated_images <span class="op">=</span> generator(random_latent_vectors)</span>
<span id="cb127-14"><a href="#cb127-14"></a>  <span class="co"># Combine them with real images</span></span>
<span id="cb127-15"><a href="#cb127-15"></a>  combined_images <span class="op">=</span> tf.concat([generated_images, real_images], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb127-16"><a href="#cb127-16"></a></span>
<span id="cb127-17"><a href="#cb127-17"></a>  <span class="co"># Assemble labels discriminating real from fake images</span></span>
<span id="cb127-18"><a href="#cb127-18"></a>  labels <span class="op">=</span> tf.concat([</span>
<span id="cb127-19"><a href="#cb127-19"></a>    tf.ones((batch_size, <span class="dv">1</span>)),</span>
<span id="cb127-20"><a href="#cb127-20"></a>    tf.zeros((real_images.shape[<span class="dv">0</span>], <span class="dv">1</span>))], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb127-21"><a href="#cb127-21"></a></span>
<span id="cb127-22"><a href="#cb127-22"></a>  <span class="co"># Add random noise to the labels - important trick!</span></span>
<span id="cb127-23"><a href="#cb127-23"></a>  labels <span class="op">+=</span> <span class="fl">0.05</span> <span class="op">*</span> tf.random.uniform(labels.shape)</span>
<span id="cb127-24"><a href="#cb127-24"></a></span>
<span id="cb127-25"><a href="#cb127-25"></a>  <span class="co"># Train the discriminator</span></span>
<span id="cb127-26"><a href="#cb127-26"></a>  <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb127-27"><a href="#cb127-27"></a>    predictions <span class="op">=</span> discriminator(combined_images)</span>
<span id="cb127-28"><a href="#cb127-28"></a>    d_loss <span class="op">=</span> loss_fn(labels, predictions)</span>
<span id="cb127-29"><a href="#cb127-29"></a>  grads <span class="op">=</span> tape.gradient(d_loss, discriminator.trainable_weights)</span>
<span id="cb127-30"><a href="#cb127-30"></a>  d_optimizer.apply_gradients(<span class="bu">zip</span>(grads, discriminator.trainable_weights))</span>
<span id="cb127-31"><a href="#cb127-31"></a></span>
<span id="cb127-32"><a href="#cb127-32"></a>  <span class="co"># Sample random points in the latent space</span></span>
<span id="cb127-33"><a href="#cb127-33"></a>  random_latent_vectors <span class="op">=</span> tf.random.normal(shape<span class="op">=</span>(batch_size, latent_dim))</span>
<span id="cb127-34"><a href="#cb127-34"></a></span>
<span id="cb127-35"><a href="#cb127-35"></a>  <span class="co"># Assemble labels that say "all real images"</span></span>
<span id="cb127-36"><a href="#cb127-36"></a>  misleading_labels <span class="op">=</span> tf.zeros((batch_size, <span class="dv">1</span>))</span>
<span id="cb127-37"><a href="#cb127-37"></a></span>
<span id="cb127-38"><a href="#cb127-38"></a>  <span class="co"># Train the generator (note that we should *not* update the weights</span></span>
<span id="cb127-39"><a href="#cb127-39"></a>  <span class="co"># of the discriminator)!</span></span>
<span id="cb127-40"><a href="#cb127-40"></a>  <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb127-41"><a href="#cb127-41"></a>    predictions <span class="op">=</span> discriminator(generator(random_latent_vectors))</span>
<span id="cb127-42"><a href="#cb127-42"></a>    g_loss <span class="op">=</span> loss_fn(misleading_labels, predictions)</span>
<span id="cb127-43"><a href="#cb127-43"></a></span>
<span id="cb127-44"><a href="#cb127-44"></a>  grads <span class="op">=</span> tape.gradient(g_loss, generator.trainable_weights)</span>
<span id="cb127-45"><a href="#cb127-45"></a>  g_optimizer.apply_gradients(<span class="bu">zip</span>(grads, generator.trainable_weights))</span>
<span id="cb127-46"><a href="#cb127-46"></a>  <span class="cf">return</span> d_loss, g_loss, generated_images</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="grab-the-data" class="slide level2">
<h2>Grab the data</h2>
<div class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1"></a><span class="co"># Prepare the dataset.</span></span>
<span id="cb128-2"><a href="#cb128-2"></a><span class="co"># We use both the training &amp; test MNIST digits.</span></span>
<span id="cb128-3"><a href="#cb128-3"></a>batch_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb128-4"><a href="#cb128-4"></a>(x_train, _), (x_test, _) <span class="op">=</span> keras.datasets.mnist.load_data()</span>
<span id="cb128-5"><a href="#cb128-5"></a>all_digits <span class="op">=</span> np.concatenate([x_train, x_test])</span>
<span id="cb128-6"><a href="#cb128-6"></a>all_digits <span class="op">=</span> all_digits.astype(<span class="st">"float32"</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb128-7"><a href="#cb128-7"></a>all_digits <span class="op">=</span> np.reshape(all_digits, (<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>))</span>
<span id="cb128-8"><a href="#cb128-8"></a>dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices(all_digits)</span>
<span id="cb128-9"><a href="#cb128-9"></a>dataset <span class="op">=</span> dataset.shuffle(buffer_size<span class="op">=</span><span class="dv">1024</span>).batch(batch_size)</span>
<span id="cb128-10"><a href="#cb128-10"></a></span>
<span id="cb128-11"><a href="#cb128-11"></a><span class="co"># In practice you need at least 20 epochs to generate nice digits.</span></span>
<span id="cb128-12"><a href="#cb128-12"></a>epochs <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb128-13"><a href="#cb128-13"></a>save_dir <span class="op">=</span> <span class="st">"./"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="train-the-gan" class="slide level2">
<h2>Train the GAN</h2>
<div class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1"></a><span class="op">%%</span>time</span>
<span id="cb129-2"><a href="#cb129-2"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb129-3"><a href="#cb129-3"></a>  <span class="cf">for</span> step, real_images <span class="kw">in</span> <span class="bu">enumerate</span>(dataset):</span>
<span id="cb129-4"><a href="#cb129-4"></a>    <span class="co"># Train the discriminator &amp; generator on one batch of real images.</span></span>
<span id="cb129-5"><a href="#cb129-5"></a>    d_loss, g_loss, generated_images <span class="op">=</span> train_step(real_images)</span>
<span id="cb129-6"><a href="#cb129-6"></a></span>
<span id="cb129-7"><a href="#cb129-7"></a>    <span class="co"># Logging.</span></span>
<span id="cb129-8"><a href="#cb129-8"></a>    <span class="cf">if</span> step <span class="op">%</span> <span class="dv">200</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb129-9"><a href="#cb129-9"></a>      <span class="co"># Print metrics</span></span>
<span id="cb129-10"><a href="#cb129-10"></a>      <span class="bu">print</span>(<span class="ss">f"Discriminator loss at step </span><span class="sc">{</span>step<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>d_loss<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb129-11"><a href="#cb129-11"></a>      <span class="bu">print</span>(<span class="ss">f"Adversarial loss at step </span><span class="sc">{</span>step<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>g_loss<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb129-12"><a href="#cb129-12"></a>      <span class="cf">break</span> <span class="co"># Remove this if really training the GAN</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Discriminator loss at step 0: 0.69
Adversarial loss at step 0: 0.69
CPU times: user 1.69 s, sys: 138 ms, total: 1.83 s
Wall time: 560 ms</code></pre>
</div>
</div>
<div class="callout callout-warning callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Warning</strong></p>
</div>
<div class="callout-content">
<p>Converges to a Nash equilibrium.. if at all.</p>
</div>
</div>
</div>
</section>
<section id="mode-collapse" class="slide level2 smaller">
<h2>Mode collapse</h2>
<div class="columns">
<div class="column" style="width:50%&quot;;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="gan-mode-collapse.png"></p>
<p></p><figcaption>Example of mode collapse</figcaption><p></p>
</figure>
</div>
</div><div class="column" style="width:50%;">
<p><img data-src="xkcd-random_number.png"></p>
<ul>
<li>Dongyu Liu (2021), <a href="https://youtu.be/jIDj2dhU99k">TadGAN: Time Series Anomaly Detection Using Generative Adversarial Networks</a></li>
<li>Jeff Heaton (2022), <a href="https://youtu.be/yujdA46HKwA">GANs for Tabular Synthetic Data Generation (7.5)</a></li>
<li>Jeff Heaton (2022), <a href="https://youtu.be/0OTd5GlHRx4">GANs to Enhance Old Photographs Deoldify (7.4)</a></li>
<li>Jeff Heaton (2021), <a href="https://youtu.be/kbDd5lW6rkM">Training a GAN from your Own Images: StyleGAN2</a></li>
</ul>
</div>
</div>
<div class="footer">
<p>Source: Metz et al.&nbsp;(2017), <a href="https://arxiv.org/pdf/1611.02163.pdf">Unrolled Generative Adversarial Networks</a> and Randall Munroe (2007), <a href="https://xkcd.com/221/">xkcd #221: Random Number</a>.</p>
</div>
</section></section>
<section>
<section id="other-useful-packages" class="title-slide slide level1 center" data-background-image="unsw-yellow-shape.png" data-visibility="uncounted">
<h1>Other Useful Packages</h1>

</section>
<section id="tensorflow-probability" class="slide level2">
<h2>Tensorflow Probability</h2>
<div class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1"></a><span class="im">import</span> tensorflow_probability <span class="im">as</span> tfp</span>
<span id="cb131-2"><a href="#cb131-2"></a>tfd <span class="op">=</span> tfp.distributions</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1"></a>tf.random.set_seed(<span class="dv">123</span>)</span>
<span id="cb132-2"><a href="#cb132-2"></a>model <span class="op">=</span> keras.Sequential([</span>
<span id="cb132-3"><a href="#cb132-3"></a>  layers.Dense(<span class="dv">24</span>, <span class="st">"leaky_relu"</span>, input_dim<span class="op">=</span>X_train.shape[<span class="dv">1</span>]),</span>
<span id="cb132-4"><a href="#cb132-4"></a>  layers.Dense(<span class="dv">1</span>, <span class="st">"exponential"</span>),</span>
<span id="cb132-5"><a href="#cb132-5"></a>  tfp.layers.DistributionLambda(tfd.Poisson)</span>
<span id="cb132-6"><a href="#cb132-6"></a>])</span>
<span id="cb132-7"><a href="#cb132-7"></a></span>
<span id="cb132-8"><a href="#cb132-8"></a><span class="kw">def</span> NLL(y_true, y_hat):</span>
<span id="cb132-9"><a href="#cb132-9"></a>  <span class="cf">return</span> <span class="op">-</span>y_hat.log_prob(y_true)</span>
<span id="cb132-10"><a href="#cb132-10"></a></span>
<span id="cb132-11"><a href="#cb132-11"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span>NLL)</span>
<span id="cb132-12"><a href="#cb132-12"></a>model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">3</span>, verbose<span class="op">=</span><span class="dv">0</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-tip callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Suggested viewing</strong></p>
</div>
<div class="callout-content">
<p>Josh Dylan (2019), <a href="https://youtu.be/BrwKURU-wpk">TensorFlow Probability: Learning with confidence</a>, TF Dev Summit ’19, YouTube (14 mins).</p>
</div>
</div>
</div>
</section>
<section id="predictions-are-then-distributions" class="slide level2">
<h2>Predictions are then distributions</h2>
<div class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1"></a>y_pred <span class="op">=</span> model(X_val)</span>
<span id="cb133-2"><a href="#cb133-2"></a><span class="bu">type</span>(y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>tensorflow_probability.python.layers.internal.distribution_tensor_coercible._TensorCoercible</code></pre>
</div>
</div>
<div class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1"></a>y_pred.mean()[:<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[0.06],
       [0.03],
       [0.03]], dtype=float32)&gt;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1"></a>y_pred.stddev()[:<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[0.25],
       [0.16],
       [0.18]], dtype=float32)&gt;</code></pre>
</div>
</div>
</section>
<section id="zero-inflated-poisson" class="slide level2">
<h2>Zero-inflated Poisson</h2>
<div class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1"></a><span class="kw">def</span> zero_inf(out): </span>
<span id="cb139-2"><a href="#cb139-2"></a>  rate <span class="op">=</span> tf.squeeze(tf.math.exp(out[:,<span class="dv">0</span>:<span class="dv">1</span>]))</span>
<span id="cb139-3"><a href="#cb139-3"></a>  s <span class="op">=</span> tf.math.sigmoid(out[:,<span class="dv">1</span>:<span class="dv">2</span>])</span>
<span id="cb139-4"><a href="#cb139-4"></a>  probs <span class="op">=</span> tf.concat([<span class="dv">1</span><span class="op">-</span>s, s], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb139-5"><a href="#cb139-5"></a>  <span class="cf">return</span> tfd.Mixture(</span>
<span id="cb139-6"><a href="#cb139-6"></a>    cat<span class="op">=</span>tfd.Categorical(probs<span class="op">=</span>probs),</span>
<span id="cb139-7"><a href="#cb139-7"></a>    components<span class="op">=</span>[</span>
<span id="cb139-8"><a href="#cb139-8"></a>      tfd.Deterministic(loc<span class="op">=</span>tf.zeros_like(rate)),</span>
<span id="cb139-9"><a href="#cb139-9"></a>      tfd.Poisson(rate<span class="op">=</span>rate),</span>
<span id="cb139-10"><a href="#cb139-10"></a>    ])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1"></a>tf.random.set_seed(<span class="dv">123</span>)</span>
<span id="cb140-2"><a href="#cb140-2"></a></span>
<span id="cb140-3"><a href="#cb140-3"></a>zipModel <span class="op">=</span> keras.Sequential([</span>
<span id="cb140-4"><a href="#cb140-4"></a>  layers.Dense(<span class="dv">24</span>, <span class="st">"leaky_relu"</span>, input_dim<span class="op">=</span>X_train.shape[<span class="dv">1</span>]),</span>
<span id="cb140-5"><a href="#cb140-5"></a>  layers.Dense(<span class="dv">2</span>),</span>
<span id="cb140-6"><a href="#cb140-6"></a>  tfp.layers.DistributionLambda(zero_inf)</span>
<span id="cb140-7"><a href="#cb140-7"></a>])</span>
<span id="cb140-8"><a href="#cb140-8"></a></span>
<span id="cb140-9"><a href="#cb140-9"></a><span class="kw">def</span> NLL(y_true, y_hat):</span>
<span id="cb140-10"><a href="#cb140-10"></a>  <span class="cf">return</span> <span class="op">-</span>y_hat.log_prob(y_true)</span>
<span id="cb140-11"><a href="#cb140-11"></a></span>
<span id="cb140-12"><a href="#cb140-12"></a>zipModel.<span class="bu">compile</span>(loss<span class="op">=</span>NLL)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="evaluations-are-then-likelihoods" class="slide level2">
<h2>Evaluations are then likelihoods</h2>
<div class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1"></a>zipModel.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">3</span>, verbose<span class="op">=</span><span class="dv">0</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1"></a>model.evaluate(X_val, y_val, verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>0.21083223819732666</code></pre>
</div>
</div>
<div class="cell" data-execution_count="91">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1"></a>zipModel.evaluate(X_val, y_val, verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="91">
<pre><code>0.21178053319454193</code></pre>
</div>
</div>
<div class="smaller">
<blockquote>
<p>In statistics, sometimes we only use a single data set. To still be able to evaluate the performance of the developed prediction model on the same data, sophisticated methods have developed over a long period of time and are still in use in some parts of the statistics community. These methods account for the fact that the model saw the data during fitting and applied corrections to account for that. These methods include, for example, the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC). Don’t get confused. If you have a validation set, you don’t need these methods.</p>
</blockquote>
</div>
<div class="footer">
<p>Source: Sic &amp; Duerr (2020), Probabilistic Deep Learning, Chapter 5.</p>
</div>
</section>
<section id="huggingfaces-transformers" class="slide level2">
<h2>HuggingFace’s Transformers</h2>
<div class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1"></a><span class="im">import</span> transformers</span>
<span id="cb146-2"><a href="#cb146-2"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb146-3"><a href="#cb146-3"></a>generator <span class="op">=</span> pipeline(task<span class="op">=</span><span class="st">"text-generation"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1"></a>transformers.set_seed(<span class="dv">1</span>)</span>
<span id="cb147-2"><a href="#cb147-2"></a><span class="bu">print</span>(generator(<span class="st">"It's the holidays so I'm going to enjoy"</span>)[<span class="dv">0</span>][<span class="st">"generated_text"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>It's the holidays so I'm going to enjoy the rest of the time and look forward to this week with new friends!"</code></pre>
</div>
</div>
<div class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1"></a>transformers.set_seed(<span class="dv">1337</span>)</span>
<span id="cb149-2"><a href="#cb149-2"></a><span class="bu">print</span>(generator(<span class="st">"It's the holidays so I'm going to enjoy"</span>)[<span class="dv">0</span>][<span class="st">"generated_text"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>It's the holidays so I'm going to enjoy working as much as possible," he told ABC Radio's Today.

On Thursday, Labor leader Bill Shorten made another announcement about his party's plans for the 2015 ballot.

"We</code></pre>
</div>
</div>
</section>
<section id="reading-the-course-profile" class="slide level2">
<h2>Reading the course profile</h2>
<div class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1"></a>context <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb151-2"><a href="#cb151-2"></a><span class="st">StoryWall Formative Discussions: An initial StoryWall, worth 2%, is due by noon on June 3. The following StoryWalls are worth 4</span><span class="sc">% e</span><span class="st">ach (taking the best 7 of 9) and are due at noon on the following dates:</span></span>
<span id="cb151-3"><a href="#cb151-3"></a><span class="st">The project will be submitted in stages: draft due at noon on July 1 (10%), recorded presentation due at noon on July 22 (15%), final report due at noon on August 1 (15%).</span></span>
<span id="cb151-4"><a href="#cb151-4"></a></span>
<span id="cb151-5"><a href="#cb151-5"></a><span class="st">As a student at UNSW you are expected to display academic integrity in your work and interactions. Where a student breaches the UNSW Student Code with respect to academic integrity, the University may take disciplinary action under the Student Misconduct Procedure. To assure academic integrity, you may be required to demonstrate reasoning, research and the process of constructing work submitted for assessment.</span></span>
<span id="cb151-6"><a href="#cb151-6"></a><span class="st">To assist you in understanding what academic integrity means, and how to ensure that you do comply with the UNSW Student Code, it is strongly recommended that you complete the Working with Academic Integrity module before submitting your first assessment task. It is a free, online self-paced Moodle module that should take about one hour to complete.</span></span>
<span id="cb151-7"><a href="#cb151-7"></a></span>
<span id="cb151-8"><a href="#cb151-8"></a><span class="st">StoryWall (30%)</span></span>
<span id="cb151-9"><a href="#cb151-9"></a></span>
<span id="cb151-10"><a href="#cb151-10"></a><span class="st">The StoryWall format will be used for small weekly questions. Each week of questions will be released on a Monday, and most of them will be due the following Monday at midday (see assessment table for exact dates). Students will upload their responses to the question sets, and give comments on another student's submission. Each week will be worth 4%, and the grading is pass/fail, with the best 7 of 9 being counted. The first week's basic 'introduction' StoryWall post is counted separately and is worth 2%.</span></span>
<span id="cb151-11"><a href="#cb151-11"></a></span>
<span id="cb151-12"><a href="#cb151-12"></a><span class="st">Project (40%)</span></span>
<span id="cb151-13"><a href="#cb151-13"></a></span>
<span id="cb151-14"><a href="#cb151-14"></a><span class="st">Over the term, students will complete an individual project. There will be a selection of deep learning topics to choose from (this will be outlined during Week 1).</span></span>
<span id="cb151-15"><a href="#cb151-15"></a></span>
<span id="cb151-16"><a href="#cb151-16"></a><span class="st">The deliverables for the project will include: a draft/progress report mid-way through the term, a presentation (recorded), a final report including a written summary of the project and the relevant Python code (Jupyter notebook).</span></span>
<span id="cb151-17"><a href="#cb151-17"></a></span>
<span id="cb151-18"><a href="#cb151-18"></a><span class="st">Exam (30%)</span></span>
<span id="cb151-19"><a href="#cb151-19"></a></span>
<span id="cb151-20"><a href="#cb151-20"></a><span class="st">The exam will test the concepts presented in the lectures. For example, students will be expected to: provide definitions for various deep learning terminology, suggest neural network designs to solve risk and actuarial problems, give advice to mock deep learning engineers whose projects have hit common roadblocks, find/explain common bugs in deep learning Python code.</span></span>
<span id="cb151-21"><a href="#cb151-21"></a><span class="st">"""</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="question-answering" class="slide level2">
<h2>Question answering</h2>
<div class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1"></a>qa <span class="op">=</span> pipeline(<span class="st">"question-answering"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1"></a>qa(question<span class="op">=</span><span class="st">"What weight is the exam?"</span>, context<span class="op">=</span>context)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>{'score': 0.5968161821365356, 'start': 2092, 'end': 2095, 'answer': '30%'}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1"></a>qa(question<span class="op">=</span><span class="st">"What topics are in the exam?"</span>, context<span class="op">=</span>context)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="98">
<pre><code>{'score': 0.563531756401062,
 'start': 1778,
 'end': 1791,
 'answer': 'deep learning'}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1"></a>qa(question<span class="op">=</span><span class="st">"When is the presentation due?"</span>, context<span class="op">=</span>context)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="99">
<pre><code>{'score': 0.6302009224891663,
 'start': 1319,
 'end': 1335,
 'answer': 'Monday at midday'}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1"></a>qa(question<span class="op">=</span><span class="st">"How many StoryWall tasks are there?"</span>, context<span class="op">=</span>context)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="100">
<pre><code>{'score': 0.47484666109085083, 'start': 1155, 'end': 1158, 'answer': '30%'}</code></pre>
</div>
</div>
</section>
<section id="recommended-reading" class="slide level2 smaller">
<h2>Recommended reading</h2>
<ul>
<li>The Verge (2022), <a href="https://www.theverge.com/c/23194235/ai-fiction-writing-amazon-kindle-sudowrite-jasper">The Great Fiction of AI: The strange world of high-speed semi-automated genre fiction</a></li>
<li>Vaswani et al.&nbsp;(2017), <a href="https://arxiv.org/pdf/1706.03762.pdf">Attention Is All You Need</a>, NeurIPS</li>
<li>Bommasani et al.&nbsp;(2021), <a href="https://arxiv.org/pdf/2108.07258.pdf">On the Opportunities and Risks of Foundation Models</a></li>
<li>Gary Marcus (2022), <a href="https://nautil.us/deep-learning-is-hitting-a-wall-14467/">Deep Learning Is Hitting a Wall</a>, Nautilus article</li>
<li>SDS 564, <a href="https://podcasts.apple.com/au/podcast/super-data-science/id1163599059?i=1000556643700">Clem Delangue on Hugging Face and Transformers</a></li>
<li>SDS 559, <a href="https://podcasts.apple.com/au/podcast/super-data-science/id1163599059?i=1000554847681">GPT-3 for Natural Language Processing</a></li>
<li>Computerphile (2019), <a href="https://youtu.be/rURRYI66E54">AI Language Models &amp; Transformers</a> (20m)</li>
<li>Computerphile (2020), <a href="https://youtu.be/_8yVOC4ciXc">GPT3: An Even Bigger Language Model</a> (25m)</li>
<li>Nicholas Renotte (2021), <a href="https://youtu.be/JctmnczWg0U">AI Blog Post Summarization with Hugging Face Transformers…</a> (33m)</li>
<li>Seattle Applied Deep Learning (2019), <a href="https://youtu.be/S27pHKBEp30">LSTM is dead. Long Live Transformers!</a> (28m)</li>
</ul>
</section></section>
<section>
<section id="revision" class="title-slide slide level1 center" data-background-image="unsw-yellow-shape.png" data-visibility="uncounted">
<h1>Revision</h1>

</section>
<section id="lecture-1-ai" class="slide level2">
<h2>Lecture 1: AI</h2>
<div class="columns">
<div class="column">
<ul>
<li>artificial intelligence</li>
<li><del>Deep Blue</del></li>
<li>default arguments</li>
<li>dictionaries</li>
<li>f-strings</li>
<li>function definitions</li>
<li><del>Google Colaboratory</del></li>
<li><del><code>help</code></del></li>
<li>list</li>
</ul>
</div><div class="column">
<ul>
<li><del>minimax algorithm</del></li>
<li><del><code>pip install ...</code></del></li>
<li><strong>pseudocode</strong></li>
<li><code>range</code></li>
<li>slicing</li>
<li>tuple</li>
<li><del><code>type</code></del></li>
<li>whitespace indentation</li>
<li>zero-indexing</li>
</ul>
</div>
</div>
</section>
<section id="lecture-2-deep-learning" class="slide level2 smaller">
<h2>Lecture 2: Deep Learning</h2>
<div class="columns">
<div class="column">
<ul>
<li><strong>activations, activation function</strong></li>
<li>artificial intelligence vs machine learning</li>
<li>artificial neural network</li>
<li>biases (in neurons)</li>
<li>classification problem</li>
<li><strong>cost/loss function</strong></li>
<li>deep network, network depth</li>
<li>dense or fully-connected layer</li>
<li>epoch</li>
<li>feed-forward neural network</li>
<li><del>Keras, Tensorflow, PyTorch</del></li>
</ul>
</div><div class="column">
<ul>
<li>labelled/unlabelled data</li>
<li>machine learning</li>
<li><del>matplotlib, seaborn</del></li>
<li><strong>neural network architecture</strong></li>
<li>perceptron</li>
<li>ReLU</li>
<li>representation learning</li>
<li>sigmoid activation function</li>
<li>targets</li>
<li><del>training/test split</del></li>
<li>universal approximation theorem</li>
<li>weights (in a neuron)</li>
</ul>
</div>
</div>
</section>
<section id="lecture-3-math-of-deep-learning" class="slide level2">
<h2>Lecture 3: Math of Deep Learning</h2>
<div class="columns">
<div class="column">
<ul>
<li>accuracy</li>
<li>batches, batch size</li>
<li>callbacks</li>
<li>cross-entropy loss</li>
<li><strong>early stopping</strong></li>
<li>gradient-based learning, hill-climbing</li>
</ul>
</div><div class="column">
<ul>
<li>metrics</li>
<li><strong>overfitting</strong></li>
<li>shallow neural network</li>
<li>stochastic (mini-batch) gradient descent</li>
<li><strong>training/validation/test split</strong></li>
</ul>
</div>
</div>
<div class="callout callout-tip callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p>See this set of slides for an example of <a href="https://pat-laub.github.io/DeepLearningMaterials/Lecture-5-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#/dense-layers-in-matrices">calculating the output of a dense layer</a>.</p>
</div>
</div>
</div>
</section>
<section id="lecture-4-tabular-data" class="slide level2">
<h2>Lecture 4: Tabular Data</h2>
<div class="columns">
<div class="column">
<ul>
<li>confusion matrix</li>
<li>dead ReLU neurons</li>
<li>dropout</li>
<li>ensemble model</li>
<li><strong>entity embeddings</strong></li>
<li>Input layer</li>
<li>Keras eager execution</li>
<li>Keras functional API</li>
</ul>
</div><div class="column">
<ul>
<li><span class="math inline">\(\ell_1\)</span> &amp; <span class="math inline">\(\ell_2\)</span> regularisation</li>
<li>leaky ReLU</li>
<li>Monte Carlo dropout</li>
<li>regularisation</li>
<li>Reshape layer</li>
<li>skip connection</li>
<li>wide &amp; deep network structure</li>
</ul>
</div>
</div>
</section>
<section id="lecture-5-rnns" class="slide level2">
<h2>Lecture 5: RNNs</h2>
<ul>
<li>dimensions (tensor)</li>
<li>GRU</li>
<li>LSTM</li>
<li>rank (tensor)</li>
<li>recurrent neural networks</li>
<li>SimpleRNN</li>
</ul>
</section>
<section id="lecture-6-cnns" class="slide level2">
<h2>Lecture 6: CNNs</h2>
<div class="columns">
<div class="column">
<ul>
<li>channels</li>
<li>computer vision</li>
<li>convolutional layer &amp; CNN</li>
<li>error analysis</li>
<li>filter</li>
</ul>
</div><div class="column">
<ul>
<li>flatten layer</li>
<li>kernel</li>
<li>max pooling</li>
<li>MNIST</li>
<li>stride</li>
</ul>
</div>
</div>
</section>
<section id="lecture-7-nlp" class="slide level2">
<h2>Lecture 7: NLP</h2>
<div class="columns">
<div class="column">
<ul>
<li><del>AlexNet</del></li>
<li>bag of words</li>
<li><del>CIFAR-10 / CIFAR-100</del></li>
<li><del>GoogLeNet &amp; Inception</del></li>
<li>ImageNet</li>
</ul>
</div><div class="column">
<ul>
<li>fine-tuning</li>
<li>lemmatization</li>
<li>one-hot embedding</li>
<li><strong>transfer learning</strong></li>
<li>vocabulary</li>
</ul>
</div>
</div>
</section>
<section id="lecture-8-generative-networks" class="slide level2">
<h2>Lecture 8: Generative Networks</h2>
<div class="columns">
<div class="column">
<ul>
<li>autoencoder</li>
<li>bias</li>
<li><del>DeepDream</del></li>
<li>greedy sampling</li>
<li><del>GloVe</del></li>
<li><del>Grad-CAM</del></li>
<li>language model</li>
</ul>
</div><div class="column">
<ul>
<li>latent space</li>
<li><del>neural style transfer</del></li>
<li><del>softmax temperature</del></li>
<li>stochastic sampling</li>
<li><strong>word embeddings/vectors</strong></li>
<li>word2vec</li>
</ul>
</div>
</div>
</section>
<section id="lecture-9" class="slide level2">
<h2>Lecture 9</h2>
<ul>
<li><strong>Dissecting <code>model.fit</code></strong></li>
<li><del>Object oriented programming &amp; PyTorch</del></li>
<li>Generative adversarial networks</li>
</ul>
</section>
<section id="storywalls" class="slide level2 smaller">
<h2>StoryWalls</h2>
<ol type="1">
<li>Chess AI: Basic Python</li>
<li>French motor #1: Basic feed-forward networks</li>
<li>Stroke prediction: Classification network, preprocessing (one-hot encoding)</li>
<li><strong>French motor #2</strong>: Entity embeddings</li>
<li><strong>Stock price prediction</strong>: Recurrent neural networks</li>
<li><a href="https://colab.research.google.com/drive/1WX3UQ9pLfHYiUXZ8o5DcAOQj6-AGdo5M?usp=sharing"><strong>Hurricane damage</strong></a>: Convolutional neural networks and hyperparameter tuning</li>
<li><strong>Police reports</strong>: NLP with bag-of-words, TF-IDF.</li>
<li>Generative networks experimenting</li>
<li>Reflection</li>
</ol>
<script defer="">
    // Remove the highlight.js class for the 'compile', 'min', 'max'
    // as there's a bug where they are treated like the Python built-in
    // global functions but we only ever see it as methods like
    // 'model.compile()' or 'predictions.max()'
    buggyBuiltIns = ["abs", "compile", "eval", "min", "max", "round", "sum"];

    document.querySelectorAll('.bu').forEach((elem) => {
        if (buggyBuiltIns.includes(elem.innerHTML)) {
            elem.classList.remove('bu');
        }
    })

    var registerRevealCallbacks = function() {
        Reveal.on('overviewshown', event => {
            document.querySelector(".line.right").hidden = true;
        });
        Reveal.on('overviewhidden', event => {
            document.querySelector(".line.right").hidden = false;
        });
    };
</script>

<img src="unsw-logo.svg" class="slide-logo r-stretch"><div class="footer footer-default">
<p>Slides: <a href="https://pat-laub.github.io">Dr Patrick Laub</a> (<span class="citation" data-cites="PatrickLaub">@PatrickLaub</span>).</p>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="advanced-topics_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="advanced-topics_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="advanced-topics_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="advanced-topics_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="advanced-topics_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="advanced-topics_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="advanced-topics_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="advanced-topics_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="advanced-topics_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="advanced-topics_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="advanced-topics_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true,"boardmarkerWidth":6,"grid":false,"background":["rgba(255,255,255,0.0)","https://github.com/rajgoel/reveal.js-plugins/raw/master/chalkboard/img/blackboard.png"]},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.2,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        setTimeout(function() {
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const cites = ref.parentNode.getAttribute('data-cites').split(' ');
        tippyHover(ref, function() {
          var popup = window.document.createElement('div');
          cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    });
    </script>
    <script>registerRevealCallbacks();</script>
    

</body></html>