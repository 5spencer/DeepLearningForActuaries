<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Eric Dong &amp; Patrick Laub">

<title>AI for Actuaries - Interpretability</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../Lecture-8-Generative-Networks/generative-networks.html" rel="next">
<link href="../Labs/distributional-forecasting-lab.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../Lecture-9-Advanced-Topics/interpretability.html">Module 7</a></li><li class="breadcrumb-item"><a href="../Lecture-9-Advanced-Topics/interpretability.html">Interpretability</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">AI for Actuaries</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Module 1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Lecture-1-Artificial-Intelligence/course-overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Lecture-1-Artificial-Intelligence/artificial-intelligence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Artificial Intelligence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Lecture-1-Artificial-Intelligence/python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/python-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: Intro Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/python-for-data-science-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: Python for Data Science</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Exercises/chess-ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercise: Chess AI</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Module 2</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Lecture-2-Deep-Learning-Keras/deep-learning-keras.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deep Learning with Keras</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Lecture-2-Deep-Learning-Keras/project.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project Details</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Lecture-3-Tabular-Data/categorical-variables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Categorical Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Lecture-3-Tabular-Data/classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/matplotlib-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: Matplotlib</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/forward-pass-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: Forward Pass</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Exercises/victorian-crash-severity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercise: Victorian Car Crash Severity</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Module 3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Lecture-4-Computer-Vision/computer-vision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Computer Vision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/latex-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: LaTeX</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/optimisation-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: Optimisation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Exercises/hurricane-damage.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercise: Aerial Photos of Hurricane Damage</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Module 4</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Lecture-5-Natural-Language-Processing/natural-language-processing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Natural Language Processing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Exercises/police-reports.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercise: Police Reports of US Car Crashes</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Module 5</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recurrent Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Exercises/sydney-airport-temperature.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercise: Sydney Temperature Forecasting</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Module 6</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Distributional Forecasting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/backpropagation-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: Backpropagation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/distributional-forecasting-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: Distributional Forecasting</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">Module 7</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Lecture-9-Advanced-Topics/interpretability.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Interpretability</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">Module 8</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Lecture-8-Generative-Networks/generative-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Generative Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Lecture-8-Generative-Networks/gans.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Generative Adversarial Networks</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
 <span class="menu-text">Module 9</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Lecture-9-Advanced-Topics/next-steps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Next Steps</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#interpretability" id="toc-interpretability" class="nav-link active" data-scroll-target="#interpretability">Interpretability</a>
  <ul class="collapse">
  <li><a href="#interpretability-and-trust" id="toc-interpretability-and-trust" class="nav-link" data-scroll-target="#interpretability-and-trust">Interpretability and Trust</a></li>
  <li><a href="#interpretability-1" id="toc-interpretability-1" class="nav-link" data-scroll-target="#interpretability-1">Interpretability</a></li>
  <li><a href="#first-dimension-of-interpretability" id="toc-first-dimension-of-interpretability" class="nav-link" data-scroll-target="#first-dimension-of-interpretability">First Dimension of Interpretability</a></li>
  <li><a href="#second-dimension-of-interpretability" id="toc-second-dimension-of-interpretability" class="nav-link" data-scroll-target="#second-dimension-of-interpretability">Second Dimension of Interpretability</a></li>
  </ul></li>
  <li><a href="#inherent-interpretability" id="toc-inherent-interpretability" class="nav-link" data-scroll-target="#inherent-interpretability">Inherent Interpretability</a>
  <ul class="collapse">
  <li><a href="#trees-are-interpretable" id="toc-trees-are-interpretable" class="nav-link" data-scroll-target="#trees-are-interpretable">Trees are interpretable!</a></li>
  <li><a href="#trees-are-interpretable-1" id="toc-trees-are-interpretable-1" class="nav-link" data-scroll-target="#trees-are-interpretable-1">Trees are interpretable?</a></li>
  <li><a href="#linear-models" id="toc-linear-models" class="nav-link" data-scroll-target="#linear-models">Linear models</a></li>
  <li><a href="#localglmnet" id="toc-localglmnet" class="nav-link" data-scroll-target="#localglmnet">LocalGLMNet</a></li>
  </ul></li>
  <li><a href="#post-hoc-interpretability" id="toc-post-hoc-interpretability" class="nav-link" data-scroll-target="#post-hoc-interpretability">Post-hoc Interpretability</a>
  <ul class="collapse">
  <li><a href="#permutation-importance" id="toc-permutation-importance" class="nav-link" data-scroll-target="#permutation-importance">Permutation importance</a></li>
  <li><a href="#permutation-importance-1" id="toc-permutation-importance-1" class="nav-link" data-scroll-target="#permutation-importance-1">Permutation importance</a></li>
  <li><a href="#lime" id="toc-lime" class="nav-link" data-scroll-target="#lime">LIME</a></li>
  <li><a href="#globally-vs.-locally-faithful" id="toc-globally-vs.-locally-faithful" class="nav-link" data-scroll-target="#globally-vs.-locally-faithful">Globally vs.&nbsp;Locally Faithful</a></li>
  <li><a href="#lime-algorithm" id="toc-lime-algorithm" class="nav-link" data-scroll-target="#lime-algorithm">LIME Algorithm</a></li>
  <li><a href="#lime-algorithm-1" id="toc-lime-algorithm-1" class="nav-link" data-scroll-target="#lime-algorithm-1">LIME Algorithm</a></li>
  <li><a href="#explaining-to-bob" id="toc-explaining-to-bob" class="nav-link" data-scroll-target="#explaining-to-bob">“Explaining” to Bob</a></li>
  <li><a href="#shap-values" id="toc-shap-values" class="nav-link" data-scroll-target="#shap-values">SHAP Values</a></li>
  </ul></li>
  <li><a href="#explaining-specific-models" id="toc-explaining-specific-models" class="nav-link" data-scroll-target="#explaining-specific-models">Explaining Specific Models</a>
  <ul class="collapse">
  <li><a href="#grad-cam" id="toc-grad-cam" class="nav-link" data-scroll-target="#grad-cam">Grad-CAM</a></li>
  
  
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="interpretability.slides.html"><i class="bi bi-file-slides"></i>RevealJS</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../Lecture-9-Advanced-Topics/interpretability.html">Module 7</a></li><li class="breadcrumb-item"><a href="../Lecture-9-Advanced-Topics/interpretability.html">Interpretability</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Interpretability</h1>
<p class="subtitle lead">ACTL3143 &amp; ACTL5111 Deep Learning for Actuaries</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Eric Dong &amp; Patrick Laub </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<div id="07b85a67" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Show the package imports</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy.random <span class="im">as</span> rnd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="interpretability" class="level2" data-visibility="uncounted">
<h2 data-visibility="uncounted" class="anchored" data-anchor-id="interpretability">Interpretability</h2>
<p>Interpretability on a high-level refers to understanding how a model works. Understanding how a model works is very important for decision making. Traditional statistical methods like linear regression and generalized linear regressions are inherently interpretable because we can see and understand how different variables impact the model predictions collectively and individually. In contrast, deep learning algorithms do not readily provide insights into how variables contributed to the predictions. They are composed of multiple layers of interconnected nodes that learn different representations of data. Hence, it is not clear how inputs directly contributed to the outputs. This makes neural networks less interpretable. This is not very desirable, especially in situations which demand making explanations. As such, there is active discussion going on about how we can make less interpretable models more interpretable so that we start trusting these models more.</p>
<section id="interpretability-and-trust" class="level3">
<h3 class="anchored" data-anchor-id="interpretability-and-trust">Interpretability and Trust</h3>
<p>Suppose a neural network informs us to increase the premium for Bob.</p>
<ul>
<li>Why are we getting such a conclusion from the neural network, and should we trust it?</li>
<li>How can we explain our pricing scheme to Bob and the regulators?</li>
<li>Should we be concerned with moral hazards, discrimination, unfairness, and ethical affairs?</li>
</ul>
<p>We need to trust the model to employ it! With interpretability, we can trust it!</p>
</section>
<section id="interpretability-1" class="level3">
<h3 class="anchored" data-anchor-id="interpretability-1">Interpretability</h3>
<dl>
<dt>Interpretability Definition</dt>
<dd>
<p><em>Interpretability refers to the ease with which one can understand and comprehend the model’s algorithm and predictions.</em></p>
</dd>
</dl>
<p>Interpretability of black-box models can be crucial to ascertaining trust.</p>
</section>
<section id="first-dimension-of-interpretability" class="level3">
<h3 class="anchored" data-anchor-id="first-dimension-of-interpretability">First Dimension of Interpretability</h3>
<dl>
<dt>Inherent Interpretability</dt>
<dd>
<p><em>The model is interpretable by design.</em></p>
</dd>
</dl>
<p>Models with inherent interpretability generally have a simple model architecture where the relationships between inputs and outputs are straightforward. This makes it easy to understand and comprehend model’s inner workings and its predictions. As a result, decision making processes convenient. Examples for models with inherent interpretability include linear regression models, generalized linear regression models and decision trees.</p>
<dl>
<dt>Post-hoc Interpretability</dt>
<dd>
<p><em>The model is not interpretable by design, but we can use other methods to explain the model.</em></p>
</dd>
</dl>
<p>Post-hoc interpretability refers to applying various techniques to understand how the model makes its predictions after the model is trained. Post-hoc interpretability is useful for understanding predictions coming from complex models (less interpretable models) such as neural networks, random forests and gradient boosting trees.</p>
</section>
<section id="second-dimension-of-interpretability" class="level3">
<h3 class="anchored" data-anchor-id="second-dimension-of-interpretability">Second Dimension of Interpretability</h3>
<p>Global Interpretability:</p>
<ul>
<li><em>The ability to understand how the model works.</em></li>
<li>Example: how each feature impacts the overall mean prediction.</li>
</ul>
<p>Global Interpretability focuses on understanding the model’s decision-making process as a whole. Global interpretability takes in to account the entire dataset. These techniques will try to look at general patterns related how input data drives the output in general. Examples for techniques include global feature importance method and permutation importance methods.</p>
<p>Local Interpretability:</p>
<ul>
<li><em>The ability to interpret/understand each prediction.</em></li>
<li>Example: how Bob’s mean prediction has increased the most.</li>
</ul>
<p>Local Interpretability focuses on understanding the model’s decision-making for a specific input observation. These techniques will try to look at how different input features contributed to the output.</p>
</section>
</section>
<section id="inherent-interpretability" class="level2" data-visibility="uncounted">
<h2 data-visibility="uncounted" class="anchored" data-anchor-id="inherent-interpretability">Inherent Interpretability</h2>
<hr>
<p><img src="stop-explaining-black-box.png" class="img-fluid"></p>
<div class="footer">
<p>Rudin (2019), <a href="https://arxiv.org/pdf/1811.10154.pdf">Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead</a>, Nature Machine Intelligence.</p>
</div>
<section id="trees-are-interpretable" class="level3">
<h3 class="anchored" data-anchor-id="trees-are-interpretable">Trees are interpretable!</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="opal-train-pricing-tree.png" class="img-fluid figure-img"></p>
<figcaption>Train prices</figcaption>
</figure>
</div>
</section>
<section id="trees-are-interpretable-1" class="level3">
<h3 class="anchored" data-anchor-id="trees-are-interpretable-1">Trees are interpretable?</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="opal-train-pricing-full-tree.png" class="img-fluid figure-img"></p>
<figcaption>Full train pricing</figcaption>
</figure>
</div>
</section>
<section id="linear-models" class="level3">
<h3 class="anchored" data-anchor-id="linear-models">Linear models</h3>
<p>A GLM has the form</p>
<p><span class="math display">
\hat{y} = g^{-1}\bigl( \beta_0 + \beta_1 x_1 + \dots + \beta_p x_p \bigr)
</span></p>
<p>where <span class="math inline">\beta_0, \dots, \beta_p</span> are the model parameters.</p>
<p>Global &amp; local interpretations are easy to obtain.</p>
<p>The above GLM representation provides a clear interpretation of how a marginal change in a variable <span class="math inline">x</span> can contribute to a change in the mean of the output. This makes GLM inherently interpretable.</p>
</section>
<section id="localglmnet" class="level3">
<h3 class="anchored" data-anchor-id="localglmnet">LocalGLMNet</h3>
<p>Imagine: <span class="math display">
\hat{y_i} = g^{-1}\bigl( \beta_0(\boldsymbol{x}_i) + \beta_1(\boldsymbol{x}_i) x_{i1} + \dots + \beta_p(\boldsymbol{x}_i) x_{ip} \bigr)
</span></p>
<p>A GLM with local parameters <span class="math inline">\beta_0(\boldsymbol{x}_i), \dots, \beta_p(\boldsymbol{x}_i)</span> for each observation <span class="math inline">\boldsymbol{x}_i</span>.</p>
<p>The local parameters are the output of a neural network.</p>
<p>Here, <span class="math inline">\beta_p</span>’s are the neurons from the output layer. First, we define a Feed Foward Neural Network using an input layer, several hidden layers and an output layer. The number of neurons in the output layer must be equal to the number of inputs. Thereafter, we define a skip connection from the input layer directly to the output layer, and merge them using scaler multiplication. Thereafter, the neural network returns the coefficients of the GLM fitted for each individual. We then train the model with the <em>response</em> variable.</p>
</section>
</section>
<section id="post-hoc-interpretability" class="level2" data-visibility="uncounted">
<h2 data-visibility="uncounted" class="anchored" data-anchor-id="post-hoc-interpretability">Post-hoc Interpretability</h2>
<section id="permutation-importance" class="level3 smaller">
<h3 class="smaller anchored" data-anchor-id="permutation-importance">Permutation importance</h3>
<ul>
<li><p>Inputs: fitted model <span class="math inline">m</span>, tabular dataset <span class="math inline">D</span>.</p></li>
<li><p>Compute the reference score <span class="math inline">s</span> of the model <span class="math inline">m</span> on data <span class="math inline">D</span> (for instance the accuracy for a classifier or the <span class="math inline">R^2</span> for a regressor).</p></li>
<li><p>For each feature <span class="math inline">j</span> (column of <span class="math inline">D</span>):</p>
<ul>
<li><p>For each repetition <span class="math inline">k</span> in <span class="math inline">{1, \dots, K}</span>:</p>
<ul>
<li>Randomly shuffle column <span class="math inline">j</span> of dataset <span class="math inline">D</span> to generate a corrupted version of the data named <span class="math inline">\tilde{D}_{k,j}</span>.</li>
<li>Compute the score <span class="math inline">s_{k,j}</span> of model <span class="math inline">m</span> on corrupted data <span class="math inline">\tilde{D}_{k,j}</span>.</li>
</ul></li>
<li><p>Compute importance <span class="math inline">i_j</span> for feature <span class="math inline">f_j</span> defined as:</p>
<p><span class="math display"> i_j = s - \frac{1}{K} \sum_{k=1}^{K} s_{k,j} </span></p></li>
</ul></li>
</ul>
<div class="footer">
<p>Source: scikit-learn documentation, <a href="https://scikit-learn.org/stable/modules/permutation_importance.html">permutation_importance function</a>.</p>
</div>
</section>
<section id="permutation-importance-1" class="level3" data-visibility="uncounted">
<h3 data-visibility="uncounted" class="anchored" data-anchor-id="permutation-importance-1">Permutation importance</h3>
<div id="596b835a" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> permutation_test(model, X, y, num_reps<span class="op">=</span><span class="dv">1</span>, seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Run the permutation test for variable importance.</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns matrix of shape (X.shape[1], len(model.evaluate(X, y))).</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    rnd.seed(seed)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> []    </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(X.shape[<span class="dv">1</span>]):</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        original_column <span class="op">=</span> np.copy(X[:, j])</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        col_scores <span class="op">=</span> []</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> r <span class="kw">in</span> <span class="bu">range</span>(num_reps):</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>            rnd.shuffle(X[:,j])</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>            col_scores.append(model.evaluate(X, y, verbose<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        scores.append(np.mean(col_scores, axis<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        X[:,j] <span class="op">=</span> original_column</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(scores)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="lime" class="level3">
<h3 class="anchored" data-anchor-id="lime">LIME</h3>
<p><em>Local Interpretable Model-agnostic Explanations</em> employs an interpretable surrogate model to explain locally how the black-box model makes predictions for individual instances.</p>
<p>E.g. a black-box model predicts Bob’s premium as the highest among all policyholders. LIME uses an interpretable model (a linear regression) to explain how Bob’s features influence the black-box model’s prediction.</p>
<div class="footer">
<p>Cf. <a href="https://youtu.be/hUnRCxnydCc">“Why Should I Trust You?”: Explaining the Predictions of Any Classifier</a>.</p>
</div>
</section>
<section id="globally-vs.-locally-faithful" class="level3">
<h3 class="anchored" data-anchor-id="globally-vs.-locally-faithful">Globally vs.&nbsp;Locally Faithful</h3>
<dl>
<dt>Globally Faithful</dt>
<dd>
<p><em>The interpretable model’s explanations accurately reflect the behaviour of the black-box model across the entire input space.</em></p>
</dd>
<dt>Locally Faithful</dt>
<dd>
<p><em>The interpretable model’s explanations accurately reflect the behaviour of the black-box model for a specific instance.</em></p>
</dd>
</dl>
<p>LIME aims to construct an interpretable model that mimics the black-box model’s behaviour in a <em>locally faithful</em> manner.</p>
</section>
<section id="lime-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="lime-algorithm">LIME Algorithm</h3>
<p>Suppose we want to explain the instance <span class="math inline">\boldsymbol{x}_{\text{Bob}}=(1, 2, 0.5)</span>.</p>
<ol type="1">
<li>Generate perturbed examples of <span class="math inline">\boldsymbol{x}_{\text{Bob}}</span> and use the trained gamma MDN <span class="math inline">f</span> to make predictions: <span class="math display">
\begin{align*}
  \boldsymbol{x}^{'(1)}_{\text{Bob}} &amp;= (1.1, 1.9, 0.6), \quad f\big(\boldsymbol{x}^{'(1)}_{\text{Bob}}\big)=34000 \\
  \boldsymbol{x}^{'(2)}_{\text{Bob}} &amp;= (0.8, 2.1, 0.4), \quad f\big(\boldsymbol{x}^{'(2)}_{\text{Bob}}\big)=31000 \\
  &amp;\vdots \quad \quad \quad \quad\quad \quad\quad \quad\quad \quad \quad \vdots
\end{align*}</span> We can then construct a dataset of <span class="math inline">N_{\text{Examples}}</span> perturbed examples: <span class="math inline">\mathcal{D}_{\text{LIME}} = \big(\big\{\boldsymbol{x}^{'(i)}_{\text{Bob}},f\big(\boldsymbol{x}^{'(i)}_{\text{Bob}}\big)\big\}\big)_{i=0}^{N_{\text{Examples}}}</span>.</li>
</ol>
</section>
<section id="lime-algorithm-1" class="level3">
<h3 class="anchored" data-anchor-id="lime-algorithm-1">LIME Algorithm</h3>
<ol start="2" type="1">
<li>Fit an interpretable model <span class="math inline">g</span>, i.e., a linear regression using <span class="math inline">\mathcal{D}_{\text{LIME}}</span> and the following loss function: <span class="math display">\mathcal{L}_{\text{LIME}}(f,g,\pi_{\boldsymbol{x}_{\text{Bob}}})=\sum_{i=1}^{N_{\text{Examples}}}\pi_{\boldsymbol{x}_{\text{Bob}}}\big(\boldsymbol{x}^{'(i)}_{\text{Bob}}\big)\cdot \bigg(f\big(\boldsymbol{x}^{'(i)}_{\text{Bob}}\big)-g\big(\boldsymbol{x}^{'(i)}_{\text{Bob}}\big)\bigg)^2,</span> where <span class="math inline">\pi_{\boldsymbol{x}_{\text{Bob}}}\big(\boldsymbol{x}^{'(i)}_{\text{Bob}}\big)</span> represents the distance from the perturbed example <span class="math inline">\boldsymbol{x}^{'(i)}_{\text{Bob}}</span> to the instance to be explained <span class="math inline">\boldsymbol{x}_{\text{Bob}}</span>.</li>
</ol>
</section>
<section id="explaining-to-bob" class="level3 smaller">
<h3 class="smaller anchored" data-anchor-id="explaining-to-bob">“Explaining” to Bob</h3>
<div class="columns">
<div class="column" style="width:60%;">
<p><img src="./LIME_Bob.png" class="img-fluid"></p>
</div><div class="column" style="width:40%;">
<p>The bold <span style="color:red;">red</span> cross is the instance being explained. LIME samples instances (<span style="color:gray;">grey</span> nodes), gets predictions using <span class="math inline">f</span> (gamma MDN) and weighs them by the proximity to the instance being explained (represented here by size). The dashed line <span class="math inline">g</span> is the learned local explanation.</p>
</div>
</div>
</section>
<section id="shap-values" class="level3">
<h3 class="anchored" data-anchor-id="shap-values">SHAP Values</h3>
<p>The SHapley Additive exPlanations (SHAP) value helps to quantify the contribution of each feature to the prediction for a specific instance.</p>
<p>The SHAP value for the <span class="math inline">j</span>th feature is defined as <span class="math display">\begin{align*}
\text{SHAP}^{(j)}(\boldsymbol{x}) &amp;=
\sum_{U\subset \{1, ..., p\} \backslash \{j\}} \frac{1}{p}
\binom{p-1}{|U|}^{-1}
\big(\mathbb{E}[Y| \boldsymbol{x}^{(U\cup \{j\})}] - \mathbb{E}[Y|\boldsymbol{x}^{(U)}]\big),
\end{align*}
</span> where <span class="math inline">p</span> is the number of features. A positive SHAP value indicates that the variable increases the prediction value.</p>
<div class="footer">
<p>Reference: Lundberg &amp; Lee (2017), <a href="https://arxiv.org/pdf/1705.07874.pdf">A Unified Approach to Interpreting Model Predictions</a>, Advances in Neural Information Processing Systems, 30.</p>
</div>
</section>
</section>
<section id="explaining-specific-models" class="level2" data-visibility="uncounted">
<h2 data-visibility="uncounted" class="anchored" data-anchor-id="explaining-specific-models">Explaining Specific Models</h2>
<section id="grad-cam" class="level3">
<h3 class="anchored" data-anchor-id="grad-cam">Grad-CAM</h3>
<div class="columns">
<div class="column">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="fountain-square.jpg" class="img-fluid figure-img"></p>
<figcaption>Original image</figcaption>
</figure>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="cam.jpg" class="img-fluid figure-img"></p>
<figcaption>Grad-CAM</figcaption>
</figure>
</div>
</div>
</div>
<div class="footer">
<p>Cf. Chollet (2021), Deep Learning with Python, Section 9.4.3.</p>
</div>
</section>


</section>

<div id="quarto-appendix" class="default"><section id="package-versions" class="level3 appendix" data-visibility="uncounted"><h2 class="anchored quarto-appendix-heading">Package Versions</h2><div class="quarto-appendix-contents">

<div id="61c625fe" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> watermark <span class="im">import</span> watermark</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(watermark(python<span class="op">=</span><span class="va">True</span>, packages<span class="op">=</span><span class="st">"keras,matplotlib,numpy,pandas,seaborn,scipy,torch,tensorflow,tf_keras"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2024-05-13 16:52:55.852708: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-13 16:52:56.474730: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-13 16:52:57.739485: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Python implementation: CPython
Python version       : 3.11.9
IPython version      : 8.24.0

keras     : 3.3.3
matplotlib: 3.8.4
numpy     : 1.26.4
pandas    : 2.2.2
seaborn   : 0.13.2
scipy     : 1.11.0
torch     : 2.0.1
tensorflow: 2.16.1
tf_keras  : 2.16.0
</code></pre>
</div>
</div>
</div></section><section id="glossary" class="level3 appendix" data-visibility="uncounted"><h2 class="anchored quarto-appendix-heading">Glossary</h2><div class="quarto-appendix-contents">

<ul>
<li>global interpretability</li>
<li>Grad-CAM</li>
<li>inherent interpretability</li>
<li>LIME</li>
<li>local interpretability</li>
<li>permutation importance</li>
<li>post-hoc interpretability</li>
<li>SHAP values</li>
</ul>


</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../Labs/distributional-forecasting-lab.html" class="pagination-link" aria-label="Lab: Distributional Forecasting">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Lab: Distributional Forecasting</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../Lecture-8-Generative-Networks/generative-networks.html" class="pagination-link" aria-label="Generative Networks">
        <span class="nav-page-text">Generative Networks</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>