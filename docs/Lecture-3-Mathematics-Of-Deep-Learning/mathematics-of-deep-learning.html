<!DOCTYPE html>
<html lang="en"><head>
<script src="mathematics-of-deep-learning_files/libs/clipboard/clipboard.min.js"></script>
<script src="mathematics-of-deep-learning_files/libs/quarto-html/tabby.min.js"></script>
<script src="mathematics-of-deep-learning_files/libs/quarto-html/popper.min.js"></script>
<script src="mathematics-of-deep-learning_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="mathematics-of-deep-learning_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="mathematics-of-deep-learning_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="mathematics-of-deep-learning_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.2.269">

  <meta name="author" content="Dr Patrick Laub">
  <title>Mathematics of Deep Learning</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="mathematics-of-deep-learning_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="mathematics-of-deep-learning_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #1f1c1b;  }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #1f1c1b; } /* Normal */
    code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
    code span.an { color: #ca60ca; } /* Annotation */
    code span.at { color: #0057ae; } /* Attribute */
    code span.bn { color: #b08000; } /* BaseN */
    code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
    code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #924c9d; } /* Char */
    code span.cn { color: #aa5500; } /* Constant */
    code span.co { color: #898887; } /* Comment */
    code span.cv { color: #0095ff; } /* CommentVar */
    code span.do { color: #607880; } /* Documentation */
    code span.dt { color: #0057ae; } /* DataType */
    code span.dv { color: #b08000; } /* DecVal */
    code span.er { color: #bf0303; text-decoration: underline; } /* Error */
    code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
    code span.fl { color: #b08000; } /* Float */
    code span.fu { color: #644a9b; } /* Function */
    code span.im { color: #ff5500; } /* Import */
    code span.in { color: #b08000; } /* Information */
    code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
    code span.op { color: #ca60ca; } /* Operator */
    code span.ot { color: #006e28; } /* Other */
    code span.pp { color: #006e28; } /* Preprocessor */
    code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
    code span.sc { color: #3daee9; } /* SpecialChar */
    code span.ss { color: #ff5500; } /* SpecialString */
    code span.st { color: #bf0303; } /* String */
    code span.va { color: #0057ae; } /* Variable */
    code span.vs { color: #bf0303; } /* VerbatimString */
    code span.wa { color: #bf0303; } /* Warning */
  </style>
  <link rel="stylesheet" href="mathematics-of-deep-learning_files/libs/revealjs/dist/theme/quarto.css" id="theme">
  <link href="mathematics-of-deep-learning_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="mathematics-of-deep-learning_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="mathematics-of-deep-learning_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="mathematics-of-deep-learning_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="mathematics-of-deep-learning_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="mathematics-of-deep-learning_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="mathematics-of-deep-learning_files/libs/quarto-diagram/mermaid.min.js"></script>
  <script src="mathematics-of-deep-learning_files/libs/quarto-diagram/mermaid-init.js"></script>
  <link href="mathematics-of-deep-learning_files/libs/quarto-diagram/mermaid.css" rel="stylesheet">
</head>
<body class="quarto-light">
<div class="line right"></div>

<script defer="" src="https://pyscript.net/latest/pyscript.js"></script>
<py-env>
  - matplotlib
</py-env>
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="unsw-yellow-shape.png" data-background-size="contain !important" class="quarto-title-block center">
  <h1 class="title">Mathematics of Deep Learning</h1>
  <p class="subtitle">ACTL3143 &amp; ACTL5111 Deep Learning for Actuaries</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Dr Patrick Laub 
</div>
</div>
</div>

</section>
<section id="load-packages" class="slide level2" data-visibility="uncounted">
<h2>Load packages</h2>
<p><br> <br></p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> random</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-7"><a href="#cb1-7"></a></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Sequential</span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Dense</span>
<span id="cb1-11"><a href="#cb1-11"></a></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section>
<section id="dense-layers-in-matrices" class="title-slide slide level1 center" data-background-image="unsw-yellow-shape.png" data-visibility="uncounted">
<h1>Dense Layers in Matrices</h1>

</section>
<section id="logistic-regression" class="slide level2">
<h2>Logistic regression</h2>
<div class="columns">
<div class="column">
<p>Observations: <span class="math inline">\(\mathbf{x}_{i,\bullet} \in \mathbb{R}^{2}\)</span>.</p>
<p>Target: <span class="math inline">\(y_i \in \{0, 1\}\)</span>.</p>
<p>Predict: <span class="math inline">\(\hat{y}_i = \mathbb{P}(Y_i = 1)\)</span>.</p>
<p><br></p>
<p><strong>The model</strong></p>
<p>For <span class="math inline">\(\mathbf{x}_{i,\bullet} = (x_{i,1}, x_{i,2})\)</span>: <span class="math display">\[
z_i = x_{i,1} w_1 + x_{i,2} w_2 + b
\]</span></p>
<p><span class="math display">\[
\hat{y}_i = \sigma(z_i) = \frac{1}{1 + \mathrm{e}^{-z_i}} .
\]</span></p>
</div><div class="column">
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="im">import</span> sympy</span>
<span id="cb2-2"><a href="#cb2-2"></a>sympy.plot(<span class="st">"1/(1 + exp(-z))"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img data-src="mathematics-of-deep-learning_files/figure-revealjs/cell-5-output-1.png"></p>
</div>
</div>
</div>
</div>
</section>
<section id="multiple-observations" class="slide level2">
<h2>Multiple observations</h2>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>data <span class="op">=</span> pd.DataFrame({<span class="st">"x_1"</span>: [<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>], <span class="st">"x_2"</span>: [<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">6</span>], <span class="st">"y"</span>: [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>]})</span>
<span id="cb3-2"><a href="#cb3-2"></a>data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x_1</th>
      <th>x_2</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>4</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>6</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Let <span class="math inline">\(w_1 = 1\)</span>, <span class="math inline">\(w_2 = 2\)</span> and <span class="math inline">\(b = -10\)</span>.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>w_1 <span class="op">=</span> <span class="dv">1</span><span class="op">;</span> w_2 <span class="op">=</span> <span class="dv">2</span><span class="op">;</span> b <span class="op">=</span> <span class="op">-</span><span class="dv">10</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>data[<span class="st">"x_1"</span>] <span class="op">*</span> w_1 <span class="op">+</span> data[<span class="st">"x_2"</span>] <span class="op">*</span> w_2 <span class="op">+</span> b </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>0   -5
1    1
2    7
dtype: int64</code></pre>
</div>
</div>
</section>
<section id="matrix-notation" class="slide level2">
<h2>Matrix notation</h2>
<div class="columns">
<div class="column">
<p>Have <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{3 \times 2}\)</span>.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>X_df <span class="op">=</span> data[[<span class="st">"x_1"</span>, <span class="st">"x_2"</span>]]</span>
<span id="cb6-2"><a href="#cb6-2"></a>X <span class="op">=</span> X_df.to_numpy()</span>
<span id="cb6-3"><a href="#cb6-3"></a>X</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>array([[1, 2],
       [3, 4],
       [5, 6]], dtype=int64)</code></pre>
</div>
</div>
</div><div class="column">
<p>Let <span class="math inline">\(\mathbf{w} = (w_1, w_2)^\top \in \mathbb{R}^{2 \times 1}\)</span>.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a>w <span class="op">=</span> np.array([[<span class="dv">1</span>], [<span class="dv">2</span>]])</span>
<span id="cb8-2"><a href="#cb8-2"></a>w</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>array([[1],
       [2]])</code></pre>
</div>
</div>
</div>
</div>
<p><span class="math display">\[
\mathbf{z} = \mathbf{X} \mathbf{w} + b , \quad \mathbf{a} = \sigma(\mathbf{z})
\]</span></p>
<div class="columns">
<div class="column">
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a>z <span class="op">=</span> X.dot(w) <span class="op">+</span> b</span>
<span id="cb10-2"><a href="#cb10-2"></a>z</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>array([[-5],
       [ 1],
       [ 7]], dtype=int64)</code></pre>
</div>
</div>
</div><div class="column">
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a><span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>z))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>array([[0.01],
       [0.73],
       [1.  ]])</code></pre>
</div>
</div>
</div>
</div>
</section>
<section id="in-keras" class="slide level2">
<h2>In Keras</h2>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a>model <span class="op">=</span> Sequential([</span>
<span id="cb14-2"><a href="#cb14-2"></a>    Dense(<span class="dv">1</span>, input_dim<span class="op">=</span><span class="dv">2</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>),</span>
<span id="cb14-3"><a href="#cb14-3"></a>])</span>
<span id="cb14-4"><a href="#cb14-4"></a></span>
<span id="cb14-5"><a href="#cb14-5"></a>w, b <span class="op">=</span> model.get_weights()</span>
<span id="cb14-6"><a href="#cb14-6"></a><span class="bu">print</span>(<span class="ss">f"w's shape is </span><span class="sc">{</span>w<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, b's shape is </span><span class="sc">{</span>b<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>w's shape is (2, 1), b's shape is (1,)</code></pre>
</div>
</div>
<div class="columns">
<div class="column">
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a>w</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>array([[0.28],
       [1.  ]], dtype=float32)</code></pre>
</div>
</div>
</div><div class="column">
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a>b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>array([0.], dtype=float32)</code></pre>
</div>
</div>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a>model(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[0.91],
       [0.99],
       [1.  ]], dtype=float32)&gt;</code></pre>
</div>
</div>
</section>
<section id="in-keras-with-fixed-weights-bias" class="slide level2">
<h2>In Keras with fixed weights &amp; bias</h2>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a><span class="im">from</span> tensorflow.keras.initializers <span class="im">import</span> Constant</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a>model <span class="op">=</span> Sequential([</span>
<span id="cb23-2"><a href="#cb23-2"></a>    Dense(<span class="dv">1</span>, input_dim<span class="op">=</span><span class="dv">2</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>,</span>
<span id="cb23-3"><a href="#cb23-3"></a>      kernel_initializer<span class="op">=</span>Constant(value<span class="op">=</span>[<span class="fl">1.0</span>, <span class="fl">2.0</span>]),</span>
<span id="cb23-4"><a href="#cb23-4"></a>      bias_initializer<span class="op">=</span>Constant(value<span class="op">=-</span><span class="dv">10</span>))</span>
<span id="cb23-5"><a href="#cb23-5"></a>])</span>
<span id="cb23-6"><a href="#cb23-6"></a></span>
<span id="cb23-7"><a href="#cb23-7"></a>w, b <span class="op">=</span> model.get_weights()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="columns">
<div class="column">
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a>w</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>array([[1.],
       [2.]], dtype=float32)</code></pre>
</div>
</div>
</div><div class="column">
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a>b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>array([-10.], dtype=float32)</code></pre>
</div>
</div>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a>model(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[0.01],
       [0.73],
       [1.  ]], dtype=float32)&gt;</code></pre>
</div>
</div>
</section>
<section id="using-a-softmax-output" class="slide level2">
<h2>Using a softmax output</h2>
<div class="columns">
<div class="column">
<p>Observations: <span class="math inline">\(\mathbf{x}_{i,\bullet} \in \mathbb{R}^{2}\)</span>. Predict: <span class="math inline">\(\hat{y}_{i,j} = \mathbb{P}(Y_i = j)\)</span>.</p>
</div><div class="column">
<p>Target: <span class="math inline">\(\mathbf{y}_{i,\bullet} \in \{(1, 0), (0, 1)\}\)</span>.</p>
</div>
</div>
<p><strong>The model</strong>: For <span class="math inline">\(\mathbf{x}_{i,\bullet} = (x_{i,1}, x_{i,2})\)</span> <span class="math display">\[
\begin{aligned}
z_{i,1} &amp;= x_{i,1} w_{1,1} + x_{i,2} w_{2,1} + b_1 , \\
z_{i,2} &amp;= x_{i,1} w_{1,2} + x_{i,2} w_{2,2} + b_2 .
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\hat{y}_{i,1} &amp;= \text{Softmax}_1(\mathbf{z}_i) = \frac{\mathrm{e}^{z_{i,1}}}{\mathrm{e}^{z_{i,1}} + \mathrm{e}^{z_{i,2}}} , \\
\hat{y}_{i,2} &amp;= \text{Softmax}_2(\mathbf{z}_i) = \frac{\mathrm{e}^{z_{i,2}}}{\mathrm{e}^{z_{i,1}} + \mathrm{e}^{z_{i,2}}} .
\end{aligned}
\]</span></p>
</section>
<section id="multiple-observations-1" class="slide level2">
<h2>Multiple observations</h2>
<div class="columns">
<div class="column">
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a>data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x_1</th>
      <th>x_2</th>
      <th>y_1</th>
      <th>y_2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5</td>
      <td>6</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</div><div class="column">
<p>Choose:</p>
<p><span class="math inline">\(w_{1,1} = 1\)</span>, <span class="math inline">\(w_{2,1} = 2\)</span>,</p>
<p><span class="math inline">\(w_{1,2} = 3\)</span>, <span class="math inline">\(w_{2,2} = 4\)</span>, and</p>
<p><span class="math inline">\(b_1 = -10\)</span>, <span class="math inline">\(b_2 = -20\)</span>.</p>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a>w_11 <span class="op">=</span> <span class="dv">1</span><span class="op">;</span> w_21 <span class="op">=</span> <span class="dv">2</span><span class="op">;</span> b_1 <span class="op">=</span> <span class="op">-</span><span class="dv">10</span></span>
<span id="cb31-2"><a href="#cb31-2"></a>w_12 <span class="op">=</span> <span class="dv">3</span><span class="op">;</span> w_22 <span class="op">=</span> <span class="dv">4</span><span class="op">;</span> b_2 <span class="op">=</span> <span class="op">-</span><span class="dv">20</span></span>
<span id="cb31-3"><a href="#cb31-3"></a>data[<span class="st">"x_1"</span>] <span class="op">*</span> w_11 <span class="op">+</span> data[<span class="st">"x_2"</span>] <span class="op">*</span> w_21 <span class="op">+</span> b_1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>0   -5
1    1
2    7
dtype: int64</code></pre>
</div>
</div>
</section>
<section id="matrix-notation-1" class="slide level2">
<h2>Matrix notation</h2>
<div class="columns">
<div class="column">
<p>Have <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{3 \times 2}\)</span>.</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1"></a>X</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>array([[1, 2],
       [3, 4],
       [5, 6]], dtype=int64)</code></pre>
</div>
</div>
</div><div class="column">
<p><span class="math inline">\(\mathbf{W}\in \mathbb{R}^{2\times2}\)</span>, <span class="math inline">\(\mathbf{b}\in \mathbb{R}^{2}\)</span></p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1"></a>W <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">3</span>], [<span class="dv">2</span>, <span class="dv">4</span>]])</span>
<span id="cb35-2"><a href="#cb35-2"></a>b <span class="op">=</span> np.array([<span class="op">-</span><span class="dv">10</span>, <span class="op">-</span><span class="dv">20</span>])</span>
<span id="cb35-3"><a href="#cb35-3"></a>display(W)<span class="op">;</span> b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>array([[1, 3],
       [2, 4]])</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>array([-10, -20])</code></pre>
</div>
</div>
</div>
</div>
<p><span class="math display">\[
  \mathbf{Z} = \mathbf{X} \mathbf{W} + \mathbf{b} , \quad \mathbf{A} = \text{Softmax}(\mathbf{Z}) .
\]</span></p>
<div class="columns">
<div class="column">
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1"></a>Z <span class="op">=</span> X <span class="op">@</span> W <span class="op">+</span> b</span>
<span id="cb38-2"><a href="#cb38-2"></a>Z</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>array([[-5, -9],
       [ 1,  5],
       [ 7, 19]], dtype=int64)</code></pre>
</div>
</div>
</div><div class="column">
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1"></a>np.exp(Z) <span class="op">/</span> np.<span class="bu">sum</span>(np.exp(Z),</span>
<span id="cb40-2"><a href="#cb40-2"></a>  axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>array([[9.82e-01, 1.80e-02],
       [1.80e-02, 9.82e-01],
       [6.14e-06, 1.00e+00]])</code></pre>
</div>
</div>
</div>
</div>
</section>
<section id="in-keras-1" class="slide level2">
<h2>In Keras</h2>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1"></a>model <span class="op">=</span> Sequential([</span>
<span id="cb42-2"><a href="#cb42-2"></a>    Dense(<span class="dv">2</span>, input_dim<span class="op">=</span><span class="dv">2</span>, activation<span class="op">=</span><span class="st">'softmax'</span>),</span>
<span id="cb42-3"><a href="#cb42-3"></a>])</span>
<span id="cb42-4"><a href="#cb42-4"></a></span>
<span id="cb42-5"><a href="#cb42-5"></a>W, b <span class="op">=</span> model.get_weights()</span>
<span id="cb42-6"><a href="#cb42-6"></a><span class="bu">print</span>(<span class="ss">f"W's shape is </span><span class="sc">{</span>W<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, b's shape is </span><span class="sc">{</span>b<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>W's shape is (2, 2), b's shape is (2,)</code></pre>
</div>
</div>
<div class="columns">
<div class="column">
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1"></a>W</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>array([[ 0.25,  0.87],
       [ 0.09, -0.88]], dtype=float32)</code></pre>
</div>
</div>
</div><div class="column">
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1"></a>b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>array([0., 0.], dtype=float32)</code></pre>
</div>
</div>
</div>
</div>
<div class="columns">
<div class="column">
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1"></a>model(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>&lt;tf.Tensor: shape=(3, 2), dtype=float32, numpy=
array([[0.79, 0.21],
       [0.88, 0.12],
       [0.94, 0.06]], dtype=float32)&gt;</code></pre>
</div>
</div>
</div><div class="column">
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1"></a>tf.reduce_sum(model(X),</span>
<span id="cb50-2"><a href="#cb50-2"></a>    axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[1.],
       [1.],
       [1.]], dtype=float32)&gt;</code></pre>
</div>
</div>
</div>
</div>
</section>
<section id="in-keras-with-fixed-weights-bias-1" class="slide level2">
<h2>In Keras with fixed weights &amp; bias</h2>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1"></a>model <span class="op">=</span> Sequential([</span>
<span id="cb52-2"><a href="#cb52-2"></a>    Dense(<span class="dv">2</span>, input_dim<span class="op">=</span><span class="dv">2</span>, activation<span class="op">=</span><span class="st">'softmax'</span>,</span>
<span id="cb52-3"><a href="#cb52-3"></a>      kernel_initializer<span class="op">=</span>Constant(value<span class="op">=</span>[[<span class="fl">1.0</span>, <span class="fl">3.0</span>], [<span class="fl">2.0</span>, <span class="fl">4.0</span>]]),</span>
<span id="cb52-4"><a href="#cb52-4"></a>      bias_initializer<span class="op">=</span>Constant(value<span class="op">=</span>[<span class="op">-</span><span class="dv">10</span>, <span class="op">-</span><span class="dv">20</span>]))</span>
<span id="cb52-5"><a href="#cb52-5"></a>])</span>
<span id="cb52-6"><a href="#cb52-6"></a></span>
<span id="cb52-7"><a href="#cb52-7"></a>W, b <span class="op">=</span> model.get_weights()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="columns">
<div class="column">
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1"></a>W</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>array([[1., 3.],
       [2., 4.]], dtype=float32)</code></pre>
</div>
</div>
</div><div class="column">
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1"></a>b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>array([-10., -20.], dtype=float32)</code></pre>
</div>
</div>
</div>
</div>
<div class="columns">
<div class="column">
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1"></a>model(X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>&lt;tf.Tensor: shape=(3, 2), dtype=float32, numpy=
array([[9.82e-01, 1.80e-02],
       [1.80e-02, 9.82e-01],
       [6.14e-06, 1.00e+00]], dtype=float32)&gt;</code></pre>
</div>
</div>
</div><div class="column">
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1"></a>tf.reduce_sum(model(X),</span>
<span id="cb59-2"><a href="#cb59-2"></a>    axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[1.],
       [1.],
       [1.]], dtype=float32)&gt;</code></pre>
</div>
</div>
</div>
</div>
</section></section>
<section>
<section id="loss-and-derivatives" class="title-slide slide level1 center" data-background-image="unsw-yellow-shape.png" data-visibility="uncounted">
<h1>Loss and derivatives</h1>

</section>
<section id="example-linear-regression" class="slide level2">
<h2>Example: linear regression</h2>
<p><span class="math display">\[
\hat{y}(x) = w x + b
\]</span></p>
<p>For some observation <span class="math inline">\(\{ x_i, y_i \}\)</span>, the (MSE) loss is</p>
<p><span class="math display">\[
\text{Loss}_i = (\hat{y}(x_i) - y_i)^2
\]</span></p>
<p>For a batch of the first <span class="math inline">\(n\)</span> observations the loss is</p>
<p><span class="math display">\[
\text{Loss}_{1:n} = \frac{1}{n} \sum_{i=1}^n (\hat{y}(x_i) - y_i)^2
\]</span></p>
</section>
<section id="derivatives" class="slide level2">
<h2>Derivatives</h2>
<p>Since <span class="math inline">\(\hat{y}(x) = w x + b\)</span>,</p>
<p><span class="math display">\[
\frac{\partial \hat{y}(x)}{\partial w} = x \text{ and }
\frac{\partial \hat{y}(x)}{\partial b} = 1 .
\]</span></p>
<p>As <span class="math inline">\(\text{Loss}_i = (\hat{y}(x_i) - y_i)^2\)</span>, we know <span class="math display">\[
\frac{\partial \text{Loss}_i}{\partial \hat{y}(x_i) } = 2 (\hat{y}(x_i) - y_i) .
\]</span></p>
</section>
<section id="chain-rule" class="slide level2">
<h2>Chain rule</h2>
<p><span class="math display">\[
\frac{\partial \text{Loss}_i}{\partial \hat{y}(x_i) } = 2 (\hat{y}(x_i) - y_i), \,\,
\frac{\partial \hat{y}(x)}{\partial w} = x , \, \text{ and } \,
\frac{\partial \hat{y}(x)}{\partial b} = 1 .
\]</span></p>
<p>Putting this together, we have</p>
<p><span class="math display">\[
\frac{\partial \text{Loss}_i}{\partial w}
= \frac{\partial \text{Loss}_i}{\partial \hat{y}(x_i) }
  \times \frac{\partial \hat{y}(x_i)}{\partial w}
= 2 (\hat{y}(x_i) - y_i) \, x_i
\]</span></p>
<p>and <span class="math display">\[
\frac{\partial \text{Loss}_i}{\partial b}
= \frac{\partial \text{Loss}_i}{\partial \hat{y}(x_i) }
  \times \frac{\partial \hat{y}(x_i)}{\partial b}
= 2 (\hat{y}(x_i) - y_i) .
\]</span></p>
</section>
<section id="stochastic-gradient-descent-sgd" class="slide level2">
<h2>Stochastic gradient descent (SGD)</h2>
<p>Start with <span class="math inline">\(\boldsymbol{\theta}_0 = (w, b)^\top = (0, 0)^\top\)</span>.</p>
<p>Randomly pick <span class="math inline">\(i=5\)</span>, say <span class="math inline">\(x_i = 5\)</span> and <span class="math inline">\(y_i = 5\)</span>.</p>
<div class="fragment">
<p><span class="math display">\[
\hat{y}(x_i) = 0 \times 5 + 0 = 0 \Rightarrow \text{Loss}_i = (0 - 5)^2 = 25.
\]</span></p>
</div>
<div class="fragment">
<p>The partial derivatives are <span class="math display">\[
\begin{aligned}
\frac{\partial \text{Loss}_i}{\partial w}
&amp;= 2 (\hat{y}(x_i) - y_i) \, x_i = 2 \cdot (0 - 5) \cdot 5 = -50, \text{ and} \\
\frac{\partial \text{Loss}_i}{\partial b}
&amp;= 2 (0 - 5) = - 10.
\end{aligned}
\]</span> The gradient is <span class="math inline">\(\nabla \text{Loss}_i = (-50, -10)^\top\)</span>.</p>
</div>
</section>
<section id="sgd-first-iteration" class="slide level2">
<h2>SGD, first iteration</h2>
<p>Start with <span class="math inline">\(\boldsymbol{\theta}_0 = (w, b)^\top = (0, 0)^\top\)</span>.</p>
<p>Randomly pick <span class="math inline">\(i=5\)</span>, say <span class="math inline">\(x_i = 5\)</span> and <span class="math inline">\(y_i = 5\)</span>.</p>
<p>The gradient is <span class="math inline">\(\nabla \text{Loss}_i = (-50, -10)^\top\)</span>.</p>
<p>Use learning rate <span class="math inline">\(\eta = 0.01\)</span> to update <span class="math display">\[
\begin{aligned}
\boldsymbol{\theta}_1
&amp;= \boldsymbol{\theta}_0 - \eta \nabla \text{Loss}_i \\
&amp;= \begin{pmatrix} 0 \\ 0 \end{pmatrix} - 0.01 \begin{pmatrix} -50 \\ -10 \end{pmatrix} \\
&amp;= \begin{pmatrix} 0 \\ 0 \end{pmatrix} + \begin{pmatrix} 0.5 \\ 0.1 \end{pmatrix} = \begin{pmatrix} 0.5 \\ 0.1 \end{pmatrix}.
\end{aligned}
\]</span></p>
</section>
<section id="sgd-second-iteration" class="slide level2">
<h2>SGD, second iteration</h2>
<p>Start with <span class="math inline">\(\boldsymbol{\theta}_1 = (w, b)^\top = (0.5, 0.1)^\top\)</span>.</p>
<p>Randomly pick <span class="math inline">\(i=9\)</span>, say <span class="math inline">\(x_i = 9\)</span> and <span class="math inline">\(y_i = 17\)</span>.</p>
<p>The gradient is <span class="math inline">\(\nabla \text{Loss}_i = (-223.2, -24.8)^\top\)</span>.</p>
<p>Use learning rate <span class="math inline">\(\eta = 0.01\)</span> to update <span class="math display">\[
\begin{aligned}
\boldsymbol{\theta}_2
&amp;= \boldsymbol{\theta}_1 - \eta \nabla \text{Loss}_i \\
&amp;= \begin{pmatrix} 0.5 \\ 0.1 \end{pmatrix} - 0.01 \begin{pmatrix} -223.2 \\ -24.8 \end{pmatrix} \\
&amp;= \begin{pmatrix} 0.5 \\ 0.1 \end{pmatrix} + \begin{pmatrix} 2.232 \\ 0.248 \end{pmatrix} = \begin{pmatrix} 2.732 \\ 0.348 \end{pmatrix}.
\end{aligned}
\]</span></p>
</section>
<section id="batch-gradient-descent-bgd" class="slide level2">
<h2>Batch gradient descent (BGD)</h2>
<p>For the first <span class="math inline">\(n\)</span> observations <span class="math inline">\(\text{Loss}_{1:n} = \frac{1}{n} \sum_{i=1}^n \text{Loss}_i\)</span> so</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial \text{Loss}_{1:n}}{\partial w}
&amp;= \frac{1}{n} \sum_{i=1}^n \frac{\partial \text{Loss}_{i}}{\partial w}
= \frac{1}{n} \sum_{i=1}^n \frac{\partial \text{Loss}_{i}}{\hat{y}(x_i)} \frac{\partial \hat{y}(x_i)}{\partial w} \\
&amp;= \frac{1}{n} \sum_{i=1}^n 2 (\hat{y}(x_i) - y_i) \, x_i .
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial \text{Loss}_{1:n}}{\partial b}
&amp;= \frac{1}{n} \sum_{i=1}^n \frac{\partial \text{Loss}_{i}}{\partial b}
= \frac{1}{n} \sum_{i=1}^n \frac{\partial \text{Loss}_{i}}{\hat{y}(x_i)} \frac{\partial \hat{y}(x_i)}{\partial b} \\
&amp;= \frac{1}{n} \sum_{i=1}^n 2 (\hat{y}(x_i) - y_i) .
\end{aligned}
\]</span></p>
</section>
<section id="bgd-first-iteration-boldsymboltheta_0-boldsymbol0" class="slide level2">
<h2>BGD, first iteration (<span class="math inline">\(\boldsymbol{\theta}_0 = \boldsymbol{0}\)</span>)</h2>
<div class="cell" data-execution_count="41">
<div class="cell-output cell-output-display" data-execution_count="41">

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
      <th>y_hat</th>
      <th>loss</th>
      <th>dL/dw</th>
      <th>dL/db</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0.99</td>
      <td>0</td>
      <td>0.98</td>
      <td>-1.98</td>
      <td>-1.98</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>3.00</td>
      <td>0</td>
      <td>9.02</td>
      <td>-12.02</td>
      <td>-6.01</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>5.01</td>
      <td>0</td>
      <td>25.15</td>
      <td>-30.09</td>
      <td>-10.03</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>So <span class="math inline">\(\nabla \text{Loss}_{1:3}\)</span> is</p>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1"></a>nabla <span class="op">=</span> np.array([df[<span class="st">"dL/dw"</span>].mean(), df[<span class="st">"dL/db"</span>].mean()])</span>
<span id="cb61-2"><a href="#cb61-2"></a>nabla </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>array([-14.69,  -6.  ])</code></pre>
</div>
</div>
<p>so with <span class="math inline">\(\eta = 0.1\)</span> then <span class="math inline">\(\boldsymbol{\theta}_1\)</span> becomes</p>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1"></a>theta_1 <span class="op">=</span> theta_0 <span class="op">-</span> <span class="fl">0.1</span> <span class="op">*</span> nabla</span>
<span id="cb63-2"><a href="#cb63-2"></a>theta_1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>array([1.47, 0.6 ])</code></pre>
</div>
</div>
</section>
<section id="bgd-second-iteration" class="slide level2">
<h2>BGD, second iteration</h2>
<div class="cell" data-execution_count="45">
<div class="cell-output cell-output-display" data-execution_count="45">

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
      <th>y_hat</th>
      <th>loss</th>
      <th>dL/dw</th>
      <th>dL/db</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0.99</td>
      <td>2.07</td>
      <td>1.17</td>
      <td>2.16</td>
      <td>2.16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>3.00</td>
      <td>3.54</td>
      <td>0.29</td>
      <td>2.14</td>
      <td>1.07</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>5.01</td>
      <td>5.01</td>
      <td>0.00</td>
      <td>-0.04</td>
      <td>-0.01</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>So <span class="math inline">\(\nabla \text{Loss}_{1:3}\)</span> is</p>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1"></a>nabla <span class="op">=</span> np.array([df[<span class="st">"dL/dw"</span>].mean(), df[<span class="st">"dL/db"</span>].mean()])</span>
<span id="cb65-2"><a href="#cb65-2"></a>nabla </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>array([1.42, 1.07])</code></pre>
</div>
</div>
<p>so with <span class="math inline">\(\eta = 0.1\)</span> then <span class="math inline">\(\boldsymbol{\theta}_2\)</span> becomes</p>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1"></a>theta_2 <span class="op">=</span> theta_1 <span class="op">-</span> <span class="fl">0.1</span> <span class="op">*</span> nabla</span>
<span id="cb67-2"><a href="#cb67-2"></a>theta_2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>array([1.33, 0.49])</code></pre>
</div>
</div>
</section></section>
<section>
<section id="optimisation" class="title-slide slide level1 center" data-background-image="unsw-yellow-shape.png" data-visibility="uncounted">
<h1>Optimisation</h1>

</section>
<section id="gradient-based-learning" class="slide level2">
<h2>Gradient-based learning</h2>
<div>
Make a guess: <input type="range" min="1" max="100" value="50" class="slider" id="new_guess" oninput="this.nextElementSibling.value = this.value">
<output>
50
</output>
<p>Show derivatives: <input type="checkbox" id="derivs" py-onclick="show_derivatives"> Reveal function: <input type="checkbox" id="reveal" py-onclick="reveal_function"></p>
</div>
<div id="mpl" style="text-align: center;">

</div>
<p><py-script output="mpl" src="pyscript-demo.py"></py-script></p>
</section>
<section id="gradient-descent-pitfalls" class="slide level2">
<h2>Gradient descent pitfalls</h2>

<img data-src="Geron-mls2_0406-blur.png" class="r-stretch quarto-figure-center"><p class="caption">Potential problems with gradient descent.</p><div class="footer">
<p>Source: Aurélien Géron (2019), <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>, 2nd Edition, Figure 4-6.</p>
</div>
</section>
<section id="go-over-all-the-training-data" class="slide level2">
<h2>Go over all the training data</h2>
<p><br></p>
<p>Called <em>batch gradient descent</em>.</p>
<p><br></p>
<div class="sourceCode" id="cb69"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(numEpochs):</span>
<span id="cb69-2"><a href="#cb69-2"></a>  gradient <span class="op">=</span> evaluate_gradient(loss_function, data, weights)</span>
<span id="cb69-3"><a href="#cb69-3"></a>  weights <span class="op">=</span> weights <span class="op">-</span> learningRate <span class="op">*</span> gradient</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="pick-a-random-training-example" class="slide level2">
<h2>Pick a random training example</h2>
<p><br></p>
<p>Called <em>stochastic gradient descent</em>.</p>
<p><br></p>
<div class="sourceCode" id="cb70"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(numEpochs):</span>
<span id="cb70-2"><a href="#cb70-2"></a>  rnd.shuffle(data)</span>
<span id="cb70-3"><a href="#cb70-3"></a>  <span class="cf">for</span> example <span class="kw">in</span> data:</span>
<span id="cb70-4"><a href="#cb70-4"></a>    gradient <span class="op">=</span> evaluate_gradient(loss_function, example, weights)</span>
<span id="cb70-5"><a href="#cb70-5"></a>    weights <span class="op">=</span> weights <span class="op">-</span> learningRate <span class="op">*</span> gradient</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="take-a-group-of-training-examples" class="slide level2">
<h2>Take a group of training examples</h2>
<p><br></p>
<p>Called <em>mini-batch gradient descent</em>.</p>
<p><br></p>
<div class="sourceCode" id="cb71"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(numEpochs):</span>
<span id="cb71-2"><a href="#cb71-2"></a>  rnd.shuffle(data)</span>
<span id="cb71-3"><a href="#cb71-3"></a>  <span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(numBatches):</span>
<span id="cb71-4"><a href="#cb71-4"></a>    batch <span class="op">=</span> data[b<span class="op">*</span>batchSize:(b<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>batchSize]</span>
<span id="cb71-5"><a href="#cb71-5"></a>    gradient <span class="op">=</span> evaluate_gradient(loss_function, batch, weights)</span>
<span id="cb71-6"><a href="#cb71-6"></a>    weights <span class="op">=</span> weights <span class="op">-</span> learningRate <span class="op">*</span> gradient</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="mini-batch-gradient-descent" class="slide level2">
<h2>Mini-batch gradient descent</h2>
<div class="columns">
<div class="column">
<p>Why?</p>
<ol type="1">
<li>Because we have to (data is too big)</li>
<li>Because it is faster (lots of quick noisy steps &gt; a few slow super accurate steps)</li>
<li>The noise helps us jump out of local minima</li>
</ol>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Geron-mls2_0406-blur.png"></p>
<p></p><figcaption>Example of jumping from local minima.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="footer">
<p>Source: Aurélien Géron (2019), <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>, 2nd Edition, Figure 4-6.</p>
</div>
</section>
<section id="learning-rates" class="slide level2">
<h2>Learning rates</h2>
<div class="columns">
<div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Geron-mls2_0404-blur.png"></p>
<p></p><figcaption>The learning rate is too small</figcaption><p></p>
</figure>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Geron-mls2_0405-blur.png"></p>
<p></p><figcaption>The learning rate is too large</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="footer">
<p>Source: Aurélien Géron (2019), <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>, 2nd Edition, Figures 4-4 and 4-5.</p>
</div>
</section>
<section id="learning-rates-2" class="slide level2">
<h2>Learning rates #2</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><video data-src="matt-henderson-learning-rates-animation.mov" style="width:60.0%" controls=""><a href="matt-henderson-learning-rates-animation.mov">Video</a></video></p>
<p></p><figcaption>Changing the learning rates for a robot arm.</figcaption><p></p>
</figure>
</div>
<div class="footer">
<p>Source: Matt Henderson (2021), <a href="https://twitter.com/matthen2/status/1520427516997025792">Twitter post</a></p>
</div>
</section>
<section id="learning-rate-schedule" class="slide level2">
<h2>Learning rate schedule</h2>

<img data-src="Geron-mls2_1108-blur.png" class="r-stretch quarto-figure-center"><p class="caption">Learning curves for various learning rates η</p><p>In training the learning rate may be tweaked manually.</p>
<div class="footer">
<p>Source: Aurélien Géron (2019), <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>, 2nd Edition, Figure 11-8.</p>
</div>
</section>
<section id="we-need-non-zero-derivatives" class="slide level2">
<h2>We need non-zero derivatives</h2>
<p>This is why can’t use accuracy as the loss function for classification.</p>
<p>This is why we can have the <em>dead ReLU</em> problem.</p>
<figure>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/KpKog-L9veg?enablejsapi=1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</center>
<p>
</p>
<figcaption aria-hidden="true">
The “Explain Like I’m 5” version of softmax/argmax classifiers.
</figcaption>
<p>
</p>
</figure>
</section></section>
<section>
<section id="dissecting-model.fit" class="title-slide slide level1 center" data-background-image="unsw-yellow-shape.png" data-visibility="uncounted">
<h1>Dissecting <code>model.fit</code></h1>
<br>
<center>
<blockquote class="twitter-tweet" data-theme="light">
<p lang="en" dir="ltr">
Spoiler: it's going to be a 20-lines Python script that calls model.fіt()<a href="https://t.co/AqLZSQ0kwD">https://t.co/AqLZSQ0kwD</a>
</p>
— François Chollet (<span class="citation" data-cites="fchollet">@fchollet</span>) <a href="https://twitter.com/fchollet/status/1518702623892799488?ref_src=twsrc%5Etfw">April 25, 2022</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<div class="footer">
<p>Source: <a href="https://twitter.com/fchollet/status/1518702623892799488?s=20&amp;t=RZyyrUzgI5VhGfq730ynBg">Twitter</a></p>
</div>
</section>
<section id="load-mnist-dataset" class="slide level2">
<h2>Load MNIST dataset</h2>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1"></a>(X_train, y_train), (X_test, y_test) <span class="op">=</span> keras.datasets.mnist.load_data()</span>
<span id="cb72-2"><a href="#cb72-2"></a>X_train <span class="op">=</span> X_train.astype(<span class="st">"float32"</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb72-3"><a href="#cb72-3"></a>X_test <span class="op">=</span> X_test.astype(<span class="st">"float32"</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb72-4"><a href="#cb72-4"></a></span>
<span id="cb72-5"><a href="#cb72-5"></a><span class="co"># Reserve 10,000 samples for validation.</span></span>
<span id="cb72-6"><a href="#cb72-6"></a>X_val <span class="op">=</span> X_train[<span class="op">-</span><span class="dv">10000</span>:]</span>
<span id="cb72-7"><a href="#cb72-7"></a>y_val <span class="op">=</span> y_train[<span class="op">-</span><span class="dv">10000</span>:]</span>
<span id="cb72-8"><a href="#cb72-8"></a>X_train <span class="op">=</span> X_train[:<span class="op">-</span><span class="dv">10000</span>]</span>
<span id="cb72-9"><a href="#cb72-9"></a>y_train <span class="op">=</span> y_train[:<span class="op">-</span><span class="dv">10000</span>]</span>
<span id="cb72-10"><a href="#cb72-10"></a></span>
<span id="cb72-11"><a href="#cb72-11"></a><span class="co"># Prepare the training dataset.</span></span>
<span id="cb72-12"><a href="#cb72-12"></a>batch_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb72-13"><a href="#cb72-13"></a>train_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((X_train, y_train))</span>
<span id="cb72-14"><a href="#cb72-14"></a><span class="co"># train_dataset = train_dataset.shuffle(buffer_size=1024)</span></span>
<span id="cb72-15"><a href="#cb72-15"></a>train_dataset <span class="op">=</span> train_dataset.batch(batch_size)</span>
<span id="cb72-16"><a href="#cb72-16"></a></span>
<span id="cb72-17"><a href="#cb72-17"></a><span class="co"># Prepare the validation dataset.</span></span>
<span id="cb72-18"><a href="#cb72-18"></a>val_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((X_val, y_val))</span>
<span id="cb72-19"><a href="#cb72-19"></a>val_dataset <span class="op">=</span> val_dataset.batch(batch_size)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="a-basic-mnist-model" class="slide level2">
<h2>A basic MNIST model</h2>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1"></a><span class="kw">def</span> build_model(seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb73-2"><a href="#cb73-2"></a>  random.seed(seed)</span>
<span id="cb73-3"><a href="#cb73-3"></a>  <span class="cf">return</span> keras.Sequential([</span>
<span id="cb73-4"><a href="#cb73-4"></a>    layers.Flatten(input_shape<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>)),</span>
<span id="cb73-5"><a href="#cb73-5"></a>    layers.Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb73-6"><a href="#cb73-6"></a>    layers.Dense(<span class="dv">10</span>)</span>
<span id="cb73-7"><a href="#cb73-7"></a>  ])</span>
<span id="cb73-8"><a href="#cb73-8"></a></span>
<span id="cb73-9"><a href="#cb73-9"></a>firstModel <span class="op">=</span> build_model()</span>
<span id="cb73-10"><a href="#cb73-10"></a>firstModel.summary(print_fn<span class="op">=</span>skip_empty)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_4"
_________________________________________________________________
Layer (type)                Output Shape              Param #
=================================================================
flatten (Flatten)           (None, 784)               0
dense_4 (Dense)             (None, 128)               100480
dense_5 (Dense)             (None, 10)                1290
=================================================================
Total params: 101,770
Trainable params: 101,770
Non-trainable params: 0
_________________________________________________________________</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="fitting-like-normal" class="slide level2">
<h2>Fitting like normal</h2>
<p>Specify fitting requirements.</p>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1"></a>epochs <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb75-2"><a href="#cb75-2"></a>lr <span class="op">=</span> <span class="fl">1e-2</span></span>
<span id="cb75-3"><a href="#cb75-3"></a>optimizer <span class="op">=</span> keras.optimizers.SGD(learning_rate<span class="op">=</span>lr)</span>
<span id="cb75-4"><a href="#cb75-4"></a>loss_fn <span class="op">=</span> keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Create a model &amp; run <code>model.fit</code>.</p>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1"></a>firstModel <span class="op">=</span> build_model()</span>
<span id="cb76-2"><a href="#cb76-2"></a>firstModel.<span class="bu">compile</span>(optimizer, loss_fn)</span>
<span id="cb76-3"><a href="#cb76-3"></a><span class="op">%</span>time firstFit <span class="op">=</span> firstModel.fit(train_dataset, epochs<span class="op">=</span>epochs, <span class="op">\</span></span>
<span id="cb76-4"><a href="#cb76-4"></a>        validation_data<span class="op">=</span>val_dataset, verbose<span class="op">=</span><span class="dv">0</span>)<span class="op">;</span></span>
<span id="cb76-5"><a href="#cb76-5"></a>firstFit.history[<span class="st">"loss"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: total: 312 ms
Wall time: 1.84 s</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>[0.9254468679428101, 0.4413444399833679]</code></pre>
</div>
</div>
</section>
<section id="going-through-the-epochs" class="slide level2">
<h2>Going through the epochs</h2>
<p>Create a new model:</p>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb79-2"><a href="#cb79-2"></a>model.<span class="bu">compile</span>(optimizer, loss_fn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Repeatedly call <code>model.fit</code>:</p>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1"></a><span class="co"># Go through all the training data multiple times.</span></span>
<span id="cb80-2"><a href="#cb80-2"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb80-3"><a href="#cb80-3"></a>    model.fit(train_dataset, epochs<span class="op">=</span><span class="dv">1</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-warning callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Warning</strong></p>
</div>
<div class="callout-content">
<p>Reusing the same optimiser works here because SGD is stateless. In contrast, RMSprop &amp; Adam have internal state (e.g.&nbsp;to calculate/store momentum).</p>
</div>
</div>
</div>
</section>
<section id="are-they-exactly-the-same" class="slide level2">
<h2>Are they <em>exactly</em> the same?</h2>
<div class="columns">
<div class="column">
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1"></a>firstModel.layers[<span class="op">-</span><span class="dv">1</span>].get_weights()[<span class="dv">0</span>][:<span class="dv">3</span>,:<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>array([[ 0.19, -0.01,  0.12],
       [-0.11,  0.01,  0.05],
       [ 0.1 ,  0.21, -0.01]], dtype=float32)</code></pre>
</div>
</div>
</div><div class="column">
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1"></a>model.layers[<span class="op">-</span><span class="dv">1</span>].get_weights()[<span class="dv">0</span>][:<span class="dv">3</span>,:<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>array([[ 0.19, -0.01,  0.12],
       [-0.11,  0.01,  0.05],
       [ 0.1 ,  0.21, -0.01]], dtype=float32)</code></pre>
</div>
</div>
</div>
</div>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1"></a><span class="kw">def</span> same_last_layer(model1, model2):</span>
<span id="cb85-2"><a href="#cb85-2"></a>    weights1 <span class="op">=</span> model1.layers[<span class="op">-</span><span class="dv">1</span>].get_weights()[<span class="dv">0</span>]</span>
<span id="cb85-3"><a href="#cb85-3"></a>    weights2 <span class="op">=</span> model2.layers[<span class="op">-</span><span class="dv">1</span>].get_weights()[<span class="dv">0</span>]</span>
<span id="cb85-4"><a href="#cb85-4"></a>    <span class="cf">return</span> np.<span class="bu">max</span>(np.<span class="bu">abs</span>(weights1 <span class="op">-</span> weights2)) <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb85-5"><a href="#cb85-5"></a></span>
<span id="cb85-6"><a href="#cb85-6"></a>same_last_layer(firstModel, model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>True</code></pre>
</div>
</div>
</section>
<section id="going-through-the-batches" class="slide level2">
<h2>Going through the batches</h2>
<p>Create a new model:</p>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb87-2"><a href="#cb87-2"></a>model.<span class="bu">compile</span>(optimizer, loss_fn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Repeatedly call <code>train_on_batch</code>:</p>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1"></a><span class="co"># Go through all the training data multiple times.</span></span>
<span id="cb88-2"><a href="#cb88-2"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb88-3"><a href="#cb88-3"></a></span>
<span id="cb88-4"><a href="#cb88-4"></a>    <span class="co"># Go through the entire training dataset in batches.</span></span>
<span id="cb88-5"><a href="#cb88-5"></a>    <span class="cf">for</span> (X_batch_train, y_batch_train) <span class="kw">in</span> train_dataset:</span>
<span id="cb88-6"><a href="#cb88-6"></a></span>
<span id="cb88-7"><a href="#cb88-7"></a>        <span class="co"># Update weights &amp; biases to make this batch's predictions better.</span></span>
<span id="cb88-8"><a href="#cb88-8"></a>        <span class="co"># model.train_on_batch(X_batch_train, y_batch_train)</span></span>
<span id="cb88-9"><a href="#cb88-9"></a></span>
<span id="cb88-10"><a href="#cb88-10"></a>        <span class="co"># </span><span class="al">BUG</span><span class="co">: 'train_on_batch' hangs on Windows.</span></span>
<span id="cb88-11"><a href="#cb88-11"></a>        <span class="co"># Later on, check to see if an updated TF fixes it. </span></span>
<span id="cb88-12"><a href="#cb88-12"></a>        <span class="cf">pass</span></span>
<span id="cb88-13"><a href="#cb88-13"></a></span>
<span id="cb88-14"><a href="#cb88-14"></a><span class="bu">print</span>(same_last_layer(firstModel, model))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>False</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="what-is-model.fit-really-doing" class="slide level2">
<h2>What is <code>model.fit()</code> really doing?</h2>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1"></a><span class="op">%%</span>time</span>
<span id="cb90-2"><a href="#cb90-2"></a>model <span class="op">=</span> build_model() <span class="co"># No model.compile!</span></span>
<span id="cb90-3"><a href="#cb90-3"></a></span>
<span id="cb90-4"><a href="#cb90-4"></a><span class="co"># Go through all the training data multiple times.</span></span>
<span id="cb90-5"><a href="#cb90-5"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb90-6"><a href="#cb90-6"></a>    <span class="co"># Go through the entire training dataset in batches.</span></span>
<span id="cb90-7"><a href="#cb90-7"></a>    <span class="cf">for</span> (X_batch_train, y_batch_train) <span class="kw">in</span> train_dataset:</span>
<span id="cb90-8"><a href="#cb90-8"></a>        <span class="co"># Calculate the loss, while keeping track of gradients.</span></span>
<span id="cb90-9"><a href="#cb90-9"></a>        <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb90-10"><a href="#cb90-10"></a>            y_pred <span class="op">=</span> model(X_batch_train, training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb90-11"><a href="#cb90-11"></a>            loss_value <span class="op">=</span> loss_fn(y_batch_train, y_pred)</span>
<span id="cb90-12"><a href="#cb90-12"></a></span>
<span id="cb90-13"><a href="#cb90-13"></a>        <span class="co"># Calculate the gradients &amp; take a SGD step.</span></span>
<span id="cb90-14"><a href="#cb90-14"></a>        grads <span class="op">=</span> tape.gradient(loss_value, model.trainable_weights)</span>
<span id="cb90-15"><a href="#cb90-15"></a>        optimizer.apply_gradients(<span class="bu">zip</span>(grads, model.trainable_weights))</span>
<span id="cb90-16"><a href="#cb90-16"></a></span>
<span id="cb90-17"><a href="#cb90-17"></a><span class="bu">print</span>(same_last_layer(firstModel, model))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True
CPU times: total: 297 ms
Wall time: 5.46 s</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="what-about-optimizer-stuff" class="slide level2">
<h2>What about <code>optimizer</code> stuff?</h2>
<p><span class="math display">\[
\boldsymbol{\theta}_i = \boldsymbol{\theta}_{i-1} - \eta \nabla \text{LossOnBatch} \\
\]</span></p>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb92-2"><a href="#cb92-2"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb92-3"><a href="#cb92-3"></a>    <span class="cf">for</span> (X_batch_train, y_batch_train) <span class="kw">in</span> train_dataset:</span>
<span id="cb92-4"><a href="#cb92-4"></a>        <span class="co"># Calculate the loss, while keeping track of gradients.</span></span>
<span id="cb92-5"><a href="#cb92-5"></a>        <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb92-6"><a href="#cb92-6"></a>            y_pred <span class="op">=</span> model(X_batch_train, training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb92-7"><a href="#cb92-7"></a>            loss_value <span class="op">=</span> loss_fn(y_batch_train, y_pred)</span>
<span id="cb92-8"><a href="#cb92-8"></a></span>
<span id="cb92-9"><a href="#cb92-9"></a>        <span class="co"># Calculate the gradients &amp; take a SGD step.</span></span>
<span id="cb92-10"><a href="#cb92-10"></a>        grads <span class="op">=</span> tape.gradient(loss_value, model.trainable_weights)</span>
<span id="cb92-11"><a href="#cb92-11"></a>        <span class="cf">for</span> grad, weight <span class="kw">in</span> <span class="bu">zip</span>(grads, model.trainable_weights):</span>
<span id="cb92-12"><a href="#cb92-12"></a>            <span class="co"># Take a small negative step in the direction of the gradient.</span></span>
<span id="cb92-13"><a href="#cb92-13"></a>            weight.assign(weight <span class="op">-</span> lr <span class="op">*</span> grad) </span>
<span id="cb92-14"><a href="#cb92-14"></a></span>
<span id="cb92-15"><a href="#cb92-15"></a><span class="bu">print</span>(same_last_layer(firstModel, model))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="inspecting-the-gradients" class="slide level2">
<h2>Inspecting the gradients</h2>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1"></a>grads</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>[&lt;tf.Tensor: shape=(784, 128), dtype=float32, numpy=
 array([[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)&gt;,
 &lt;tf.Tensor: shape=(128,), dtype=float32, numpy=
 array([ 0.01, -0.  , -0.02,  0.02, -0.01,  0.01,  0.  , -0.03, -0.01,
         0.02, -0.03, -0.01,  0.01, -0.01, -0.  ,  0.  , -0.01,  0.  ,
         0.01,  0.01, -0.01,  0.01, -0.02, -0.  ,  0.04,  0.05,  0.  ,
        -0.04, -0.03,  0.06, -0.  ,  0.01, -0.02,  0.01, -0.03,  0.01,
         0.  , -0.01, -0.01,  0.01,  0.06, -0.  ,  0.01, -0.  , -0.01,
         0.01, -0.04,  0.01,  0.  ,  0.03,  0.  ,  0.02, -0.03,  0.01,
        -0.  ,  0.01, -0.05,  0.06,  0.01,  0.  ,  0.02, -0.02, -0.01,
         0.04, -0.02,  0.02, -0.05,  0.02,  0.  ,  0.  ,  0.  , -0.01,
         0.06, -0.01, -0.04,  0.02, -0.01, -0.02,  0.02,  0.01, -0.05,
        -0.07,  0.01, -0.  ,  0.01,  0.  ,  0.  , -0.01,  0.01, -0.06,
         0.  ,  0.  ,  0.01, -0.02, -0.01,  0.01,  0.01,  0.02,  0.03,
        -0.01, -0.04, -0.01, -0.02, -0.02,  0.  ,  0.  , -0.02, -0.  ,
        -0.02, -0.03, -0.02, -0.02,  0.04, -0.02,  0.03,  0.03,  0.05,
         0.  , -0.01, -0.01,  0.02, -0.  ,  0.03, -0.02, -0.02,  0.01,
         0.01,  0.06], dtype=float32)&gt;,
 &lt;tf.Tensor: shape=(128, 10), dtype=float32, numpy=
 array([[-1.57e-03,  5.26e-04,  5.21e-03, ...,  5.26e-04,  1.54e-03,
          5.21e-03],
        [-2.40e-03,  5.08e-06,  2.75e-05, ...,  3.69e-05,  1.19e-04,
          1.82e-05],
        [-2.92e-03,  2.62e-03,  2.05e-02, ...,  2.52e-03, -1.68e-02,
          2.56e-04],
        ...,
        [-3.93e-02,  5.23e-04,  5.74e-02, ...,  9.99e-04, -6.75e-04,
          3.01e-03],
        [-1.05e-01,  2.49e-03,  9.37e-02, ...,  8.29e-03,  1.82e-02,
          4.05e-03],
        [-9.47e-02,  2.75e-03,  1.02e-01, ...,  7.20e-03,  1.36e-02,
          1.32e-02]], dtype=float32)&gt;,
 &lt;tf.Tensor: shape=(10,), dtype=float32, numpy=
 array([-0.08,  0.  ,  0.06, -0.01, -0.02, -0.06,  0.11,  0.01, -0.01,
         0.01], dtype=float32)&gt;]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1"></a>[np.mean(np.<span class="bu">abs</span>(grad.numpy())) <span class="cf">for</span> grad <span class="kw">in</span> grads]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>[0.0033017197, 0.017349988, 0.026732732, 0.037057698]</code></pre>
</div>
</div>
</section>
<section id="calculating-training-losses" class="slide level2">
<h2>Calculating training losses</h2>
<div class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1"></a>firstFit.history[<span class="st">"loss"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>[0.9254468679428101, 0.4413444399833679]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb100-2"><a href="#cb100-2"></a></span>
<span id="cb100-3"><a href="#cb100-3"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb100-4"><a href="#cb100-4"></a>    loss_history <span class="op">=</span> []</span>
<span id="cb100-5"><a href="#cb100-5"></a>    <span class="cf">for</span> (X_batch_train, y_batch_train) <span class="kw">in</span> train_dataset:</span>
<span id="cb100-6"><a href="#cb100-6"></a>        <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb100-7"><a href="#cb100-7"></a>            y_pred <span class="op">=</span> model(X_batch_train, training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb100-8"><a href="#cb100-8"></a>            loss_value <span class="op">=</span> loss_fn(y_batch_train, y_pred)</span>
<span id="cb100-9"><a href="#cb100-9"></a>            loss_history.append(loss_value.numpy())</span>
<span id="cb100-10"><a href="#cb100-10"></a></span>
<span id="cb100-11"><a href="#cb100-11"></a>        grads <span class="op">=</span> tape.gradient(loss_value, model.trainable_weights)</span>
<span id="cb100-12"><a href="#cb100-12"></a>        optimizer.apply_gradients(<span class="bu">zip</span>(grads, model.trainable_weights))</span>
<span id="cb100-13"><a href="#cb100-13"></a></span>
<span id="cb100-14"><a href="#cb100-14"></a>    <span class="bu">print</span>(<span class="ss">f"[Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">] Loss avg </span><span class="sc">{</span>np<span class="sc">.</span>mean(loss_history)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Epoch 0] Loss avg 0.9254943132400513</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[Epoch 1] Loss avg 0.4416849613189697</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="calculating-validation-losses" class="slide level2">
<h2>Calculating validation losses</h2>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1"></a>firstFit.history[<span class="st">"val_loss"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>[0.4692622125148773, 0.35921722650527954]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb105-2"><a href="#cb105-2"></a>model.<span class="bu">compile</span>(optimizer, loss_fn)</span>
<span id="cb105-3"><a href="#cb105-3"></a></span>
<span id="cb105-4"><a href="#cb105-4"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb105-5"><a href="#cb105-5"></a>    model.fit(train_dataset, epochs<span class="op">=</span><span class="dv">1</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb105-6"><a href="#cb105-6"></a></span>
<span id="cb105-7"><a href="#cb105-7"></a>    val_losses <span class="op">=</span> []</span>
<span id="cb105-8"><a href="#cb105-8"></a>    <span class="cf">for</span> (X_batch_val, y_batch_val) <span class="kw">in</span> val_dataset:</span>
<span id="cb105-9"><a href="#cb105-9"></a>        y_pred <span class="op">=</span> model(X_batch_val)</span>
<span id="cb105-10"><a href="#cb105-10"></a>        val_losses.append(loss_fn(y_batch_val, y_pred))</span>
<span id="cb105-11"><a href="#cb105-11"></a></span>
<span id="cb105-12"><a href="#cb105-12"></a>    <span class="bu">print</span>(<span class="ss">f"[Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">] Val loss avg </span><span class="sc">{</span>np<span class="sc">.</span>mean(val_losses)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Epoch 0] Val loss avg 0.468784362077713</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[Epoch 1] Val loss avg 0.35841864347457886</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="comparable-training-val.-losses" class="slide level2">
<h2>Comparable training &amp; val. losses</h2>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1"></a><span class="bu">print</span>(firstFit.history[<span class="st">"loss"</span>])</span>
<span id="cb108-2"><a href="#cb108-2"></a><span class="bu">print</span>(firstFit.history[<span class="st">"val_loss"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.9254468679428101, 0.4413444399833679]
[0.4692622125148773, 0.35921722650527954]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb110-2"><a href="#cb110-2"></a>model.<span class="bu">compile</span>(optimizer, loss_fn)</span>
<span id="cb110-3"><a href="#cb110-3"></a></span>
<span id="cb110-4"><a href="#cb110-4"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb110-5"><a href="#cb110-5"></a>    model.fit(train_dataset, epochs<span class="op">=</span><span class="dv">1</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb110-6"><a href="#cb110-6"></a></span>
<span id="cb110-7"><a href="#cb110-7"></a>    <span class="co"># Now the epoch is over and the model isn't being updated,</span></span>
<span id="cb110-8"><a href="#cb110-8"></a>    <span class="co"># calculate the losses on train and validation data.</span></span>
<span id="cb110-9"><a href="#cb110-9"></a>    train_loss <span class="op">=</span> model.evaluate(train_dataset, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb110-10"><a href="#cb110-10"></a>    val_loss <span class="op">=</span> model.evaluate(val_dataset, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb110-11"><a href="#cb110-11"></a>    <span class="bu">print</span>(<span class="ss">f"[Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">] Train loss </span><span class="sc">{</span>train_loss<span class="sc">}</span><span class="ss"> Val loss </span><span class="sc">{</span>val_loss<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Epoch 0] Train loss 0.511987566947937 Val loss 0.4692622125148773</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[Epoch 1] Train loss 0.3935200273990631 Val loss 0.35921722650527954</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="how-to-use-losses" class="slide level2">
<h2>How to use losses</h2>
<p>A common strategy is to:</p>
<ol type="1">
<li>Keep fitting bigger and bigger models until training error is <span class="math inline">\(\approx 0\)</span>. <em>This will likely produce a huge error on the validation set, called generalisation error, due to overfitting</em>.</li>
<li>Apply regularisation/dropout/early stopping to reduce the generalisation error.</li>
<li>Watch out for <em>overfitting the validation set</em> by looking at the test loss.</li>
</ol>
</section>
<section id="what-is-this-with-syntax" class="slide level2">
<h2>What is this <code>with</code> syntax?</h2>
<p>Example, opening a file:</p>
<div class="columns">
<div class="column">
<p>Most basic way is:</p>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1"></a>f <span class="op">=</span> <span class="bu">open</span>(<span class="st">"haiku1.txt"</span>, <span class="st">"r"</span>)</span>
<span id="cb113-2"><a href="#cb113-2"></a><span class="bu">print</span>(f.read())</span>
<span id="cb113-3"><a href="#cb113-3"></a>f.close()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Chaos reigns within.
Reflect, repent, and reboot.
Order shall return.</code></pre>
</div>
</div>
</div><div class="column">
<p>Instead, use:</p>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">"haiku2.txt"</span>, <span class="st">"r"</span>) <span class="im">as</span> f:</span>
<span id="cb115-2"><a href="#cb115-2"></a>    <span class="bu">print</span>(f.read())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The Web site you seek
Cannot be located, but
Countless more exist.</code></pre>
</div>
</div>
</div>
</div>
<div class="footer">
<p>Haikus from http://www.libertybasicuniversity.com/lbnews/nl107/haiku.htm</p>
</div>
</section>
<section id="what-is-gradienttape" class="slide level2">
<h2>What is <code>GradientTape()</code>?</h2>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1"></a>x <span class="op">=</span> tf.Variable(<span class="fl">3.0</span>)</span>
<span id="cb117-2"><a href="#cb117-2"></a></span>
<span id="cb117-3"><a href="#cb117-3"></a><span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb117-4"><a href="#cb117-4"></a>  y <span class="op">=</span> x<span class="op">**</span><span class="dv">2</span></span>
<span id="cb117-5"><a href="#cb117-5"></a></span>
<span id="cb117-6"><a href="#cb117-6"></a>dy_dx <span class="op">=</span> tape.gradient(y, x)</span>
<span id="cb117-7"><a href="#cb117-7"></a>dy_dx.numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>6.0</code></pre>
</div>
</div>
<div class="footer">
<p>Source: Tensorflow (2022), <a href="https://www.tensorflow.org/guide/autodiff">Introduction to gradients and automatic differentiation</a>, Tensorflow docs.</p>
</div>
</section></section>
<section>
<section id="computation-graphs-automatic-differentiation" class="title-slide slide level1 center" data-background-image="unsw-yellow-shape.png" data-visibility="uncounted">
<h1>Computation Graphs &amp; Automatic Differentiation</h1>

</section>
<section id="compile-using-graph-mode" class="slide level2">
<h2>Compile using graph mode</h2>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb119-2"><a href="#cb119-2"></a></span>
<span id="cb119-3"><a href="#cb119-3"></a><span class="at">@tf.function</span></span>
<span id="cb119-4"><a href="#cb119-4"></a><span class="kw">def</span> train_step(X, y):</span>
<span id="cb119-5"><a href="#cb119-5"></a>    <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb119-6"><a href="#cb119-6"></a>        y_pred <span class="op">=</span> model(X, training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb119-7"><a href="#cb119-7"></a>        loss_value <span class="op">=</span> loss_fn(y, y_pred)</span>
<span id="cb119-8"><a href="#cb119-8"></a>    grads <span class="op">=</span> tape.gradient(loss_value, model.trainable_weights)</span>
<span id="cb119-9"><a href="#cb119-9"></a>    optimizer.apply_gradients(<span class="bu">zip</span>(grads, model.trainable_weights))</span>
<span id="cb119-10"><a href="#cb119-10"></a>    <span class="cf">return</span> loss_value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1"></a><span class="op">%%</span>time</span>
<span id="cb120-2"><a href="#cb120-2"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb120-3"><a href="#cb120-3"></a>    <span class="cf">for</span> (X_batch_train, y_batch_train) <span class="kw">in</span> train_dataset:</span>
<span id="cb120-4"><a href="#cb120-4"></a>        loss_value <span class="op">=</span> train_step(X_batch_train, y_batch_train)</span>
<span id="cb120-5"><a href="#cb120-5"></a><span class="bu">print</span>(same_last_layer(firstModel, model))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True
CPU times: total: 172 ms
Wall time: 1.41 s</code></pre>
</div>
</div>
<div class="footer">
<p>Adapted from: Chollet (2020), <a href="https://keras.io/guides/writing_a_training_loop_from_scratch/">Writing a training loop from scratch</a>, Keras docs.</p>
</div>
</section>
<section id="example-computational-graph" class="slide level2">
<h2>Example computational graph</h2>

<img data-src="Geron-mlst_0901-blur.png" class="r-stretch quarto-figure-center"><p class="caption">Each basic equation is broken down to its core components.</p><div class="footer">
<p>Source: Aurélien Géron (2017), <em>Hands-On Machine Learning with Scikit-Learn &amp; TensorFlow</em>, 1st Edition, Figure 9.1.</p>
</div>
</section>
<section id="why" class="slide level2">
<h2>Why?</h2>

<img data-src="Geron-mlst_0902-blur.png" class="r-stretch quarto-figure-center"><p class="caption">Tensorflow figures out the smartest way to evaluate your equations.</p><div class="footer">
<p>Source: Aurélien Géron (2017), <em>Hands-On Machine Learning with Scikit-Learn &amp; TensorFlow</em>, 1st Edition, Figure 9.2.</p>
</div>
</section>
<section id="example-linear-regression-1" class="slide level2">
<h2>Example: linear regression</h2>
<p><span class="math display">\[
\hat{y}(x) = w x + b
\]</span></p>
<p>For some observation <span class="math inline">\(\{ x_i, y_i \}\)</span>, the (MSE) loss is</p>
<p><span class="math display">\[
\text{Loss}_i = (\hat{y}(x_i) - y_i)^2
\]</span></p>
<p>For a batch of the first <span class="math inline">\(n\)</span> observations the loss is</p>
<p><span class="math display">\[
\text{Loss}_{1:n} = \frac{1}{n} \sum_{i=1}^n (\hat{y}(x_i) - y_i)^2
\]</span></p>
</section>
<section id="derivatives-1" class="slide level2">
<h2>Derivatives</h2>
<p>Since <span class="math inline">\(\hat{y}(x) = w x + b\)</span>,</p>
<p><span class="math display">\[
\frac{\partial \hat{y}(x)}{\partial w} = x \text{ and }
\frac{\partial \hat{y}(x)}{\partial b} = 1 .
\]</span></p>
<p>As <span class="math inline">\(\text{Loss}_i = (\hat{y}(x_i) - y_i)^2\)</span>, we know <span class="math display">\[
\frac{\partial \text{Loss}_i}{\partial \hat{y}(x_i) } = 2 (\hat{y}(x_i) - y_i) .
\]</span></p>
</section>
<section id="chain-rule-1" class="slide level2">
<h2>Chain rule</h2>
<p><span class="math display">\[
\frac{\partial \text{Loss}_i}{\partial \hat{y}(x_i) } = 2 (\hat{y}(x_i) - y_i), \,\,
\frac{\partial \hat{y}(x)}{\partial w} = x , \, \text{ and } \,
\frac{\partial \hat{y}(x)}{\partial b} = 1 .
\]</span></p>
<p>Putting this together, we have</p>
<p><span class="math display">\[
\frac{\partial \text{Loss}_i}{\partial w}
= \frac{\partial \text{Loss}_i}{\partial \hat{y}(x_i) }
  \times \frac{\partial \hat{y}(x_i)}{\partial w}
= 2 (\hat{y}(x_i) - y_i) \, x_i
\]</span></p>
<p>and <span class="math display">\[
\frac{\partial \text{Loss}_i}{\partial b}
= \frac{\partial \text{Loss}_i}{\partial \hat{y}(x_i) }
  \times \frac{\partial \hat{y}(x_i)}{\partial b}
= 2 (\hat{y}(x_i) - y_i) .
\]</span></p>
</section>
<section id="backpropagation" class="slide level2">
<h2>Backpropagation</h2>
<div class="columns">
<div class="column">
<iframe width="560" height="560" src="https://www.youtube.com/embed/Ilg3gGewQ5U" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</div><div class="column">
<iframe width="560" height="560" src="https://www.youtube.com/embed/tIeHLnjs5U8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</div>
</div>
</section>
<section id="linear-regression-graph" class="slide level2">
<h2>Linear regression graph</h2>
<p><br></p>
<div class="cell" data-reveal="true" data-fig-width="10">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid mermaid-js" data-tooltip-selector="#mermaid-tooltip-1">%%{init: {'themeVariables': {'edgeLabelBackground': 'white', 'fontSize': '25px'}}}%%
graph LR
    x[x]:::data --&gt; times(( &lt;sup&gt;.&lt;/sup&gt; ))
    w[w]:::param --&gt; times
    times --&gt;|z| plus(( + ))
    b[b]:::param --&gt; plus
    plus --&gt;|yp| minus(( - ))
    y[y]:::data --&gt; minus
    minus --&gt; loss[loss]
    
    classDef data fill:aqua,stroke-width:0px
    classDef param fill:lightGreen,stroke-width:0px
    style loss fill:white,stroke-width:0px
</pre>
<div id="mermaid-tooltip-1" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="forward-pass" class="slide level2">
<h2>Forward pass</h2>
<p><br><br></p>
<div class="cell" data-reveal="true" data-fig-width="10">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid mermaid-js" data-tooltip-selector="#mermaid-tooltip-2">%%{init: {'themeVariables': { 'edgeLabelBackground': 'white', 'fontSize': '25px'}}}%%
graph LR
    x[x = 2]:::data --&gt; times(( &lt;sup&gt;.&lt;/sup&gt; ))
    w[w = 3]:::param --&gt; times
    times --&gt;|z = 6| plus(( + ))
    b[b = 1]:::param --&gt; plus
    plus --&gt;|yp = 7| minus(( - ))
    y[y = 4]:::data --&gt; minus
    minus --&gt; loss[loss = 3]
    
    classDef data fill:aqua,stroke-width:0px
    classDef param fill:lightGreen,stroke-width:0px
    style loss fill:white,stroke-width:0px
</pre>
<div id="mermaid-tooltip-2" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="backward-pass" class="slide level2">
<h2>Backward pass</h2>
<div class="cell" data-reveal="true" data-fig-width="10">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid mermaid-js" data-tooltip-selector="#mermaid-tooltip-3">%%{init: {'themeVariables': { 'edgeLabelBackground': 'white', 'fontSize': '25px'}}}%%
graph LR
    x[x = 2]:::data --- times(( &lt;sup&gt;.&lt;/sup&gt; ))
    w[w = 3]:::param ---|"grad(z, w) = 2"| times
    times ---|"z=6&lt;br&gt;grad(yp, z) = 1"| plus(( + ))
    b[b = 1]:::param ---|"grad(yp, b) = 1"| plus
    plus ---|"yp = 7&lt;br&gt;grad(loss, yp) = 1"| minus(( - ))
    y[y = 4]:::data --- minus
    minus --- loss[loss = 3]
    
    classDef data fill:aqua,stroke-width:0px
    classDef param fill:lightGreen,stroke-width:0px
    style loss fill:white,stroke-width:0px
</pre>
<div id="mermaid-tooltip-3" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
<div class="fragment">
<div class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1"></a>x <span class="op">=</span> tf.constant(<span class="fl">2.0</span>)<span class="op">;</span> y <span class="op">=</span> tf.constant(<span class="fl">4.0</span>)</span>
<span id="cb122-2"><a href="#cb122-2"></a>w <span class="op">=</span> tf.Variable(<span class="fl">3.0</span>)<span class="op">;</span> b <span class="op">=</span> tf.Variable(<span class="fl">1.0</span>)</span>
<span id="cb122-3"><a href="#cb122-3"></a><span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb122-4"><a href="#cb122-4"></a>  yp <span class="op">=</span> w<span class="op">*</span>x <span class="op">+</span> b</span>
<span id="cb122-5"><a href="#cb122-5"></a>  loss <span class="op">=</span> tf.<span class="bu">abs</span>(yp <span class="op">-</span> y)</span>
<span id="cb122-6"><a href="#cb122-6"></a>tape.gradient(loss, [w, b])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>[&lt;tf.Tensor: shape=(), dtype=float32, numpy=2.0&gt;,
 &lt;tf.Tensor: shape=(), dtype=float32, numpy=1.0&gt;]</code></pre>
</div>
</div>
</div>
</section>
<section id="thats-it" class="slide level2">
<h2>That’s it</h2>
<blockquote>
<p>And with that, you just saw backpropagation in action! Backpropagation is simply the application of the chain rule to a computation graph. There’s nothing more to it. Backpropagation starts with the final loss value and works backward from the top layers to the bottom layers, computing the contribution that each parameter had in the loss value. That’s where the name “backpropagation” comes from: we “back propagate” the loss contributions of different nodes in a computation graph.</p>
</blockquote>
<div class="footer">
<p>Source: François Chollet (2021), <em>Deep Learning with Python</em>, Second Edition, Chapter 2.</p>
</div>
</section>
<section id="batch-gradient-descent" class="slide level2">
<h2>Batch gradient descent</h2>
<p>For the first <span class="math inline">\(n\)</span> observations <span class="math inline">\(\text{Loss}_{1:n} = \frac{1}{n} \sum_{i=1}^n \text{Loss}_i\)</span> so</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial \text{Loss}_{1:n}}{\partial w}
&amp;= \frac{1}{n} \sum_{i=1}^n \frac{\partial \text{Loss}_{i}}{\partial w}
= \frac{1}{n} \sum_{i=1}^n \frac{\partial \text{Loss}_{i}}{\hat{y}(x_i)} \frac{\partial \hat{y}(x_i)}{\partial w} \\
&amp;= \frac{1}{n} \sum_{i=1}^n 2 (\hat{y}(x_i) - y_i) \, x_i .
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial \text{Loss}_{1:n}}{\partial b}
&amp;= \frac{1}{n} \sum_{i=1}^n \frac{\partial \text{Loss}_{i}}{\partial b}
= \frac{1}{n} \sum_{i=1}^n \frac{\partial \text{Loss}_{i}}{\hat{y}(x_i)} \frac{\partial \hat{y}(x_i)}{\partial b} \\
&amp;= \frac{1}{n} \sum_{i=1}^n 2 (\hat{y}(x_i) - y_i) .
\end{aligned}
\]</span></p>
</section>
<section id="bespoke-derivatives-vs.-autodiff" class="slide level2">
<h2>Bespoke derivatives vs.&nbsp;autodiff</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1"></a>w <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> b <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb124-2"><a href="#cb124-2"></a>y_pred <span class="op">=</span> w <span class="op">*</span> x <span class="op">+</span> b</span>
<span id="cb124-3"><a href="#cb124-3"></a>loss <span class="op">=</span> (y_pred <span class="op">-</span> y) <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb124-4"><a href="#cb124-4"></a></span>
<span id="cb124-5"><a href="#cb124-5"></a>dL_dw <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (y_pred <span class="op">-</span> y) <span class="op">*</span> x</span>
<span id="cb124-6"><a href="#cb124-6"></a>dL_db <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (y_pred <span class="op">-</span> y)</span>
<span id="cb124-7"><a href="#cb124-7"></a></span>
<span id="cb124-8"><a href="#cb124-8"></a>nabla <span class="op">=</span> [dL_dw.mean(), dL_db.mean()]</span>
<span id="cb124-9"><a href="#cb124-9"></a><span class="bu">print</span>(np.array(nabla))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[-14.69  -6.  ]</code></pre>
</div>
</div>
</div><div class="column" style="width:40%;">
<div class="cell" data-execution_count="77">
<div class="cell-output cell-output-display" data-execution_count="77">

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
      <th>dL/dw</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>0.99</td>
      <td>-1.98</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>3.00</td>
      <td>-12.02</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.0</td>
      <td>5.01</td>
      <td>-30.09</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</div>
</div>
<div class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1"></a>w <span class="op">=</span> tf.Variable(<span class="fl">0.0</span>)<span class="op">;</span> b <span class="op">=</span> tf.Variable(<span class="fl">0.0</span>)</span>
<span id="cb126-2"><a href="#cb126-2"></a>x <span class="op">=</span> tf.constant(x)<span class="op">;</span> y <span class="op">=</span> tf.constant(y)</span>
<span id="cb126-3"><a href="#cb126-3"></a></span>
<span id="cb126-4"><a href="#cb126-4"></a><span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb126-5"><a href="#cb126-5"></a>  y_pred <span class="op">=</span> w <span class="op">*</span> x <span class="op">+</span> b</span>
<span id="cb126-6"><a href="#cb126-6"></a>  loss <span class="op">=</span> tf.reduce_mean((y_pred <span class="op">-</span> y) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb126-7"><a href="#cb126-7"></a></span>
<span id="cb126-8"><a href="#cb126-8"></a>dL_dw, dL_db <span class="op">=</span> tape.gradient(loss, [w, b])</span>
<span id="cb126-9"><a href="#cb126-9"></a><span class="bu">print</span>(np.array([dL_dw, dL_db]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[-14.69  -6.  ]</code></pre>
</div>
</div>
</section>
<section id="the-magic-of-autodiff" class="slide level2">
<h2>The magic of autodiff</h2>
<div class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1"></a><span class="im">from</span> tensorflow.keras.metrics <span class="im">import</span> mean_squared_error <span class="im">as</span> mse</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="columns">
<div class="column">
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1"></a><span class="op">%%</span>timeit</span>
<span id="cb129-2"><a href="#cb129-2"></a>y_pred <span class="op">=</span> w<span class="op">*</span>x <span class="op">+</span> b</span>
<span id="cb129-3"><a href="#cb129-3"></a>res <span class="op">=</span> y_pred <span class="op">-</span> y</span>
<span id="cb129-4"><a href="#cb129-4"></a>dL_db <span class="op">=</span> tf.reduce_mean(<span class="dv">2</span><span class="op">*</span>res)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>129 ms ± 1.36 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1"></a><span class="op">%%</span>timeit</span>
<span id="cb131-2"><a href="#cb131-2"></a><span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb131-3"><a href="#cb131-3"></a>  loss <span class="op">=</span> mse(y, w<span class="op">*</span>x <span class="op">+</span> b)</span>
<span id="cb131-4"><a href="#cb131-4"></a>tape.gradient(loss, b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>333 ms ± 4.22 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
</div><div class="column">
<div class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1"></a><span class="op">%%</span>timeit</span>
<span id="cb133-2"><a href="#cb133-2"></a>res <span class="op">=</span> (w<span class="op">*</span>x <span class="op">+</span> b) <span class="op">-</span> y</span>
<span id="cb133-3"><a href="#cb133-3"></a>dL_dw <span class="op">=</span> tf.reduce_mean(<span class="dv">2</span><span class="op">*</span>res<span class="op">*</span>x)</span>
<span id="cb133-4"><a href="#cb133-4"></a>dL_db <span class="op">=</span> tf.reduce_mean(<span class="dv">2</span><span class="op">*</span>res)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>203 ms ± 408 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1"></a><span class="op">%%</span>timeit</span>
<span id="cb135-2"><a href="#cb135-2"></a><span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb135-3"><a href="#cb135-3"></a>  loss <span class="op">=</span> mse(y, w<span class="op">*</span>x <span class="op">+</span> b)</span>
<span id="cb135-4"><a href="#cb135-4"></a>tape.gradient(loss, [w, b])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>334 ms ± 4.04 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
</div>
</div>
</section></section>
<section id="section" class="title-slide slide level1 center" data-visibility="uncounted">
<h1></h1>
<h2>
Glossary
</h2>
<div class="columns">
<div class="column">
<ul>
<li>accuracy</li>
<li>batches, batch size</li>
<li>cross-entropy loss</li>
<li>gradient-based learning, hill-climbing</li>
</ul>
</div><div class="column">
<ul>
<li>metrics</li>
<li>overfitting</li>
<li>shallow neural network</li>
<li>stochastic (mini-batch) gradient descent</li>
<li>universal approximation theorem</li>
</ul>
</div>
</div>
<script defer="">
    // Remove the highlight.js class for the 'compile', 'min', 'max'
    // as there's a bug where they are treated like the Python built-in
    // global functions but we only ever see it as methods like
    // 'model.compile()' or 'predictions.max()'
    buggyBuiltIns = ["compile", "min", "max", "round", "sum"];

    document.querySelectorAll('.bu').forEach((elem) => {
        if (buggyBuiltIns.includes(elem.innerHTML)) {
            elem.classList.remove('bu');
        }
    })

    var registerRevealCallbacks = function() {
        Reveal.on('overviewshown', event => {
            document.querySelector(".line.right").hidden = true;
        });
        Reveal.on('overviewhidden', event => {
            document.querySelector(".line.right").hidden = false;
        });
    };
</script>

<img src="unsw-logo.svg" class="slide-logo r-stretch"><div class="footer footer-default">
<p>Slides: <a href="https://pat-laub.github.io">Dr Patrick Laub</a> (<span class="citation" data-cites="PatrickLaub">@PatrickLaub</span>).</p>
</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="mathematics-of-deep-learning_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="mathematics-of-deep-learning_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="mathematics-of-deep-learning_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="mathematics-of-deep-learning_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="mathematics-of-deep-learning_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="mathematics-of-deep-learning_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="mathematics-of-deep-learning_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="mathematics-of-deep-learning_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="mathematics-of-deep-learning_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="mathematics-of-deep-learning_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="mathematics-of-deep-learning_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true,"boardmarkerWidth":6,"grid":false,"background":["rgba(255,255,255,0.0)","https://github.com/rajgoel/reveal.js-plugins/raw/master/chalkboard/img/blackboard.png"]},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1000,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.12,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    <script>registerRevealCallbacks();</script>
    

</body></html>