[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "",
    "text": "These are the lecture slides from my recent “Artificial Intelligence and Deep Learning Models for Actuarial Applications” courses (coded ACTL3143 & ACTL5111) at UNSW. They can be used to see what topics I covered in these courses. The slides are not intended to be used to learn deep learning from scratch. For that, you need to attend the lectures & complete the assessment.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "",
    "text": "These are the lecture slides from my recent “Artificial Intelligence and Deep Learning Models for Actuarial Applications” courses (coded ACTL3143 & ACTL5111) at UNSW. They can be used to see what topics I covered in these courses. The slides are not intended to be used to learn deep learning from scratch. For that, you need to attend the lectures & complete the assessment.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#list-of-topics-covered",
    "href": "index.html#list-of-topics-covered",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "List of Topics Covered",
    "text": "List of Topics Covered",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#lecture-1-python",
    "href": "index.html#lecture-1-python",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "Lecture 1: Python",
    "text": "Lecture 1: Python\n\n\n\ndefault arguments\ndictionaries\nf-strings\nfunction definitions\nGoogle Colaboratory\nhelp\nlist\n\n\n\npip install ...\nrange\nslicing\ntuple\ntype\nwhitespace indentation\nzero-indexing",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#lecture-2-deep-learning",
    "href": "index.html#lecture-2-deep-learning",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "Lecture 2: Deep Learning",
    "text": "Lecture 2: Deep Learning\n\n\n\nactivations, activation function\nartificial neural network\nbiases (in neurons)\ncallbacks\ncost/loss function\ndeep/shallow network, network depth\ndense or fully-connected layer\nearly stopping\nepoch\nfeed-forward neural network\n\n\n\nKeras, Tensorflow, PyTorch\nmatplotlib, seaborn\nneural network architecture\noverfitting\nperceptron\nReLU activation\nrepresentation learning\ntraining/validation/test split\nuniversal approximation theorem\nweights (in a neuron)",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#tutorial-2-forward-pass",
    "href": "index.html#tutorial-2-forward-pass",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "Tutorial 2: Forward Pass",
    "text": "Tutorial 2: Forward Pass\n\n\n\nbatches, batch size\nforward pass of network\ngradient-based learning\n\n\n\nlearning rate\nstochastic (mini-batch) gradient descent",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#lecture-3-tabular-data",
    "href": "index.html#lecture-3-tabular-data",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "Lecture 3: Tabular Data",
    "text": "Lecture 3: Tabular Data\n\n\nCategorical Variables\n\nentity embeddings\nInput layer\nKeras functional API\nnominal variables\nordinal variables\nReshape layer\nskip connection\nwide & deep network\n\n\nClassification\n\naccuracy\nconfusion matrix\ncross-entropy loss\nmetrics\nsigmoid activation\nsofmax activation",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#lecture-4-computer-vision",
    "href": "index.html#lecture-4-computer-vision",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "Lecture 4: Computer Vision",
    "text": "Lecture 4: Computer Vision\n\n\n\nAlexNet, GoogLeNet, Inception\nchannels\ncomputer vision\nconvolutional layer & CNN\nerror analysis\nfine-tuning\nfilter/kernel\n\n\n\nflatten layer\nImageNet\nmax pooling\nMNIST\nstride\ntensor (rank, dimension)\ntransfer learning",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#tutorial-4-backpropagation",
    "href": "index.html#tutorial-4-backpropagation",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "Tutorial 4: Backpropagation",
    "text": "Tutorial 4: Backpropagation\n\nbackpropagation\npartial derivatives",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#lecture-5-natural-language-processing",
    "href": "index.html#lecture-5-natural-language-processing",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "Lecture 5: Natural Language Processing",
    "text": "Lecture 5: Natural Language Processing\n\n\n\nbag of words\nlemmatization\none-hot embedding\nstop words\n\n\n\nvocabulary\nword embeddings/vectors\nword2vec",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#lecture-6-uncertainy-quantification",
    "href": "index.html#lecture-6-uncertainy-quantification",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "Lecture 6: Uncertainy Quantification",
    "text": "Lecture 6: Uncertainy Quantification\n\n\n\naleatoric and epistemic uncertainty\nBayesian neural network\ndeep ensembles\ndropout\nensemble model\nCANN\nGLM\n\n\n\nMDN\nmixture distribution\nMonte Carlo dropout\nposterior sampling\nproper scoring rule\nuncertainty quantification\nvariational approximation",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#lecture-7-recurrent-networks-and-time-series",
    "href": "index.html#lecture-7-recurrent-networks-and-time-series",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "Lecture 7: Recurrent Networks and Time Series",
    "text": "Lecture 7: Recurrent Networks and Time Series\n\nGRU\nLSTM\nrecurrent neural networks\nSimpleRNN",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#lecture-8-generative-networks",
    "href": "index.html#lecture-8-generative-networks",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "Lecture 8: Generative Networks",
    "text": "Lecture 8: Generative Networks",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#lecture-8-9-generative-networks",
    "href": "index.html#lecture-8-9-generative-networks",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "Lecture 8-9: Generative Networks",
    "text": "Lecture 8-9: Generative Networks\n\n\n\nautoencoder (variational)\nbeam search\nbias\nChatGPT (& RLHF)\nDeepDream\ngenerative adversarial networks\ngreedy sampling\n\n\n\nHugging Face\nlanguage model\nlatent space\nneural style transfer\nsoftmax temperature\nstochastic sampling",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#lecture-9-interpretability",
    "href": "index.html#lecture-9-interpretability",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "Lecture 9: Interpretability",
    "text": "Lecture 9: Interpretability\n\nglobal interpretability\nGrad-CAM\ninherent interpretability\nLIME\nlocal interpretability\npermutation importance\npost-hoc interpretability\nSHAP values",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#contributors",
    "href": "index.html#contributors",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "Contributors",
    "text": "Contributors\n\nTian (Eric) Dong\nMichael Jacinto\nHang Nguyen\nMarcus Lautier\nGayani Thalagoda",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#copyright",
    "href": "index.html#copyright",
    "title": "Artificial Intelligence and Deep Learning Models for Actuarial Applications",
    "section": "Copyright",
    "text": "Copyright\nUNSW Sydney.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html",
    "title": "Examinable Topics for Revision",
    "section": "",
    "text": "Exam is on Inspera\nOpen book\nNo handwritten answers, maybe have a calculator handy\nYou’ll have 1.5 hours to complete plus 15 mins reading\nComplete the IT preparation checklist (MFA, speed test, read policies)",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html#exam-details",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html#exam-details",
    "title": "Examinable Topics for Revision",
    "section": "",
    "text": "Exam is on Inspera\nOpen book\nNo handwritten answers, maybe have a calculator handy\nYou’ll have 1.5 hours to complete plus 15 mins reading\nComplete the IT preparation checklist (MFA, speed test, read policies)",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-1-ai",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-1-ai",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 1: AI",
    "text": "Lecture 1: AI\n\n\n\nartificial intelligence\nartificial intelligence vs machine learning\nclassification problem\nDeep Blue\nlabelled/unlabelled data\n\n\n\nmachine learning\nminimax algorithm\npseudocode\nregression problem\ntargets",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-1-python",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-1-python",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 1: Python",
    "text": "Lecture 1: Python\n\n\n\ndefault arguments\ndictionaries\nf-strings\nfunction definitions\nGoogle Colaboratory\nhelp\nlist\n\n\n\npip install ...\nrange\nslicing\ntuple\ntype\nwhitespace indentation\nzero-indexing",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-2-deep-learning",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-2-deep-learning",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 2: Deep Learning",
    "text": "Lecture 2: Deep Learning\n\n\n\nactivations, activation function\nartificial neural network\nbiases (in neurons)\ncallbacks\ncost/loss function\ndeep/shallow network, network depth\ndense or fully-connected layer\nearly stopping\nepoch\nfeed-forward neural network\n\n\n\nKeras, Tensorflow, PyTorch\nmatplotlib, seaborn\nneural network architecture\noverfitting\nperceptron\nReLU activation\nrepresentation learning\ntraining/validation/test split\nuniversal approximation theorem\nweights (in a neuron)",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html#tutorial-2-forward-pass",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html#tutorial-2-forward-pass",
    "title": "Examinable Topics for Revision",
    "section": "Tutorial 2: Forward Pass",
    "text": "Tutorial 2: Forward Pass\n\n\n\nbatches, batch size\nforward pass of network\ngradient-based learning\n\n\n\nlearning rate\nstochastic (mini-batch) gradient descent",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-3-mixed-topics",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-3-mixed-topics",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 3: Mixed Topics",
    "text": "Lecture 3: Mixed Topics\n\n\nCategorical Variables\n\nentity embeddings\nInput layer\nKeras functional API\nnominal variables\nordinal variables\nReshape layer\nskip connection\nwide & deep network\n\n\nClassification\n\naccuracy\nconfusion matrix\ncross-entropy loss\nmetrics\nsigmoid activation\nsofmax activation",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-4-computer-vision",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-4-computer-vision",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 4: Computer Vision",
    "text": "Lecture 4: Computer Vision\n\n\n\nchannels\ncomputer vision\nconvolutional layer & CNN\nerror analysis\nfilter/kernel\n\n\n\nflatten layer\nmax pooling\nMNIST\nstride\ntensor (rank, dimension)",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html#tutorial-4-backpropagation",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html#tutorial-4-backpropagation",
    "title": "Examinable Topics for Revision",
    "section": "Tutorial 4: Backpropagation",
    "text": "Tutorial 4: Backpropagation\n\nbackpropagation\npartial derivatives",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-5-natural-language",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-5-natural-language",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 5: Natural Language",
    "text": "Lecture 5: Natural Language\n\n\n\nbag of words\nlemmatization\none-hot embedding\nstop words\n\n\n\nvocabulary\nword embeddings/vectors\nword2vec",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html#week-6-uncertainy-quantification",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html#week-6-uncertainy-quantification",
    "title": "Examinable Topics for Revision",
    "section": "Week 6: Uncertainy Quantification",
    "text": "Week 6: Uncertainy Quantification\n\n\n\naleatoric and epistemic uncertainty\nBayesian neural network\ndeep ensembles\ndropout\nensemble model\nCANN\nGLM\n\n\n\nMDN\nmixture distribution\nMonte Carlo dropout\nposterior sampling\nproper scoring rule\nuncertainty quantification\nvariational approximation",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-7-recurrent-networks",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-7-recurrent-networks",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 7: Recurrent Networks",
    "text": "Lecture 7: Recurrent Networks\n\nGRU\nLSTM\nrecurrent neural networks\nSimpleRNN",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-8-transfer-learning",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-8-transfer-learning",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 8: Transfer Learning",
    "text": "Lecture 8: Transfer Learning\n\n\n\nAlexNet, GoogLeNet, Inception\nImageNet\n\n\n\nfine-tuning\ntransfer learning",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-8-9-generative-networks",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-8-9-generative-networks",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 8-9: Generative Networks",
    "text": "Lecture 8-9: Generative Networks\n\n\n\nautoencoder (variational)\nbeam search\nbias\nChatGPT (& RLHF)\nDeepDream\ngenerative adversarial networks\ngreedy sampling\n\n\n\nHugging Face\nlanguage model\nlatent space\nneural style transfer\nsoftmax temperature\nstochastic sampling",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-9-interpretability",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html#lecture-9-interpretability",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 9: Interpretability",
    "text": "Lecture 9: Interpretability\n\nglobal interpretability\nGrad-CAM\ninherent interpretability\nLIME\nlocal interpretability\npermutation importance\npost-hoc interpretability\nSHAP values",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.html#storywalls",
    "href": "Lecture-9-Advanced-Topics/exam-revision.html#storywalls",
    "title": "Examinable Topics for Revision",
    "section": "StoryWalls",
    "text": "StoryWalls\n\nGo AI: Basic Python\nSydney Temperature Forecasting: Basic MLP\nVictorian Crash Severity: Classification & entity-embedding\nHurricane damage: Convolutional neural networks and hyperparameter tuning\nUS Police reports: NLP with bag-of-words, TF-IDF, permutation importance\nHealth Insurance Premiums: Uncertainty Quantification\nGenerative networks experimenting",
    "crumbs": [
      "Module 9",
      "Examinable Topics for Revision"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.slides.html#exam-details",
    "href": "Lecture-9-Advanced-Topics/exam-revision.slides.html#exam-details",
    "title": "Examinable Topics for Revision",
    "section": "Exam details",
    "text": "Exam details\n\nExam is on Inspera\nOpen book\nNo handwritten answers, maybe have a calculator handy\nYou’ll have 1.5 hours to complete plus 15 mins reading\nComplete the IT preparation checklist (MFA, speed test, read policies)"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-1-ai",
    "href": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-1-ai",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 1: AI",
    "text": "Lecture 1: AI\n\n\n\nartificial intelligence\nartificial intelligence vs machine learning\nclassification problem\nDeep Blue\nlabelled/unlabelled data\n\n\n\nmachine learning\nminimax algorithm\npseudocode\nregression problem\ntargets"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-1-python",
    "href": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-1-python",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 1: Python",
    "text": "Lecture 1: Python\n\n\n\ndefault arguments\ndictionaries\nf-strings\nfunction definitions\nGoogle Colaboratory\nhelp\nlist\n\n\n\npip install ...\nrange\nslicing\ntuple\ntype\nwhitespace indentation\nzero-indexing"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-2-deep-learning",
    "href": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-2-deep-learning",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 2: Deep Learning",
    "text": "Lecture 2: Deep Learning\n\n\n\nactivations, activation function\nartificial neural network\nbiases (in neurons)\ncallbacks\ncost/loss function\ndeep/shallow network, network depth\ndense or fully-connected layer\nearly stopping\nepoch\nfeed-forward neural network\n\n\n\nKeras, Tensorflow, PyTorch\nmatplotlib, seaborn\nneural network architecture\noverfitting\nperceptron\nReLU activation\nrepresentation learning\ntraining/validation/test split\nuniversal approximation theorem\nweights (in a neuron)"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.slides.html#tutorial-2-forward-pass",
    "href": "Lecture-9-Advanced-Topics/exam-revision.slides.html#tutorial-2-forward-pass",
    "title": "Examinable Topics for Revision",
    "section": "Tutorial 2: Forward Pass",
    "text": "Tutorial 2: Forward Pass\n\n\n\nbatches, batch size\nforward pass of network\ngradient-based learning\n\n\n\nlearning rate\nstochastic (mini-batch) gradient descent"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-3-mixed-topics",
    "href": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-3-mixed-topics",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 3: Mixed Topics",
    "text": "Lecture 3: Mixed Topics\n\n\nCategorical Variables\n\nentity embeddings\nInput layer\nKeras functional API\nnominal variables\nordinal variables\nReshape layer\nskip connection\nwide & deep network\n\n\nClassification\n\naccuracy\nconfusion matrix\ncross-entropy loss\nmetrics\nsigmoid activation\nsofmax activation"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-4-computer-vision",
    "href": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-4-computer-vision",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 4: Computer Vision",
    "text": "Lecture 4: Computer Vision\n\n\n\nchannels\ncomputer vision\nconvolutional layer & CNN\nerror analysis\nfilter/kernel\n\n\n\nflatten layer\nmax pooling\nMNIST\nstride\ntensor (rank, dimension)"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.slides.html#tutorial-4-backpropagation",
    "href": "Lecture-9-Advanced-Topics/exam-revision.slides.html#tutorial-4-backpropagation",
    "title": "Examinable Topics for Revision",
    "section": "Tutorial 4: Backpropagation",
    "text": "Tutorial 4: Backpropagation\n\nbackpropagation\npartial derivatives"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-5-natural-language",
    "href": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-5-natural-language",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 5: Natural Language",
    "text": "Lecture 5: Natural Language\n\n\n\nbag of words\nlemmatization\none-hot embedding\nstop words\n\n\n\nvocabulary\nword embeddings/vectors\nword2vec"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.slides.html#week-6-uncertainy-quantification",
    "href": "Lecture-9-Advanced-Topics/exam-revision.slides.html#week-6-uncertainy-quantification",
    "title": "Examinable Topics for Revision",
    "section": "Week 6: Uncertainy Quantification",
    "text": "Week 6: Uncertainy Quantification\n\n\n\naleatoric and epistemic uncertainty\nBayesian neural network\ndeep ensembles\ndropout\nensemble model\nCANN\nGLM\n\n\n\nMDN\nmixture distribution\nMonte Carlo dropout\nposterior sampling\nproper scoring rule\nuncertainty quantification\nvariational approximation"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-7-recurrent-networks",
    "href": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-7-recurrent-networks",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 7: Recurrent Networks",
    "text": "Lecture 7: Recurrent Networks\n\nGRU\nLSTM\nrecurrent neural networks\nSimpleRNN"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-8-transfer-learning",
    "href": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-8-transfer-learning",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 8: Transfer Learning",
    "text": "Lecture 8: Transfer Learning\n\n\n\nAlexNet, GoogLeNet, Inception\nImageNet\n\n\n\nfine-tuning\ntransfer learning"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-8-9-generative-networks",
    "href": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-8-9-generative-networks",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 8-9: Generative Networks",
    "text": "Lecture 8-9: Generative Networks\n\n\n\nautoencoder (variational)\nbeam search\nbias\nChatGPT (& RLHF)\nDeepDream\ngenerative adversarial networks\ngreedy sampling\n\n\n\nHugging Face\nlanguage model\nlatent space\nneural style transfer\nsoftmax temperature\nstochastic sampling"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-9-interpretability",
    "href": "Lecture-9-Advanced-Topics/exam-revision.slides.html#lecture-9-interpretability",
    "title": "Examinable Topics for Revision",
    "section": "Lecture 9: Interpretability",
    "text": "Lecture 9: Interpretability\n\nglobal interpretability\nGrad-CAM\ninherent interpretability\nLIME\nlocal interpretability\npermutation importance\npost-hoc interpretability\nSHAP values"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/exam-revision.slides.html#storywalls",
    "href": "Lecture-9-Advanced-Topics/exam-revision.slides.html#storywalls",
    "title": "Examinable Topics for Revision",
    "section": "StoryWalls",
    "text": "StoryWalls\n\nGo AI: Basic Python\nSydney Temperature Forecasting: Basic MLP\nVictorian Crash Severity: Classification & entity-embedding\nHurricane damage: Convolutional neural networks and hyperparameter tuning\nUS Police reports: NLP with bag-of-words, TF-IDF, permutation importance\nHealth Insurance Premiums: Uncertainty Quantification\nGenerative networks experimenting"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html",
    "href": "Lecture-8-Generative-Networks/gans.html",
    "title": "Generative Adversarial Networks",
    "section": "",
    "text": "GANs consist of two neural networks, a generator, and a discriminator, and they are trained simultaneously through adversarial training. The generator takes in random noise and generates a synthetic data observation. The goal of the generator is to learn how to generate synthetic data that resembles actual data very well. The discriminator distinguishes between real and synthetic data and classifies them as ‘real’ or ‘fake’. The goal of the discriminator is to correctly identify whether the input is real or synthetic. An equilibrium is reached when the generator is able to generate data that very well resembles actual data and the discriminator is unable to distinguish them with high confidence.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#before-gans-we-had-autoencoders",
    "href": "Lecture-8-Generative-Networks/gans.html#before-gans-we-had-autoencoders",
    "title": "Generative Adversarial Networks",
    "section": "Before GANs we had autoencoders",
    "text": "Before GANs we had autoencoders\nAn autoencoder takes a data/image, maps it to a latent space via en encoder module, then decodes it back to an output with the same dimensions via a decoder module.\n\n\n\nSchematic of an autoencoder.\n\n\n\nSource: Marcus Lautier (2022).",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#gan-faces",
    "href": "Lecture-8-Generative-Networks/gans.html#gan-faces",
    "title": "Generative Adversarial Networks",
    "section": "GAN faces",
    "text": "GAN faces\n\n\n\n\n\n\n\nTry out https://www.whichfaceisreal.com.\n\nSource: https://thispersondoesnotexist.com.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#example-stylegan2-ada-outputs",
    "href": "Lecture-8-Generative-Networks/gans.html#example-stylegan2-ada-outputs",
    "title": "Generative Adversarial Networks",
    "section": "Example StyleGAN2-ADA outputs",
    "text": "Example StyleGAN2-ADA outputs\n\n\nSource: Jeff Heaton (2021), Training a GAN from your Own Images: StyleGAN2.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#gan-structure",
    "href": "Lecture-8-Generative-Networks/gans.html#gan-structure",
    "title": "Generative Adversarial Networks",
    "section": "GAN structure",
    "text": "GAN structure\n\n\n\nA schematic of a generative adversarial network.\n\n\n\nSource: Thales Silva (2018), An intuitive introduction to Generative Adversarial Networks (GANs), freeCodeCamp.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#gan-intuition",
    "href": "Lecture-8-Generative-Networks/gans.html#gan-intuition",
    "title": "Generative Adversarial Networks",
    "section": "GAN intuition",
    "text": "GAN intuition\n  \n\nSource: Google Developers, Overview of GAN Structure, Google Machine Learning Education.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#intuition-about-gans",
    "href": "Lecture-8-Generative-Networks/gans.html#intuition-about-gans",
    "title": "Generative Adversarial Networks",
    "section": "Intuition about GANs",
    "text": "Intuition about GANs\n\nA forger creates a fake Picasso painting to sell to an art dealer.\nThe art dealer assesses the painting.\n\nHow they best each other:\n\nThe art dealer is given both authentic paintings and fake paintings to look at. Later on, the validity his assessment is evaluated and he trains to become better at detecting fakes. Over time, he becomes increasingly expert at authenticating Picasso’s artwork.\nThe forger receives an assessment from the art dealer everytime he gives him a fake. He knows he has to perfect his craft if the art dealer can detect his fake. He becomes increasingly adept at imitating Picasso’s style.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#generative-adversarial-networks",
    "href": "Lecture-8-Generative-Networks/gans.html#generative-adversarial-networks",
    "title": "Generative Adversarial Networks",
    "section": "Generative adversarial networks",
    "text": "Generative adversarial networks\n\nA GAN is made up of two parts:\n\nGenerator network: the forger. Takes a random point in the latent space, and decodes it into a synthetic data/image.\nDiscriminator network (or adversary): the expert. Takes a data/image and decide whether it exists in the original data set (the training set) or was created by the generator network.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#discriminator",
    "href": "Lecture-8-Generative-Networks/gans.html#discriminator",
    "title": "Generative Adversarial Networks",
    "section": "Discriminator",
    "text": "Discriminator\nlrelu = layers.LeakyReLU(alpha=0.2)\n\ndiscriminator = keras.Sequential([\n    keras.Input(shape=(28, 28, 1)),\n    layers.Conv2D(64, 3, strides=2, padding=\"same\", activation=lrelu),\n    layers.Conv2D(128, 3, strides=2, padding=\"same\", activation=lrelu),\n    layers.GlobalMaxPooling2D(),\n    layers.Dense(1)])\n\ndiscriminator.summary()",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#generator",
    "href": "Lecture-8-Generative-Networks/gans.html#generator",
    "title": "Generative Adversarial Networks",
    "section": "Generator",
    "text": "Generator\nlatent_dim = 128\ngenerator = keras.Sequential([\n    layers.Dense(7 * 7 * 128, input_dim=latent_dim, activation=lrelu),\n    layers.Reshape((7, 7, 128)),\n    layers.Conv2DTranspose(128, 4, strides=2, padding=\"same\", activation=lrelu),\n    layers.Conv2DTranspose(128, 4, strides=2, padding=\"same\", activation=lrelu),\n    layers.Conv2D(1, 7, padding=\"same\", activation=\"sigmoid\")])\ngenerator.summary()",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#gan-cost-functions",
    "href": "Lecture-8-Generative-Networks/gans.html#gan-cost-functions",
    "title": "Generative Adversarial Networks",
    "section": "GAN cost functions",
    "text": "GAN cost functions\n\n\nVideo\nThe loss function à la 3Blue1Brown.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#gan---schematic-process",
    "href": "Lecture-8-Generative-Networks/gans.html#gan---schematic-process",
    "title": "Generative Adversarial Networks",
    "section": "GAN - Schematic process",
    "text": "GAN - Schematic process\nFirst step: Training discriminator:\n\nDraw random points in the latent space (random noise).\nUse generator to generate data from this random noise.\nMix generated data with real data and input them into the discriminator. The training targets are the correct labels of real data or fake data. Use discriminator to give feedback on the mixed data whether they are real or synthetic. Train discriminator to minimize the loss function which is the difference between the discriminator’s feedback and the correct labels.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#gan---schematic-process-ii",
    "href": "Lecture-8-Generative-Networks/gans.html#gan---schematic-process-ii",
    "title": "Generative Adversarial Networks",
    "section": "GAN - Schematic process II",
    "text": "GAN - Schematic process II\nSecond step: Training generator:\n\nDraw random points in the latent space and generate data with generator.\nUse discriminator to give feedback on the generated data. What the generator tries to achieve is to fool the discriminator into thinking all generated data are real data. Train generator to minimize the loss function which is the difference between the discriminator’s feedback and the desired feedback: “All data are real data” (which is not true).",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#gan---schematic-process-iii",
    "href": "Lecture-8-Generative-Networks/gans.html#gan---schematic-process-iii",
    "title": "Generative Adversarial Networks",
    "section": "GAN - Schematic process III",
    "text": "GAN - Schematic process III\n\nWhen training, the discriminator may end up dominating the generator because the loss function for training the discriminator tends to zero faster. In that case, try reducing the learning rate and increase the dropout rate of the discriminator.\nThere are a few tricks for implementing GANS such as introducing stochasticity by adding random noise to the labels for the discriminator, using stride instead of pooling in the discriminator, using kernel size that is divisible by stride size, etc.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#train-step",
    "href": "Lecture-8-Generative-Networks/gans.html#train-step",
    "title": "Generative Adversarial Networks",
    "section": "Train step",
    "text": "Train step\n# Separate optimisers for discriminator and generator.\nd_optimizer = keras.optimizers.Adam(learning_rate=0.0003)\ng_optimizer = keras.optimizers.Adam(learning_rate=0.0004)\n\n# Instantiate a loss function.\nloss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n\n@tf.function\ndef train_step(real_images):\n  # Sample random points in the latent space\n  random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n  # Decode them to fake images\n  generated_images = generator(random_latent_vectors)\n  # Combine them with real images\n  combined_images = tf.concat([generated_images, real_images], axis=0)\n\n  # Assemble labels discriminating real from fake images\n  labels = tf.concat([\n    tf.zeros((batch_size, 1)),\n    tf.ones((real_images.shape[0], 1))], axis=0)\n\n  # Add random noise to the labels - important trick!\n  labels += 0.05 * tf.random.uniform(labels.shape)\n\n  # Train the discriminator\n  with tf.GradientTape() as tape:\n    predictions = discriminator(combined_images)\n    d_loss = loss_fn(labels, predictions)\n  grads = tape.gradient(d_loss, discriminator.trainable_weights)\n  d_optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))\n\n  # Sample random points in the latent space\n  random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n\n  # Assemble labels that say \"all real images\"\n  misleading_labels = tf.ones((batch_size, 1))\n\n  # Train the generator (note that we should *not* update the weights\n  # of the discriminator)!\n  with tf.GradientTape() as tape:\n    predictions = discriminator(generator(random_latent_vectors))\n    g_loss = loss_fn(misleading_labels, predictions)\n\n  grads = tape.gradient(g_loss, generator.trainable_weights)\n  g_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n  return d_loss, g_loss, generated_images",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#grab-the-data",
    "href": "Lecture-8-Generative-Networks/gans.html#grab-the-data",
    "title": "Generative Adversarial Networks",
    "section": "Grab the data",
    "text": "Grab the data\n# Prepare the dataset.\n# We use both the training & test MNIST digits.\nbatch_size = 64\n(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\nall_digits = np.concatenate([x_train, x_test])\nall_digits = all_digits.astype(\"float32\") / 255.0\nall_digits = np.reshape(all_digits, (-1, 28, 28, 1))\ndataset = tf.data.Dataset.from_tensor_slices(all_digits)\ndataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n\n# In practice you need at least 20 epochs to generate nice digits.\nepochs = 1\nsave_dir = \"./\"",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#train-the-gan",
    "href": "Lecture-8-Generative-Networks/gans.html#train-the-gan",
    "title": "Generative Adversarial Networks",
    "section": "Train the GAN",
    "text": "Train the GAN\n%%time\nfor epoch in range(epochs):\n  for step, real_images in enumerate(dataset):\n    # Train the discriminator & generator on one batch of real images.\n    d_loss, g_loss, generated_images = train_step(real_images)\n\n    # Logging.\n    if step % 200 == 0:\n      # Print metrics\n      print(f\"Discriminator loss at step {step}: {d_loss:.2f}\")\n      print(f\"Adversarial loss at step {step}: {g_loss:.2f}\")\n      break # Remove this if really training the GAN",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#unconditional-gans",
    "href": "Lecture-8-Generative-Networks/gans.html#unconditional-gans",
    "title": "Generative Adversarial Networks",
    "section": "Unconditional GANs",
    "text": "Unconditional GANs\n\n\n\nAnalogy for an unconditional GAN\n\n\n\nSource: Sharon Zhou, Conditional Generation: Intuition Build Basic Generative Adversarial Networks (Week 4), DeepLearning.AI on Coursera.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#conditional-gans-1",
    "href": "Lecture-8-Generative-Networks/gans.html#conditional-gans-1",
    "title": "Generative Adversarial Networks",
    "section": "Conditional GANs",
    "text": "Conditional GANs\n\n\n\nAnalogy for a conditional GAN\n\n\n\nSource: Sharon Zhou, Conditional Generation: Intuition Build Basic Generative Adversarial Networks (Week 4), DeepLearning.AI on Coursera.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#hurricane-example-data",
    "href": "Lecture-8-Generative-Networks/gans.html#hurricane-example-data",
    "title": "Generative Adversarial Networks",
    "section": "Hurricane example data",
    "text": "Hurricane example data\n\n\n\nOriginal data",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#hurricane-example",
    "href": "Lecture-8-Generative-Networks/gans.html#hurricane-example",
    "title": "Generative Adversarial Networks",
    "section": "Hurricane example",
    "text": "Hurricane example\n\n\n\nInitial fakes",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#hurricane-example-after-54s",
    "href": "Lecture-8-Generative-Networks/gans.html#hurricane-example-after-54s",
    "title": "Generative Adversarial Networks",
    "section": "Hurricane example (after 54s)",
    "text": "Hurricane example (after 54s)\n\n\n\nFakes after 1 iteration",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#hurricane-example-after-21m",
    "href": "Lecture-8-Generative-Networks/gans.html#hurricane-example-after-21m",
    "title": "Generative Adversarial Networks",
    "section": "Hurricane example (after 21m)",
    "text": "Hurricane example (after 21m)\n\n\n\nFakes after 100 kimg",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#hurricane-example-after-47m",
    "href": "Lecture-8-Generative-Networks/gans.html#hurricane-example-after-47m",
    "title": "Generative Adversarial Networks",
    "section": "Hurricane example (after 47m)",
    "text": "Hurricane example (after 47m)\n\n\n\nFakes after 200 kimg",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#hurricane-example-after-4h10m",
    "href": "Lecture-8-Generative-Networks/gans.html#hurricane-example-after-4h10m",
    "title": "Generative Adversarial Networks",
    "section": "Hurricane example (after 4h10m)",
    "text": "Hurricane example (after 4h10m)\n\n\n\nFakes after 1000 kimg",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#hurricane-example-after-14h41m",
    "href": "Lecture-8-Generative-Networks/gans.html#hurricane-example-after-14h41m",
    "title": "Generative Adversarial Networks",
    "section": "Hurricane example (after 14h41m)",
    "text": "Hurricane example (after 14h41m)\n\n\n\nFakes after 3700 kimg",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#example-deoldify-images-1",
    "href": "Lecture-8-Generative-Networks/gans.html#example-deoldify-images-1",
    "title": "Generative Adversarial Networks",
    "section": "Example: Deoldify images #1",
    "text": "Example: Deoldify images #1\n\n\n\nA deoldified version of the famous “Migrant Mother” photograph.\n\n\n\nSource: Deoldify package.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#example-deoldify-images-2",
    "href": "Lecture-8-Generative-Networks/gans.html#example-deoldify-images-2",
    "title": "Generative Adversarial Networks",
    "section": "Example: Deoldify images #2",
    "text": "Example: Deoldify images #2\n\n\n\nA deoldified Golden Gate Bridge under construction.\n\n\n\nSource: Deoldify package.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#example-deoldify-images-3",
    "href": "Lecture-8-Generative-Networks/gans.html#example-deoldify-images-3",
    "title": "Generative Adversarial Networks",
    "section": "Example: Deoldify images #3",
    "text": "Example: Deoldify images #3",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#explore-the-latent-space",
    "href": "Lecture-8-Generative-Networks/gans.html#explore-the-latent-space",
    "title": "Generative Adversarial Networks",
    "section": "Explore the latent space",
    "text": "Explore the latent space",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#generator-cant-generate-everything",
    "href": "Lecture-8-Generative-Networks/gans.html#generator-cant-generate-everything",
    "title": "Generative Adversarial Networks",
    "section": "Generator can’t generate everything",
    "text": "Generator can’t generate everything\n\n\n\n\n\nTarget\n\n\n\n\n\n\nProjection",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#they-are-slow-to-train",
    "href": "Lecture-8-Generative-Networks/gans.html#they-are-slow-to-train",
    "title": "Generative Adversarial Networks",
    "section": "They are slow to train",
    "text": "They are slow to train\nStyleGAN2-ADA training times on V100s (1024x1024):\n\n\n\n\n\n\n\n\n\n\n\nGPUs\n1000 kimg\n25000 kimg\nsec / kimg\nGPU mem\nCPU mem\n\n\n\n\n1\n1d 20h\n46d 03h\n158\n8.1 GB\n5.3 GB\n\n\n2\n23h 09m\n24d 02h\n83\n8.6 GB\n11.9 GB\n\n\n4\n11h 36m\n12d 02h\n40\n8.4 GB\n21.9 GB\n\n\n8\n5h 54m\n6d 03h\n20\n8.3 GB\n44.7 GB\n\n\n\n\nSource: NVIDIA’s Github, StyleGAN2-ADA — Official PyTorch implementation.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#uncertain-convergence",
    "href": "Lecture-8-Generative-Networks/gans.html#uncertain-convergence",
    "title": "Generative Adversarial Networks",
    "section": "Uncertain convergence",
    "text": "Uncertain convergence\nConverges to a Nash equilibrium.. if at all.\n\n\n\nAnalogy of minimax update failure.\n\n\n\nSource: Lilian Weng (2019), From GAN to WGAN, ArXiV.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#mode-collapse",
    "href": "Lecture-8-Generative-Networks/gans.html#mode-collapse",
    "title": "Generative Adversarial Networks",
    "section": "Mode collapse",
    "text": "Mode collapse\n\n\n\n\n\nExample of mode collapse\n\n\n\n\n\n\n\nSource: Metz et al. (2017), Unrolled Generative Adversarial Networks and Randall Munroe (2007), xkcd #221: Random Number.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#generation-is-harder",
    "href": "Lecture-8-Generative-Networks/gans.html#generation-is-harder",
    "title": "Generative Adversarial Networks",
    "section": "Generation is harder",
    "text": "Generation is harder\n\n\n\nA schematic of a generative adversarial network.\n\n\n# Separate optimisers for discriminator and generator.\nd_optimizer = keras.optimizers.Adam(learning_rate=0.0003)\ng_optimizer = keras.optimizers.Adam(learning_rate=0.0004)\n\nSource: Thales Silva (2018), An intuitive introduction to Generative Adversarial Networks (GANs), freeCodeCamp.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#advanced-image-layers",
    "href": "Lecture-8-Generative-Networks/gans.html#advanced-image-layers",
    "title": "Generative Adversarial Networks",
    "section": "Advanced image layers",
    "text": "Advanced image layers\n\nConv2D\n\n\nGlobalMaxPool2D\n\n\nConv2DTranspose\n\n\n\n\n\nSources: Pröve (2017), An Introduction to different Types of Convolutions in Deep Learning, and Peltarion Knowledge Center, Global max pooling 2D.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#vanishing-gradients-i",
    "href": "Lecture-8-Generative-Networks/gans.html#vanishing-gradients-i",
    "title": "Generative Adversarial Networks",
    "section": "Vanishing gradients (I)",
    "text": "Vanishing gradients (I)\n\n\n\nWhen the discriminator is too good, vanishing gradients\n\n\n\nSource: Sharon Zhou, Problem with BCE Loss, Build Basic Generative Adversarial Networks (Week 3), DeepLearning.AI on Coursera.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#vanishing-gradients-ii",
    "href": "Lecture-8-Generative-Networks/gans.html#vanishing-gradients-ii",
    "title": "Generative Adversarial Networks",
    "section": "Vanishing gradients (II)",
    "text": "Vanishing gradients (II)\n\n\n\nVanishing gradients\n\n\n\nSource: Lilian Weng (2019), From GAN to WGAN, ArXiV.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#were-comparing-distributions",
    "href": "Lecture-8-Generative-Networks/gans.html#were-comparing-distributions",
    "title": "Generative Adversarial Networks",
    "section": "We’re comparing distributions",
    "text": "We’re comparing distributions\nTrying to minimise the distance between the distribution of generated samples and the distribution of real data.\nVanilla GAN is equivalent to minimising the Jensen–Shannon Divergence between the two.\nAn alternative distance between distributions is the Wasserstein distance.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#discriminator-critic",
    "href": "Lecture-8-Generative-Networks/gans.html#discriminator-critic",
    "title": "Generative Adversarial Networks",
    "section": "Discriminator Critic",
    "text": "Discriminator Critic\nCritic D : \\text{Input} \\to \\mathbb{R} how “authentic” the input looks. It can’t discriminate real from fake exactly.\nCritic’s goal is\n \\max_{D \\in \\mathscr{D}} \\mathbb{E}[ D(X) ] - \\mathbb{E}[ D(G(Z)) ] \nwhere we \\mathscr{D} is space of 1-Lipschitz functions. Either use gradient clipping or penalise gradients far from 1:\n \\max_{D} \\mathbb{E}[ D(X) ] - \\mathbb{E}[ D(G(Z)) ] + \\lambda \\mathbb{E} \\Bigl[ ( \\bigl|\\bigl| \\nabla D \\bigr|\\bigr| - 1)^2 \\Bigr] .",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#schematic",
    "href": "Lecture-8-Generative-Networks/gans.html#schematic",
    "title": "Generative Adversarial Networks",
    "section": "Schematic",
    "text": "Schematic\n\n\n\nWasserstein\n\n\n\nSource: Côté et al. (2020), Synthesizing Property & Casualty Ratemaking Datasets using Generative Adversarial Networks, Working Paper?.",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.html#links",
    "href": "Lecture-8-Generative-Networks/gans.html#links",
    "title": "Generative Adversarial Networks",
    "section": "Links",
    "text": "Links\n\nDongyu Liu (2021), TadGAN: Time Series Anomaly Detection Using Generative Adversarial Networks\nJeff Heaton (2022), GANs for Tabular Synthetic Data Generation (7.5)\nJeff Heaton (2022), GANs to Enhance Old Photographs Deoldify (7.4)",
    "crumbs": [
      "Module 8",
      "Generative Adversarial Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#before-gans-we-had-autoencoders",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#before-gans-we-had-autoencoders",
    "title": "Generative Adversarial Networks",
    "section": "Before GANs we had autoencoders",
    "text": "Before GANs we had autoencoders\nAn autoencoder takes a data/image, maps it to a latent space via en encoder module, then decodes it back to an output with the same dimensions via a decoder module.\n\nSchematic of an autoencoder.\nSource: Marcus Lautier (2022)."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#gan-faces",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#gan-faces",
    "title": "Generative Adversarial Networks",
    "section": "GAN faces",
    "text": "GAN faces\n\n\n\n\n\n\n\nTry out https://www.whichfaceisreal.com.\n\nSource: https://thispersondoesnotexist.com."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#example-stylegan2-ada-outputs",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#example-stylegan2-ada-outputs",
    "title": "Generative Adversarial Networks",
    "section": "Example StyleGAN2-ADA outputs",
    "text": "Example StyleGAN2-ADA outputs\n\n\nSource: Jeff Heaton (2021), Training a GAN from your Own Images: StyleGAN2."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#gan-structure",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#gan-structure",
    "title": "Generative Adversarial Networks",
    "section": "GAN structure",
    "text": "GAN structure\n\nA schematic of a generative adversarial network.\nSource: Thales Silva (2018), An intuitive introduction to Generative Adversarial Networks (GANs), freeCodeCamp."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#gan-intuition",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#gan-intuition",
    "title": "Generative Adversarial Networks",
    "section": "GAN intuition",
    "text": "GAN intuition\n  \n\nSource: Google Developers, Overview of GAN Structure, Google Machine Learning Education."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#intuition-about-gans",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#intuition-about-gans",
    "title": "Generative Adversarial Networks",
    "section": "Intuition about GANs",
    "text": "Intuition about GANs\n\nA forger creates a fake Picasso painting to sell to an art dealer.\nThe art dealer assesses the painting.\n\nHow they best each other:\n\nThe art dealer is given both authentic paintings and fake paintings to look at. Later on, the validity his assessment is evaluated and he trains to become better at detecting fakes. Over time, he becomes increasingly expert at authenticating Picasso’s artwork.\nThe forger receives an assessment from the art dealer everytime he gives him a fake. He knows he has to perfect his craft if the art dealer can detect his fake. He becomes increasingly adept at imitating Picasso’s style."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#generative-adversarial-networks",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#generative-adversarial-networks",
    "title": "Generative Adversarial Networks",
    "section": "Generative adversarial networks",
    "text": "Generative adversarial networks\n\nA GAN is made up of two parts:\n\nGenerator network: the forger. Takes a random point in the latent space, and decodes it into a synthetic data/image.\nDiscriminator network (or adversary): the expert. Takes a data/image and decide whether it exists in the original data set (the training set) or was created by the generator network."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#discriminator",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#discriminator",
    "title": "Generative Adversarial Networks",
    "section": "Discriminator",
    "text": "Discriminator\nlrelu = layers.LeakyReLU(alpha=0.2)\n\ndiscriminator = keras.Sequential([\n    keras.Input(shape=(28, 28, 1)),\n    layers.Conv2D(64, 3, strides=2, padding=\"same\", activation=lrelu),\n    layers.Conv2D(128, 3, strides=2, padding=\"same\", activation=lrelu),\n    layers.GlobalMaxPooling2D(),\n    layers.Dense(1)])\n\ndiscriminator.summary()"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#generator",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#generator",
    "title": "Generative Adversarial Networks",
    "section": "Generator",
    "text": "Generator\nlatent_dim = 128\ngenerator = keras.Sequential([\n    layers.Dense(7 * 7 * 128, input_dim=latent_dim, activation=lrelu),\n    layers.Reshape((7, 7, 128)),\n    layers.Conv2DTranspose(128, 4, strides=2, padding=\"same\", activation=lrelu),\n    layers.Conv2DTranspose(128, 4, strides=2, padding=\"same\", activation=lrelu),\n    layers.Conv2D(1, 7, padding=\"same\", activation=\"sigmoid\")])\ngenerator.summary()"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#gan-cost-functions",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#gan-cost-functions",
    "title": "Generative Adversarial Networks",
    "section": "GAN cost functions",
    "text": "GAN cost functions\n\n\nVideo\nThe loss function à la 3Blue1Brown."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#gan---schematic-process",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#gan---schematic-process",
    "title": "Generative Adversarial Networks",
    "section": "GAN - Schematic process",
    "text": "GAN - Schematic process\nFirst step: Training discriminator:\n\nDraw random points in the latent space (random noise).\nUse generator to generate data from this random noise.\nMix generated data with real data and input them into the discriminator. The training targets are the correct labels of real data or fake data. Use discriminator to give feedback on the mixed data whether they are real or synthetic. Train discriminator to minimize the loss function which is the difference between the discriminator’s feedback and the correct labels."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#gan---schematic-process-ii",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#gan---schematic-process-ii",
    "title": "Generative Adversarial Networks",
    "section": "GAN - Schematic process II",
    "text": "GAN - Schematic process II\nSecond step: Training generator:\n\nDraw random points in the latent space and generate data with generator.\nUse discriminator to give feedback on the generated data. What the generator tries to achieve is to fool the discriminator into thinking all generated data are real data. Train generator to minimize the loss function which is the difference between the discriminator’s feedback and the desired feedback: “All data are real data” (which is not true)."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#gan---schematic-process-iii",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#gan---schematic-process-iii",
    "title": "Generative Adversarial Networks",
    "section": "GAN - Schematic process III",
    "text": "GAN - Schematic process III\n\nWhen training, the discriminator may end up dominating the generator because the loss function for training the discriminator tends to zero faster. In that case, try reducing the learning rate and increase the dropout rate of the discriminator.\nThere are a few tricks for implementing GANS such as introducing stochasticity by adding random noise to the labels for the discriminator, using stride instead of pooling in the discriminator, using kernel size that is divisible by stride size, etc."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#train-step",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#train-step",
    "title": "Generative Adversarial Networks",
    "section": "Train step",
    "text": "Train step\n# Separate optimisers for discriminator and generator.\nd_optimizer = keras.optimizers.Adam(learning_rate=0.0003)\ng_optimizer = keras.optimizers.Adam(learning_rate=0.0004)\n\n# Instantiate a loss function.\nloss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n\n@tf.function\ndef train_step(real_images):\n  # Sample random points in the latent space\n  random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n  # Decode them to fake images\n  generated_images = generator(random_latent_vectors)\n  # Combine them with real images\n  combined_images = tf.concat([generated_images, real_images], axis=0)\n\n  # Assemble labels discriminating real from fake images\n  labels = tf.concat([\n    tf.zeros((batch_size, 1)),\n    tf.ones((real_images.shape[0], 1))], axis=0)\n\n  # Add random noise to the labels - important trick!\n  labels += 0.05 * tf.random.uniform(labels.shape)\n\n  # Train the discriminator\n  with tf.GradientTape() as tape:\n    predictions = discriminator(combined_images)\n    d_loss = loss_fn(labels, predictions)\n  grads = tape.gradient(d_loss, discriminator.trainable_weights)\n  d_optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))\n\n  # Sample random points in the latent space\n  random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n\n  # Assemble labels that say \"all real images\"\n  misleading_labels = tf.ones((batch_size, 1))\n\n  # Train the generator (note that we should *not* update the weights\n  # of the discriminator)!\n  with tf.GradientTape() as tape:\n    predictions = discriminator(generator(random_latent_vectors))\n    g_loss = loss_fn(misleading_labels, predictions)\n\n  grads = tape.gradient(g_loss, generator.trainable_weights)\n  g_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n  return d_loss, g_loss, generated_images"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#grab-the-data",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#grab-the-data",
    "title": "Generative Adversarial Networks",
    "section": "Grab the data",
    "text": "Grab the data\n# Prepare the dataset.\n# We use both the training & test MNIST digits.\nbatch_size = 64\n(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\nall_digits = np.concatenate([x_train, x_test])\nall_digits = all_digits.astype(\"float32\") / 255.0\nall_digits = np.reshape(all_digits, (-1, 28, 28, 1))\ndataset = tf.data.Dataset.from_tensor_slices(all_digits)\ndataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n\n# In practice you need at least 20 epochs to generate nice digits.\nepochs = 1\nsave_dir = \"./\""
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#train-the-gan",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#train-the-gan",
    "title": "Generative Adversarial Networks",
    "section": "Train the GAN",
    "text": "Train the GAN\n%%time\nfor epoch in range(epochs):\n  for step, real_images in enumerate(dataset):\n    # Train the discriminator & generator on one batch of real images.\n    d_loss, g_loss, generated_images = train_step(real_images)\n\n    # Logging.\n    if step % 200 == 0:\n      # Print metrics\n      print(f\"Discriminator loss at step {step}: {d_loss:.2f}\")\n      print(f\"Adversarial loss at step {step}: {g_loss:.2f}\")\n      break # Remove this if really training the GAN"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#unconditional-gans",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#unconditional-gans",
    "title": "Generative Adversarial Networks",
    "section": "Unconditional GANs",
    "text": "Unconditional GANs\n\nAnalogy for an unconditional GAN\nSource: Sharon Zhou, Conditional Generation: Intuition Build Basic Generative Adversarial Networks (Week 4), DeepLearning.AI on Coursera."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#conditional-gans-1",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#conditional-gans-1",
    "title": "Generative Adversarial Networks",
    "section": "Conditional GANs",
    "text": "Conditional GANs\n\nAnalogy for a conditional GAN\nSource: Sharon Zhou, Conditional Generation: Intuition Build Basic Generative Adversarial Networks (Week 4), DeepLearning.AI on Coursera."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#hurricane-example-data",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#hurricane-example-data",
    "title": "Generative Adversarial Networks",
    "section": "Hurricane example data",
    "text": "Hurricane example data\n\nOriginal data"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#hurricane-example",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#hurricane-example",
    "title": "Generative Adversarial Networks",
    "section": "Hurricane example",
    "text": "Hurricane example\n\nInitial fakes"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#hurricane-example-after-54s",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#hurricane-example-after-54s",
    "title": "Generative Adversarial Networks",
    "section": "Hurricane example (after 54s)",
    "text": "Hurricane example (after 54s)\n\nFakes after 1 iteration"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#hurricane-example-after-21m",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#hurricane-example-after-21m",
    "title": "Generative Adversarial Networks",
    "section": "Hurricane example (after 21m)",
    "text": "Hurricane example (after 21m)\n\nFakes after 100 kimg"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#hurricane-example-after-47m",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#hurricane-example-after-47m",
    "title": "Generative Adversarial Networks",
    "section": "Hurricane example (after 47m)",
    "text": "Hurricane example (after 47m)\n\nFakes after 200 kimg"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#hurricane-example-after-4h10m",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#hurricane-example-after-4h10m",
    "title": "Generative Adversarial Networks",
    "section": "Hurricane example (after 4h10m)",
    "text": "Hurricane example (after 4h10m)\n\nFakes after 1000 kimg"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#hurricane-example-after-14h41m",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#hurricane-example-after-14h41m",
    "title": "Generative Adversarial Networks",
    "section": "Hurricane example (after 14h41m)",
    "text": "Hurricane example (after 14h41m)\n\nFakes after 3700 kimg"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#example-deoldify-images-1",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#example-deoldify-images-1",
    "title": "Generative Adversarial Networks",
    "section": "Example: Deoldify images #1",
    "text": "Example: Deoldify images #1\n\nA deoldified version of the famous “Migrant Mother” photograph.\nSource: Deoldify package."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#example-deoldify-images-2",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#example-deoldify-images-2",
    "title": "Generative Adversarial Networks",
    "section": "Example: Deoldify images #2",
    "text": "Example: Deoldify images #2\n\nA deoldified Golden Gate Bridge under construction.\nSource: Deoldify package."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#example-deoldify-images-3",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#example-deoldify-images-3",
    "title": "Generative Adversarial Networks",
    "section": "Example: Deoldify images #3",
    "text": "Example: Deoldify images #3"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#explore-the-latent-space",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#explore-the-latent-space",
    "title": "Generative Adversarial Networks",
    "section": "Explore the latent space",
    "text": "Explore the latent space"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#generator-cant-generate-everything",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#generator-cant-generate-everything",
    "title": "Generative Adversarial Networks",
    "section": "Generator can’t generate everything",
    "text": "Generator can’t generate everything\n\n\n\n\n\nTarget\n\n\n\n\n\n\nProjection"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#they-are-slow-to-train",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#they-are-slow-to-train",
    "title": "Generative Adversarial Networks",
    "section": "They are slow to train",
    "text": "They are slow to train\nStyleGAN2-ADA training times on V100s (1024x1024):\n\n\n\n\n\n\n\n\n\n\n\nGPUs\n1000 kimg\n25000 kimg\nsec / kimg\nGPU mem\nCPU mem\n\n\n\n\n1\n1d 20h\n46d 03h\n158\n8.1 GB\n5.3 GB\n\n\n2\n23h 09m\n24d 02h\n83\n8.6 GB\n11.9 GB\n\n\n4\n11h 36m\n12d 02h\n40\n8.4 GB\n21.9 GB\n\n\n8\n5h 54m\n6d 03h\n20\n8.3 GB\n44.7 GB\n\n\n\n\nSource: NVIDIA’s Github, StyleGAN2-ADA — Official PyTorch implementation."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#uncertain-convergence",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#uncertain-convergence",
    "title": "Generative Adversarial Networks",
    "section": "Uncertain convergence",
    "text": "Uncertain convergence\nConverges to a Nash equilibrium.. if at all.\n\nAnalogy of minimax update failure.\nSource: Lilian Weng (2019), From GAN to WGAN, ArXiV."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#mode-collapse",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#mode-collapse",
    "title": "Generative Adversarial Networks",
    "section": "Mode collapse",
    "text": "Mode collapse\n\n\n\n\n\nExample of mode collapse\n\n\n\n\n\n\n\nSource: Metz et al. (2017), Unrolled Generative Adversarial Networks and Randall Munroe (2007), xkcd #221: Random Number."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#generation-is-harder",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#generation-is-harder",
    "title": "Generative Adversarial Networks",
    "section": "Generation is harder",
    "text": "Generation is harder\n\nA schematic of a generative adversarial network.# Separate optimisers for discriminator and generator.\nd_optimizer = keras.optimizers.Adam(learning_rate=0.0003)\ng_optimizer = keras.optimizers.Adam(learning_rate=0.0004)\n\nSource: Thales Silva (2018), An intuitive introduction to Generative Adversarial Networks (GANs), freeCodeCamp."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#advanced-image-layers",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#advanced-image-layers",
    "title": "Generative Adversarial Networks",
    "section": "Advanced image layers",
    "text": "Advanced image layers\n\nConv2D\n\n\nGlobalMaxPool2D\n\n\nConv2DTranspose\n\n\n\n\n\nSources: Pröve (2017), An Introduction to different Types of Convolutions in Deep Learning, and Peltarion Knowledge Center, Global max pooling 2D."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#vanishing-gradients-i",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#vanishing-gradients-i",
    "title": "Generative Adversarial Networks",
    "section": "Vanishing gradients (I)",
    "text": "Vanishing gradients (I)\n\nWhen the discriminator is too good, vanishing gradients\nSource: Sharon Zhou, Problem with BCE Loss, Build Basic Generative Adversarial Networks (Week 3), DeepLearning.AI on Coursera."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#vanishing-gradients-ii",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#vanishing-gradients-ii",
    "title": "Generative Adversarial Networks",
    "section": "Vanishing gradients (II)",
    "text": "Vanishing gradients (II)\n\nVanishing gradients\nSource: Lilian Weng (2019), From GAN to WGAN, ArXiV."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#were-comparing-distributions",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#were-comparing-distributions",
    "title": "Generative Adversarial Networks",
    "section": "We’re comparing distributions",
    "text": "We’re comparing distributions\nTrying to minimise the distance between the distribution of generated samples and the distribution of real data.\nVanilla GAN is equivalent to minimising the Jensen–Shannon Divergence between the two.\nAn alternative distance between distributions is the Wasserstein distance."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#discriminator-critic",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#discriminator-critic",
    "title": "Generative Adversarial Networks",
    "section": "Discriminator Critic",
    "text": "Discriminator Critic\nCritic D : \\text{Input} \\to \\mathbb{R} how “authentic” the input looks. It can’t discriminate real from fake exactly.\nCritic’s goal is\n \\max_{D \\in \\mathscr{D}} \\mathbb{E}[ D(X) ] - \\mathbb{E}[ D(G(Z)) ] \nwhere we \\mathscr{D} is space of 1-Lipschitz functions. Either use gradient clipping or penalise gradients far from 1:\n \\max_{D} \\mathbb{E}[ D(X) ] - \\mathbb{E}[ D(G(Z)) ] + \\lambda \\mathbb{E} \\Bigl[ ( \\bigl|\\bigl| \\nabla D \\bigr|\\bigr| - 1)^2 \\Bigr] ."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#schematic",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#schematic",
    "title": "Generative Adversarial Networks",
    "section": "Schematic",
    "text": "Schematic\n\nWasserstein\nSource: Côté et al. (2020), Synthesizing Property & Casualty Ratemaking Datasets using Generative Adversarial Networks, Working Paper?."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/gans.slides.html#links",
    "href": "Lecture-8-Generative-Networks/gans.slides.html#links",
    "title": "Generative Adversarial Networks",
    "section": "Links",
    "text": "Links\n\nDongyu Liu (2021), TadGAN: Time Series Anomaly Detection Using Generative Adversarial Networks\nJeff Heaton (2022), GANs for Tabular Synthetic Data Generation (7.5)\nJeff Heaton (2022), GANs to Enhance Old Photographs Deoldify (7.4)"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html",
    "title": "Uncertainty Quantification",
    "section": "",
    "text": "import random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport numpy.random as rnd\n\nfrom sklearn import set_config\nset_config(transform_output=\"pandas\")\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.initializers import Constant\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OrdinalEncoder\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.21.0\n\nsklearn   : 1.4.0\nkeras     : 2.15.0\ntorch     : 2.0.1\ntensorflow: 2.15.0.post1",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#load-packages",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#load-packages",
    "title": "Uncertainty Quantification",
    "section": "",
    "text": "import random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport numpy.random as rnd\n\nfrom sklearn import set_config\nset_config(transform_output=\"pandas\")\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.initializers import Constant\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OrdinalEncoder\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.21.0\n\nsklearn   : 1.4.0\nkeras     : 2.15.0\ntorch     : 2.0.1\ntensorflow: 2.15.0.post1",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#quiz",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#quiz",
    "title": "Uncertainty Quantification",
    "section": "Quiz",
    "text": "Quiz\nQuestion: If you decide to predict the claim amount of Bob using a deep learning model, which source(s) of uncertainty are you confronting?\n\nThe inherent variability of the data-generating process.\nParameter error.\nModel error.\nData uncertainty.\nAll of the above.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#answer",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#answer",
    "title": "Uncertainty Quantification",
    "section": "Answer",
    "text": "Answer\nAll of the above!\nParameter error stems primarily due to lack of data. Model error stems from assuming wrong distributional properties of the data. Data uncertainty arises due to the lack of confidence we may have about the quality of the collected data. Noisy data, inconsistent data, data with missing values or data with missing important variables can result in data uncertainty.\nThere are two major types of uncertainty in statistical or machine learning:\n\nAleatoric uncertainty\nEpistemic uncertainty\n\nSince there is no consensus on the definitions of aleatoric and epistemic uncertainty, we provide the most acknowledged definitions in the following slides.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#aleatoric-uncertainty",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#aleatoric-uncertainty",
    "title": "Uncertainty Quantification",
    "section": "Aleatoric Uncertainty",
    "text": "Aleatoric Uncertainty\n\nQualitative Definition\n\nAleatoric uncertainty refers to the statistical variability and inherent noise with data distribution that modelling cannot explain.\n\nQuantitative Definition\n\n\\text{Ale}(Y|\\boldsymbol{x}) = \\mathbb{V}[Y|\\boldsymbol{x}],i.e., if Y|\\boldsymbol{x} \\sim \\mathcal{N}(\\mu, \\sigma^2), the aleatoric uncertainty would be \\sigma^2. Simply, it is the conditional variance of the response variable Y given features/covariates \\boldsymbol{x}.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#epistemic-uncertainty",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#epistemic-uncertainty",
    "title": "Uncertainty Quantification",
    "section": "Epistemic Uncertainty",
    "text": "Epistemic Uncertainty\n\nQualitative Definition\n\nEpistemic uncertainty refers to the lack of knowledge, limited data information, parameter errors and model errors.\n\nQuantitative Definition\n\n\\text{Epi}(Y|\\boldsymbol{x}) = \\text{Uncertainty}(Y|\\boldsymbol{x}) - \\text{Ale}(Y|\\boldsymbol{x}),\n\n\ni.e., the total uncertainty subtracting the aleatoric uncertainty \\mathbb{V}[Y|\\boldsymbol{x}] would be the epistemic uncertainty.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#uncertainty-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#uncertainty-1",
    "title": "Uncertainty Quantification",
    "section": "Uncertainty",
    "text": "Uncertainty\nLet’s go back to the question at the beginning:\nIf you decide to predict the claim amount of an individual using a deep learning model, which source(s) of uncertainty are you dealing with?\n\nThe inherent variability of the data-generating process \\rightarrow aleatoric uncertainty.\nParameter error \\rightarrow epistemic uncertainty.\nModel error \\rightarrow epistemic uncertainty.\nData uncertainty \\rightarrow epistemic uncertainty.\n\nThe following sections show how we prepare the datasets for studying uncertainty.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-data",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-data",
    "title": "Uncertainty Quantification",
    "section": "Code: Data",
    "text": "Code: Data\n\nimport pandas as pd\n1sev_df = pd.read_csv('freMTPL2sev.csv')\n2freq_df = pd.read_csv('freMTPL2freq.csv')\n\n# Create a copy of freq dataframe without 'claimfreq' column\n3freq_without_claimfreq = freq_df.drop(columns=['ClaimNb'])\n\n# Merge severity dataframe with freq_without_claimfreq dataframe\nnew_sev_df = pd.merge(sev_df, freq_without_claimfreq, on='IDpol', \n4                                                      how='left')\n5new_sev_df = new_sev_df.dropna()\n6new_sev_df = new_sev_df.drop(\"IDpol\", axis=1)\n7new_sev_df[:2]\n\n\n1\n\nImports freMTPL2sev.csv dataset\n\n2\n\nImports freMTPL2freq.csv dataset\n\n3\n\nDrops ClaimNb column\n\n4\n\nMerges the two datasets ,sev_df and freq_without_claimfreq by matching the IDpol column. Assigning how='left' ensures that all rows from the left dataset sev_df is considered, and only the matching columns from freq_without_claimfreq are selected\n\n5\n\nDrops missing values or/and NAN values\n\n6\n\nDrops the IDpol column from new_sev_df\n\n7\n\nRetrieves first two rows of the dataset\n\n\n\n\n\n\n\n\n\n\n\nClaimAmount\nExposure\nVehPower\nVehAge\nDrivAge\nBonusMalus\nVehBrand\nVehGas\nArea\nDensity\nRegion\n\n\n\n\n0\n995.20\n0.59\n11.0\n0.0\n39.0\n56.0\nB12\nDiesel\nD\n778.0\nPicardie\n\n\n1\n1128.12\n0.95\n4.0\n1.0\n49.0\n50.0\nB12\nRegular\nE\n2354.0\nIle-de-France",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-preprocessing",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-preprocessing",
    "title": "Uncertainty Quantification",
    "section": "Code: Preprocessing",
    "text": "Code: Preprocessing\nNext we carry out some basic preprocessing\n\nX_train, X_test, y_train, y_test = train_test_split(\n  new_sev_df.drop(\"ClaimAmount\", axis=1),\n  new_sev_df[\"ClaimAmount\"],\n  random_state=2023)\n\n# Reset each index to start at 0 again.\nX_train = X_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\ny_train = y_train.reset_index(drop=True)\ny_test = y_test.reset_index(drop=True)",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-preprocessing-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-preprocessing-1",
    "title": "Uncertainty Quantification",
    "section": "Code: Preprocessing",
    "text": "Code: Preprocessing\nNext we define the column transfer. The column transfer first applies ordinal encoding to VehBrand, Region, Area and VehGas variables, and applies standard scaling to all remaining numerical values. Next we fit the defined column transfer to the training set. The fitted transformation is then applied on both training and test sets. (Note that the fitting is only carried out on the train set and the same fit is applied to both train, validation and test sets.)\nSince this task does not apply entity embeddings, VehBrand and Region variables are dropped from the dataframe.\n\n#Transformation\nct = make_column_transformer(\n  (OrdinalEncoder(), [\"VehBrand\", \"Region\", \"Area\", \"VehGas\"]),\n  remainder=StandardScaler(),\n   verbose_feature_names_out=False\n)\n\n#We don't apply entity embedding \nX_train_ct = ct.fit_transform(X_train)\nX_test_ct = ct.transform(X_test)\nX_train = X_train_ct.drop([\"VehBrand\", \"Region\"], axis=1)\nX_test = X_test_ct.drop([\"VehBrand\", \"Region\"], axis=1)\n\n\n\\texttt{VehGas=1} if the car gas is regular.\n\\texttt{Area=0} represents the rural area, and \\texttt{Area=5} represents the urban center.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#histogram-of-the-claimamount",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#histogram-of-the-claimamount",
    "title": "Uncertainty Quantification",
    "section": "Histogram of the ClaimAmount",
    "text": "Histogram of the ClaimAmount\nPlotting the empirical distribution of the target variable help us get an understanding of the inherent variability associated with the data.\n\nplt.hist(y_train[y_train &lt; 5000], bins=30);",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#glm",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#glm",
    "title": "Uncertainty Quantification",
    "section": "GLM",
    "text": "GLM\nThe generalised linear model (GLM) is a statistical regression model that estimates the conditional mean of the response variable Y given an instance \\boldsymbol{x} via a link function g: \n    \\mathbb{E}[Y|\\boldsymbol{x}]\n    = \\mu(\\boldsymbol{x}; \\boldsymbol{\\beta}_{\\text{GLM}})\n    = g^{-1} \\big(\\big \\langle \\boldsymbol{\\beta}_{\\text{GLM}}, \\boldsymbol{x} \\big \\rangle\\big),\n where\n\n\\boldsymbol{x} \\in \\mathbb{R}^{d_{\\boldsymbol{x}}} is the vector of explanatory variables, with d_{\\boldsymbol{x}} denoting its dimension.\n\\boldsymbol{\\beta}_{\\text{GLM}} represents the vector of regression coefficients.\n\\langle \\boldsymbol{a}, \\boldsymbol{b}\\rangle represents the inner product of \\boldsymbol{a} and \\boldsymbol{b}.\n\nThe idea of GLM is to find a linear combination of independent variables \\boldsymbol{x} and coefficients \\boldsymbol{\\beta}, apply a non-linear transformation (g^{-1}) to that linear combination and set it equal to conditional mean of the response variable Y given an instance \\boldsymbol{x}. The non-linear transformation provides added flexibility.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#gamma-glm",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#gamma-glm",
    "title": "Uncertainty Quantification",
    "section": "Gamma GLM",
    "text": "Gamma GLM\nSuppose a fitted gamma GLM model has\n\na log link function g(x)=\\log(x) and\nregression coefficients \\boldsymbol{\\beta}_{\\text{GLM}}=(\\beta_0, \\beta_1, \\beta_2, \\beta_3).\n\nThen, it estimates the conditional mean of Y given a new instance \\boldsymbol{x}=(1, x_1, x_2, x_3) as follows: \n    \\mathbb{E}[Y|\\boldsymbol{x}]=g^{-1}(\\langle \\boldsymbol{\\beta}_{\\text{GLM}}, \\boldsymbol{x}\\rangle)=\\exp\\big(\\beta_0+ \\beta_1x_1+\\beta_2x_2+\\beta_3x_3\\big).\n\nA GLM can model any other exponential family distribution using an appropriate link function g.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#loss-function-for-a-gamma-glm",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#loss-function-for-a-gamma-glm",
    "title": "Uncertainty Quantification",
    "section": "“Loss Function” for a Gamma GLM",
    "text": "“Loss Function” for a Gamma GLM\nIf Y|\\boldsymbol{x} is a gamma r.v., we can parameterise its density by its mean \\mu(\\boldsymbol{x}; \\boldsymbol{\\beta}) and dispersion parameter \\phi: \n    f_{Y|\\boldsymbol{X}}(y|\\boldsymbol{x}, \\boldsymbol{\\beta}, \\phi)\n    = \\frac{(\\mu (\\boldsymbol{x}; \\boldsymbol{\\beta})\\cdot \\phi)^{-1/\\phi}}{{\\Gamma(1/\\phi)}} \\cdot y^{1/\\phi - 1} \\cdot \\mathrm{e}^{-y/(\\mu (\\boldsymbol{x}; \\boldsymbol{\\beta})\\cdot\\phi)}.\n The “loss function” for a gamma GLM is typically the negative log-likelihood (NLL): \n    \\sum_{i=1}^{N}-\\log f_{Y|\\boldsymbol{X}}(y_i|\\boldsymbol{x}_i, \\boldsymbol{\\beta},\\phi)\n    \\propto \\sum_{i=1}^{N}\\log \\mu (\\boldsymbol{x}_i; \\boldsymbol{\\beta})+\\frac{y_i}{\\mu (\\boldsymbol{x}_i; \\boldsymbol{\\beta})} + \\text{const},\n i.e., we ignore the dispersion parameter \\phi while estimating the regression coefficients.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#fitting-steps",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#fitting-steps",
    "title": "Uncertainty Quantification",
    "section": "Fitting Steps",
    "text": "Fitting Steps\nStep 1. Use the advanced second derivative iterative method to find the regression coefficients: \n    \\boldsymbol{\\beta}_{\\text{GLM}} = \\underset{\\boldsymbol{\\beta}}{\\text{arg min}} \\ \\sum_{i=1}^{N}\\log \\mu (\\boldsymbol{x}_i; \\boldsymbol{\\beta})+\\frac{y_i}{\\mu (\\boldsymbol{x}_i; \\boldsymbol{\\beta})}\n\nStep 2. Estimate the dispersion parameter: \n    \\phi_{\\text{GLM}}=\\frac{1}{N-d_{\\boldsymbol{x}}}\\sum_{i=1}^{N}\\frac{(y_i-\\mu(\\boldsymbol{x}_i; \\boldsymbol{\\beta}_{\\text{GLM}} ))^2}{\\mu(\\boldsymbol{x}_i; \\boldsymbol{\\beta}_{\\text{GLM}} )^2}",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-gamma-glm",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-gamma-glm",
    "title": "Uncertainty Quantification",
    "section": "Code: Gamma GLM",
    "text": "Code: Gamma GLM\nIn Python, we can fit a gamma GLM as follows:\n\nimport statsmodels.api as sm\n\n# Add a column of ones to include an intercept in the model\nX_train_design = sm.add_constant(X_train)\n\n# Create a Gamma GLM with a log link function\ngamma_GLM = sm.GLM(y_train, X_train_design,                   \n            family=sm.families.Gamma(sm.families.links.Log()))\n\n# Fit the model\ngamma_GLM = gamma_GLM.fit()\n\n#Dispersion Parameter\nmus = gamma_GLM.predict(X_train_design)\nresiduals = mus-y_train\nvariance = mus**2\ndof = (len(y_train)-X_train.shape[1])\nphi_GLM =  np.sum(residuals**2/variance)/dof\nprint(phi_GLM)\n\n59.6306232357824\n\n\nThe above example of fitting a Gamma distribution assumes a constant dispersion, meaning that, the dispersion of claim amount is constant for all policyholders. If we believe that the constant dispersion assumption is quite strong, we can use a double GLM model. Fitting a GLM is the traditional way of modelling a claim amount.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#cann",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#cann",
    "title": "Uncertainty Quantification",
    "section": "CANN",
    "text": "CANN\nThe Combined Actuarial Neural Network is a novel actuarial neural network architecture proposed by Schelldorfer and Wüthrich (2019). We summarise the CANN approach as follows:\n\nFind the coefficients \\boldsymbol{\\beta}_{\\text{GLM}} of the GLM with a link function g(\\cdot).\nFind the weights \\boldsymbol{w}_{\\text{CANN}} of a neural network \\mathcal{M}_{\\text{CANN}}:\\mathbb{R}^{d_{\\boldsymbol{x}}}\\to\\mathbb{R}.\nGiven a new instance \\boldsymbol{x}, we have \\mathbb{E}[Y|\\boldsymbol{x}] = g^{-1}\\Big( \\langle\\boldsymbol{\\beta}_{\\text{GLM}}, \\boldsymbol{x}\\rangle + \\mathcal{M}_{\\text{CANN}}(\\boldsymbol{x};\\boldsymbol{w}_{\\text{CANN}})\\Big).",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#architecture",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#architecture",
    "title": "Uncertainty Quantification",
    "section": "Architecture",
    "text": "Architecture\n\n\n\nFigure: CANN approach.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-architecture",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-architecture",
    "title": "Uncertainty Quantification",
    "section": "Code: Architecture",
    "text": "Code: Architecture\n\ngamma_GLM.params\n\nconst         7.786576\nArea         -0.073226\nVehGas        0.082292\n                ...   \nDrivAge      -0.022147\nBonusMalus    0.157204\nDensity       0.010539\nLength: 9, dtype: float64\n\n\n\n# Ensure reproducibility\n1random.seed(1); tf.random.set_seed(1)\n\n# Pre-defined constants\n2glm_weights = gamma_GLM.params.iloc[1:]\n3glm_bias = gamma_GLM.params.iloc[0]\n\n# Define model inputs\n4inputs = Input(shape=X_train.shape[1:])\n\n# Non-trainable GLM linear part\nglm_logmu = Dense(1, activation='linear', trainable=False,\n                     kernel_initializer=Constant(glm_weights),\n5                     bias_initializer=Constant(glm_bias))(inputs)\n\n# Neural network layers\n6x = Dense(64, activation='relu')(inputs)\n7x = Dense(64, activation='relu')(x)\n8cann_logmu = Dense(1, activation='linear')(x)\n\n\n1\n\nSets the random seed for reproducibility\n\n2\n\nStores weights computed from GLM in glm_weights\n\n3\n\nStores bias computed from GLM in glm_bias\n\n4\n\nSpecifies the model input features\n\n5\n\nAdds a Dense layer with just one neuron, to store the model output from the GLM. The linear activation is used to make sure that the output is a linear combination of inputs. The weights are set to be non-trainable, hence the values obtained during GLM fitting will not change during the neural network training process. kernel_initializer=Constant(glm_weights) and bias_initializer=Constant(glm_bias) ensures that weights are initialized with the optimal values estimated from GLM fit.\n\n6\n\nAdds another Dense layer\n\n7\n\nAdds another Dense layer\n\n8\n\nAdds the output layer with linear activation",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-loss-function",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-loss-function",
    "title": "Uncertainty Quantification",
    "section": "Code: Loss Function",
    "text": "Code: Loss Function\n\n# Combine GLM and CANN estimates\n1CANN = Model(inputs, Concatenate(axis=1)([cann_logmu, glm_logmu]))\n\n\n1\n\nSince the output of the model is evaluated by combining the output from both branches, the model is constructed by concatenating outputs from cann_logmu and glm_logmu. Note that there are two predicted values, one predicted value from the glm_logmu component and the other coming from the cann_logmu component.\n\n\n\n\nWe need to customise the loss function for CANN.\n\ndef CANN_negative_log_likelihood(y_true, y_pred):\n    #the new mean estimate\n1    CANN_logmu = y_pred[:, 0]\n2    GLM_logmu = y_pred[:, 1]\n3    mu = tf.math.exp(CANN_logmu + GLM_logmu)\n\n    # Compute the negative log likelihood of the Gamma distribution\n4    nll = tf.reduce_mean(CANN_logmu + GLM_logmu + y_true/mu)\n    \n    return nll\n\n\n1\n\nStores the first column of the y_pred matrix as CANN_logmu (the prediction from the CANN)\n\n2\n\nStores the second column of the y_pred matrix as GLM_logmu (the prediction from the glm)\n\n3\n\nComputes the exponential of the sum of them as mu\n\n4\n\nComputes the negative log likelihood of a Gamma distribution where log(\\mu) is now the sum CANN_logmu + GLM_logmu",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-model-training",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-model-training",
    "title": "Uncertainty Quantification",
    "section": "Code: Model Training",
    "text": "Code: Model Training\n\n1CANN.compile(optimizer=\"adam\", loss=CANN_negative_log_likelihood)\nhist = CANN.fit(X_train, y_train,\n    epochs=300, \n    callbacks=[EarlyStopping(patience=30)],  \n    verbose=0,\n    batch_size=64, \n2    validation_split=0.2)\n\n\n1\n\nCompiles the model with adam optimizer and the custom loss function\n\n2\n\nFits the model (with a validation split defined inside the fit function)\n\n\n\n\nFind the dispersion parameter.\n\nmus = np.exp(np.sum(CANN.predict(X_train, verbose=0), axis = 1))\nresiduals = mus-y_train\nvariance = mus**2\ndof = (len(y_train)-X_train.shape[1])\nphi_CANN =  np.sum(residuals**2/variance) / dof\nprint(phi_CANN)\n\n98.60976911896634",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#mixture-distribution",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#mixture-distribution",
    "title": "Uncertainty Quantification",
    "section": "Mixture Distribution",
    "text": "Mixture Distribution\nOne intuitive way to capture uncertainty using neural networks would be to estimate the parameters of the target distribution, instead of predicting the value it self. For example, suppose we want to predict y coming from a Gaussian distribution. Most common method would be to predict (\\hat{y}) directly using a single neuron at the output layer. Another possible way would be to estimate the parameters (\\mu and \\sigma) of the y distribution using 2 neurons at the output layer. Estimating parameters of the distribution instead of point estimates for y can help us get an idea about the uncertainty. However, assuming distributional properties at times could be too restrictive. For example, it is possible that the actual distribution of y values is bimodal or multi modal. In such situations, assuming a mixture distribution is more intuitive.\nGiven a finite set of resulting random variables (Y_1, ..., Y_{K}), one can generate a multinomial random variable Y\\sim \\text{Multinomial}(1, \\boldsymbol{\\pi}). Meanwhile, Y can be regarded as a mixture of Y_1, ..., Y_{K}, i.e., \n  Y = \\begin{cases}\n      Y_1 & \\text{w.p. } \\pi_1, \\\\\n      \\vdots & \\vdots\\\\\n      Y_K & \\text{w.p. } \\pi_K, \\\\\n  \\end{cases}\n where we define a set of finite set of weights \\boldsymbol{\\pi}=(\\pi_{1} ..., \\pi_{K}) such that \\pi_k \\ge 0 for k \\in \\{1, ..., K\\} and \\sum_{k=1}^{K}\\pi_k=1.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#mixture-distribution-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#mixture-distribution-1",
    "title": "Uncertainty Quantification",
    "section": "Mixture Distribution",
    "text": "Mixture Distribution\nLet f_{Y_k|\\boldsymbol{X}} and F_{Y_k|\\boldsymbol{X}} be the probability density function and the cumulative density function, respectively, of Y_k|\\boldsymbol{X} for all k\\in \\{1, ..., K\\}. The random variable Y|\\boldsymbol{X}, which mixes Y_k|\\boldsymbol{X}’s with weights \\pi_k’s, has the density function \n    f_{Y|\\boldsymbol{X}}(y|\\boldsymbol{x}) = \\sum_{k=1}^{K}\\pi_k(\\boldsymbol{x}) f_{k}(y|\\boldsymbol{x}),\n and the cumulative density function \n    F_{Y|\\boldsymbol{X}}(y|\\boldsymbol{x}) = \\sum_{k=1}^{K}\\pi_k(\\boldsymbol{x}) F_{k}(y|\\boldsymbol{x}).",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#mixture-density-network",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#mixture-density-network",
    "title": "Uncertainty Quantification",
    "section": "Mixture Density Network",
    "text": "Mixture Density Network\nA mixture density network (MDN) \\mathcal{M}_{\\boldsymbol{w}^*} outputs each distribution component’s mixing weights and parameters of Y given the input features \\boldsymbol{x}, i.e., \n    \\mathcal{M}_{\\boldsymbol{w}^*}(\\boldsymbol{x})=(\\boldsymbol{\\pi}(\\boldsymbol{x};\\boldsymbol{w}^*), \\boldsymbol{\\theta}(\\boldsymbol{x};\\boldsymbol{w}^*)),\n where \\boldsymbol{w}^* is the networks’ weights found by minimising the following negative log-likelihood loss function \n    \\mathcal{L}(\\mathcal{D}, \\boldsymbol{\\theta})= - \\sum_{i=1}^{N} \\log f_{Y|\\boldsymbol{x}}(y_i|\\boldsymbol{x}, \\boldsymbol{w}^*),\n where \\mathcal{D}=\\{(\\boldsymbol{x}_i,y_i)\\}_{i=1}^{N} is the training dataset.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#mixture-density-network-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#mixture-density-network-1",
    "title": "Uncertainty Quantification",
    "section": "Mixture Density Network",
    "text": "Mixture Density Network\n\n\n\nFigure: An MDN that outputs the parameters for a K component mixture distribution. \\boldsymbol{\\theta}_k(\\boldsymbol{x}; \\boldsymbol{w}^*)= (\\theta_{k,1}(\\boldsymbol{x}; \\boldsymbol{w}^*), ..., \\theta_{k,|\\boldsymbol{\\theta}_k|}(\\boldsymbol{x}; \\boldsymbol{w}^*)) consists of the parameter estimates for the kth mixture component.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#model-specification",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#model-specification",
    "title": "Uncertainty Quantification",
    "section": "Model Specification",
    "text": "Model Specification\nSuppose there are two types of claims:\n\nType I: Y_1|\\boldsymbol{x}\\sim \\text{Gamma}(\\alpha_1(\\boldsymbol{x}), \\beta_1(\\boldsymbol{x})) and,\nType II: Y_2|\\boldsymbol{x}\\sim \\text{Gamma}(\\alpha_2(\\boldsymbol{x}), \\beta_2(\\boldsymbol{x})).\n\nThe density of the actual claim amount Y|\\boldsymbol{x} follows \n    \\begin{align*}\n        f_{Y|\\boldsymbol{X}}(y|\\boldsymbol{x})\n        &= \\pi_1(\\boldsymbol{x})\\cdot \\frac{\\beta_1(\\boldsymbol{x})^{\\alpha_1(\\boldsymbol{x})}}{\\Gamma(\\alpha_1(\\boldsymbol{x}))}\\mathrm{e}^{-\\beta_1(\\boldsymbol{x})y}y^{\\alpha_1(\\boldsymbol{x})-1} \\\\\n        &\\quad + (1-\\pi_1(\\boldsymbol{x}))\\cdot \\frac{\\beta_2(\\boldsymbol{x})^{\\alpha_2(\\boldsymbol{x})}}{\\Gamma(\\alpha_2(\\boldsymbol{x}))}\\mathrm{e}^{-\\beta_2(\\boldsymbol{x})y}y^{\\alpha_2(\\boldsymbol{x})-1}.\n    \\end{align*}\n where \\pi_1(\\boldsymbol{x}) is the probability of a Type I claim given \\boldsymbol{x}.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#output",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#output",
    "title": "Uncertainty Quantification",
    "section": "Output",
    "text": "Output\nThe aim is to find the optimum weights \n    \\boldsymbol{w}^* = \\underset{w}{\\text{arg min}} \\ \\mathcal{L}(\\mathcal{D}, \\boldsymbol{w})\n for the Gamma mixture density network \\mathcal{M}_{\\boldsymbol{w}^*} that outputs the mixing weights, shapes and scales of Y given the input features \\boldsymbol{x}, i.e., \n    \\begin{align*}\n        \\mathcal{M}_{\\boldsymbol{w}^*}(\\boldsymbol{x})\n        = ( &\\pi_1(\\boldsymbol{x}; \\boldsymbol{w}^*),\n             \\pi_2(\\boldsymbol{x}; \\boldsymbol{w}^*), \\\\\n            &\\alpha_1(\\boldsymbol{x}; \\boldsymbol{w}^*),\n            \\alpha_2(\\boldsymbol{x}; \\boldsymbol{w}^*),\\\\\n            &\\beta_1(\\boldsymbol{x}; \\boldsymbol{w}^*),\n            \\beta_2(\\boldsymbol{x}; \\boldsymbol{w}^*)\n        ).\n    \\end{align*}",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#architecture-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#architecture-1",
    "title": "Uncertainty Quantification",
    "section": "Architecture",
    "text": "Architecture\n\n\n\nFigure: We demonstrate the structure of a gamma MDN that outputs the parameters for a gamma mixture with two components.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-architecture-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-architecture-1",
    "title": "Uncertainty Quantification",
    "section": "Code: Architecture",
    "text": "Code: Architecture\nThe following code resembles the architecture of the architecture of the gamma MDN from the previous slide.\n\n# Ensure reproducibility\n1random.seed(1); tf.random.set_seed(1)\n\n2inputs = Input(shape=X_train.shape[1:])\n\n# Two hidden layers \n3x = Dense(64, activation='relu')(inputs)\nx = Dense(64, activation='relu')(x)\n\n4pis = Dense(2, activation='softmax')(x) #mixing weights\nalphas = Dense(2, activation='exponential')(x) #shape parameters\nbetas = Dense(2, activation='exponential')(x) #scale parameters\n\n#`y_pred` will now have 6 columns\n5gamma_mdn = Model(inputs, Concatenate(axis=1)([pis, alphas, betas]))\n\n\n1\n\nSets the random seeds for reproducibility\n\n2\n\nDefines the input layer with the number of neurons being equal to the number of input features\n\n3\n\nSpecifies the hidden layers of the neural network\n\n4\n\nSpecifies the neurons of the output layer. Here, softmax is used for \\pi values as they must sum up to 1. exponential activation is used for both \\alpha’s and \\beta’s as they must be non-negative.\n\n5\n\nDefines the model by specifying the inputs and outputs",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#loss-function",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#loss-function",
    "title": "Uncertainty Quantification",
    "section": "Loss Function",
    "text": "Loss Function\nThe negative log-likelihood loss function is given by\n\n    \\mathcal{L}(\\mathcal{D}, \\boldsymbol{w})\n    = - \\sum_{i=1}^{N} \\log \\  f_{Y|\\boldsymbol{x}}(y_i|\\boldsymbol{x}, \\boldsymbol{w})\n where the f_{Y|\\boldsymbol{x}}(y_i|\\boldsymbol{x}, \\boldsymbol{w}) is defined by \n\\begin{align*}\n    &\\pi_1(\\boldsymbol{x};\\boldsymbol{w})\\cdot \\frac{\\beta_1(\\boldsymbol{x};\\boldsymbol{w})^{\\alpha_1(\\boldsymbol{x};\\boldsymbol{w})}}{\\Gamma(\\alpha_1(\\boldsymbol{x};\\boldsymbol{w}))}\\mathrm{e}^{-\\beta_1(\\boldsymbol{x};\\boldsymbol{w})y}y^{\\alpha_1(\\boldsymbol{x};\\boldsymbol{w})-1} \\\\\n    & \\quad + (1-\\pi_1(\\boldsymbol{x};\\boldsymbol{w}))\\cdot \\frac{\\beta_2(\\boldsymbol{x};\\boldsymbol{w})^{\\alpha_2(\\boldsymbol{x};\\boldsymbol{w})}}{\\Gamma(\\alpha_2(\\boldsymbol{x};\\boldsymbol{w}))}\\mathrm{e}^{-\\beta_2(\\boldsymbol{x};\\boldsymbol{w})y}y^{\\alpha_2(\\boldsymbol{x};\\boldsymbol{w})-1}\n\\end{align*}",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-loss-function-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-loss-function-1",
    "title": "Uncertainty Quantification",
    "section": "Code: Loss Function",
    "text": "Code: Loss Function\nWe employ functions from tensorflow_probability to code the loss function for the gamma MDN. The MixtureSameFamily function facilitates defining a mixture distribution all components from the same distribution but have different parametrization.\n\n1import tensorflow_probability as tfp\n2tfd = tfp.distributions\n3K = 2 # number of mixture components\n\ndef gamma_mixture_NLL(y_true, y_pred):                                      \n4    K = y_pred.shape[1] // 3\n    pis =  y_pred[:, :K]                                                    \n    alphas = y_pred[:, K:2*K]                                               \n    betas = y_pred[:, 2*K:3*K]                                              \n\n    # The mixture distribution is a MixtureSameFamily distribution\n    mixture_distribution = tfd.MixtureSameFamily(\n        mixture_distribution=tfd.Categorical(probs=pis),\n5        components_distribution=tfd.Gamma(alphas, betas))\n\n    # The loss is the negative log-likelihood of the data\n6    return -mixture_distribution.log_prob(y_true)\n\n\n1\n\nImports tfp class from tensorflow_probability\n\n2\n\nStores statistical distributions in the tfp class as tfd\n\n3\n\nSpecifies the number of components in the mixture model\n\n4\n\nExtracts predicted values for all model components and stores them in separate matrices\n\n5\n\nSpecifies the mixture distribution using computed model components\n\n6\n\nUse the fitted model to calculate negative log likelihood given the observed data",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-model-training-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-model-training-1",
    "title": "Uncertainty Quantification",
    "section": "Code: Model Training",
    "text": "Code: Model Training\n\n#Employ the loss function from previous slide\n1gamma_mdn.compile(optimizer=\"adam\", loss=gamma_mixture_NLL)\n\nhist = gamma_mdn.fit(X_train, y_train,\n    epochs=300, \n    callbacks=[EarlyStopping(patience=30)],  \n    verbose=0,\n    batch_size=64, \n2    validation_split=0.2)\n\n\n1\n\nCompiles the model using adam optimizer and the gamma_mixture_NLL(negative log likelihood) as the loss function\n\n2\n\nFits the model using the training data, with a validation split",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#proper-scoring-rules",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#proper-scoring-rules",
    "title": "Uncertainty Quantification",
    "section": "Proper Scoring Rules",
    "text": "Proper Scoring Rules\nProper scoring rules provide a summary measure for the performance of the probabilistic predictions. They are useful in comparing performances across models.\n\nDefinition\n\nThe scoring rule S : \\mathcal{F} \\times \\mathbb{R} \\to \\bar{\\mathbb{R}} is proper relative to the class \\mathcal{F} if \nS(G, G)\\le S(F, G)\n for all F,G\\in \\mathcal{F}. It is strictly proper if equality holds only if F = G.\n\n\nExamples:\n\nLogarithmic Score (NLL)\nContinuous Ranked Probability Score (CRPS)",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#proper-scoring-rules-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#proper-scoring-rules-1",
    "title": "Uncertainty Quantification",
    "section": "Proper Scoring Rules",
    "text": "Proper Scoring Rules\n\nLogarithmic Score (NLL)\n\nThe logarithmic score is defined as \n    \\mathrm{LogS}(f, y) = - \\log f(y),\n where f is the predictive density.\n\nContinuous Ranked Probability Score (CRPS)\n\nThe continuous ranked probability score is defined as \n    \\mathrm{crps}(F, y) = \\int_{-\\infty}^{\\infty} (F(t) - {1}_{t\\ge y})^2 \\ \\mathrm{d}t,\n where F is the cumulative distribution function.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-nll",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-nll",
    "title": "Uncertainty Quantification",
    "section": "Code: NLL",
    "text": "Code: NLL\n\nfrom scipy.stats import gamma\n\ndef gamma_nll(mean, dispersion, y):\n    # Calculate shape and scale parameters from mean and dispersion\n    shape = 1 / dispersion; scale = mean * dispersion\n\n    # Create a gamma distribution object\n    gamma_dist = gamma(a=shape, scale=scale)\n    \n    return -np.mean(gamma_dist.logpdf(y))\n\n#GLM\nX_test_design = sm.add_constant(X_test)\nmus = gamma_GLM.predict(X_test_design)\nNLL_GLM = gamma_nll(mus, phi_GLM, y_test)\n\n#CANN\nmus = np.exp(np.sum(CANN.predict(X_test, verbose=0), axis = 1))\nNLL_CANN = gamma_nll(mus, phi_CANN, y_test)\n\n#MDN\nNLL_MDN = gamma_mdn.evaluate(X_test, y_test, verbose=0)",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#model-comparisons",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#model-comparisons",
    "title": "Uncertainty Quantification",
    "section": "Model Comparisons",
    "text": "Model Comparisons\n\nprint(f'GLM: {round(NLL_GLM, 2)}')\nprint(f'CANN: {round(NLL_CANN, 2)}')\nprint(f'MDN: {round(NLL_MDN, 2)}')\n\nGLM: 11.02\nCANN: 11.5\nMDN: 8.67\n\n\nThe above results show that MDN provides the lowest value for the Logarithmic Score(NLL). Low values for NLL indicate better calibration. One possible reason for the better performance of the MDN model(compared to the Gamma model) is the added flexibility from multiple modelling components. The multiple modelling components in the MDN model, together, can capture the inherent variation in the data better.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#dropout",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#dropout",
    "title": "Uncertainty Quantification",
    "section": "Dropout",
    "text": "Dropout\nDropout is one of the most popular methods for handling epistemic uncertainty. However this method does not directly quantify the epistemic uncertainty, rather, it helps reduce the risk of overfitting. Dropout is the act of randomly selecting a proportion of neurons and deactivating them during each training iteration. It is a regularization technique that aims to reduce overfitting and improve the generalization ability of the model.\n\n\n\nAn example of neurons dropped during training.\n\n\n\nSources: Marcus Lautier (2022).",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#dropout-quote-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#dropout-quote-1",
    "title": "Uncertainty Quantification",
    "section": "Dropout quote #1",
    "text": "Dropout quote #1\n\nIt’s surprising at first that this destructive technique works at all. Would a company perform better if its employees were told to toss a coin every morning to decide whether or not to go to work? Well, who knows; perhaps it would! The company would be forced to adapt its organization; it could not rely on any single person to work the coffee machine or perform any other critical tasks, so this expertise would have to be spread across several people. Employees would have to learn to cooperate with many of their coworkers, not just a handful of them.\n\n\nSource: Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, p. 366",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#dropout-quote-2",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#dropout-quote-2",
    "title": "Uncertainty Quantification",
    "section": "Dropout quote #2",
    "text": "Dropout quote #2\n\nThe company would become much more resilient. If one person quit, it wouldn’t make much of a difference. It’s unclear whether this idea would actually work for companies, but it certainly does for neural networks. Neurons trained with dropout cannot co-adapt with their neighboring neurons; they have to be as useful as possible on their own. They also cannot rely excessively on just a few input neurons; they must pay attention to each of their input neurons. They end up being less sensitive to slight changes in the inputs. In the end, you get a more robust network that generalizes better.\n\n\nSource: Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, p. 366",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-dropout",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-dropout",
    "title": "Uncertainty Quantification",
    "section": "Code: Dropout",
    "text": "Code: Dropout\nDropout is just another layer in Keras.\nThe following code shows how we can apply a dropout to each hidden layer in the neural network. The dropout rate for each layer is 0.2. There is also an option called seed in the Dropout function, which can be used to ensure reproducibility.\n\nfrom tensorflow.keras.layers import Dropout\n#Ensure reproducibility\nrandom.seed(2); tf.random.set_seed(2)\n\nmodel = Sequential([\n    Dense(30, activation=\"leaky_relu\", name=\"hidden1\"),\n    Dropout(0.2),\n    Dense(30, activation=\"leaky_relu\", name=\"hidden2\"),\n    Dropout(0.2),\n    Dense(1, activation=\"exponential\", name=\"output\")\n])\n\nmodel.compile(\"adam\", \"mse\")\nmodel.fit(X_train, y_train, epochs=4, verbose=0);",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-dropout-after-training",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-dropout-after-training",
    "title": "Uncertainty Quantification",
    "section": "Code: Dropout after training",
    "text": "Code: Dropout after training\nMaking predictions is the same as any other model:\nDropout has no impact on model predictions because Dropout function is carried out only during the training stage. Once the model finishes its training (once the weights and biases are computed), all neurons together contribute to the predictions(no dropping out during the prediction stage). Therefore, predictions from the model will not change across different runs.\n\n\n\nmodel.predict(X_test.head(3),\n                  verbose=0)\n\narray([[ 53.365997],\n       [149.5073  ],\n       [ 84.2315  ]], dtype=float32)\n\n\n\n\nmodel.predict(X_test.head(3),\n                  verbose=0)\n\narray([[ 53.365997],\n       [149.5073  ],\n       [ 84.2315  ]], dtype=float32)\n\n\n\n\nWe can make the model think it is still training:\nBy setting the training=True, we can let drop out happen during prediction stage as well. This will change predictions for the same output different. This is known as the Monte Carlo dropout.\n\n\n\nmodel(X_test.head(3).to_numpy(),\n    training=True).numpy()\n\narray([[ 45.215286],\n       [506.83798 ],\n       [ 80.71608 ]], dtype=float32)\n\n\n\n\nmodel(X_test.head(3).to_numpy(),\n    training=True).numpy()\n\narray([[170.87773],\n       [140.37846],\n       [231.01816]], dtype=float32)",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#dropout-limitation",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#dropout-limitation",
    "title": "Uncertainty Quantification",
    "section": "Dropout Limitation",
    "text": "Dropout Limitation\n\nIncreased Training Time: Since dropout introduces noise into the training process, it can make the training process slower.\nSensitivity to Dropout Rates: the performance of dropout is highly dependent on the chosen dropout rate.\nUncertainty Quantification: the dropout can only provide a crude approximation to the theoretically justified Bayesian approach in terms of quantifying uncertainty.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#bayesian-neural-network",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#bayesian-neural-network",
    "title": "Uncertainty Quantification",
    "section": "Bayesian Neural Network",
    "text": "Bayesian Neural Network\nBayesian Neural Networks facilitate a systematic way to quantify uncertainty about the model predictions. BNNs assume a distribution for each parameter (weights and biases) of the model. Since BNNs assume distributions for the parameters of the model, the model end up with distributions for the outputs as well. The distributions of the output help in quantifying the uncertainty related to model predictions.\nThe weights \\boldsymbol{w} of a Bayesian neural network (BNN) have their posterior distribution: p(\\boldsymbol{w}|\\mathcal{D})\\propto \\mathcal{L}(\\mathcal{D}|\\boldsymbol{w})p(\\boldsymbol{w}) according to the Bayes’ theorem.\n\n\\mathcal{L}(\\mathcal{D}|\\boldsymbol{w}) represents the likelihood of data given the weights.\np(\\boldsymbol{w}) represents the density of the prior distribution of the weights.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#tractability-of-posterior-distribution",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#tractability-of-posterior-distribution",
    "title": "Uncertainty Quantification",
    "section": "Tractability of Posterior Distribution",
    "text": "Tractability of Posterior Distribution\nLet \\boldsymbol{\\theta}_0=(\\boldsymbol{\\mu}_{\\boldsymbol{w}_0},\\boldsymbol{\\sigma}_{\\boldsymbol{w}_0}) be the parameters of the prior distribution of weights: \n    \\boldsymbol{w}\\sim \\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{w}_0},\\boldsymbol{\\sigma}_{\\boldsymbol{w}_0}).\n The derivation of the true posterior \n    p(\\boldsymbol{w}|\\mathcal{D})\n    \\propto \\mathcal{L}(\\mathcal{D}|\\boldsymbol{w})p(\\boldsymbol{w})\n is non-trivial due to the complexity of the model. We cannot compute the true posterior distribution efficiently.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#variational-approximation",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#variational-approximation",
    "title": "Uncertainty Quantification",
    "section": "Variational Approximation",
    "text": "Variational Approximation\nThe variational approximation is a potential solution. Intuitively, we approximate the true posterior distribution with a variational distribution that is more tractable: \n    \\underbrace{p(\\boldsymbol{w}|\\mathcal{D})}_{\\text{True Posterior Distribution}}\\approx \\underbrace{q(\\boldsymbol{w}|\\boldsymbol{\\theta})}_{\\text{Variational Distribution}}\n    \\sim\\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{w}},\\boldsymbol{\\sigma}_{\\boldsymbol{w}}),\n i.e., a normal distribution with parameters \\boldsymbol{\\theta}= (\\boldsymbol{\\mu}_{\\boldsymbol{w}},\\boldsymbol{\\sigma}_{\\boldsymbol{w}}) is used to approximate the true posterior distribution of \\boldsymbol{w}|\\mathcal{D}.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#demonstration",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#demonstration",
    "title": "Uncertainty Quantification",
    "section": "Demonstration",
    "text": "Demonstration\n\n\n\nFigure: The idea is to use the blue curve (variational distribution) to approximate the purple curve (true posterior).",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-variational-layers",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-variational-layers",
    "title": "Uncertainty Quantification",
    "section": "Code: Variational Layers",
    "text": "Code: Variational Layers\n\n1import tensorflow_probability as tfp\n2tfd = tfp.distributions #tensorflow prob. distributions\n\n3def prior(kernel_size, bias_size, dtype=None):\n    n = kernel_size + bias_size\n    return lambda t: tfd.Independent(\n        tfd.Normal(loc=tf.zeros(n, dtype=dtype),\n                   scale=1),\n4                   reinterpreted_batch_ndims=1)\n\n5def posterior(kernel_size, bias_size, dtype=None):\n    n = kernel_size + bias_size\n    return Sequential([\n      tfp.layers.VariableLayer(2 * n, dtype=dtype),\n      tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n          tfd.Normal(loc=t[..., :n],\n                     scale=1e-5 + tf.nn.softplus(0.01 * t[..., n:])),\n6          reinterpreted_batch_ndims=1)),\n    ])\n\n\n1\n\nImports tensorflow_probability using the shortened name tfp\n\n2\n\nStores statistical distributions in the tfp class as tfd\n\n3\n\nSpecifies the prior which takes in the number of weights and biases (their sum would be the total number of parameters to estimate)\n\n4\n\nSpecifies the prior for each parameter (normal distribution with mean=0 and standard deviation=1) reinterpreted_batch_ndims=1 specifies that the distributions of weights and biases should be considered as independent distributions.\n\n5\n\nSpecifies the posterior distribution which taken in the number of weights and biases.\n\n6\n\nBuilds a sequential model with (i) a VariableLayer which manages the parameters of the model(since there are n parameters with their own Normal distribution, there 2*n prior parameters) and (ii) a DistributionLambda layer which wraps the independent normal distributions as a Keras layer.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#architecture-2",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#architecture-2",
    "title": "Uncertainty Quantification",
    "section": "Architecture",
    "text": "Architecture\n\n\n\nFigure: We demonstrate the typical structure of a Bayesian neural network (BNN).\n\n\n\nSource: Blundell et al. (2015), Weight Uncertainty in Neural Networks.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#loss-function-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#loss-function-1",
    "title": "Uncertainty Quantification",
    "section": "Loss Function",
    "text": "Loss Function\nThe KL divergence between the true posterior and variational distribution is given by: \n    D_{\\text{KL}}\\left[q(\\boldsymbol{w}|\\boldsymbol{\\theta}) || p(\\boldsymbol{w}|\\mathcal{D})\\right]\n    =\\mathbb{E}_{\\boldsymbol{w} \\sim q(\\boldsymbol{w}|\\boldsymbol{\\theta})}\\left[\\log\\left(\\frac{q(\\boldsymbol{w}|\\boldsymbol{\\theta})}{p(\\boldsymbol{w}|\\mathcal{D})}\\right) \\right]\n After some algebra, we acknowledge the final representation: \n\\begin{align*}\n    D_{\\text{KL}}\\left[q(\\boldsymbol{w}|\\boldsymbol{\\theta}) || p(\\boldsymbol{w}|\\mathcal{D})\\right]\n    &=\\underbrace{D_{\\text{KL}}\\left[{q(\\boldsymbol{w}|\\boldsymbol{\\theta})} || {p(\\boldsymbol{w})}\\right]}_{{\\text{Complexity Loss}}}  \\underbrace{-\\mathbb{E}_{\\boldsymbol{w} \\sim q(\\boldsymbol{w}|\\boldsymbol{\\theta})}\\left[\\log{p(\\mathcal{D}|\\boldsymbol{w})}\\right]}_{{\\text{Error Loss}}} \\\\\n    & \\quad\\quad\\quad\\quad\\quad\\quad+  \\ \\text{const}.\n\\end{align*}\n\nError Loss here corresponds to the NLL. Average loss is obtained by calculating the error for each random sample and then averaging over it.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#evaluation-of-loss",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#evaluation-of-loss",
    "title": "Uncertainty Quantification",
    "section": "Evaluation of Loss",
    "text": "Evaluation of Loss\nIn practice, we estimate loss function \n    \\mathcal{L}(\\mathcal{D}, \\boldsymbol{\\theta})\n    =\\underbrace{D_{\\text{KL}}\\left[{q(\\boldsymbol{w}|\\boldsymbol{\\theta})} || {p(\\boldsymbol{w})}\\right]}_{{\\text{Complexity Loss}}}  \\underbrace{-\\mathbb{E}_{\\boldsymbol{w} \\sim q(\\boldsymbol{w}|\\boldsymbol{\\theta})}\\left[\\log{p(\\mathcal{D}|\\boldsymbol{w})}\\right]}_{{\\text{Error Loss}}}\n through Monte Carlo estimates \n   \\mathcal{L}(\\mathcal{D}, \\boldsymbol{\\theta})\\approx\\frac{1}{M}\\sum_{m=1}^{M}\\underbrace{\\log\\Bigg({\\frac{q\\left(\\boldsymbol{w}^{(m)}|\\boldsymbol{\\theta}^{(m)}\\right) }{ p\\left(\\boldsymbol{w}^{(m)}\\right)}}\\Bigg)}_{\\text{Complexity Loss}}\n   \\underbrace{-\\log{p\\left(\\mathcal{D}|\\boldsymbol{w}^{(m)}\\right)}}_{\\text{Error Loss}}\n where \\left\\{\\boldsymbol{w}^{(m)}\\right\\}_{m=1}^{M} are random samples of \\boldsymbol{w}|\\boldsymbol{\\theta}.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#bayesian-gamma-loss",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#bayesian-gamma-loss",
    "title": "Uncertainty Quantification",
    "section": "“Bayesian-Gamma” Loss",
    "text": "“Bayesian-Gamma” Loss\nIf the output consists of the shape and scale parameter of a gamma distribution, the loss function would be \n    \\mathcal{L}(\\mathcal{D}, \\boldsymbol{\\theta})\\approx\\frac{1}{M}\\sum_{m=1}^{M}\\underbrace{\\log\\Bigg({\\frac{q\\left(\\boldsymbol{w}^{(m)}|\\boldsymbol{\\theta}^{(m)}\\right) }{ p\\left(\\boldsymbol{w}^{(m)}\\right)}}\\Bigg)}_{\\text{Complexity Loss}}\n   \\underbrace{-\\sum_{i=1}^{N}\\log \\ f(y_i|\\boldsymbol{x}_i,\\boldsymbol{w}^{(m)})}_{\\text{Error Loss}},\n where f(y_i|\\boldsymbol{x}_i,\\boldsymbol{w}^{(m)}) denotes the density value of y_i given \\boldsymbol{x}_i, under the mth Monte Carlo sample \\boldsymbol{w}^{(m)}, i.e., \n    f(y_i|\\boldsymbol{x}_i,\\boldsymbol{w}^{(m)})=\\frac{\\beta(\\boldsymbol{x};\\boldsymbol{w}^{(m)})^{\\alpha(\\boldsymbol{x};\\boldsymbol{w}^{(m)})}}{\\Gamma(\\alpha(\\boldsymbol{x}^{(m)};\\boldsymbol{w}^{(m)}))}\\mathrm{e}^{-\\beta(\\boldsymbol{x};\\boldsymbol{w}^{(m)})y}y^{\\alpha(\\boldsymbol{x};\\boldsymbol{w}^{(m)})-1}.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#architecture-3",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#architecture-3",
    "title": "Uncertainty Quantification",
    "section": "Architecture",
    "text": "Architecture\n\n\n\nFigure: The output of our Bayesian neural network now consists of the shape parameter \\alpha(\\boldsymbol{x}; \\boldsymbol{w}) and the scale parameter \\beta(\\boldsymbol{x}; \\boldsymbol{w}).",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-architecture-2",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-architecture-2",
    "title": "Uncertainty Quantification",
    "section": "Code: Architecture",
    "text": "Code: Architecture\nThe tfp.layers allows us to extract the parameters from the output, which is a gamma distribution object.\n\n# Ensure reproducibility\n1random.seed(1); tf.random.set_seed(1)\n\n2inputs = Input(shape=X_train.shape[1:])\n\n# DenseVariational layer\nx = tfp.layers.DenseVariational(64, posterior, prior,\n3                kl_weight=1/X_train.shape[0])(inputs)\nx = tfp.layers.DenseVariational(64, posterior, prior,\n                kl_weight=1/X_train.shape[0])(inputs)\noutputs = Dense(2, activation = 'softplus')(x)\n\n# Construct the Gamma distribution on the last layer\ndistributions = tfp.layers.DistributionLambda(\n      lambda t: tfd.Gamma(concentration=t[..., 0:1], \n4                          rate=t[..., 1:2]))(outputs)\n# Define the model\n5gamma_bnn = Model(inputs, distributions)\n\n\n1\n\nSets the random seed for reproducibility\n\n2\n\nSpecifies the input layer with dimensions equal to the number of features\n\n3\n\nSpecifies the DenseVariational layer with 64 neurons, posteriors, prior and KL divergence weight. In the above example KL divergence term in the loss function is scaled by the inverse of the train set size. Scaling helps stabilize the training process\n\n4\n\nTakes the outputs from the previous layers and specifies a gamma distribution with first component as the concentration parameter and second component as the rate parameter\n\n5\n\nSpecifies the model architecture",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-loss-function-and-training",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-loss-function-and-training",
    "title": "Uncertainty Quantification",
    "section": "Code: Loss Function and Training",
    "text": "Code: Loss Function and Training\n\n1def gamma_loss(y_true, y_pred):\n    return -y_pred.log_prob(y_true)\n\n# Then use the loss function when compiling the model\ngamma_bnn.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n2                loss=gamma_loss)\n\nhist = gamma_bnn.fit(X_train, y_train,\n    epochs=300,\n    callbacks=[EarlyStopping(patience=30)],\n    verbose=0,\n    batch_size=64,\n3    validation_split=0.2)\n\n\n1\n\nDefines the loss function which computes the negative log likelihood of observing the true data under the predicted probability distribution\n\n2\n\nCompiles the model with the optimizer, loss function and a custom learning rate\n\n3\n\nFits the BNN model using train set with a validation split defined inside the function",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-output-sampling",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-output-sampling",
    "title": "Uncertainty Quantification",
    "section": "Code: Output Sampling",
    "text": "Code: Output Sampling\nIn practice, we can further increase the number of samples.\n\n# Define the number of samples\nn_samples = 1000\n\n# Store all predictions in a list\nalphas = []; betas = []\n\n# Run the model `n_samples` times and store the predicted parameters\nfor i in range(n_samples):\n  # Predict the distributions\n  predicted_distributions = gamma_bnn(X_test[9:10].values)\n  # Get the parameters\n  alphas.append(predicted_distributions.concentration.numpy())\n  betas.append(predicted_distributions.rate.numpy())",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#sampled-density-functions",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#sampled-density-functions",
    "title": "Uncertainty Quantification",
    "section": "Sampled Density Functions",
    "text": "Sampled Density Functions\n\n\n\n\n\n\n\n\n\nWe plot some of the sampled posterior density functions. The variability of the sampled density functions is one critical consideration for epistemic uncertainty.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#uncertainty-quantification-uq",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#uncertainty-quantification-uq",
    "title": "Uncertainty Quantification",
    "section": "Uncertainty Quantification (UQ)",
    "text": "Uncertainty Quantification (UQ)\nWe analyse the total variance formula: \n\\begin{align*}\n    \\mathbb{V}[Y]&=\\mathbb{E}[\\mathbb{V}[Y|\\boldsymbol{x}]] + \\mathbb{V}[\\mathbb{E}[Y|\\boldsymbol{x}]]\\\\\n    &\\approx \\underbrace{\\frac{1}{M}\\sum_{m=1}^{M}\\mathbb{V}\\big[Y|\\boldsymbol{x},\\boldsymbol{w}^{(m)}\\big]}_{\\text{Aleatoric}} \\\\\n    &\\quad \\quad +\\underbrace{\\frac{1}{M}\\sum_{m=1}^{M}\\bigg(\\mathbb{E}\\big[Y|\\boldsymbol{x},\\boldsymbol{w}^{(m)}\\big]-\\frac{1}{M}\\sum_{m=1}^{M}\\mathbb{E}\\big[Y|\\boldsymbol{x},\\boldsymbol{w}^{(m)}\\big]\\bigg)^2}_{\\text{Epistemic}},\n\\end{align*}\n where M is the number of posterior samples generated.",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-applying-uq",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-applying-uq",
    "title": "Uncertainty Quantification",
    "section": "Code: Applying UQ",
    "text": "Code: Applying UQ\n\n# Convert to numpy array for easier manipulation\nalphas = np.array(alphas); betas = np.array(betas)\n\n# Aleatoric uncertainty: Mean of the variances of the predicted Gamma distributions\naleatoric_uncertainty = np.mean(alphas/betas**2)\n\n# Epistemic uncertainty: Variance of the means of the model's predictions\nepistemic_uncertainty = np.var(alphas/betas)\n\nprint(f\"Aleatoric uncertainty: {aleatoric_uncertainty}\")\nprint(f\"Epistemic uncertainty: {epistemic_uncertainty}\")\n\nAleatoric uncertainty: 12227640.0\nEpistemic uncertainty: 1425122.0",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#deep-ensembles",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#deep-ensembles",
    "title": "Uncertainty Quantification",
    "section": "Deep Ensembles",
    "text": "Deep Ensembles\nLakshminarayanan et al. (2017) proposed deep ensembles as another prominent approach to obtaining epistemic uncertainty. Such a technique can be an alternative to BNNs. It’s simple to implement and requires very little hyperparameter tuning.\nWe summarise the deep ensemble approach for uncertainty quantification as follows:\n\nTrain D neural networks with different random weights initialisations independently in parallel. The trained weights are \\boldsymbol{w}^{(1)}, ..., \\boldsymbol{w}^{(D)} .",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-deep-ensembles-i",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-deep-ensembles-i",
    "title": "Uncertainty Quantification",
    "section": "Code: Deep Ensembles I",
    "text": "Code: Deep Ensembles I\n\nK = 1 # number of mixtures\n\ndef MDN_DE(num_ensembles):\n  models = []\n  for k in range(num_ensembles):\n    #Ensure reproducibility\n    random.seed(k); tf.random.set_seed(k)\n    inputs = Input(shape=X_train.shape[1:])\n\n    #Two hidden layers \n    x = Dense(64, activation='relu')(inputs)\n    x = Dense(64, activation='relu')(x)\n\n    pis = Dense(1, activation='softmax')(x) #mixing weights\n    alphas = Dense(1, activation='softplus')(x) #shape parameters\n    betas = Dense(1, activation='softplus')(x) #scale parameters\n\n    #Concatenate by columns: `y_pred` will now have 6 columns\n    gamma_mdn_new = Model(inputs, Concatenate(axis=1)([pis, alphas, betas]))\n    gamma_mdn_new.compile(optimizer=\"adam\",\n                          loss=gamma_mixture_NLL)\n    gamma_mdn_new.fit(X_train, y_train,\n        epochs=300, callbacks=[EarlyStopping(patience=30)],  \n        verbose=0, batch_size=64, validation_split=0.2)\n    models.append(gamma_mdn_new)\n\n  return(models)",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-deep-ensembles-ii",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-deep-ensembles-ii",
    "title": "Uncertainty Quantification",
    "section": "Code: Deep Ensembles II",
    "text": "Code: Deep Ensembles II\n\nFor a new instance \\boldsymbol{x}, obtain \\Big\\{\\big(\\mathbb{E}\\big[Y|\\boldsymbol{x},\\boldsymbol{w}^{(d)}\\big],\\mathbb{V}\\big[Y|\\boldsymbol{x},\\boldsymbol{w}^{(d)}\\big]\\big)\\Big\\}_{d=1}^{D},\n\n\nD = 10 # number of MDNs\nMDN_models = MDN_DE(D)\n\n# Store all predictions in a list\nweights = [0]*D; alphas = [0]*D; betas = [0]*D\n\n#Store the paramters\nfor i in range(D):\n  weights[i], alphas[i], betas[i] = MDN_models[i].predict(X_test[9:10], verbose=0)[0]\n\n#Predict the means and variances\nmeans = np.array(alphas)/np.array(betas)\nvariances = np.array(alphas)/np.array(betas)**2",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-deep-ensembles-iii",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#code-deep-ensembles-iii",
    "title": "Uncertainty Quantification",
    "section": "Code: Deep Ensembles III",
    "text": "Code: Deep Ensembles III\n\nApply the variance decomposition \n    \\mathbb{V}[Y]=\\mathbb{E}[\\mathbb{V}[Y|\\boldsymbol{x}]] + \\mathbb{V}[\\mathbb{E}[Y|\\boldsymbol{x}]]\n\n\n\naleatoric_uncertainty = np.mean(variances)\nepistemic_uncertainty = np.var(means)\n\nprint(f\"Aleatoric uncertainty: {aleatoric_uncertainty}\")\nprint(f\"Epistemic uncertainty: {epistemic_uncertainty}\")\n\nAleatoric uncertainty: 38137052.0\nEpistemic uncertainty: 2651202.5",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#glossary",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html#glossary",
    "title": "Uncertainty Quantification",
    "section": "Glossary",
    "text": "Glossary\n\n\n\naleatoric and epistemic uncertainty\nBayesian neural network\ndeep ensembles\ndropout\nCANN\nGLM\n\n\n\nMDN\nmixture distribution\nposterior sampling\nproper scoring rule\nuncertainty quantification\nvariational approximation",
    "crumbs": [
      "Module 6",
      "Uncertainty Quantification"
    ]
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#load-packages",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#load-packages",
    "title": "Uncertainty Quantification",
    "section": "Load packages",
    "text": "Load packages\n\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport numpy.random as rnd\n\nfrom sklearn import set_config\nset_config(transform_output=\"pandas\")\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.initializers import Constant\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OrdinalEncoder\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.21.0\n\nsklearn   : 1.4.0\nkeras     : 2.15.0\ntorch     : 2.0.1\ntensorflow: 2.15.0.post1"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#quiz",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#quiz",
    "title": "Uncertainty Quantification",
    "section": "Quiz",
    "text": "Quiz\nQuestion: If you decide to predict the claim amount of Bob using a deep learning model, which source(s) of uncertainty are you confronting?\n\nThe inherent variability of the data-generating process.\nParameter error.\nModel error.\nData uncertainty.\nAll of the above."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#answer",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#answer",
    "title": "Uncertainty Quantification",
    "section": "Answer",
    "text": "Answer\nAll of the above!\nThere are two major types of uncertainty in statistical or machine learning:\n\nAleatoric uncertainty\nEpistemic uncertainty\n\nSince there is no consensus on the definitions of aleatoric and epistemic uncertainty, we provide the most acknowledged definitions in the following slides."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#aleatoric-uncertainty",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#aleatoric-uncertainty",
    "title": "Uncertainty Quantification",
    "section": "Aleatoric Uncertainty",
    "text": "Aleatoric Uncertainty\n\nQualitative Definition\n\nAleatoric uncertainty refers to the statistical variability and inherent noise with data distribution that modelling cannot explain.\n\nQuantitative Definition\n\n\\text{Ale}(Y|\\boldsymbol{x}) = \\mathbb{V}[Y|\\boldsymbol{x}],i.e., if Y|\\boldsymbol{x} \\sim \\mathcal{N}(\\mu, \\sigma^2), the aleatoric uncertainty would be \\sigma^2. Simply, it is the conditional variance of the response variable Y given features/covariates \\boldsymbol{x}."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#epistemic-uncertainty",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#epistemic-uncertainty",
    "title": "Uncertainty Quantification",
    "section": "Epistemic Uncertainty",
    "text": "Epistemic Uncertainty\n\nQualitative Definition\n\nEpistemic uncertainty refers to the lack of knowledge, limited data information, parameter errors and model errors.\n\nQuantitative Definition\n\n\\text{Epi}(Y|\\boldsymbol{x}) = \\text{Uncertainty}(Y|\\boldsymbol{x}) - \\text{Ale}(Y|\\boldsymbol{x}),\n\n\ni.e., the total uncertainty subtracting the aleatoric uncertainty \\mathbb{V}[Y|\\boldsymbol{x}] would be the epistemic uncertainty."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#uncertainty-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#uncertainty-1",
    "title": "Uncertainty Quantification",
    "section": "Uncertainty",
    "text": "Uncertainty\nLet’s go back to the question at the beginning:\nIf you decide to predict the claim amount of an individual using a deep learning model, which source(s) of uncertainty are you dealing with?\n\nThe inherent variability of the data-generating process \\rightarrow aleatoric uncertainty.\nParameter error \\rightarrow epistemic uncertainty.\nModel error \\rightarrow epistemic uncertainty.\nData uncertainty \\rightarrow epistemic uncertainty."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-data",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-data",
    "title": "Uncertainty Quantification",
    "section": "Code: Data",
    "text": "Code: Data\n\nimport pandas as pd\nsev_df = pd.read_csv('freMTPL2sev.csv')\nfreq_df = pd.read_csv('freMTPL2freq.csv')\n\n# Create a copy of freq dataframe without 'claimfreq' column\nfreq_without_claimfreq = freq_df.drop(columns=['ClaimNb'])\n\n# Merge severity dataframe with freq_without_claimfreq dataframe\nnew_sev_df = pd.merge(sev_df, freq_without_claimfreq, on='IDpol', \n                                                      how='left')\nnew_sev_df = new_sev_df.dropna()\nnew_sev_df = new_sev_df.drop(\"IDpol\", axis=1)\nnew_sev_df[:2]\n\n\n\n\n\n\n\n\nClaimAmount\nExposure\nVehPower\nVehAge\nDrivAge\nBonusMalus\nVehBrand\nVehGas\nArea\nDensity\nRegion\n\n\n\n\n0\n995.20\n0.59\n11.0\n0.0\n39.0\n56.0\nB12\nDiesel\nD\n778.0\nPicardie\n\n\n1\n1128.12\n0.95\n4.0\n1.0\n49.0\n50.0\nB12\nRegular\nE\n2354.0\nIle-de-France"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-preprocessing",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-preprocessing",
    "title": "Uncertainty Quantification",
    "section": "Code: Preprocessing",
    "text": "Code: Preprocessing\n\nX_train, X_test, y_train, y_test = train_test_split(\n  new_sev_df.drop(\"ClaimAmount\", axis=1),\n  new_sev_df[\"ClaimAmount\"],\n  random_state=2023)\n\n# Reset each index to start at 0 again.\nX_train = X_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\ny_train = y_train.reset_index(drop=True)\ny_test = y_test.reset_index(drop=True)"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-preprocessing-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-preprocessing-1",
    "title": "Uncertainty Quantification",
    "section": "Code: Preprocessing",
    "text": "Code: Preprocessing\n\n#Transformation\nct = make_column_transformer(\n  (OrdinalEncoder(), [\"VehBrand\", \"Region\", \"Area\", \"VehGas\"]),\n  remainder=StandardScaler(),\n   verbose_feature_names_out=False\n)\n\n#We don't apply entity embedding \nX_train_ct = ct.fit_transform(X_train)\nX_test_ct = ct.transform(X_test)\nX_train = X_train_ct.drop([\"VehBrand\", \"Region\"], axis=1)\nX_test = X_test_ct.drop([\"VehBrand\", \"Region\"], axis=1)\n\n\n\\texttt{VehGas=1} if the car gas is regular.\n\\texttt{Area=0} represents the rural area, and \\texttt{Area=5} represents the urban center."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#histogram-of-the-claimamount",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#histogram-of-the-claimamount",
    "title": "Uncertainty Quantification",
    "section": "Histogram of the ClaimAmount",
    "text": "Histogram of the ClaimAmount\n\nplt.hist(y_train[y_train &lt; 5000], bins=30);"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#glm",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#glm",
    "title": "Uncertainty Quantification",
    "section": "GLM",
    "text": "GLM\nThe generalised linear model (GLM) is a statistical regression model that estimates the conditional mean of the response variable Y given an instance \\boldsymbol{x} via a link function g: \n    \\mathbb{E}[Y|\\boldsymbol{x}]\n    = \\mu(\\boldsymbol{x}; \\boldsymbol{\\beta}_{\\text{GLM}})\n    = g^{-1} \\big(\\big \\langle \\boldsymbol{\\beta}_{\\text{GLM}}, \\boldsymbol{x} \\big \\rangle\\big),\n where\n\n\\boldsymbol{x} \\in \\mathbb{R}^{d_{\\boldsymbol{x}}} is the vector of explanatory variables, with d_{\\boldsymbol{x}} denoting its dimension.\n\\boldsymbol{\\beta}_{\\text{GLM}} represents the vector of regression coefficients.\n\\langle \\boldsymbol{a}, \\boldsymbol{b}\\rangle represents the inner product of \\boldsymbol{a} and \\boldsymbol{b}."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#gamma-glm",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#gamma-glm",
    "title": "Uncertainty Quantification",
    "section": "Gamma GLM",
    "text": "Gamma GLM\nSuppose a fitted gamma GLM model has\n\na log link function g(x)=\\log(x) and\nregression coefficients \\boldsymbol{\\beta}_{\\text{GLM}}=(\\beta_0, \\beta_1, \\beta_2, \\beta_3).\n\nThen, it estimates the conditional mean of Y given a new instance \\boldsymbol{x}=(1, x_1, x_2, x_3) as follows: \n    \\mathbb{E}[Y|\\boldsymbol{x}]=g^{-1}(\\langle \\boldsymbol{\\beta}_{\\text{GLM}}, \\boldsymbol{x}\\rangle)=\\exp\\big(\\beta_0+ \\beta_1x_1+\\beta_2x_2+\\beta_3x_3\\big).\n\nA GLM can model any other exponential family distribution using an appropriate link function g."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#loss-function-for-a-gamma-glm",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#loss-function-for-a-gamma-glm",
    "title": "Uncertainty Quantification",
    "section": "“Loss Function” for a Gamma GLM",
    "text": "“Loss Function” for a Gamma GLM\nIf Y|\\boldsymbol{x} is a gamma r.v., we can parameterise its density by its mean \\mu(\\boldsymbol{x}; \\boldsymbol{\\beta}) and dispersion parameter \\phi: \n    f_{Y|\\boldsymbol{X}}(y|\\boldsymbol{x}, \\boldsymbol{\\beta}, \\phi)\n    = \\frac{(\\mu (\\boldsymbol{x}; \\boldsymbol{\\beta})\\cdot \\phi)^{-1/\\phi}}{{\\Gamma(1/\\phi)}} \\cdot y^{1/\\phi - 1} \\cdot \\mathrm{e}^{-y/(\\mu (\\boldsymbol{x}; \\boldsymbol{\\beta})\\cdot\\phi)}.\n The “loss function” for a gamma GLM is typically the negative log-likelihood (NLL): \n    \\sum_{i=1}^{N}-\\log f_{Y|\\boldsymbol{X}}(y_i|\\boldsymbol{x}_i, \\boldsymbol{\\beta},\\phi)\n    \\propto \\sum_{i=1}^{N}\\log \\mu (\\boldsymbol{x}_i; \\boldsymbol{\\beta})+\\frac{y_i}{\\mu (\\boldsymbol{x}_i; \\boldsymbol{\\beta})} + \\text{const},\n i.e., we ignore the dispersion parameter \\phi while estimating the regression coefficients."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#fitting-steps",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#fitting-steps",
    "title": "Uncertainty Quantification",
    "section": "Fitting Steps",
    "text": "Fitting Steps\nStep 1. Use the advanced second derivative iterative method to find the regression coefficients: \n    \\boldsymbol{\\beta}_{\\text{GLM}} = \\underset{\\boldsymbol{\\beta}}{\\text{arg min}} \\ \\sum_{i=1}^{N}\\log \\mu (\\boldsymbol{x}_i; \\boldsymbol{\\beta})+\\frac{y_i}{\\mu (\\boldsymbol{x}_i; \\boldsymbol{\\beta})}\n\nStep 2. Estimate the dispersion parameter: \n    \\phi_{\\text{GLM}}=\\frac{1}{N-d_{\\boldsymbol{x}}}\\sum_{i=1}^{N}\\frac{(y_i-\\mu(\\boldsymbol{x}_i; \\boldsymbol{\\beta}_{\\text{GLM}} ))^2}{\\mu(\\boldsymbol{x}_i; \\boldsymbol{\\beta}_{\\text{GLM}} )^2}"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-gamma-glm",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-gamma-glm",
    "title": "Uncertainty Quantification",
    "section": "Code: Gamma GLM",
    "text": "Code: Gamma GLM\nIn Python, we can fit a gamma GLM as follows:\n\nimport statsmodels.api as sm\n\n# Add a column of ones to include an intercept in the model\nX_train_design = sm.add_constant(X_train)\n\n# Create a Gamma GLM with a log link function\ngamma_GLM = sm.GLM(y_train, X_train_design,                   \n            family=sm.families.Gamma(sm.families.links.Log()))\n\n# Fit the model\ngamma_GLM = gamma_GLM.fit()\n\n#Dispersion Parameter\nmus = gamma_GLM.predict(X_train_design)\nresiduals = mus-y_train\nvariance = mus**2\ndof = (len(y_train)-X_train.shape[1])\nphi_GLM =  np.sum(residuals**2/variance)/dof\nprint(phi_GLM)\n\n59.6306232357824"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#cann",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#cann",
    "title": "Uncertainty Quantification",
    "section": "CANN",
    "text": "CANN\nThe Combined Actuarial Neural Network is a novel actuarial neural network architecture proposed by Schelldorfer and Wüthrich (2019). We summarise the CANN approach as follows:\n\nFind the coefficients \\boldsymbol{\\beta}_{\\text{GLM}} of the GLM with a link function g(\\cdot).\nFind the weights \\boldsymbol{w}_{\\text{CANN}} of a neural network \\mathcal{M}_{\\text{CANN}}:\\mathbb{R}^{d_{\\boldsymbol{x}}}\\to\\mathbb{R}.\nGiven a new instance \\boldsymbol{x}, we have \\mathbb{E}[Y|\\boldsymbol{x}] = g^{-1}\\Big( \\langle\\boldsymbol{\\beta}_{\\text{GLM}}, \\boldsymbol{x}\\rangle + \\mathcal{M}_{\\text{CANN}}(\\boldsymbol{x};\\boldsymbol{w}_{\\text{CANN}})\\Big)."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#architecture",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#architecture",
    "title": "Uncertainty Quantification",
    "section": "Architecture",
    "text": "Architecture\n\nFigure: CANN approach."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-architecture",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-architecture",
    "title": "Uncertainty Quantification",
    "section": "Code: Architecture",
    "text": "Code: Architecture\n\ngamma_GLM.params\n\nconst         7.786576\nArea         -0.073226\nVehGas        0.082292\n                ...   \nDrivAge      -0.022147\nBonusMalus    0.157204\nDensity       0.010539\nLength: 9, dtype: float64\n\n\n\n# Ensure reproducibility\nrandom.seed(1); tf.random.set_seed(1)\n\n# Pre-defined constants\nglm_weights = gamma_GLM.params.iloc[1:]\nglm_bias = gamma_GLM.params.iloc[0]\n\n# Define model inputs\ninputs = Input(shape=X_train.shape[1:])\n\n# Non-trainable GLM linear part\nglm_logmu = Dense(1, activation='linear', trainable=False,\n                     kernel_initializer=Constant(glm_weights),\n                     bias_initializer=Constant(glm_bias))(inputs)\n\n# Neural network layers\nx = Dense(64, activation='relu')(inputs)\nx = Dense(64, activation='relu')(x)\ncann_logmu = Dense(1, activation='linear')(x)"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-loss-function",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-loss-function",
    "title": "Uncertainty Quantification",
    "section": "Code: Loss Function",
    "text": "Code: Loss Function\n\n# Combine GLM and CANN estimates\nCANN = Model(inputs, Concatenate(axis=1)([cann_logmu, glm_logmu]))\n\nWe need to customise the loss function for CANN.\n\ndef CANN_negative_log_likelihood(y_true, y_pred):\n    #the new mean estimate\n    CANN_logmu = y_pred[:, 0]\n    GLM_logmu = y_pred[:, 1]\n    mu = tf.math.exp(CANN_logmu + GLM_logmu)\n\n    # Compute the negative log likelihood of the Gamma distribution\n    nll = tf.reduce_mean(CANN_logmu + GLM_logmu + y_true/mu)\n    \n    return nll"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-model-training",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-model-training",
    "title": "Uncertainty Quantification",
    "section": "Code: Model Training",
    "text": "Code: Model Training\n\nCANN.compile(optimizer=\"adam\", loss=CANN_negative_log_likelihood)\nhist = CANN.fit(X_train, y_train,\n    epochs=300, \n    callbacks=[EarlyStopping(patience=30)],  \n    verbose=0,\n    batch_size=64, \n    validation_split=0.2)\n\nFind the dispersion parameter.\n\nmus = np.exp(np.sum(CANN.predict(X_train, verbose=0), axis = 1))\nresiduals = mus-y_train\nvariance = mus**2\ndof = (len(y_train)-X_train.shape[1])\nphi_CANN =  np.sum(residuals**2/variance) / dof\nprint(phi_CANN)\n\n98.60976911896634"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#mixture-distribution",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#mixture-distribution",
    "title": "Uncertainty Quantification",
    "section": "Mixture Distribution",
    "text": "Mixture Distribution\nGiven a finite set of resulting random variables (Y_1, ..., Y_{K}), one can generate a multinomial random variable Y\\sim \\text{Multinomial}(1, \\boldsymbol{\\pi}). Meanwhile, Y can be regarded as a mixture of Y_1, ..., Y_{K}, i.e., \n  Y = \\begin{cases}\n      Y_1 & \\text{w.p. } \\pi_1, \\\\\n      \\vdots & \\vdots\\\\\n      Y_K & \\text{w.p. } \\pi_K, \\\\\n  \\end{cases}\n where we define a set of finite set of weights \\boldsymbol{\\pi}=(\\pi_{1} ..., \\pi_{K}) such that \\pi_k \\ge 0 for k \\in \\{1, ..., K\\} and \\sum_{k=1}^{K}\\pi_k=1."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#mixture-distribution-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#mixture-distribution-1",
    "title": "Uncertainty Quantification",
    "section": "Mixture Distribution",
    "text": "Mixture Distribution\nLet f_{Y_k|\\boldsymbol{X}} and F_{Y_k|\\boldsymbol{X}} be the probability density function and the cumulative density function, respectively, of Y_k|\\boldsymbol{X} for all k\\in \\{1, ..., K\\}. The random variable Y|\\boldsymbol{X}, which mixes Y_k|\\boldsymbol{X}’s with weights \\pi_k’s, has the density function \n    f_{Y|\\boldsymbol{X}}(y|\\boldsymbol{x}) = \\sum_{k=1}^{K}\\pi_k(\\boldsymbol{x}) f_{k}(y|\\boldsymbol{x}),\n and the cumulative density function \n    F_{Y|\\boldsymbol{X}}(y|\\boldsymbol{x}) = \\sum_{k=1}^{K}\\pi_k(\\boldsymbol{x}) F_{k}(y|\\boldsymbol{x})."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#mixture-density-network",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#mixture-density-network",
    "title": "Uncertainty Quantification",
    "section": "Mixture Density Network",
    "text": "Mixture Density Network\nA mixture density network (MDN) \\mathcal{M}_{\\boldsymbol{w}^*} outputs each distribution component’s mixing weights and parameters of Y given the input features \\boldsymbol{x}, i.e., \n    \\mathcal{M}_{\\boldsymbol{w}^*}(\\boldsymbol{x})=(\\boldsymbol{\\pi}(\\boldsymbol{x};\\boldsymbol{w}^*), \\boldsymbol{\\theta}(\\boldsymbol{x};\\boldsymbol{w}^*)),\n where \\boldsymbol{w}^* is the networks’ weights found by minimising the following negative log-likelihood loss function \n    \\mathcal{L}(\\mathcal{D}, \\boldsymbol{\\theta})= - \\sum_{i=1}^{N} \\log f_{Y|\\boldsymbol{x}}(y_i|\\boldsymbol{x}, \\boldsymbol{w}^*),\n where \\mathcal{D}=\\{(\\boldsymbol{x}_i,y_i)\\}_{i=1}^{N} is the training dataset."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#mixture-density-network-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#mixture-density-network-1",
    "title": "Uncertainty Quantification",
    "section": "Mixture Density Network",
    "text": "Mixture Density Network\n\nFigure: An MDN that outputs the parameters for a K component mixture distribution. \\boldsymbol{\\theta}_k(\\boldsymbol{x}; \\boldsymbol{w}^*)= (\\theta_{k,1}(\\boldsymbol{x}; \\boldsymbol{w}^*), ..., \\theta_{k,|\\boldsymbol{\\theta}_k|}(\\boldsymbol{x}; \\boldsymbol{w}^*)) consists of the parameter estimates for the kth mixture component."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#model-specification",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#model-specification",
    "title": "Uncertainty Quantification",
    "section": "Model Specification",
    "text": "Model Specification\nSuppose there are two types of claims:\n\nType I: Y_1|\\boldsymbol{x}\\sim \\text{Gamma}(\\alpha_1(\\boldsymbol{x}), \\beta_1(\\boldsymbol{x})) and,\nType II: Y_2|\\boldsymbol{x}\\sim \\text{Gamma}(\\alpha_2(\\boldsymbol{x}), \\beta_2(\\boldsymbol{x})).\n\nThe density of the actual claim amount Y|\\boldsymbol{x} follows \n    \\begin{align*}\n        f_{Y|\\boldsymbol{X}}(y|\\boldsymbol{x})\n        &= \\pi_1(\\boldsymbol{x})\\cdot \\frac{\\beta_1(\\boldsymbol{x})^{\\alpha_1(\\boldsymbol{x})}}{\\Gamma(\\alpha_1(\\boldsymbol{x}))}\\mathrm{e}^{-\\beta_1(\\boldsymbol{x})y}y^{\\alpha_1(\\boldsymbol{x})-1} \\\\\n        &\\quad + (1-\\pi_1(\\boldsymbol{x}))\\cdot \\frac{\\beta_2(\\boldsymbol{x})^{\\alpha_2(\\boldsymbol{x})}}{\\Gamma(\\alpha_2(\\boldsymbol{x}))}\\mathrm{e}^{-\\beta_2(\\boldsymbol{x})y}y^{\\alpha_2(\\boldsymbol{x})-1}.\n    \\end{align*}\n where \\pi_1(\\boldsymbol{x}) is the probability of a Type I claim given \\boldsymbol{x}."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#output",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#output",
    "title": "Uncertainty Quantification",
    "section": "Output",
    "text": "Output\nThe aim is to find the optimum weights \n    \\boldsymbol{w}^* = \\underset{w}{\\text{arg min}} \\ \\mathcal{L}(\\mathcal{D}, \\boldsymbol{w})\n for the Gamma mixture density network \\mathcal{M}_{\\boldsymbol{w}^*} that outputs the mixing weights, shapes and scales of Y given the input features \\boldsymbol{x}, i.e., \n    \\begin{align*}\n        \\mathcal{M}_{\\boldsymbol{w}^*}(\\boldsymbol{x})\n        = ( &\\pi_1(\\boldsymbol{x}; \\boldsymbol{w}^*),\n             \\pi_2(\\boldsymbol{x}; \\boldsymbol{w}^*), \\\\\n            &\\alpha_1(\\boldsymbol{x}; \\boldsymbol{w}^*),\n            \\alpha_2(\\boldsymbol{x}; \\boldsymbol{w}^*),\\\\\n            &\\beta_1(\\boldsymbol{x}; \\boldsymbol{w}^*),\n            \\beta_2(\\boldsymbol{x}; \\boldsymbol{w}^*)\n        ).\n    \\end{align*}"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#architecture-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#architecture-1",
    "title": "Uncertainty Quantification",
    "section": "Architecture",
    "text": "Architecture\n\nFigure: We demonstrate the structure of a gamma MDN that outputs the parameters for a gamma mixture with two components."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-architecture-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-architecture-1",
    "title": "Uncertainty Quantification",
    "section": "Code: Architecture",
    "text": "Code: Architecture\nThe following code resembles the architecture of the architecture of the gamma MDN from the previous slide.\n\n# Ensure reproducibility\nrandom.seed(1); tf.random.set_seed(1)\n\ninputs = Input(shape=X_train.shape[1:])\n\n# Two hidden layers \nx = Dense(64, activation='relu')(inputs)\nx = Dense(64, activation='relu')(x)\n\npis = Dense(2, activation='softmax')(x) #mixing weights\nalphas = Dense(2, activation='exponential')(x) #shape parameters\nbetas = Dense(2, activation='exponential')(x) #scale parameters\n\n#`y_pred` will now have 6 columns\ngamma_mdn = Model(inputs, Concatenate(axis=1)([pis, alphas, betas]))"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#loss-function",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#loss-function",
    "title": "Uncertainty Quantification",
    "section": "Loss Function",
    "text": "Loss Function\nThe negative log-likelihood loss function is given by\n\n    \\mathcal{L}(\\mathcal{D}, \\boldsymbol{w})\n    = - \\sum_{i=1}^{N} \\log \\  f_{Y|\\boldsymbol{x}}(y_i|\\boldsymbol{x}, \\boldsymbol{w})\n where the f_{Y|\\boldsymbol{x}}(y_i|\\boldsymbol{x}, \\boldsymbol{w}) is defined by \n\\begin{align*}\n    &\\pi_1(\\boldsymbol{x};\\boldsymbol{w})\\cdot \\frac{\\beta_1(\\boldsymbol{x};\\boldsymbol{w})^{\\alpha_1(\\boldsymbol{x};\\boldsymbol{w})}}{\\Gamma(\\alpha_1(\\boldsymbol{x};\\boldsymbol{w}))}\\mathrm{e}^{-\\beta_1(\\boldsymbol{x};\\boldsymbol{w})y}y^{\\alpha_1(\\boldsymbol{x};\\boldsymbol{w})-1} \\\\\n    & \\quad + (1-\\pi_1(\\boldsymbol{x};\\boldsymbol{w}))\\cdot \\frac{\\beta_2(\\boldsymbol{x};\\boldsymbol{w})^{\\alpha_2(\\boldsymbol{x};\\boldsymbol{w})}}{\\Gamma(\\alpha_2(\\boldsymbol{x};\\boldsymbol{w}))}\\mathrm{e}^{-\\beta_2(\\boldsymbol{x};\\boldsymbol{w})y}y^{\\alpha_2(\\boldsymbol{x};\\boldsymbol{w})-1}\n\\end{align*}"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-loss-function-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-loss-function-1",
    "title": "Uncertainty Quantification",
    "section": "Code: Loss Function",
    "text": "Code: Loss Function\nWe employ functions from tensorflow_probability to code the loss function for the gamma MDN. The MixtureSameFamily function facilitates defining a mixture distribution all components from the same distribution but have different parametrization.\n\nimport tensorflow_probability as tfp\ntfd = tfp.distributions\nK = 2 # number of mixture components\n\ndef gamma_mixture_NLL(y_true, y_pred):                                      \n    K = y_pred.shape[1] // 3\n    pis =  y_pred[:, :K]                                                    \n    alphas = y_pred[:, K:2*K]                                               \n    betas = y_pred[:, 2*K:3*K]                                              \n\n    # The mixture distribution is a MixtureSameFamily distribution\n    mixture_distribution = tfd.MixtureSameFamily(\n        mixture_distribution=tfd.Categorical(probs=pis),\n        components_distribution=tfd.Gamma(alphas, betas))\n\n    # The loss is the negative log-likelihood of the data\n    return -mixture_distribution.log_prob(y_true)"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-model-training-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-model-training-1",
    "title": "Uncertainty Quantification",
    "section": "Code: Model Training",
    "text": "Code: Model Training\n\n#Employ the loss function from previous slide\ngamma_mdn.compile(optimizer=\"adam\", loss=gamma_mixture_NLL)\n\nhist = gamma_mdn.fit(X_train, y_train,\n    epochs=300, \n    callbacks=[EarlyStopping(patience=30)],  \n    verbose=0,\n    batch_size=64, \n    validation_split=0.2)"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#proper-scoring-rules",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#proper-scoring-rules",
    "title": "Uncertainty Quantification",
    "section": "Proper Scoring Rules",
    "text": "Proper Scoring Rules\n\nDefinition\n\nThe scoring rule S : \\mathcal{F} \\times \\mathbb{R} \\to \\bar{\\mathbb{R}} is proper relative to the class \\mathcal{F} if \nS(G, G)\\le S(F, G)\n for all F,G\\in \\mathcal{F}. It is strictly proper if equality holds only if F = G.\n\n\nExamples:\n\nLogarithmic Score (NLL)\nContinuous Ranked Probability Score (CRPS)"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#proper-scoring-rules-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#proper-scoring-rules-1",
    "title": "Uncertainty Quantification",
    "section": "Proper Scoring Rules",
    "text": "Proper Scoring Rules\n\nLogarithmic Score (NLL)\n\nThe logarithmic score is defined as \n    \\mathrm{LogS}(f, y) = - \\log f(y),\n where f is the predictive density.\n\nContinuous Ranked Probability Score (CRPS)\n\nThe continuous ranked probability score is defined as \n    \\mathrm{crps}(F, y) = \\int_{-\\infty}^{\\infty} (F(t) - {1}_{t\\ge y})^2 \\ \\mathrm{d}t,\n where F is the cumulative distribution function."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-nll",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-nll",
    "title": "Uncertainty Quantification",
    "section": "Code: NLL",
    "text": "Code: NLL\n\nfrom scipy.stats import gamma\n\ndef gamma_nll(mean, dispersion, y):\n    # Calculate shape and scale parameters from mean and dispersion\n    shape = 1 / dispersion; scale = mean * dispersion\n\n    # Create a gamma distribution object\n    gamma_dist = gamma(a=shape, scale=scale)\n    \n    return -np.mean(gamma_dist.logpdf(y))\n\n#GLM\nX_test_design = sm.add_constant(X_test)\nmus = gamma_GLM.predict(X_test_design)\nNLL_GLM = gamma_nll(mus, phi_GLM, y_test)\n\n#CANN\nmus = np.exp(np.sum(CANN.predict(X_test, verbose=0), axis = 1))\nNLL_CANN = gamma_nll(mus, phi_CANN, y_test)\n\n#MDN\nNLL_MDN = gamma_mdn.evaluate(X_test, y_test, verbose=0)"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#model-comparisons",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#model-comparisons",
    "title": "Uncertainty Quantification",
    "section": "Model Comparisons",
    "text": "Model Comparisons\n\nprint(f'GLM: {round(NLL_GLM, 2)}')\nprint(f'CANN: {round(NLL_CANN, 2)}')\nprint(f'MDN: {round(NLL_MDN, 2)}')\n\nGLM: 11.02\nCANN: 11.5\nMDN: 8.67"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#dropout",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#dropout",
    "title": "Uncertainty Quantification",
    "section": "Dropout",
    "text": "Dropout\n\nAn example of neurons dropped during training.\nSources: Marcus Lautier (2022)."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#dropout-quote-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#dropout-quote-1",
    "title": "Uncertainty Quantification",
    "section": "Dropout quote #1",
    "text": "Dropout quote #1\n\nIt’s surprising at first that this destructive technique works at all. Would a company perform better if its employees were told to toss a coin every morning to decide whether or not to go to work? Well, who knows; perhaps it would! The company would be forced to adapt its organization; it could not rely on any single person to work the coffee machine or perform any other critical tasks, so this expertise would have to be spread across several people. Employees would have to learn to cooperate with many of their coworkers, not just a handful of them.\n\n\nSource: Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, p. 366"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#dropout-quote-2",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#dropout-quote-2",
    "title": "Uncertainty Quantification",
    "section": "Dropout quote #2",
    "text": "Dropout quote #2\n\nThe company would become much more resilient. If one person quit, it wouldn’t make much of a difference. It’s unclear whether this idea would actually work for companies, but it certainly does for neural networks. Neurons trained with dropout cannot co-adapt with their neighboring neurons; they have to be as useful as possible on their own. They also cannot rely excessively on just a few input neurons; they must pay attention to each of their input neurons. They end up being less sensitive to slight changes in the inputs. In the end, you get a more robust network that generalizes better.\n\n\nSource: Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, p. 366"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-dropout",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-dropout",
    "title": "Uncertainty Quantification",
    "section": "Code: Dropout",
    "text": "Code: Dropout\nDropout is just another layer in Keras.\n\nfrom tensorflow.keras.layers import Dropout\n#Ensure reproducibility\nrandom.seed(2); tf.random.set_seed(2)\n\nmodel = Sequential([\n    Dense(30, activation=\"leaky_relu\", name=\"hidden1\"),\n    Dropout(0.2),\n    Dense(30, activation=\"leaky_relu\", name=\"hidden2\"),\n    Dropout(0.2),\n    Dense(1, activation=\"exponential\", name=\"output\")\n])\n\nmodel.compile(\"adam\", \"mse\")\nmodel.fit(X_train, y_train, epochs=4, verbose=0);"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-dropout-after-training",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-dropout-after-training",
    "title": "Uncertainty Quantification",
    "section": "Code: Dropout after training",
    "text": "Code: Dropout after training\nMaking predictions is the same as any other model:\n\n\n\nmodel.predict(X_test.head(3),\n                  verbose=0)\n\narray([[ 53.365997],\n       [149.5073  ],\n       [ 84.2315  ]], dtype=float32)\n\n\n\n\nmodel.predict(X_test.head(3),\n                  verbose=0)\n\narray([[ 53.365997],\n       [149.5073  ],\n       [ 84.2315  ]], dtype=float32)\n\n\n\n\nWe can make the model think it is still training:\n\n\n\nmodel(X_test.head(3).to_numpy(),\n    training=True).numpy()\n\narray([[ 45.215286],\n       [506.83798 ],\n       [ 80.71608 ]], dtype=float32)\n\n\n\n\nmodel(X_test.head(3).to_numpy(),\n    training=True).numpy()\n\narray([[170.87773],\n       [140.37846],\n       [231.01816]], dtype=float32)"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#dropout-limitation",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#dropout-limitation",
    "title": "Uncertainty Quantification",
    "section": "Dropout Limitation",
    "text": "Dropout Limitation\n\nIncreased Training Time: Since dropout introduces noise into the training process, it can make the training process slower.\nSensitivity to Dropout Rates: the performance of dropout is highly dependent on the chosen dropout rate.\nUncertainty Quantification: the dropout can only provide a crude approximation to the theoretically justified Bayesian approach in terms of quantifying uncertainty."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#bayesian-neural-network",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#bayesian-neural-network",
    "title": "Uncertainty Quantification",
    "section": "Bayesian Neural Network",
    "text": "Bayesian Neural Network\nThe weights \\boldsymbol{w} of a Bayesian neural network (BNN) have their posterior distribution: p(\\boldsymbol{w}|\\mathcal{D})\\propto \\mathcal{L}(\\mathcal{D}|\\boldsymbol{w})p(\\boldsymbol{w}) according to the Bayes’ theorem.\n\n\\mathcal{L}(\\mathcal{D}|\\boldsymbol{w}) represents the likelihood of data given the weights.\np(\\boldsymbol{w}) represents the density of the prior distribution of the weights."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#tractability-of-posterior-distribution",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#tractability-of-posterior-distribution",
    "title": "Uncertainty Quantification",
    "section": "Tractability of Posterior Distribution",
    "text": "Tractability of Posterior Distribution\nLet \\boldsymbol{\\theta}_0=(\\boldsymbol{\\mu}_{\\boldsymbol{w}_0},\\boldsymbol{\\sigma}_{\\boldsymbol{w}_0}) be the parameters of the prior distribution of weights: \n    \\boldsymbol{w}\\sim \\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{w}_0},\\boldsymbol{\\sigma}_{\\boldsymbol{w}_0}).\n The derivation of the true posterior \n    p(\\boldsymbol{w}|\\mathcal{D})\n    \\propto \\mathcal{L}(\\mathcal{D}|\\boldsymbol{w})p(\\boldsymbol{w})\n is non-trivial due to the complexity of the model. We cannot compute the true posterior distribution efficiently."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#variational-approximation",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#variational-approximation",
    "title": "Uncertainty Quantification",
    "section": "Variational Approximation",
    "text": "Variational Approximation\nThe variational approximation is a potential solution. Intuitively, we approximate the true posterior distribution with a variational distribution that is more tractable: \n    \\underbrace{p(\\boldsymbol{w}|\\mathcal{D})}_{\\text{True Posterior Distribution}}\\approx \\underbrace{q(\\boldsymbol{w}|\\boldsymbol{\\theta})}_{\\text{Variational Distribution}}\n    \\sim\\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{w}},\\boldsymbol{\\sigma}_{\\boldsymbol{w}}),\n i.e., a normal distribution with parameters \\boldsymbol{\\theta}= (\\boldsymbol{\\mu}_{\\boldsymbol{w}},\\boldsymbol{\\sigma}_{\\boldsymbol{w}}) is used to approximate the true posterior distribution of \\boldsymbol{w}|\\mathcal{D}."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#demonstration",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#demonstration",
    "title": "Uncertainty Quantification",
    "section": "Demonstration",
    "text": "Demonstration\n\nFigure: The idea is to use the blue curve (variational distribution) to approximate the purple curve (true posterior)."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-variational-layers",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-variational-layers",
    "title": "Uncertainty Quantification",
    "section": "Code: Variational Layers",
    "text": "Code: Variational Layers\n\nimport tensorflow_probability as tfp\ntfd = tfp.distributions #tensorflow prob. distributions\n\ndef prior(kernel_size, bias_size, dtype=None):\n    n = kernel_size + bias_size\n    return lambda t: tfd.Independent(\n        tfd.Normal(loc=tf.zeros(n, dtype=dtype),\n                   scale=1),\n                   reinterpreted_batch_ndims=1)\n\ndef posterior(kernel_size, bias_size, dtype=None):\n    n = kernel_size + bias_size\n    return Sequential([\n      tfp.layers.VariableLayer(2 * n, dtype=dtype),\n      tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n          tfd.Normal(loc=t[..., :n],\n                     scale=1e-5 + tf.nn.softplus(0.01 * t[..., n:])),\n          reinterpreted_batch_ndims=1)),\n    ])"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#architecture-2",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#architecture-2",
    "title": "Uncertainty Quantification",
    "section": "Architecture",
    "text": "Architecture\n\nFigure: We demonstrate the typical structure of a Bayesian neural network (BNN).\nSource: Blundell et al. (2015), Weight Uncertainty in Neural Networks."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#loss-function-1",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#loss-function-1",
    "title": "Uncertainty Quantification",
    "section": "Loss Function",
    "text": "Loss Function\nThe KL divergence between the true posterior and variational distribution is given by: \n    D_{\\text{KL}}\\left[q(\\boldsymbol{w}|\\boldsymbol{\\theta}) || p(\\boldsymbol{w}|\\mathcal{D})\\right]\n    =\\mathbb{E}_{\\boldsymbol{w} \\sim q(\\boldsymbol{w}|\\boldsymbol{\\theta})}\\left[\\log\\left(\\frac{q(\\boldsymbol{w}|\\boldsymbol{\\theta})}{p(\\boldsymbol{w}|\\mathcal{D})}\\right) \\right]\n After some algebra, we acknowledge the final representation: \n\\begin{align*}\n    D_{\\text{KL}}\\left[q(\\boldsymbol{w}|\\boldsymbol{\\theta}) || p(\\boldsymbol{w}|\\mathcal{D})\\right]\n    &=\\underbrace{D_{\\text{KL}}\\left[{q(\\boldsymbol{w}|\\boldsymbol{\\theta})} || {p(\\boldsymbol{w})}\\right]}_{{\\text{Complexity Loss}}}  \\underbrace{-\\mathbb{E}_{\\boldsymbol{w} \\sim q(\\boldsymbol{w}|\\boldsymbol{\\theta})}\\left[\\log{p(\\mathcal{D}|\\boldsymbol{w})}\\right]}_{{\\text{Error Loss}}} \\\\\n    & \\quad\\quad\\quad\\quad\\quad\\quad+  \\ \\text{const}.\n\\end{align*}"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#evaluation-of-loss",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#evaluation-of-loss",
    "title": "Uncertainty Quantification",
    "section": "Evaluation of Loss",
    "text": "Evaluation of Loss\nIn practice, we estimate loss function \n    \\mathcal{L}(\\mathcal{D}, \\boldsymbol{\\theta})\n    =\\underbrace{D_{\\text{KL}}\\left[{q(\\boldsymbol{w}|\\boldsymbol{\\theta})} || {p(\\boldsymbol{w})}\\right]}_{{\\text{Complexity Loss}}}  \\underbrace{-\\mathbb{E}_{\\boldsymbol{w} \\sim q(\\boldsymbol{w}|\\boldsymbol{\\theta})}\\left[\\log{p(\\mathcal{D}|\\boldsymbol{w})}\\right]}_{{\\text{Error Loss}}}\n through Monte Carlo estimates \n   \\mathcal{L}(\\mathcal{D}, \\boldsymbol{\\theta})\\approx\\frac{1}{M}\\sum_{m=1}^{M}\\underbrace{\\log\\Bigg({\\frac{q\\left(\\boldsymbol{w}^{(m)}|\\boldsymbol{\\theta}^{(m)}\\right) }{ p\\left(\\boldsymbol{w}^{(m)}\\right)}}\\Bigg)}_{\\text{Complexity Loss}}\n   \\underbrace{-\\log{p\\left(\\mathcal{D}|\\boldsymbol{w}^{(m)}\\right)}}_{\\text{Error Loss}}\n where \\left\\{\\boldsymbol{w}^{(m)}\\right\\}_{m=1}^{M} are random samples of \\boldsymbol{w}|\\boldsymbol{\\theta}."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#bayesian-gamma-loss",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#bayesian-gamma-loss",
    "title": "Uncertainty Quantification",
    "section": "“Bayesian-Gamma” Loss",
    "text": "“Bayesian-Gamma” Loss\nIf the output consists of the shape and scale parameter of a gamma distribution, the loss function would be \n    \\mathcal{L}(\\mathcal{D}, \\boldsymbol{\\theta})\\approx\\frac{1}{M}\\sum_{m=1}^{M}\\underbrace{\\log\\Bigg({\\frac{q\\left(\\boldsymbol{w}^{(m)}|\\boldsymbol{\\theta}^{(m)}\\right) }{ p\\left(\\boldsymbol{w}^{(m)}\\right)}}\\Bigg)}_{\\text{Complexity Loss}}\n   \\underbrace{-\\sum_{i=1}^{N}\\log \\ f(y_i|\\boldsymbol{x}_i,\\boldsymbol{w}^{(m)})}_{\\text{Error Loss}},\n where f(y_i|\\boldsymbol{x}_i,\\boldsymbol{w}^{(m)}) denotes the density value of y_i given \\boldsymbol{x}_i, under the mth Monte Carlo sample \\boldsymbol{w}^{(m)}, i.e., \n    f(y_i|\\boldsymbol{x}_i,\\boldsymbol{w}^{(m)})=\\frac{\\beta(\\boldsymbol{x};\\boldsymbol{w}^{(m)})^{\\alpha(\\boldsymbol{x};\\boldsymbol{w}^{(m)})}}{\\Gamma(\\alpha(\\boldsymbol{x}^{(m)};\\boldsymbol{w}^{(m)}))}\\mathrm{e}^{-\\beta(\\boldsymbol{x};\\boldsymbol{w}^{(m)})y}y^{\\alpha(\\boldsymbol{x};\\boldsymbol{w}^{(m)})-1}."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#architecture-3",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#architecture-3",
    "title": "Uncertainty Quantification",
    "section": "Architecture",
    "text": "Architecture\n\nFigure: The output of our Bayesian neural network now consists of the shape parameter \\alpha(\\boldsymbol{x}; \\boldsymbol{w}) and the scale parameter \\beta(\\boldsymbol{x}; \\boldsymbol{w})."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-architecture-2",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-architecture-2",
    "title": "Uncertainty Quantification",
    "section": "Code: Architecture",
    "text": "Code: Architecture\nThe tfp.layers allows us to extract the parameters from the output, which is a gamma distribution object.\n\n# Ensure reproducibility\nrandom.seed(1); tf.random.set_seed(1)\n\ninputs = Input(shape=X_train.shape[1:])\n\n# DenseVariational layer\nx = tfp.layers.DenseVariational(64, posterior, prior,\n                kl_weight=1/X_train.shape[0])(inputs)\nx = tfp.layers.DenseVariational(64, posterior, prior,\n                kl_weight=1/X_train.shape[0])(inputs)\noutputs = Dense(2, activation = 'softplus')(x)\n\n# Construct the Gamma distribution on the last layer\ndistributions = tfp.layers.DistributionLambda(\n      lambda t: tfd.Gamma(concentration=t[..., 0:1], \n                          rate=t[..., 1:2]))(outputs)\n# Define the model\ngamma_bnn = Model(inputs, distributions)"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-loss-function-and-training",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-loss-function-and-training",
    "title": "Uncertainty Quantification",
    "section": "Code: Loss Function and Training",
    "text": "Code: Loss Function and Training\n\ndef gamma_loss(y_true, y_pred):\n    return -y_pred.log_prob(y_true)\n\n# Then use the loss function when compiling the model\ngamma_bnn.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n                loss=gamma_loss)\n\nhist = gamma_bnn.fit(X_train, y_train,\n    epochs=300,\n    callbacks=[EarlyStopping(patience=30)],\n    verbose=0,\n    batch_size=64,\n    validation_split=0.2)"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-output-sampling",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-output-sampling",
    "title": "Uncertainty Quantification",
    "section": "Code: Output Sampling",
    "text": "Code: Output Sampling\nIn practice, we can further increase the number of samples.\n\n# Define the number of samples\nn_samples = 1000\n\n# Store all predictions in a list\nalphas = []; betas = []\n\n# Run the model `n_samples` times and store the predicted parameters\nfor i in range(n_samples):\n  # Predict the distributions\n  predicted_distributions = gamma_bnn(X_test[9:10].values)\n  # Get the parameters\n  alphas.append(predicted_distributions.concentration.numpy())\n  betas.append(predicted_distributions.rate.numpy())"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#sampled-density-functions",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#sampled-density-functions",
    "title": "Uncertainty Quantification",
    "section": "Sampled Density Functions",
    "text": "Sampled Density Functions\n\nWe plot some of the sampled posterior density functions. The variability of the sampled density functions is one critical consideration for epistemic uncertainty."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#uncertainty-quantification-uq",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#uncertainty-quantification-uq",
    "title": "Uncertainty Quantification",
    "section": "Uncertainty Quantification (UQ)",
    "text": "Uncertainty Quantification (UQ)\nWe analyse the total variance formula: \n\\begin{align*}\n    \\mathbb{V}[Y]&=\\mathbb{E}[\\mathbb{V}[Y|\\boldsymbol{x}]] + \\mathbb{V}[\\mathbb{E}[Y|\\boldsymbol{x}]]\\\\\n    &\\approx \\underbrace{\\frac{1}{M}\\sum_{m=1}^{M}\\mathbb{V}\\big[Y|\\boldsymbol{x},\\boldsymbol{w}^{(m)}\\big]}_{\\text{Aleatoric}} \\\\\n    &\\quad \\quad +\\underbrace{\\frac{1}{M}\\sum_{m=1}^{M}\\bigg(\\mathbb{E}\\big[Y|\\boldsymbol{x},\\boldsymbol{w}^{(m)}\\big]-\\frac{1}{M}\\sum_{m=1}^{M}\\mathbb{E}\\big[Y|\\boldsymbol{x},\\boldsymbol{w}^{(m)}\\big]\\bigg)^2}_{\\text{Epistemic}},\n\\end{align*}\n where M is the number of posterior samples generated."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-applying-uq",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-applying-uq",
    "title": "Uncertainty Quantification",
    "section": "Code: Applying UQ",
    "text": "Code: Applying UQ\n\n# Convert to numpy array for easier manipulation\nalphas = np.array(alphas); betas = np.array(betas)\n\n# Aleatoric uncertainty: Mean of the variances of the predicted Gamma distributions\naleatoric_uncertainty = np.mean(alphas/betas**2)\n\n# Epistemic uncertainty: Variance of the means of the model's predictions\nepistemic_uncertainty = np.var(alphas/betas)\n\nprint(f\"Aleatoric uncertainty: {aleatoric_uncertainty}\")\nprint(f\"Epistemic uncertainty: {epistemic_uncertainty}\")\n\nAleatoric uncertainty: 12227640.0\nEpistemic uncertainty: 1425122.0"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#deep-ensembles",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#deep-ensembles",
    "title": "Uncertainty Quantification",
    "section": "Deep Ensembles",
    "text": "Deep Ensembles\nLakshminarayanan et al. (2017) proposed deep ensembles as another prominent approach to obtaining epistemic uncertainty. Such a technique can be an alternative to BNNs. It’s simple to implement and requires very little hyperparameter tuning.\nWe summarise the deep ensemble approach for uncertainty quantification as follows:\n\nTrain D neural networks with different random weights initialisations independently in parallel. The trained weights are \\boldsymbol{w}^{(1)}, ..., \\boldsymbol{w}^{(D)} ."
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-deep-ensembles-i",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-deep-ensembles-i",
    "title": "Uncertainty Quantification",
    "section": "Code: Deep Ensembles I",
    "text": "Code: Deep Ensembles I\n\nK = 1 # number of mixtures\n\ndef MDN_DE(num_ensembles):\n  models = []\n  for k in range(num_ensembles):\n    #Ensure reproducibility\n    random.seed(k); tf.random.set_seed(k)\n    inputs = Input(shape=X_train.shape[1:])\n\n    #Two hidden layers \n    x = Dense(64, activation='relu')(inputs)\n    x = Dense(64, activation='relu')(x)\n\n    pis = Dense(1, activation='softmax')(x) #mixing weights\n    alphas = Dense(1, activation='softplus')(x) #shape parameters\n    betas = Dense(1, activation='softplus')(x) #scale parameters\n\n    #Concatenate by columns: `y_pred` will now have 6 columns\n    gamma_mdn_new = Model(inputs, Concatenate(axis=1)([pis, alphas, betas]))\n    gamma_mdn_new.compile(optimizer=\"adam\",\n                          loss=gamma_mixture_NLL)\n    gamma_mdn_new.fit(X_train, y_train,\n        epochs=300, callbacks=[EarlyStopping(patience=30)],  \n        verbose=0, batch_size=64, validation_split=0.2)\n    models.append(gamma_mdn_new)\n\n  return(models)"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-deep-ensembles-ii",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-deep-ensembles-ii",
    "title": "Uncertainty Quantification",
    "section": "Code: Deep Ensembles II",
    "text": "Code: Deep Ensembles II\n\nFor a new instance \\boldsymbol{x}, obtain \\Big\\{\\big(\\mathbb{E}\\big[Y|\\boldsymbol{x},\\boldsymbol{w}^{(d)}\\big],\\mathbb{V}\\big[Y|\\boldsymbol{x},\\boldsymbol{w}^{(d)}\\big]\\big)\\Big\\}_{d=1}^{D},\n\n\nD = 10 # number of MDNs\nMDN_models = MDN_DE(D)\n\n# Store all predictions in a list\nweights = [0]*D; alphas = [0]*D; betas = [0]*D\n\n#Store the paramters\nfor i in range(D):\n  weights[i], alphas[i], betas[i] = MDN_models[i].predict(X_test[9:10], verbose=0)[0]\n\n#Predict the means and variances\nmeans = np.array(alphas)/np.array(betas)\nvariances = np.array(alphas)/np.array(betas)**2"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-deep-ensembles-iii",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#code-deep-ensembles-iii",
    "title": "Uncertainty Quantification",
    "section": "Code: Deep Ensembles III",
    "text": "Code: Deep Ensembles III\n\nApply the variance decomposition \n    \\mathbb{V}[Y]=\\mathbb{E}[\\mathbb{V}[Y|\\boldsymbol{x}]] + \\mathbb{V}[\\mathbb{E}[Y|\\boldsymbol{x}]]\n\n\n\naleatoric_uncertainty = np.mean(variances)\nepistemic_uncertainty = np.var(means)\n\nprint(f\"Aleatoric uncertainty: {aleatoric_uncertainty}\")\nprint(f\"Epistemic uncertainty: {epistemic_uncertainty}\")\n\nAleatoric uncertainty: 38137052.0\nEpistemic uncertainty: 2651202.5"
  },
  {
    "objectID": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#glossary",
    "href": "Lecture-6-Uncertainty-Quantification/uncertainty-quantification.slides.html#glossary",
    "title": "Uncertainty Quantification",
    "section": "Glossary",
    "text": "Glossary\n\n\n\naleatoric and epistemic uncertainty\nBayesian neural network\ndeep ensembles\ndropout\nCANN\nGLM\n\n\n\nMDN\nmixture distribution\nposterior sampling\nproper scoring rule\nuncertainty quantification\nvariational approximation"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html",
    "href": "Lecture-4-Computer-Vision/computer-vision.html",
    "title": "Computer Vision",
    "section": "",
    "text": "Computer vision is a field of Artificial Intelligence (AI) that focuses on extracting meaningful information from visual data (images and videos). One of the primary goals of computer vision is to correctly identify and classify visual data. Convolution Neural Networks (CNNs) are the most commonly used neural network architectures for computer vision related tasks.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#load-packages",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#load-packages",
    "title": "Computer Vision",
    "section": "Load packages",
    "text": "Load packages\n\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import plot_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.0\nIPython version      : 8.20.0\n\nsklearn   : 1.4.0\nkeras     : 3.0.4\ntorch     : 2.2.0\ntensorflow: 2.15.0.post1",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#shapes-of-data",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#shapes-of-data",
    "title": "Computer Vision",
    "section": "Shapes of data",
    "text": "Shapes of data\nA special attention to shapes of data are important in CNN architectures, because CNNs have special types of layers (e.g. convolution and pooling) which require explicit specifications of array dimensions.\n\n\n\nIllustration of tensors of different rank.\n\n\n\nSource: Paras Patidar (2019), Tensors — Representation of Data In Neural Networks, Medium article.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#shapes-of-photos",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#shapes-of-photos",
    "title": "Computer Vision",
    "section": "Shapes of photos",
    "text": "Shapes of photos\n\n\n\nA photo is a rank 3 tensor.\n\n\n\nSource: Kim et al (2021), Data Hiding Method for Color AMBTC Compressed Images Using Color Difference, Applied Sciences.\n\nSince the position of a pixel(one small sqaure) in a photo can be represented using 3 positional values, we call it a rank 3 tensor.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#how-the-computer-sees-them",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#how-the-computer-sees-them",
    "title": "Computer Vision",
    "section": "How the computer sees them",
    "text": "How the computer sees them\n\nfrom matplotlib.image import imread\nimg1 = imread('pu.gif'); img2 = imread('pl.gif')\nimg3 = imread('pr.gif'); img4 = imread('pg.bmp')\nf\"Shapes are: {img1.shape}, {img2.shape}, {img3.shape}, {img4.shape}.\"\n\n\n\n'Shapes are: (16, 16, 3), (16, 16, 3), (16, 16, 3), (16, 16, 3).'\n\n\n\n\n\nimg1\n\narray([[[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]]], dtype=uint8)\n\n\n\n\nimg2\n\narray([[[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]]], dtype=uint8)\n\n\n\n\nimg3\n\narray([[[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]]], dtype=uint8)\n\n\n\n\nimg4\n\narray([[[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [ 51,   0, 255],\n        [ 51,   0, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [ 51,   0, 255],\n        [ 51,   0, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [ 51,   0, 255],\n        [ 51,   0, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [ 51,   0, 255],\n        [ 51,   0, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]]], dtype=uint8)\n\n\n\n\nThe above code reads 4 images and then shows how computers read those images. Each image is read by the computer as a rank 3 tensor. Each image is of (16,16,3) dimensions.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#how-we-see-them",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#how-we-see-them",
    "title": "Computer Vision",
    "section": "How we see them",
    "text": "How we see them\n\nfrom matplotlib.pyplot import imshow\n\n\n\n\nimshow(img1);\n\n\n\n\n\n\n\n\n\n\nimshow(img2);\n\n\n\n\n\n\n\n\n\n\nimshow(img3);\n\n\n\n\n\n\n\n\n\n\nimshow(img4);",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#why-is-255-special",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#why-is-255-special",
    "title": "Computer Vision",
    "section": "Why is 255 special?",
    "text": "Why is 255 special?\nEach pixel’s colour intensity is stored in one byte.\nOne byte is 8 bits, so in binary that is 00000000 to 11111111.\nThe largest unsigned number this can be is 2^8-1 = 255.\n\nnp.array([0, 1, 255, 256]).astype(np.uint8)\n\narray([  0,   1, 255,   0], dtype=uint8)\n\n\nIf you had signed numbers, this would go from -128 to 127.\n\nnp.array([-128, 1, 127, 128]).astype(np.int8)\n\narray([-128,    1,  127, -128], dtype=int8)\n\n\nAlternatively, hexidecimal numbers are used. E.g. 10100001 is split into 1010 0001, and 1010=A, 0001=1, so combined it is 0xA1.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#image-editing-with-kernels",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#image-editing-with-kernels",
    "title": "Computer Vision",
    "section": "Image editing with kernels",
    "text": "Image editing with kernels\nTake a look at https://setosa.io/ev/image-kernels/.\n\n\n\nAn example of an image kernel in action.\n\n\n\nSource: Stanford’s deep learning tutorial via Stack Exchange.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#convolution-not-complicated",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#convolution-not-complicated",
    "title": "Computer Vision",
    "section": "‘Convolution’ not ‘complicated’",
    "text": "‘Convolution’ not ‘complicated’\nSay X_1, X_2 \\sim f_X are i.i.d., and we look at S = X_1 + X_2.\nThe density for S is then\n\nf_S(s) = \\int_{x_1=-\\infty}^{\\infty} f_X(x_1) \\, f_X(s-x_1) \\,\\mathrm{d}s .\n\nThis is the convolution operation, f_S = f_X \\star f_X.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#images-are-rank-3-tensors",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#images-are-rank-3-tensors",
    "title": "Computer Vision",
    "section": "Images are rank 3 tensors",
    "text": "Images are rank 3 tensors\nHeight, width, and number of channels.\nAn image can be represented using a rank 3 tensor, since it has 3 dimensions; height, width, and number of channels. The number of channels is also known as the ‘depth’. The left hand side of the picture shown below is tensor with height =5, width =5 and depth =3.\n\n\n\nExamples of rank 3 tensors.\n\n\nGrayscale image has 1 channel. RGB image has 3 channels.\nEach colour can be represented as a combination of three primary colours; red, green and blue.\nExample: Yellow = Red + Green.\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#example-detecting-yellow",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#example-detecting-yellow",
    "title": "Computer Vision",
    "section": "Example: Detecting yellow",
    "text": "Example: Detecting yellow\nSuppose we wish to detect if a picture has yellow colour in it. One option would be to apply a neuron over each pixel and see if it detects the colour yellow. We know that each pixel is represented by 3 numerical values that correspond to red, green and blue. Higher numeric values for red and green indicate higher chances of detecting yellow. Higher values for blue indicate lower chances of detecting yellow. Utilising this information, we can assign RGB weights to be 1, 1, -1 respectively.\nNext, a standard multiplication between numeric values and weights is carried out, and the weighted sum is passed through the neuron.\n\n\n\n\n\nApplying a neuron to an image pixel.\n\n\n\n\nApply a neuron to each pixel in the image.\n\nIf red/green \\nearrow or blue \\searrow then yellowness \\nearrow.\n\nSet RGB weights to 1, 1, -1.\n\n\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#example-detecting-yellow-ii",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#example-detecting-yellow-ii",
    "title": "Computer Vision",
    "section": "Example: Detecting yellow II",
    "text": "Example: Detecting yellow II\n\n\n\nScan the 3-channel input (colour image) with the neuron to produce a 1-channel output (grayscale image).\n\n\nThe output is produced by sweeping the neuron over the input. This is called convolution.\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#example-detecting-yellow-iii",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#example-detecting-yellow-iii",
    "title": "Computer Vision",
    "section": "Example: Detecting yellow III",
    "text": "Example: Detecting yellow III\nThe following picture demonstrates how yellow-coloured areas (in the colour picture) are transformed into a white colour (in the greyscale picture). This is a result of the way we assigned the weights. Since we assigned +1 weights to red and green, and -1 to blue, it ended up resulting in large positive values (for the weighted sum) for the pixels in the yellow-coloured areas. Large positive values in the greyscale correspond to white colour. Therefore, the areas which were yellow in the colour picture converted to white in the greyscale. In practice, we do not manually assign weights, instead, we let the neural network decide the optimal weights during training.\n\n\n\nThe more yellow the pixel in the colour image (left), the more white it is in the grayscale image.\n\n\nThe neuron or its weights is called a filter. We convolve the image with a filter, i.e. a convolutional filter.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#terminology",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#terminology",
    "title": "Computer Vision",
    "section": "Terminology",
    "text": "Terminology\n\nThe same neuron is used to sweep over the image, so we can store the weights in some shared memory and process the pixels in parallel. We say that the neurons are weight sharing.\nIn the previous example, the neuron only takes one pixel as input. Usually a larger filter containing a block of weights is used to process not only a pixel but also its neighboring pixels all at once.\nThe weights are called the filter kernels.\nThe cluster of pixels that forms the input of a filter is called its footprint.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#spatial-filter",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#spatial-filter",
    "title": "Computer Vision",
    "section": "Spatial filter",
    "text": "Spatial filter\n\n\n\nExample 3x3 filter\n\n\nWhen a filter’s footprint is &gt; 1 pixel, it is a spatial filter.\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16.\n\nThe above spatial filter is a 3x3 filter. Hence, there are 9 weights to learn.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#multidimensional-convolution",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#multidimensional-convolution",
    "title": "Computer Vision",
    "section": "Multidimensional convolution",
    "text": "Multidimensional convolution\nIn a multidimensional filter, the number of channels of the input must be equal to the number of channels in the filter (depths must be the same).\nNeed \\# \\text{ Channels in Input} = \\# \\text{ Channels in Filter}.\n\n\n\nExample: a 3x3 filter with 3 channels, containing 27 weights.\n\n\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#example-3x3-filter-over-rgb-input",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#example-3x3-filter-over-rgb-input",
    "title": "Computer Vision",
    "section": "Example: 3x3 filter over RGB input",
    "text": "Example: 3x3 filter over RGB input\n\n\n\nEach channel is multipled separately & then added together.\n\n\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16.\n\nThe above figure shows how we pick a 3x3x3 block from the image, and then apply the 3x3 filter. The multiplication is carried out channel-wise, i.e. we select the first channel of the filter and the first channel of the image and carry out the element wise multiplation. Once the elementwise multiplications for the three pairs of channels are completed, we sum them all, and pass through the neuron.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#input-output-relationship",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#input-output-relationship",
    "title": "Computer Vision",
    "section": "Input-output relationship",
    "text": "Input-output relationship\n\n\n\nMatching the original image footprints against the output location.\n\n\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16.\n\nThe above figure shows how 9 inputs transform in to one output. As a result, dimensions of the output matrix is smaller than the dimensions of the input matrix. There are some options we can use if we wish to keep the size of input and output matrices same.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#padding",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#padding",
    "title": "Computer Vision",
    "section": "Padding",
    "text": "Padding\n\n\n\nWhat happens when filters go off the edge of the input?\n\n\n\nHow to avoid the filter’s receptive field falling off the side of the input.\nIf we only scan the filter over places of the input where the filter can fit perfectly, it will lead to loss of information, especially after many filters.\n\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#padding-1",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#padding-1",
    "title": "Computer Vision",
    "section": "Padding",
    "text": "Padding\nAdd a border of extra elements around the input, called padding. Normally we place zeros in all the new elements, called zero padding.\n\n\n\nPadded values can be added to the outside of the input.\n\n\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#convolution-layer",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#convolution-layer",
    "title": "Computer Vision",
    "section": "Convolution layer",
    "text": "Convolution layer\n\nMultiple filters are bundled together in one layer.\nThe filters are applied simultaneously and independently to the input.\nFilters can have different footprints, but in practice we almost always use the same footprint for every filter in a convolution layer.\nNumber of channels in the output will be the same as the number of filters.\n\nThe motivation behind applying filters simultaneously and independently is to let the filters learn different patterns in the input-output relationship. The idea is quite similar to using many neurons in one Dense layer (in a Dense layer, we would use multiple neurons so that different neurons can capture different patterns in the input-output relationship).",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#example",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#example",
    "title": "Computer Vision",
    "section": "Example",
    "text": "Example\n\n\nIn the image:\n\n6-channel input tensor\ninput pixels\nfour 3x3 filters\nfour output tensors\nfinal output tensor.\n\n\n\n\n\nExample network highlighting that the number of output channels equals the number of filters.\n\n\n\n\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16.\n\nThe above picture shows how we take in an image with 6 channels, select a 3x3 block (in pink colour), apply 4 different filters of same dimensions (in pink, green, blue and yellow), retrieve the output with 1 channel (1 output for each filter) and finally stack them together to create 1 output tensor. Note that the number of channels in the output tensor is 4, which is equal to the number of spatial filters used.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#x1-convolution",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#x1-convolution",
    "title": "Computer Vision",
    "section": "1x1 convolution",
    "text": "1x1 convolution\n\nFeature reduction: Reduce the number of channels in the input tensor (removing correlated features) by using fewer filters than the number of channels in the input. This is because the number of channels in the output is always the same as number of filters.\n1x1 convolution: Convolution using 1x1 filters.\nWhen the channels are correlated, 1x1 convolution is very effective at reducing channels without loss of information.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#example-of-1x1-convolution",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#example-of-1x1-convolution",
    "title": "Computer Vision",
    "section": "Example of 1x1 convolution",
    "text": "Example of 1x1 convolution\n\n\n\nExample network with 1x1 convolution.\n\n\n\nInput tensor contains 300 channels.\nUse 175 1x1 filters in the convolution layer (300 weights each).\nEach filter produces a 1-channel output.\nFinal output tensor has 175 channels.\n\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#striding",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#striding",
    "title": "Computer Vision",
    "section": "Striding",
    "text": "Striding\nStriding options allows to modify the movement of the filter across the image. Instead moving one step at a time (either horizontally or vertically), we can increase the number of steps using the striding option.\nWe don’t have to go one pixel across/down at a time.\n\n\n\nExample: Use a stride of three horizontally and two vertically.\n\n\nDimension of output will be smaller than input.\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#choosing-strides",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#choosing-strides",
    "title": "Computer Vision",
    "section": "Choosing strides",
    "text": "Choosing strides\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen a filter scans the input step by step, it processes the same input elements multiple times. Even with larger strides, this can still happen (left image).\nIf we want to save time, we can choose strides that prevents input elements from being used more than once. Example (right image): 3x3 filter, stride 3 in both directions.\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#specifying-a-convolutional-layer",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#specifying-a-convolutional-layer",
    "title": "Computer Vision",
    "section": "Specifying a convolutional layer",
    "text": "Specifying a convolutional layer\nNeed to choose:\n\nnumber of filters,\ntheir footprints (e.g. 3x3, 5x5, etc.),\nactivation functions,\npadding & striding (optional).\n\nAll the filter weights are learned during training.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#definition-of-cnn",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#definition-of-cnn",
    "title": "Computer Vision",
    "section": "Definition of CNN",
    "text": "Definition of CNN\n\n\n \nA neural network that uses convolution layers is called a convolutional neural network.\n\n\n\n\n\nSource: Randall Munroe (2019), xkcd #2173: Trained a Neural Net.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#architecture",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#architecture",
    "title": "Computer Vision",
    "section": "Architecture",
    "text": "Architecture\n\n\n\nTypical CNN architecture.\n\n\n\nSource: Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Figure 14-11.\n\nA standard CNN architecture has the following components: an input layer, a sequence of feature extraction layers (which combine convolution and pooling operations sequentially), a sequence of classification layers (which include flattening and fully connected layers) and a final output layer. Convolution layers are used to extract meaningful patterns from the input using spatial filters. Pooling layers are used to reduce the spatial dimensions of the feature maps generated from convolutional layers. The purpose of the feature extraction layers is to learn complex but meaningful, high levels patterns in data. The aim of classification layers is to receive the learned patterns and make decisions more closely related to the classification task at hand.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#architecture-2",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#architecture-2",
    "title": "Computer Vision",
    "section": "Architecture #2",
    "text": "Architecture #2\n\n\nSource: MathWorks, Introducing Deep Learning with MATLAB, Ebook.\n\nOn a high level, the idea would be to keep on increasing the number of channels (depth) and decrease the dimensions of the feature map. We can see how the depth increases, and spatial dimensions reduce from first convolution layer to the second pooling layer.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#pooling",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#pooling",
    "title": "Computer Vision",
    "section": "Pooling",
    "text": "Pooling\nPooling, or downsampling, is a technique to blur a tensor.\n\n\n\nIllustration of pool operations.\n\n\n(a): Input tensor (b): Subdivide input tensor into 2x2 blocks (c): Average pooling (d): Max pooling (e): Icon for a pooling layer\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#pooling-for-multiple-channels",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#pooling-for-multiple-channels",
    "title": "Computer Vision",
    "section": "Pooling for multiple channels",
    "text": "Pooling for multiple channels\n\n\n\nPooling a multichannel input.\n\n\n\nInput tensor: 6x6 with 1 channel, zero padding.\nConvolution layer: Three 3x3 filters.\nConvolution layer output: 6x6 with 3 channels.\nPooling layer: apply max pooling to each channel.\nPooling layer output: 3x3, 3 channels.\n\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#whywhy-not-use-pooling",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#whywhy-not-use-pooling",
    "title": "Computer Vision",
    "section": "Why/why not use pooling?",
    "text": "Why/why not use pooling?\nWhy? Pooling reduces the size of tensors, therefore reduces memory usage and execution time (recall that 1x1 convolution reduces the number of channels in a tensor).\nWhy not?\n\n\n\nGeoffrey Hinton\n\n\n\nSource: Hinton, Reddit AMA.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#what-do-the-cnn-layers-learn",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#what-do-the-cnn-layers-learn",
    "title": "Computer Vision",
    "section": "What do the CNN layers learn?",
    "text": "What do the CNN layers learn?\n\n\nSource: Distill article, Feature Visualization.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#mnist-dataset",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#mnist-dataset",
    "title": "Computer Vision",
    "section": "MNIST Dataset",
    "text": "MNIST Dataset\n\n\n\nThe MNIST dataset.\n\n\n\nSource: Wikipedia, MNIST database.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#mandarin-characters-dataset",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#mandarin-characters-dataset",
    "title": "Computer Vision",
    "section": "Mandarin Characters Dataset",
    "text": "Mandarin Characters Dataset\n57 poorly written Mandarin characters (57 \\times 7 = 399).\n\n\n\nDataset of notes when learning/practising basic characters.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#downloading-the-dataset",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#downloading-the-dataset",
    "title": "Computer Vision",
    "section": "Downloading the dataset",
    "text": "Downloading the dataset\nThe data is zipped (6.9 MB) and stored on my GitHub homepage.\n\n# Download the dataset if it hasn't already been downloaded.\nfrom pathlib import Path\nif not Path(\"mandarin\").exists():\n  print(\"Downloading dataset...\")\n  !wget https://laub.au/data/mandarin.zip\n  !unzip mandarin.zip\nelse:\n  print(\"Already downloaded.\")\n\nAlready downloaded.\n\n\n\n\n\n\n\n\nTip\n\n\n\nRemember, the Jupyter notebook associated with your final report should either download your dataset when it is run, or you should supply the data separately.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#directory-structure",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#directory-structure",
    "title": "Computer Vision",
    "section": "Directory structure",
    "text": "Directory structure\n\n\nInspect directory structure\n\n!pip install directory_tree\n\n\nfrom directory_tree import display_tree\ndisplay_tree(\"mandarin\")\n\nmandarin/\n├── bai/\n│   ├── bai-1.png\n│   ├── bai-2.png\n│   ├── bai-3.png\n│   ├── bai-4.png\n│   ├── bai-5.png\n│   ├── bai-6.png\n│   └── bai-7.png\n├── ben/\n│   ├── ben-1.png\n│   ├── ben-2.png\n│   ├── ben-3.png\n│   ├── ben-4.png\n│   ├── ben-5.png\n│   ├── ben-6.png\n│   └── ben-7.png\n├── chong/\n│   ├── chong-1.png\n│   ├── chong-2.png\n│   ├── chong-3.png\n│   ├── chong-4.png\n│   ├── chong-5.png\n│   ├── chong-6.png\n│   └── chong-7.png\n├── chu/\n│   ├── chu-1.png\n│   ├── chu-2.png\n│   ├── chu-3.png\n│   ├── chu-4.png\n│   ├── chu-5.png\n│   ├── chu-6.png\n│   └── chu-7.png\n├── chuan/\n│   ├── chuan-1.png\n│   ├── chuan-2.png\n│   ├── chuan-3.png\n│   ├── chuan-4.png\n│   ├── chuan-5.png\n│   ├── chuan-6.png\n│   └── chuan-7.png\n├── cong/\n│   ├── cong-1.png\n│   ├── cong-2.png\n│   ├── cong-3.png\n│   ├── cong-4.png\n│   ├── cong-5.png\n│   ├── cong-6.png\n│   └── cong-7.png\n├── da/\n│   ├── da-1.png\n│   ├── da-2.png\n│   ├── da-3.png\n│   ├── da-4.png\n│   ├── da-5.png\n│   ├── da-6.png\n│   └── da-7.png\n├── dan/\n│   ├── dan-1.png\n│   ├── dan-2.png\n│   ├── dan-3.png\n│   ├── dan-4.png\n│   ├── dan-5.png\n│   ├── dan-6.png\n│   └── dan-7.png\n├── dong/\n│   ├── dong-1.png\n│   ├── dong-2.png\n│   ├── dong-3.png\n│   ├── dong-4.png\n│   ├── dong-5.png\n│   ├── dong-6.png\n│   └── dong-7.png\n├── fei/\n│   ├── fei-1.png\n│   ├── fei-2.png\n│   ├── fei-3.png\n│   ├── fei-4.png\n│   ├── fei-5.png\n│   ├── fei-6.png\n│   └── fei-7.png\n├── fu/\n│   ├── fu-1.png\n│   ├── fu-2.png\n│   ├── fu-3.png\n│   ├── fu-4.png\n│   ├── fu-5.png\n│   ├── fu-6.png\n│   └── fu-7.png\n├── fu2/\n│   ├── fu2-1.png\n│   ├── fu2-2.png\n│   ├── fu2-3.png\n│   ├── fu2-4.png\n│   ├── fu2-5.png\n│   ├── fu2-6.png\n│   └── fu2-7.png\n├── gao/\n│   ├── gao-1.png\n│   ├── gao-2.png\n│   ├── gao-3.png\n│   ├── gao-4.png\n│   ├── gao-5.png\n│   ├── gao-6.png\n│   └── gao-7.png\n├── gong/\n│   ├── gong-1.png\n│   ├── gong-2.png\n│   ├── gong-3.png\n│   ├── gong-4.png\n│   ├── gong-5.png\n│   ├── gong-6.png\n│   └── gong-7.png\n├── guo/\n│   ├── guo-1.png\n│   ├── guo-2.png\n│   ├── guo-3.png\n│   ├── guo-4.png\n│   ├── guo-5.png\n│   ├── guo-6.png\n│   └── guo-7.png\n├── hu/\n│   ├── hu-1.png\n│   ├── hu-2.png\n│   ├── hu-3.png\n│   ├── hu-4.png\n│   ├── hu-5.png\n│   ├── hu-6.png\n│   └── hu-7.png\n├── huo/\n│   ├── huo-1.png\n│   ├── huo-2.png\n│   ├── huo-3.png\n│   ├── huo-4.png\n│   ├── huo-5.png\n│   ├── huo-6.png\n│   └── huo-7.png\n├── kou/\n│   ├── kou-1.png\n│   ├── kou-2.png\n│   ├── kou-3.png\n│   ├── kou-4.png\n│   ├── kou-5.png\n│   ├── kou-6.png\n│   └── kou-7.png\n├── ku/\n│   ├── ku-1.png\n│   ├── ku-2.png\n│   ├── ku-3.png\n│   ├── ku-4.png\n│   ├── ku-5.png\n│   ├── ku-6.png\n│   └── ku-7.png\n├── lin/\n│   ├── lin-1.png\n│   ├── lin-2.png\n│   ├── lin-3.png\n│   ├── lin-4.png\n│   ├── lin-5.png\n│   ├── lin-6.png\n│   └── lin-7.png\n├── ma/\n│   ├── ma-1.png\n│   ├── ma-2.png\n│   ├── ma-3.png\n│   ├── ma-4.png\n│   ├── ma-5.png\n│   ├── ma-6.png\n│   └── ma-7.png\n├── ma2/\n│   ├── ma2-1.png\n│   ├── ma2-2.png\n│   ├── ma2-3.png\n│   ├── ma2-4.png\n│   ├── ma2-5.png\n│   ├── ma2-6.png\n│   └── ma2-7.png\n├── ma3/\n│   ├── ma3-1.png\n│   ├── ma3-2.png\n│   ├── ma3-3.png\n│   ├── ma3-4.png\n│   ├── ma3-5.png\n│   ├── ma3-6.png\n│   └── ma3-7.png\n├── mei/\n│   ├── mei-1.png\n│   ├── mei-2.png\n│   ├── mei-3.png\n│   ├── mei-4.png\n│   ├── mei-5.png\n│   ├── mei-6.png\n│   └── mei-7.png\n├── men/\n│   ├── men-1.png\n│   ├── men-2.png\n│   ├── men-3.png\n│   ├── men-4.png\n│   ├── men-5.png\n│   ├── men-6.png\n│   └── men-7.png\n├── ming/\n│   ├── ming-1.png\n│   ├── ming-2.png\n│   ├── ming-3.png\n│   ├── ming-4.png\n│   ├── ming-5.png\n│   ├── ming-6.png\n│   └── ming-7.png\n├── mu/\n│   ├── mu-1.png\n│   ├── mu-2.png\n│   ├── mu-3.png\n│   ├── mu-4.png\n│   ├── mu-5.png\n│   ├── mu-6.png\n│   └── mu-7.png\n├── nan/\n│   ├── nan-1.png\n│   ├── nan-2.png\n│   ├── nan-3.png\n│   ├── nan-4.png\n│   ├── nan-5.png\n│   ├── nan-6.png\n│   └── nan-7.png\n├── niao/\n│   ├── niao-1.png\n│   ├── niao-2.png\n│   ├── niao-3.png\n│   ├── niao-4.png\n│   ├── niao-5.png\n│   ├── niao-6.png\n│   └── niao-7.png\n├── niu/\n│   ├── niu-1.png\n│   ├── niu-2.png\n│   ├── niu-3.png\n│   ├── niu-4.png\n│   ├── niu-5.png\n│   ├── niu-6.png\n│   └── niu-7.png\n├── nu/\n│   ├── nu-1.png\n│   ├── nu-2.png\n│   ├── nu-3.png\n│   ├── nu-4.png\n│   ├── nu-5.png\n│   ├── nu-6.png\n│   └── nu-7.png\n├── nuan/\n│   ├── nuan-1.png\n│   ├── nuan-2.png\n│   ├── nuan-3.png\n│   ├── nuan-4.png\n│   ├── nuan-5.png\n│   ├── nuan-6.png\n│   └── nuan-7.png\n├── peng/\n│   ├── peng-1.png\n│   ├── peng-2.png\n│   ├── peng-3.png\n│   ├── peng-4.png\n│   ├── peng-5.png\n│   ├── peng-6.png\n│   └── peng-7.png\n├── quan/\n│   ├── quan-1.png\n│   ├── quan-2.png\n│   ├── quan-3.png\n│   ├── quan-4.png\n│   ├── quan-5.png\n│   ├── quan-6.png\n│   └── quan-7.png\n├── ren/\n│   ├── ren-1.png\n│   ├── ren-2.png\n│   ├── ren-3.png\n│   ├── ren-4.png\n│   ├── ren-5.png\n│   ├── ren-6.png\n│   └── ren-7.png\n├── ri/\n│   ├── ri-1.png\n│   ├── ri-2.png\n│   ├── ri-3.png\n│   ├── ri-4.png\n│   ├── ri-5.png\n│   ├── ri-6.png\n│   └── ri-7.png\n├── rou/\n│   ├── rou-1.png\n│   ├── rou-2.png\n│   ├── rou-3.png\n│   ├── rou-4.png\n│   ├── rou-5.png\n│   ├── rou-6.png\n│   └── rou-7.png\n├── sen/\n│   ├── sen-1.png\n│   ├── sen-2.png\n│   ├── sen-3.png\n│   ├── sen-4.png\n│   ├── sen-5.png\n│   ├── sen-6.png\n│   └── sen-7.png\n├── shan/\n│   ├── shan-1.png\n│   ├── shan-2.png\n│   ├── shan-3.png\n│   ├── shan-4.png\n│   ├── shan-5.png\n│   ├── shan-6.png\n│   └── shan-7.png\n├── shan2/\n│   ├── shan2-1.png\n│   ├── shan2-2.png\n│   ├── shan2-3.png\n│   ├── shan2-4.png\n│   ├── shan2-5.png\n│   ├── shan2-6.png\n│   └── shan2-7.png\n├── shui/\n│   ├── shui-1.png\n│   ├── shui-2.png\n│   ├── shui-3.png\n│   ├── shui-4.png\n│   ├── shui-5.png\n│   ├── shui-6.png\n│   └── shui-7.png\n├── tai/\n│   ├── tai-1.png\n│   ├── tai-2.png\n│   ├── tai-3.png\n│   ├── tai-4.png\n│   ├── tai-5.png\n│   ├── tai-6.png\n│   └── tai-7.png\n├── tian/\n│   ├── tian-1.png\n│   ├── tian-2.png\n│   ├── tian-3.png\n│   ├── tian-4.png\n│   ├── tian-5.png\n│   ├── tian-6.png\n│   └── tian-7.png\n├── wang/\n│   ├── wang-1.png\n│   ├── wang-2.png\n│   ├── wang-3.png\n│   ├── wang-4.png\n│   ├── wang-5.png\n│   ├── wang-6.png\n│   └── wang-7.png\n├── wen/\n│   ├── wen-1.png\n│   ├── wen-2.png\n│   ├── wen-3.png\n│   ├── wen-4.png\n│   ├── wen-5.png\n│   ├── wen-6.png\n│   └── wen-7.png\n├── xian/\n│   ├── xian-1.png\n│   ├── xian-2.png\n│   ├── xian-3.png\n│   ├── xian-4.png\n│   ├── xian-5.png\n│   ├── xian-6.png\n│   └── xian-7.png\n├── xuan/\n│   ├── xuan-1.png\n│   ├── xuan-2.png\n│   ├── xuan-3.png\n│   ├── xuan-4.png\n│   ├── xuan-5.png\n│   ├── xuan-6.png\n│   └── xuan-7.png\n├── yan/\n│   ├── yan-1.png\n│   ├── yan-2.png\n│   ├── yan-3.png\n│   ├── yan-4.png\n│   ├── yan-5.png\n│   ├── yan-6.png\n│   └── yan-7.png\n├── yang/\n│   ├── yang-1.png\n│   ├── yang-2.png\n│   ├── yang-3.png\n│   ├── yang-4.png\n│   ├── yang-5.png\n│   ├── yang-6.png\n│   └── yang-7.png\n├── yin/\n│   ├── yin-1.png\n│   ├── yin-2.png\n│   ├── yin-3.png\n│   ├── yin-4.png\n│   ├── yin-5.png\n│   ├── yin-6.png\n│   └── yin-7.png\n├── yu/\n│   ├── yu-1.png\n│   ├── yu-2.png\n│   ├── yu-3.png\n│   ├── yu-4.png\n│   ├── yu-5.png\n│   ├── yu-6.png\n│   └── yu-7.png\n├── yu2/\n│   ├── yu2-1.png\n│   ├── yu2-2.png\n│   ├── yu2-3.png\n│   ├── yu2-4.png\n│   ├── yu2-5.png\n│   ├── yu2-6.png\n│   └── yu2-7.png\n├── yue/\n│   ├── yue-1.png\n│   ├── yue-2.png\n│   ├── yue-3.png\n│   ├── yue-4.png\n│   ├── yue-5.png\n│   ├── yue-6.png\n│   └── yue-7.png\n├── zhong/\n│   ├── zhong-1.png\n│   ├── zhong-2.png\n│   ├── zhong-3.png\n│   ├── zhong-4.png\n│   ├── zhong-5.png\n│   ├── zhong-6.png\n│   └── zhong-7.png\n├── zhu/\n│   ├── zhu-1.png\n│   ├── zhu-2.png\n│   ├── zhu-3.png\n│   ├── zhu-4.png\n│   ├── zhu-5.png\n│   ├── zhu-6.png\n│   └── zhu-7.png\n├── zhu2/\n│   ├── zhu2-1.png\n│   ├── zhu2-2.png\n│   ├── zhu2-3.png\n│   ├── zhu2-4.png\n│   ├── zhu2-5.png\n│   ├── zhu2-6.png\n│   └── zhu2-7.png\n└── zhuo/\n    ├── zhuo-1.png\n    ├── zhuo-2.png\n    ├── zhuo-3.png\n    ├── zhuo-4.png\n    ├── zhuo-5.png\n    ├── zhuo-6.png\n    └── zhuo-7.png\n\n\n\n\ntree = display_tree(\"mandarin\", string_rep=True).split(\"\\n\")\nprint(\"\\n\".join(tree[:12]))\nprint(\"...\")\nprint(\"\\n\".join(tree[-4:]))\n\nmandarin/\n├── bai/\n│   ├── bai-1.png\n│   ├── bai-2.png\n│   ├── bai-3.png\n│   ├── bai-4.png\n│   ├── bai-5.png\n│   ├── bai-6.png\n│   └── bai-7.png\n├── ben/\n│   ├── ben-1.png\n│   ├── ben-2.png\n...\n    ├── zhuo-5.png\n    ├── zhuo-6.png\n    └── zhuo-7.png",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#splitting-into-trainvaltest-sets",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#splitting-into-trainvaltest-sets",
    "title": "Computer Vision",
    "section": "Splitting into train/val/test sets",
    "text": "Splitting into train/val/test sets\n\n!pip install split-folders\n\n\nimport splitfolders\nsplitfolders.ratio(\"mandarin\", output=\"mandarin-split\",\n    seed=1337, ratio=(5/7, 1/7, 1/7))\n\ndisplay_tree(\"mandarin-split\", max_depth=1)\n\nCopying files: 0 files [00:00, ? files/s]Copying files: 399 files [00:00, 13446.74 files/s]\n\n\nmandarin-split/\n├── test/\n├── train/\n└── val/",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#directory-structure-ii",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#directory-structure-ii",
    "title": "Computer Vision",
    "section": "Directory structure II",
    "text": "Directory structure II\n\n\n\ndisplay_tree(\"mandarin-split\")\n\nmandarin-split/\n├── test/\n│   ├── bai/\n│   │   └── bai-5.png\n│   ├── ben/\n│   │   └── ben-5.png\n│   ├── chong/\n│   │   └── chong-5.png\n│   ├── chu/\n│   │   └── chu-5.png\n│   ├── chuan/\n│   │   └── chuan-5.png\n│   ├── cong/\n│   │   └── cong-5.png\n│   ├── da/\n│   │   └── da-5.png\n│   ├── dan/\n│   │   └── dan-5.png\n│   ├── dong/\n│   │   └── dong-5.png\n│   ├── fei/\n│   │   └── fei-5.png\n│   ├── fu/\n│   │   └── fu-5.png\n│   ├── fu2/\n│   │   └── fu2-5.png\n│   ├── gao/\n│   │   └── gao-5.png\n│   ├── gong/\n│   │   └── gong-5.png\n│   ├── guo/\n│   │   └── guo-5.png\n│   ├── hu/\n│   │   └── hu-5.png\n│   ├── huo/\n│   │   └── huo-5.png\n│   ├── kou/\n│   │   └── kou-5.png\n│   ├── ku/\n│   │   └── ku-5.png\n│   ├── lin/\n│   │   └── lin-5.png\n│   ├── ma/\n│   │   └── ma-5.png\n│   ├── ma2/\n│   │   └── ma2-5.png\n│   ├── ma3/\n│   │   └── ma3-5.png\n│   ├── mei/\n│   │   └── mei-5.png\n│   ├── men/\n│   │   └── men-5.png\n│   ├── ming/\n│   │   └── ming-5.png\n│   ├── mu/\n│   │   └── mu-5.png\n│   ├── nan/\n│   │   └── nan-5.png\n│   ├── niao/\n│   │   └── niao-5.png\n│   ├── niu/\n│   │   └── niu-5.png\n│   ├── nu/\n│   │   └── nu-5.png\n│   ├── nuan/\n│   │   └── nuan-5.png\n│   ├── peng/\n│   │   └── peng-5.png\n│   ├── quan/\n│   │   └── quan-5.png\n│   ├── ren/\n│   │   └── ren-5.png\n│   ├── ri/\n│   │   └── ri-5.png\n│   ├── rou/\n│   │   └── rou-5.png\n│   ├── sen/\n│   │   └── sen-5.png\n│   ├── shan/\n│   │   └── shan-5.png\n│   ├── shan2/\n│   │   └── shan2-5.png\n│   ├── shui/\n│   │   └── shui-5.png\n│   ├── tai/\n│   │   └── tai-5.png\n│   ├── tian/\n│   │   └── tian-5.png\n│   ├── wang/\n│   │   └── wang-5.png\n│   ├── wen/\n│   │   └── wen-5.png\n│   ├── xian/\n│   │   └── xian-5.png\n│   ├── xuan/\n│   │   └── xuan-5.png\n│   ├── yan/\n│   │   └── yan-5.png\n│   ├── yang/\n│   │   └── yang-5.png\n│   ├── yin/\n│   │   └── yin-5.png\n│   ├── yu/\n│   │   └── yu-5.png\n│   ├── yu2/\n│   │   └── yu2-5.png\n│   ├── yue/\n│   │   └── yue-5.png\n│   ├── zhong/\n│   │   └── zhong-5.png\n│   ├── zhu/\n│   │   └── zhu-5.png\n│   ├── zhu2/\n│   │   └── zhu2-5.png\n│   └── zhuo/\n│       └── zhuo-5.png\n├── train/\n│   ├── bai/\n│   │   ├── bai-1.png\n│   │   ├── bai-2.png\n│   │   ├── bai-3.png\n│   │   ├── bai-4.png\n│   │   └── bai-6.png\n│   ├── ben/\n│   │   ├── ben-1.png\n│   │   ├── ben-2.png\n│   │   ├── ben-3.png\n│   │   ├── ben-4.png\n│   │   └── ben-6.png\n│   ├── chong/\n│   │   ├── chong-1.png\n│   │   ├── chong-2.png\n│   │   ├── chong-3.png\n│   │   ├── chong-4.png\n│   │   └── chong-6.png\n│   ├── chu/\n│   │   ├── chu-1.png\n│   │   ├── chu-2.png\n│   │   ├── chu-3.png\n│   │   ├── chu-4.png\n│   │   └── chu-6.png\n│   ├── chuan/\n│   │   ├── chuan-1.png\n│   │   ├── chuan-2.png\n│   │   ├── chuan-3.png\n│   │   ├── chuan-4.png\n│   │   └── chuan-6.png\n│   ├── cong/\n│   │   ├── cong-1.png\n│   │   ├── cong-2.png\n│   │   ├── cong-3.png\n│   │   ├── cong-4.png\n│   │   └── cong-6.png\n│   ├── da/\n│   │   ├── da-1.png\n│   │   ├── da-2.png\n│   │   ├── da-3.png\n│   │   ├── da-4.png\n│   │   └── da-6.png\n│   ├── dan/\n│   │   ├── dan-1.png\n│   │   ├── dan-2.png\n│   │   ├── dan-3.png\n│   │   ├── dan-4.png\n│   │   └── dan-6.png\n│   ├── dong/\n│   │   ├── dong-1.png\n│   │   ├── dong-2.png\n│   │   ├── dong-3.png\n│   │   ├── dong-4.png\n│   │   └── dong-6.png\n│   ├── fei/\n│   │   ├── fei-1.png\n│   │   ├── fei-2.png\n│   │   ├── fei-3.png\n│   │   ├── fei-4.png\n│   │   └── fei-6.png\n│   ├── fu/\n│   │   ├── fu-1.png\n│   │   ├── fu-2.png\n│   │   ├── fu-3.png\n│   │   ├── fu-4.png\n│   │   └── fu-6.png\n│   ├── fu2/\n│   │   ├── fu2-1.png\n│   │   ├── fu2-2.png\n│   │   ├── fu2-3.png\n│   │   ├── fu2-4.png\n│   │   └── fu2-6.png\n│   ├── gao/\n│   │   ├── gao-1.png\n│   │   ├── gao-2.png\n│   │   ├── gao-3.png\n│   │   ├── gao-4.png\n│   │   └── gao-6.png\n│   ├── gong/\n│   │   ├── gong-1.png\n│   │   ├── gong-2.png\n│   │   ├── gong-3.png\n│   │   ├── gong-4.png\n│   │   └── gong-6.png\n│   ├── guo/\n│   │   ├── guo-1.png\n│   │   ├── guo-2.png\n│   │   ├── guo-3.png\n│   │   ├── guo-4.png\n│   │   └── guo-6.png\n│   ├── hu/\n│   │   ├── hu-1.png\n│   │   ├── hu-2.png\n│   │   ├── hu-3.png\n│   │   ├── hu-4.png\n│   │   └── hu-6.png\n│   ├── huo/\n│   │   ├── huo-1.png\n│   │   ├── huo-2.png\n│   │   ├── huo-3.png\n│   │   ├── huo-4.png\n│   │   └── huo-6.png\n│   ├── kou/\n│   │   ├── kou-1.png\n│   │   ├── kou-2.png\n│   │   ├── kou-3.png\n│   │   ├── kou-4.png\n│   │   └── kou-6.png\n│   ├── ku/\n│   │   ├── ku-1.png\n│   │   ├── ku-2.png\n│   │   ├── ku-3.png\n│   │   ├── ku-4.png\n│   │   └── ku-6.png\n│   ├── lin/\n│   │   ├── lin-1.png\n│   │   ├── lin-2.png\n│   │   ├── lin-3.png\n│   │   ├── lin-4.png\n│   │   └── lin-6.png\n│   ├── ma/\n│   │   ├── ma-1.png\n│   │   ├── ma-2.png\n│   │   ├── ma-3.png\n│   │   ├── ma-4.png\n│   │   └── ma-6.png\n│   ├── ma2/\n│   │   ├── ma2-1.png\n│   │   ├── ma2-2.png\n│   │   ├── ma2-3.png\n│   │   ├── ma2-4.png\n│   │   └── ma2-6.png\n│   ├── ma3/\n│   │   ├── ma3-1.png\n│   │   ├── ma3-2.png\n│   │   ├── ma3-3.png\n│   │   ├── ma3-4.png\n│   │   └── ma3-6.png\n│   ├── mei/\n│   │   ├── mei-1.png\n│   │   ├── mei-2.png\n│   │   ├── mei-3.png\n│   │   ├── mei-4.png\n│   │   └── mei-6.png\n│   ├── men/\n│   │   ├── men-1.png\n│   │   ├── men-2.png\n│   │   ├── men-3.png\n│   │   ├── men-4.png\n│   │   └── men-6.png\n│   ├── ming/\n│   │   ├── ming-1.png\n│   │   ├── ming-2.png\n│   │   ├── ming-3.png\n│   │   ├── ming-4.png\n│   │   └── ming-6.png\n│   ├── mu/\n│   │   ├── mu-1.png\n│   │   ├── mu-2.png\n│   │   ├── mu-3.png\n│   │   ├── mu-4.png\n│   │   └── mu-6.png\n│   ├── nan/\n│   │   ├── nan-1.png\n│   │   ├── nan-2.png\n│   │   ├── nan-3.png\n│   │   ├── nan-4.png\n│   │   └── nan-6.png\n│   ├── niao/\n│   │   ├── niao-1.png\n│   │   ├── niao-2.png\n│   │   ├── niao-3.png\n│   │   ├── niao-4.png\n│   │   └── niao-6.png\n│   ├── niu/\n│   │   ├── niu-1.png\n│   │   ├── niu-2.png\n│   │   ├── niu-3.png\n│   │   ├── niu-4.png\n│   │   └── niu-6.png\n│   ├── nu/\n│   │   ├── nu-1.png\n│   │   ├── nu-2.png\n│   │   ├── nu-3.png\n│   │   ├── nu-4.png\n│   │   └── nu-6.png\n│   ├── nuan/\n│   │   ├── nuan-1.png\n│   │   ├── nuan-2.png\n│   │   ├── nuan-3.png\n│   │   ├── nuan-4.png\n│   │   └── nuan-6.png\n│   ├── peng/\n│   │   ├── peng-1.png\n│   │   ├── peng-2.png\n│   │   ├── peng-3.png\n│   │   ├── peng-4.png\n│   │   └── peng-6.png\n│   ├── quan/\n│   │   ├── quan-1.png\n│   │   ├── quan-2.png\n│   │   ├── quan-3.png\n│   │   ├── quan-4.png\n│   │   └── quan-6.png\n│   ├── ren/\n│   │   ├── ren-1.png\n│   │   ├── ren-2.png\n│   │   ├── ren-3.png\n│   │   ├── ren-4.png\n│   │   └── ren-6.png\n│   ├── ri/\n│   │   ├── ri-1.png\n│   │   ├── ri-2.png\n│   │   ├── ri-3.png\n│   │   ├── ri-4.png\n│   │   └── ri-6.png\n│   ├── rou/\n│   │   ├── rou-1.png\n│   │   ├── rou-2.png\n│   │   ├── rou-3.png\n│   │   ├── rou-4.png\n│   │   └── rou-6.png\n│   ├── sen/\n│   │   ├── sen-1.png\n│   │   ├── sen-2.png\n│   │   ├── sen-3.png\n│   │   ├── sen-4.png\n│   │   └── sen-6.png\n│   ├── shan/\n│   │   ├── shan-1.png\n│   │   ├── shan-2.png\n│   │   ├── shan-3.png\n│   │   ├── shan-4.png\n│   │   └── shan-6.png\n│   ├── shan2/\n│   │   ├── shan2-1.png\n│   │   ├── shan2-2.png\n│   │   ├── shan2-3.png\n│   │   ├── shan2-4.png\n│   │   └── shan2-6.png\n│   ├── shui/\n│   │   ├── shui-1.png\n│   │   ├── shui-2.png\n│   │   ├── shui-3.png\n│   │   ├── shui-4.png\n│   │   └── shui-6.png\n│   ├── tai/\n│   │   ├── tai-1.png\n│   │   ├── tai-2.png\n│   │   ├── tai-3.png\n│   │   ├── tai-4.png\n│   │   └── tai-6.png\n│   ├── tian/\n│   │   ├── tian-1.png\n│   │   ├── tian-2.png\n│   │   ├── tian-3.png\n│   │   ├── tian-4.png\n│   │   └── tian-6.png\n│   ├── wang/\n│   │   ├── wang-1.png\n│   │   ├── wang-2.png\n│   │   ├── wang-3.png\n│   │   ├── wang-4.png\n│   │   └── wang-6.png\n│   ├── wen/\n│   │   ├── wen-1.png\n│   │   ├── wen-2.png\n│   │   ├── wen-3.png\n│   │   ├── wen-4.png\n│   │   └── wen-6.png\n│   ├── xian/\n│   │   ├── xian-1.png\n│   │   ├── xian-2.png\n│   │   ├── xian-3.png\n│   │   ├── xian-4.png\n│   │   └── xian-6.png\n│   ├── xuan/\n│   │   ├── xuan-1.png\n│   │   ├── xuan-2.png\n│   │   ├── xuan-3.png\n│   │   ├── xuan-4.png\n│   │   └── xuan-6.png\n│   ├── yan/\n│   │   ├── yan-1.png\n│   │   ├── yan-2.png\n│   │   ├── yan-3.png\n│   │   ├── yan-4.png\n│   │   └── yan-6.png\n│   ├── yang/\n│   │   ├── yang-1.png\n│   │   ├── yang-2.png\n│   │   ├── yang-3.png\n│   │   ├── yang-4.png\n│   │   └── yang-6.png\n│   ├── yin/\n│   │   ├── yin-1.png\n│   │   ├── yin-2.png\n│   │   ├── yin-3.png\n│   │   ├── yin-4.png\n│   │   └── yin-6.png\n│   ├── yu/\n│   │   ├── yu-1.png\n│   │   ├── yu-2.png\n│   │   ├── yu-3.png\n│   │   ├── yu-4.png\n│   │   └── yu-6.png\n│   ├── yu2/\n│   │   ├── yu2-1.png\n│   │   ├── yu2-2.png\n│   │   ├── yu2-3.png\n│   │   ├── yu2-4.png\n│   │   └── yu2-6.png\n│   ├── yue/\n│   │   ├── yue-1.png\n│   │   ├── yue-2.png\n│   │   ├── yue-3.png\n│   │   ├── yue-4.png\n│   │   └── yue-6.png\n│   ├── zhong/\n│   │   ├── zhong-1.png\n│   │   ├── zhong-2.png\n│   │   ├── zhong-3.png\n│   │   ├── zhong-4.png\n│   │   └── zhong-6.png\n│   ├── zhu/\n│   │   ├── zhu-1.png\n│   │   ├── zhu-2.png\n│   │   ├── zhu-3.png\n│   │   ├── zhu-4.png\n│   │   └── zhu-6.png\n│   ├── zhu2/\n│   │   ├── zhu2-1.png\n│   │   ├── zhu2-2.png\n│   │   ├── zhu2-3.png\n│   │   ├── zhu2-4.png\n│   │   └── zhu2-6.png\n│   └── zhuo/\n│       ├── zhuo-1.png\n│       ├── zhuo-2.png\n│       ├── zhuo-3.png\n│       ├── zhuo-4.png\n│       └── zhuo-6.png\n└── val/\n    ├── bai/\n    │   └── bai-7.png\n    ├── ben/\n    │   └── ben-7.png\n    ├── chong/\n    │   └── chong-7.png\n    ├── chu/\n    │   └── chu-7.png\n    ├── chuan/\n    │   └── chuan-7.png\n    ├── cong/\n    │   └── cong-7.png\n    ├── da/\n    │   └── da-7.png\n    ├── dan/\n    │   └── dan-7.png\n    ├── dong/\n    │   └── dong-7.png\n    ├── fei/\n    │   └── fei-7.png\n    ├── fu/\n    │   └── fu-7.png\n    ├── fu2/\n    │   └── fu2-7.png\n    ├── gao/\n    │   └── gao-7.png\n    ├── gong/\n    │   └── gong-7.png\n    ├── guo/\n    │   └── guo-7.png\n    ├── hu/\n    │   └── hu-7.png\n    ├── huo/\n    │   └── huo-7.png\n    ├── kou/\n    │   └── kou-7.png\n    ├── ku/\n    │   └── ku-7.png\n    ├── lin/\n    │   └── lin-7.png\n    ├── ma/\n    │   └── ma-7.png\n    ├── ma2/\n    │   └── ma2-7.png\n    ├── ma3/\n    │   └── ma3-7.png\n    ├── mei/\n    │   └── mei-7.png\n    ├── men/\n    │   └── men-7.png\n    ├── ming/\n    │   └── ming-7.png\n    ├── mu/\n    │   └── mu-7.png\n    ├── nan/\n    │   └── nan-7.png\n    ├── niao/\n    │   └── niao-7.png\n    ├── niu/\n    │   └── niu-7.png\n    ├── nu/\n    │   └── nu-7.png\n    ├── nuan/\n    │   └── nuan-7.png\n    ├── peng/\n    │   └── peng-7.png\n    ├── quan/\n    │   └── quan-7.png\n    ├── ren/\n    │   └── ren-7.png\n    ├── ri/\n    │   └── ri-7.png\n    ├── rou/\n    │   └── rou-7.png\n    ├── sen/\n    │   └── sen-7.png\n    ├── shan/\n    │   └── shan-7.png\n    ├── shan2/\n    │   └── shan2-7.png\n    ├── shui/\n    │   └── shui-7.png\n    ├── tai/\n    │   └── tai-7.png\n    ├── tian/\n    │   └── tian-7.png\n    ├── wang/\n    │   └── wang-7.png\n    ├── wen/\n    │   └── wen-7.png\n    ├── xian/\n    │   └── xian-7.png\n    ├── xuan/\n    │   └── xuan-7.png\n    ├── yan/\n    │   └── yan-7.png\n    ├── yang/\n    │   └── yang-7.png\n    ├── yin/\n    │   └── yin-7.png\n    ├── yu/\n    │   └── yu-7.png\n    ├── yu2/\n    │   └── yu2-7.png\n    ├── yue/\n    │   └── yue-7.png\n    ├── zhong/\n    │   └── zhong-7.png\n    ├── zhu/\n    │   └── zhu-7.png\n    ├── zhu2/\n    │   └── zhu2-7.png\n    └── zhuo/\n        └── zhuo-7.png\n\n\n\n\n\ntrain/\n├── bai/\n│   ├── bai-1.png\n│   ├── bai-2.png\n│   ├── bai-3.png\n│   ├── bai-4.png\n│   └── bai-6.png\n...\nval/\n├── bai/\n│   └── bai-7.png\n├── ben/\n│   └── ben-7.png\n...\ntest/\n├── bai/\n│   └── bai-5.png\n├── ben/\n│   └── ben-5.png\n...",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#keras-image-dataset-loading",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#keras-image-dataset-loading",
    "title": "Computer Vision",
    "section": "Keras image dataset loading",
    "text": "Keras image dataset loading\n\nfrom keras.utils import\\\n1  image_dataset_from_directory\n\n2data_dir = \"mandarin-split\"\n3batch_size = 32\n4img_height = 80\n5img_width = 80\n6img_size = (img_height, img_width)\n\n7train_ds = image_dataset_from_directory(\n    data_dir + \"/train\",\n    image_size=img_size,\n    batch_size=batch_size,\n    shuffle=False,\n    color_mode='grayscale')\n\n8val_ds = image_dataset_from_directory(\n    data_dir + \"/val\",\n    image_size=img_size,\n    batch_size=batch_size,\n    shuffle=False,\n    color_mode='grayscale')\n\n9test_ds = image_dataset_from_directory(\n    data_dir + \"/test\",\n    image_size=img_size,\n    batch_size=batch_size,\n    shuffle=False,\n    color_mode='grayscale')\n\n\n1\n\nImports image_dataset_from_directory class from keras.utils library\n\n2\n\nSpecifies the name of the folder\n\n3\n\nSpecifies the number of images to be trained at the same time\n\n4\n\nSpecifies the height of the image\n\n5\n\nSpecifies the width of the image\n\n6\n\nSpecifies the image size\n\n7\n\nCreates a data object to store the train set. Note that color_mode='grayscale' command tells the computer to bring in the images in greyscale instead of the RGB scale.\n\n8\n\nCreates a data object to store the validation set\n\n9\n\nCreates a data object to store the test set\n\n\n\n\nFound 285 files belonging to 57 classes.\nFound 57 files belonging to 57 classes.\nFound 57 files belonging to 57 classes.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#inspecting-the-datasets",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#inspecting-the-datasets",
    "title": "Computer Vision",
    "section": "Inspecting the datasets",
    "text": "Inspecting the datasets\n\nprint(train_ds.class_names)\n\n['bai', 'ben', 'chong', 'chu', 'chuan', 'cong', 'da', 'dan', 'dong', 'fei', 'fu', 'fu2', 'gao', 'gong', 'guo', 'hu', 'huo', 'kou', 'ku', 'lin', 'ma', 'ma2', 'ma3', 'mei', 'men', 'ming', 'mu', 'nan', 'niao', 'niu', 'nu', 'nuan', 'peng', 'quan', 'ren', 'ri', 'rou', 'sen', 'shan', 'shan2', 'shui', 'tai', 'tian', 'wang', 'wen', 'xian', 'xuan', 'yan', 'yang', 'yin', 'yu', 'yu2', 'yue', 'zhong', 'zhu', 'zhu2', 'zhuo']\n\n\n\n# NB: Need shuffle=False earlier for these X & y to line up.\nX_train = np.concatenate(list(train_ds.map(lambda x, y: x)))\ny_train = np.concatenate(list(train_ds.map(lambda x, y: y)))\n\nX_val = np.concatenate(list(val_ds.map(lambda x, y: x)))\ny_val = np.concatenate(list(val_ds.map(lambda x, y: y)))\n\nX_test = np.concatenate(list(test_ds.map(lambda x, y: x)))\ny_test = np.concatenate(list(test_ds.map(lambda x, y: y)))\n\nX_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape\n\n((285, 80, 80, 1), (285,), (57, 80, 80, 1), (57,), (57, 80, 80, 1), (57,))",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#plotting-some-characters-setup",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#plotting-some-characters-setup",
    "title": "Computer Vision",
    "section": "Plotting some characters (setup)",
    "text": "Plotting some characters (setup)\n\ndef plot_mandarin_characters(ds, plot_char_label = 0):\n    num_plotted = 0\n    for images, labels in ds:\n       for i in range(images.shape[0]):\n           label = labels[i]\n           if label == plot_char_label:\n               plt.subplot(1, 5, num_plotted + 1)\n               plt.imshow(images[i].numpy().astype(\"uint8\"), cmap=\"gray\")\n               plt.title(ds.class_names[label])\n               plt.axis(\"off\")\n               num_plotted += 1\n    plt.show()",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#plotting-some-training-characters",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#plotting-some-training-characters",
    "title": "Computer Vision",
    "section": "Plotting some training characters",
    "text": "Plotting some training characters",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#plotting-some-valtest-characters",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#plotting-some-valtest-characters",
    "title": "Computer Vision",
    "section": "Plotting some val/test characters",
    "text": "Plotting some val/test characters\n\n\n\nbai_val = X_val[y_val == 0][0]\nplt.imshow(bai_val, cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nbai_test = X_test[y_test == 0][0]\nplt.imshow(bai_test);",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#make-the-cnn",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#make-the-cnn",
    "title": "Computer Vision",
    "section": "Make the CNN",
    "text": "Make the CNN\n\nfrom keras.layers \\\n1  import Rescaling, Conv2D, MaxPooling2D, Flatten\n\n2num_classes = np.unique(y_train).shape[0]\nrandom.seed(123)\n\nmodel = Sequential([\n  Input((img_height, img_width, 1)),\n3  Rescaling(1./255),\n4  Conv2D(16, 3, padding=\"same\", activation=\"relu\", name=\"conv1\"),\n5  MaxPooling2D(name=\"pool1\"),\n  Conv2D(32, 3, padding=\"same\", activation=\"relu\", name=\"conv2\"),\n  MaxPooling2D(name=\"pool2\"),\n  Conv2D(64, 3, padding=\"same\", activation=\"relu\", name=\"conv3\"),\n  MaxPooling2D(name=\"pool3\"),\n6  Flatten(), Dense(128, activation=\"relu\"), Dense(num_classes)\n])\n\n\n1\n\nImports CNN specific preprocessing layers from keras.layers\n\n2\n\nSpecifies the number of unique categories in the train set\n\n3\n\nRescales the numeric representations of data which ranges from [0,255] in to [0, 1] range\n\n4\n\nApplies the convolution layer. Here padding=\"same\" ensures that the dimensions of the input and output matrices remain same\n\n5\n\nApplies MaxPooling, which reduces the spatial dimensions by carrying forward the maximum value over an input window\n\n6\n\nApplies the Flatten layer to convert the 2D array (from pooling) in to a single column vector, and passes through couple of Dense layers to train the neural network for the specific classification problem. Note that the output layer has number of neurons equal to numClasses, which corresponds to the number of unique classes in the output.\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe Rescaling layer will rescale the intensities to [0, 1].\n\n\n\nArchitecture inspired by https://www.tensorflow.org/tutorials/images/classification.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#inspect-the-model",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#inspect-the-model",
    "title": "Computer Vision",
    "section": "Inspect the model",
    "text": "Inspect the model\n\nmodel.summary()\n\nModel: \"sequential\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ rescaling (Rescaling)           │ (None, 80, 80, 1)         │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ conv1 (Conv2D)                  │ (None, 80, 80, 16)        │        160 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ pool1 (MaxPooling2D)            │ (None, 40, 40, 16)        │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ conv2 (Conv2D)                  │ (None, 40, 40, 32)        │      4,640 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ pool2 (MaxPooling2D)            │ (None, 20, 20, 32)        │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ conv3 (Conv2D)                  │ (None, 20, 20, 64)        │     18,496 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ pool3 (MaxPooling2D)            │ (None, 10, 10, 64)        │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ flatten (Flatten)               │ (None, 6400)              │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense (Dense)                   │ (None, 128)               │    819,328 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_1 (Dense)                 │ (None, 57)                │      7,353 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 849,977 (3.24 MB)\n\n\n\n Trainable params: 849,977 (3.24 MB)\n\n\n\n Non-trainable params: 0 (0.00 B)",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#plot-the-cnn",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#plot-the-cnn",
    "title": "Computer Vision",
    "section": "Plot the CNN",
    "text": "Plot the CNN\n\nplot_model(model, show_shapes=True)",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#fit-the-cnn",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#fit-the-cnn",
    "title": "Computer Vision",
    "section": "Fit the CNN",
    "text": "Fit the CNN\n\n1loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n2topk = keras.metrics.SparseTopKCategoricalAccuracy(k=5)\n3model.compile(optimizer='adam', loss=loss, metrics=['accuracy', topk])\n\nepochs = 100\nes = EarlyStopping(patience=15, restore_best_weights=True,\n    monitor=\"val_accuracy\", verbose=2)\n\nhist = model.fit(train_ds.shuffle(1000), validation_data=val_ds,\n  epochs=epochs, callbacks=[es], verbose=0)\n\n\n1\n\nDefines the loss function with an added command from_logits=True. Doing this instead of defining a softmax function at the output Dense layer of the neural network is expected to be more numerically stable\n\n2\n\nSpecifies a new metric to keep track of accuracy of the top 5 predicted classes. This means that, for each input image, the metric will consider whether the true class is among the top 5 predicted classes by the model\n\n3\n\nCompiles the model as usual with an optimizer, a loss function and metrics to monitor\n\n\n\n\nEpoch 61: early stopping\nRestoring model weights from the end of the best epoch: 46.\n\n\n\n\n\n\n\n\nTip\n\n\n\nInstead of using softmax activation, just added from_logits=True to the loss function; this is more numerically stable.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#plot-the-lossaccuracy-curves-setup",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#plot-the-lossaccuracy-curves-setup",
    "title": "Computer Vision",
    "section": "Plot the loss/accuracy curves (setup)",
    "text": "Plot the loss/accuracy curves (setup)\n\ndef plot_history(hist):\n    epochs = range(len(hist.history[\"loss\"]))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, hist.history[\"accuracy\"], label=\"Train\")\n    plt.plot(epochs, hist.history[\"val_accuracy\"], label=\"Val\")\n    plt.legend(loc=\"lower right\")\n    plt.title(\"Accuracy\")\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, hist.history[\"loss\"], label=\"Train\")\n    plt.plot(epochs, hist.history[\"val_loss\"], label=\"Val\")\n    plt.legend(loc=\"upper right\")\n    plt.title(\"Loss\")\n    plt.show()",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#plot-the-lossaccuracy-curves",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#plot-the-lossaccuracy-curves",
    "title": "Computer Vision",
    "section": "Plot the loss/accuracy curves",
    "text": "Plot the loss/accuracy curves\n\nplot_history(hist)",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#look-at-the-metrics",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#look-at-the-metrics",
    "title": "Computer Vision",
    "section": "Look at the metrics",
    "text": "Look at the metrics\n\nprint(model.evaluate(train_ds, verbose=0))\nprint(model.evaluate(val_ds, verbose=0))\nprint(model.evaluate(test_ds, verbose=0))\n\n[0.000872915843501687, 1.0, 1.0]\n[1.3904294967651367, 0.7719298005104065, 0.9473684430122375]\n[0.9015927314758301, 0.8070175647735596, 0.9649122953414917]",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#predict-on-the-test-set",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#predict-on-the-test-set",
    "title": "Computer Vision",
    "section": "Predict on the test set",
    "text": "Predict on the test set\n\nmodel.predict(X_test[17], verbose=0);\n\n\nException encountered when calling MaxPooling2D.call().\n\nGiven input size: (16x80x1). Calculated output size: (16x40x0). Output size is too small\n\nArguments received by MaxPooling2D.call():\n  • inputs=torch.Tensor(shape=torch.Size([32, 80, 1, 16]), dtype=float32)\n\n\n\n\nX_test[17].shape, X_test[17][np.newaxis, :].shape, X_test[[17]].shape\n\n((80, 80, 1), (1, 80, 80, 1), (1, 80, 80, 1))\n\n\n\nmodel.predict(X_test[[17]], verbose=0)\n\narray([[  5.3 , -39.16, -19.69,  -1.85,  -5.79, -21.37, -29.5 , -19.02,\n        -24.34, -19.76, -24.25,   4.51, -12.56, -38.95,   4.08,  -4.33,\n        -17.79,  17.11, -24.11,  -3.67,  -5.65, -11.93,  -5.19, -26.43,\n         11.84,   0.11, -28.81,   7.49,   2.03, -30.62, -25.36,  -1.65,\n         -8.67, -30.7 , -33.91,  15.12,  -4.21, -14.29,  -0.13,   0.58,\n        -27.55, -35.24, -32.54, -17.89,  -5.48, -10.58,  -9.2 , -14.83,\n        -15.91,   9.42, -13.04, -13.91,   1.75, -22.18,  -9.81, -13.85,\n        -13.8 ]], dtype=float32)",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#predict-on-the-test-set-ii",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#predict-on-the-test-set-ii",
    "title": "Computer Vision",
    "section": "Predict on the test set II",
    "text": "Predict on the test set II\n\nmodel.predict(X_test[[17]], verbose=0).argmax()\n\n17\n\n\n\ntest_ds.class_names[model.predict(X_test[[17]], verbose=0).argmax()]\n\n'kou'\n\n\n\nplt.imshow(X_test[17], cmap=\"gray\");",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#error-analysis-setup",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#error-analysis-setup",
    "title": "Computer Vision",
    "section": "Error analysis (setup)",
    "text": "Error analysis (setup)\n\ndef plot_error_analysis(X_train, y_train, X_test, y_test, y_pred, class_names):\n  plt.figure(figsize=(4, 10))\n\n  num_errors = np.sum(y_pred != y_test)\n  err_num = 0\n  for i in range(X_test.shape[0]):\n      if y_pred[i] != y_test[i]:\n          ax = plt.subplot(num_errors, 2, 2*err_num + 1)\n          plt.imshow(X_test[i].astype(\"uint8\"), cmap=\"gray\")\n          plt.title(f\"Guessed '{class_names[y_pred[i]]}' True '{class_names[y_test[i]]}'\")\n          plt.axis(\"off\")\n          \n          actual_pred_char_ind = np.argmax(y_test == y_pred[i])\n          ax = plt.subplot(num_errors, 2, 2*err_num + 2)\n          plt.imshow(X_val[actual_pred_char_ind].astype(\"uint8\"), cmap=\"gray\")\n          plt.title(f\"A real '{class_names[y_pred[i]]}'\")\n          plt.axis(\"off\")\n          err_num += 1",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#error-analysis-i",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#error-analysis-i",
    "title": "Computer Vision",
    "section": "Error analysis I",
    "text": "Error analysis I\n\n\n\nExtract from first assessment of test errors.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#error-analysis-ii",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#error-analysis-ii",
    "title": "Computer Vision",
    "section": "Error analysis II",
    "text": "Error analysis II\n\n\n\nExtract from second assessment of test errors.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#error-analysis-iii",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#error-analysis-iii",
    "title": "Computer Vision",
    "section": "Error analysis III",
    "text": "Error analysis III\n\ny_pred = model.predict(X_val, verbose=0).argmax(axis=1)\nplot_error_analysis(X_train, y_train, X_val, y_val, y_pred, val_ds.class_names)",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#error-analysis-iv",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#error-analysis-iv",
    "title": "Computer Vision",
    "section": "Error analysis IV",
    "text": "Error analysis IV\n\ny_pred = model.predict(X_test, verbose=0).argmax(axis=1)\nplot_error_analysis(X_train, y_train, X_test, y_test, y_pred, test_ds.class_names)",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#confidence-of-predictions",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#confidence-of-predictions",
    "title": "Computer Vision",
    "section": "Confidence of predictions",
    "text": "Confidence of predictions\n\ny_pred = keras.activations.softmax(model(X_test))\ny_pred_class = keras.ops.argmax(y_pred, axis=1)\ny_pred_prob = y_pred[np.arange(y_pred.shape[0]), y_pred_class]\n\ny_pred_class = keras.ops.convert_to_numpy(y_pred_class)\ny_pred_prob = keras.ops.convert_to_numpy(y_pred_prob)\n\nconfidence_when_correct = y_pred_prob[y_pred_class == y_test]\nconfidence_when_wrong = y_pred_prob[y_pred_class != y_test]\n\n\n\n\nplt.hist(confidence_when_correct);\n\n\n\n\n\n\n\n\n\n\nplt.hist(confidence_when_wrong);",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#trial-error",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#trial-error",
    "title": "Computer Vision",
    "section": "Trial & error",
    "text": "Trial & error\n\n\n \nFrankly, a lot of this is just ‘enlightened’ trial and error.\n\n\n\n\nOr ‘received wisdom’ from experts…\n\n\n\n\n\nSource: Twitter.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#keras-tuner",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#keras-tuner",
    "title": "Computer Vision",
    "section": "Keras Tuner",
    "text": "Keras Tuner\n\n!pip install keras-tuner\n\n\nimport keras_tuner as kt\n\ndef build_model(hp):\n    model = Sequential()\n    model.add(\n        Dense(\n            hp.Choice(\"neurons\", [4, 8, 16, 32, 64, 128, 256]),\n            activation=hp.Choice(\"activation\",\n                [\"relu\", \"leaky_relu\", \"tanh\"]),\n        )\n    )\n  \n    model.add(Dense(1, activation=\"exponential\"))\n    \n    learning_rate = hp.Float(\"lr\",\n        min_value=1e-4, max_value=1e-2, sampling=\"log\")\n    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n\n    model.compile(optimizer=opt, loss=\"poisson\")\n    \n    return model",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#do-a-random-search",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#do-a-random-search",
    "title": "Computer Vision",
    "section": "Do a random search",
    "text": "Do a random search\n\n\n\ntuner = kt.RandomSearch(\n  build_model,\n  objective=\"val_loss\",\n  max_trials=10,\n  directory=\"random-search\")\n\nes = EarlyStopping(patience=3,\n  restore_best_weights=True)\n\ntuner.search(X_train_sc, y_train,\n  epochs=100, callbacks = [es],\n  validation_data=(X_val_sc, y_val))\n\nbest_model = tuner.get_best_models()[0]\n\nReloading Tuner from random-search/untitled_project/tuner0.json\n\n\n/home/plaub/miniconda3/envs/ai/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:394: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n  trackable.load_own_variables(weights_store.get(inner_path))\n\n\n\n\ntuner.results_summary(1)\n\nResults summary\nResults in random-search/untitled_project\nShowing 1 best trials\nObjective(name=\"val_loss\", direction=\"min\")\n\nTrial 02 summary\nHyperparameters:\nneurons: 8\nactivation: tanh\nlr: 0.0021043482724264983\nScore: 0.3167361915111542",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#tune-layers-separately",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#tune-layers-separately",
    "title": "Computer Vision",
    "section": "Tune layers separately",
    "text": "Tune layers separately\n\ndef build_model(hp):\n    model = Sequential()\n\n    for i in range(hp.Int(\"numHiddenLayers\", 1, 3)):\n      # Tune number of units in each layer separately.\n      model.add(\n          Dense(\n              hp.Choice(f\"neurons_{i}\", [8, 16, 32, 64]),\n              activation=\"relu\"\n          )\n      )\n    model.add(Dense(1, activation=\"exponential\"))\n\n    opt = keras.optimizers.Adam(learning_rate=0.0005)\n    model.compile(optimizer=opt, loss=\"poisson\")\n    \n    return model",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#do-a-bayesian-search",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#do-a-bayesian-search",
    "title": "Computer Vision",
    "section": "Do a Bayesian search",
    "text": "Do a Bayesian search\n\n\n\ntuner = kt.BayesianOptimization(\n  build_model,\n  objective=\"val_loss\",\n  directory=\"bayesian-search\",\n  max_trials=10)\n\nes = EarlyStopping(patience=3,\n  restore_best_weights=True)\n\ntuner.search(X_train_sc, y_train,\n  epochs=100, callbacks = [es],\n  validation_data=(X_val_sc, y_val))\n\nbest_model = tuner.get_best_models()[0]\n\nReloading Tuner from bayesian-search/untitled_project/tuner0.json\n\n\n/home/plaub/miniconda3/envs/ai/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:394: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n  trackable.load_own_variables(weights_store.get(inner_path))\n\n\n\n\ntuner.results_summary(1)\n\nResults summary\nResults in bayesian-search/untitled_project\nShowing 1 best trials\nObjective(name=\"val_loss\", direction=\"min\")\n\nTrial 02 summary\nHyperparameters:\nnumHiddenLayers: 3\nneurons_0: 64\nneurons_1: 16\nneurons_2: 16\nScore: 0.3142806887626648",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#demo-object-classification",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#demo-object-classification",
    "title": "Computer Vision",
    "section": "Demo: Object classification",
    "text": "Demo: Object classification\n\n\n\n\n\nExample object classification run.\n\n\n\n\n\n\nExample of object classification.\n\n\n\n\n\nSource: Teachable Machine, https://teachablemachine.withgoogle.com/.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#how-does-that-work",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#how-does-that-work",
    "title": "Computer Vision",
    "section": "How does that work?",
    "text": "How does that work?\n\n… these models use a technique called transfer learning. There’s a pretrained neural network, and when you create your own classes, you can sort of picture that your classes are becoming the last layer or step of the neural net. Specifically, both the image and pose models are learning off of pretrained mobilenet models …\n\nTeachable Machine FAQ",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#benchmarks",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#benchmarks",
    "title": "Computer Vision",
    "section": "Benchmarks",
    "text": "Benchmarks\nCIFAR-11 / CIFAR-100 dataset from Canadian Institute for Advanced Research\n\n9 classes: 60000 32x32 colour images\n99 classes: 60000 32x32 colour images\n\nImageNet and the ImageNet Large Scale Visual Recognition Challenge (ILSVRC); originally 1,000 synsets.\n\nIn 2021: 14,197,122 labelled images from 21,841 synsets.\nSee Keras applications for downloadable models.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#lenet-6-1998",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#lenet-6-1998",
    "title": "Computer Vision",
    "section": "LeNet-6 (1998)",
    "text": "LeNet-6 (1998)\n\n\n\n\n\n\n\n\n\n\n\n\nLayer\nType\nChannels\nSize\nKernel size\nStride\nActivation\n\n\n\n\nIn\nInput\n0\n32×32\n–\n–\n–\n\n\nC0\nConvolution\n6\n28×28\n5×5\n1\ntanh\n\n\nS1\nAvg pooling\n6\n14×14\n2×2\n2\ntanh\n\n\nC2\nConvolution\n16\n10×10\n5×5\n1\ntanh\n\n\nS3\nAvg pooling\n16\n5×5\n2×2\n2\ntanh\n\n\nC4\nConvolution\n120\n1×1\n5×5\n1\ntanh\n\n\nF5\nFully connected\n–\n84\n–\n–\ntanh\n\n\nOut\nFully connected\n–\n9\n–\n–\nRBF\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nMNIST images are 27×28 pixels, and with zero-padding (for a 5×5 kernel) that becomes 32×32.\n\n\n\nSource: Aurélien Géron (2018), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Chapter 14.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#alexnet-2011",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#alexnet-2011",
    "title": "Computer Vision",
    "section": "AlexNet (2011)",
    "text": "AlexNet (2011)\n\n\n\n\n\n\n\n\n\n\n\n\n\nLayer\nType\nChannels\nSize\nKernel\nStride\nPadding\nActivation\n\n\n\n\nIn\nInput\n2\n227×227\n–\n–\n–\n–\n\n\nC0\nConvolution\n96\n55×55\n11×11\n4\nvalid\nReLU\n\n\nS1\nMax pool\n96\n27×27\n3×3\n2\nvalid\n–\n\n\nC2\nConvolution\n256\n27×27\n5×5\n1\nsame\nReLU\n\n\nS3\nMax pool\n256\n13×13\n3×3\n2\nvalid\n–\n\n\nC4\nConvolution\n384\n13×13\n3×3\n1\nsame\nReLU\n\n\nC5\nConvolution\n384\n13×13\n3×3\n1\nsame\nReLU\n\n\nC6\nConvolution\n256\n13×13\n3×3\n1\nsame\nReLU\n\n\nS7\nMax pool\n256\n6×6\n3×3\n2\nvalid\n–\n\n\nF8\nFully conn.\n–\n4,096\n–\n–\n–\nReLU\n\n\nF9\nFully conn.\n–\n4,096\n–\n–\n–\nReLU\n\n\nOut\nFully conn.\n–\n0,000\n–\n–\n–\nSoftmax\n\n\n\n\nWinner of the ILSVRC 2011 challenge (top-five error 17%), developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#data-augmentation",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#data-augmentation",
    "title": "Computer Vision",
    "section": "Data Augmentation",
    "text": "Data Augmentation\n\n\n\nExamples of data augmentation.\n\n\n\nSource: Buah et al. (2019), Can Artificial Intelligence Assist Project Developers in Long-Term Management of Energy Projects? The Case of CO2 Capture and Storage.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#inception-module-2013",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#inception-module-2013",
    "title": "Computer Vision",
    "section": "Inception module (2013)",
    "text": "Inception module (2013)\nUsed in ILSVRC 2013 winning solution (top-5 error &lt; 7%).\n\n\n\n\n\n\n\n\nVGGNet was the runner-up.\n\nSource: Szegedy, C. et al. (2014), Going deeper with convolutions. and KnowYourMeme.com",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#googlenet-inception_v0-2014",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#googlenet-inception_v0-2014",
    "title": "Computer Vision",
    "section": "GoogLeNet / Inception_v0 (2014)",
    "text": "GoogLeNet / Inception_v0 (2014)\n\n\n\nSchematic of the GoogLeNet architecture.\n\n\n\nSource: Aurélien Géron (2018), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Figure 14-14.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#depth-is-important-for-image-tasks",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#depth-is-important-for-image-tasks",
    "title": "Computer Vision",
    "section": "Depth is important for image tasks",
    "text": "Depth is important for image tasks\n\n\n\nDeeper models aren’t just better because they have more parameters. Model depth given in the legend. Accuracy is on the Street View House Numbers dataset.\n\n\n\nSource: Goodfellow et al. (2015), Deep Learning, Figure 6.7.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#residual-connection",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#residual-connection",
    "title": "Computer Vision",
    "section": "Residual connection",
    "text": "Residual connection\n\n\n\nIllustration of a residual connection.\n\n\n\nSource: Aurélien Géron (2018), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Figure 14-15.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#resnet-2014",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#resnet-2014",
    "title": "Computer Vision",
    "section": "ResNet (2014)",
    "text": "ResNet (2014)\nResNet won the ILSVRC 2014 challenge (top-5 error 3.6%), developed by Kaiming He et al.\n\n\n\nDiagram of the ResNet architecture.\n\n\n\nSource: Aurélien Géron (2018), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Figure 14-17.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#pretrained-model",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#pretrained-model",
    "title": "Computer Vision",
    "section": "Pretrained model",
    "text": "Pretrained model\n\ndef classify_imagenet(paths, model_module, ModelClass, dims):\n    images = [keras.utils.load_img(path, target_size=dims) for path in paths]\n    image_array = np.array([keras.utils.img_to_array(img) for img in images])\n    inputs = model_module.preprocess_input(image_array)\n   \n    model = ModelClass(weights=\"imagenet\")\n    Y_proba = model.predict(inputs, verbose=0)\n    top_k = model_module.decode_predictions(Y_proba, top=3)\n\n    for image_index in range(len(images)):\n        print(f\"Image #{image_index}:\")\n        for class_id, name, y_proba in top_k[image_index]:\n            print(f\" {class_id} - {name} {int(y_proba*100)}%\")\n        print()",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#predicted-classes-mobilenet-1",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#predicted-classes-mobilenet-1",
    "title": "Computer Vision",
    "section": "Predicted classes (MobileNet)",
    "text": "Predicted classes (MobileNet)\n\n\n\n\n\n\n\nImage #0:\n n03483316 - hand_blower 21%\n n03271574 - electric_fan 8%\n n07579787 - plate 4%\n\nImage #1:\n n03942813 - ping-pong_ball 88%\n n02782093 - balloon 3%\n n04023962 - punching_bag 1%\n\nImage #2:\n n04557648 - water_bottle 31%\n n04336792 - stretcher 14%\n n03868863 - oxygen_mask 7%",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#predicted-classes-mobilenetv2-1",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#predicted-classes-mobilenetv2-1",
    "title": "Computer Vision",
    "section": "Predicted classes (MobileNetV2)",
    "text": "Predicted classes (MobileNetV2)\n\n\n\n\n\n\n\nImage #0:\n n03868863 - oxygen_mask 37%\n n03483316 - hand_blower 7%\n n03271574 - electric_fan 7%\n\nImage #1:\n n03942813 - ping-pong_ball 29%\n n04270147 - spatula 12%\n n03970156 - plunger 8%\n\nImage #2:\n n02815834 - beaker 40%\n n03868863 - oxygen_mask 16%\n n04557648 - water_bottle 4%",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#predicted-classes-inceptionv3-1",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#predicted-classes-inceptionv3-1",
    "title": "Computer Vision",
    "section": "Predicted classes (InceptionV3)",
    "text": "Predicted classes (InceptionV3)\n\n\n\n\n\n\n\nImage #0:\n n02815834 - beaker 19%\n n03179701 - desk 15%\n n03868863 - oxygen_mask 9%\n\nImage #1:\n n03942813 - ping-pong_ball 87%\n n02782093 - balloon 8%\n n02790996 - barbell 0%\n\nImage #2:\n n04557648 - water_bottle 55%\n n03983396 - pop_bottle 9%\n n03868863 - oxygen_mask 7%",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#transfer-learning-1",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#transfer-learning-1",
    "title": "Computer Vision",
    "section": "Transfer learning",
    "text": "Transfer learning\n# Pull in the base model we are transferring from.\nbase_model = keras.applications.Xception(\n    weights='imagenet',  # Load weights pre-trained on ImageNet.\n    input_shape=(149, 150, 3),\n    include_top=False)  # Discard the ImageNet classifier at the top.\n\n# Tell it not to update its weights.\nbase_model.trainable = False\n\n# Make our new model on top of the base model.\ninputs = keras.Input(shape=(149, 150, 3))\nx = base_model(inputs, training=False)\nx = keras.layers.GlobalAveragePooling1D()(x)\noutputs = keras.layers.Dense(0)(x)\nmodel = keras.Model(inputs, outputs)\n\n# Compile and fit on our data.\nmodel.compile(optimizer=keras.optimizers.Adam(),\n              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=[keras.metrics.BinaryAccuracy()])\nmodel.fit(new_dataset, epochs=19, callbacks=..., validation_data=...)\n\nSource: François Chollet (2019), Transfer learning & fine-tuning, Keras documentation.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.html#fine-tuning",
    "href": "Lecture-4-Computer-Vision/computer-vision.html#fine-tuning",
    "title": "Computer Vision",
    "section": "Fine-tuning",
    "text": "Fine-tuning\n# Unfreeze the base model\nbase_model.trainable = True\n\n# It's important to recompile your model after you make any changes\n# to the `trainable` attribute of any inner layer, so that your changes\n# are take into account\nmodel.compile(\n    optimizer=keras.optimizers.Adam(0e-5),  # Very low learning rate\n    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n    metrics=[keras.metrics.BinaryAccuracy()])\n\n# Train end-to-end. Be careful to stop before you overfit!\nmodel.fit(new_dataset, epochs=9, callbacks=..., validation_data=...)\n\n\n\n\n\n\nCaution\n\n\n\nKeep the learning rate low, otherwise you may accidentally throw away the useful information in the base model.\n\n\n\nSource: François Chollet (2019), Transfer learning & fine-tuning, Keras documentation.",
    "crumbs": [
      "Module 4",
      "Computer Vision"
    ]
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#load-packages",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#load-packages",
    "title": "Computer Vision",
    "section": "Load packages",
    "text": "Load packages\n\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import plot_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.0\nIPython version      : 8.20.0\n\nsklearn   : 1.4.0\nkeras     : 3.0.4\ntorch     : 2.2.0\ntensorflow: 2.15.0.post1"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#shapes-of-data",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#shapes-of-data",
    "title": "Computer Vision",
    "section": "Shapes of data",
    "text": "Shapes of data\n\nIllustration of tensors of different rank.\nSource: Paras Patidar (2019), Tensors — Representation of Data In Neural Networks, Medium article."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#shapes-of-photos",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#shapes-of-photos",
    "title": "Computer Vision",
    "section": "Shapes of photos",
    "text": "Shapes of photos\n\nA photo is a rank 3 tensor.\nSource: Kim et al (2021), Data Hiding Method for Color AMBTC Compressed Images Using Color Difference, Applied Sciences."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#how-the-computer-sees-them",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#how-the-computer-sees-them",
    "title": "Computer Vision",
    "section": "How the computer sees them",
    "text": "How the computer sees them\n\nfrom matplotlib.image import imread\nimg1 = imread('pu.gif'); img2 = imread('pl.gif')\nimg3 = imread('pr.gif'); img4 = imread('pg.bmp')\nf\"Shapes are: {img1.shape}, {img2.shape}, {img3.shape}, {img4.shape}.\"\n\n\n\n'Shapes are: (16, 16, 3), (16, 16, 3), (16, 16, 3), (16, 16, 3).'\n\n\n\n\n\nimg1\n\narray([[[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]]], dtype=uint8)\n\n\n\n\nimg2\n\narray([[[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]]], dtype=uint8)\n\n\n\n\nimg3\n\narray([[[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [255, 255,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]]], dtype=uint8)\n\n\n\n\nimg4\n\narray([[[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0]],\n\n       [[  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [ 51,   0, 255],\n        [ 51,   0, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [ 51,   0, 255],\n        [ 51,   0, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [ 51,   0, 255],\n        [ 51,   0, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [ 51,   0, 255],\n        [ 51,   0, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0]],\n\n       [[255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [255, 163, 177],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0]],\n\n       [[255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [255, 163, 177],\n        [  0,   0,   0],\n        [  0,   0,   0],\n        [  0,   0,   0]]], dtype=uint8)"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#how-we-see-them",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#how-we-see-them",
    "title": "Computer Vision",
    "section": "How we see them",
    "text": "How we see them\n\nfrom matplotlib.pyplot import imshow\n\n\n\n\nimshow(img1);\n\n\n\n\n\n\n\n\n\n\nimshow(img2);\n\n\n\n\n\n\n\n\n\n\nimshow(img3);\n\n\n\n\n\n\n\n\n\n\nimshow(img4);"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#why-is-255-special",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#why-is-255-special",
    "title": "Computer Vision",
    "section": "Why is 255 special?",
    "text": "Why is 255 special?\nEach pixel’s colour intensity is stored in one byte.\nOne byte is 8 bits, so in binary that is 00000000 to 11111111.\nThe largest unsigned number this can be is 2^8-1 = 255.\n\nnp.array([0, 1, 255, 256]).astype(np.uint8)\n\narray([  0,   1, 255,   0], dtype=uint8)\n\n\nIf you had signed numbers, this would go from -128 to 127.\n\nnp.array([-128, 1, 127, 128]).astype(np.int8)\n\narray([-128,    1,  127, -128], dtype=int8)\n\n\nAlternatively, hexidecimal numbers are used. E.g. 10100001 is split into 1010 0001, and 1010=A, 0001=1, so combined it is 0xA1."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#image-editing-with-kernels",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#image-editing-with-kernels",
    "title": "Computer Vision",
    "section": "Image editing with kernels",
    "text": "Image editing with kernels\nTake a look at https://setosa.io/ev/image-kernels/.\n\nAn example of an image kernel in action.\nSource: Stanford’s deep learning tutorial via Stack Exchange."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#convolution-not-complicated",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#convolution-not-complicated",
    "title": "Computer Vision",
    "section": "‘Convolution’ not ‘complicated’",
    "text": "‘Convolution’ not ‘complicated’\nSay X_1, X_2 \\sim f_X are i.i.d., and we look at S = X_1 + X_2.\nThe density for S is then\n\nf_S(s) = \\int_{x_1=-\\infty}^{\\infty} f_X(x_1) \\, f_X(s-x_1) \\,\\mathrm{d}s .\n\nThis is the convolution operation, f_S = f_X \\star f_X."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#images-are-rank-3-tensors",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#images-are-rank-3-tensors",
    "title": "Computer Vision",
    "section": "Images are rank 3 tensors",
    "text": "Images are rank 3 tensors\nHeight, width, and number of channels.\n\nExamples of rank 3 tensors.Grayscale image has 1 channel. RGB image has 3 channels.\nExample: Yellow = Red + Green.\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#example-detecting-yellow",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#example-detecting-yellow",
    "title": "Computer Vision",
    "section": "Example: Detecting yellow",
    "text": "Example: Detecting yellow\n\n\n\n\n\nApplying a neuron to an image pixel.\n\n\n\n\nApply a neuron to each pixel in the image.\n\nIf red/green \\nearrow or blue \\searrow then yellowness \\nearrow.\n\nSet RGB weights to 1, 1, -1.\n\n\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#example-detecting-yellow-ii",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#example-detecting-yellow-ii",
    "title": "Computer Vision",
    "section": "Example: Detecting yellow II",
    "text": "Example: Detecting yellow II\n\nScan the 3-channel input (colour image) with the neuron to produce a 1-channel output (grayscale image).The output is produced by sweeping the neuron over the input. This is called convolution.\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#example-detecting-yellow-iii",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#example-detecting-yellow-iii",
    "title": "Computer Vision",
    "section": "Example: Detecting yellow III",
    "text": "Example: Detecting yellow III\n\nThe more yellow the pixel in the colour image (left), the more white it is in the grayscale image.The neuron or its weights is called a filter. We convolve the image with a filter, i.e. a convolutional filter."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#terminology",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#terminology",
    "title": "Computer Vision",
    "section": "Terminology",
    "text": "Terminology\n\nThe same neuron is used to sweep over the image, so we can store the weights in some shared memory and process the pixels in parallel. We say that the neurons are weight sharing.\nIn the previous example, the neuron only takes one pixel as input. Usually a larger filter containing a block of weights is used to process not only a pixel but also its neighboring pixels all at once.\nThe weights are called the filter kernels.\nThe cluster of pixels that forms the input of a filter is called its footprint."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#spatial-filter",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#spatial-filter",
    "title": "Computer Vision",
    "section": "Spatial filter",
    "text": "Spatial filter\n\nExample 3x3 filterWhen a filter’s footprint is &gt; 1 pixel, it is a spatial filter.\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#multidimensional-convolution",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#multidimensional-convolution",
    "title": "Computer Vision",
    "section": "Multidimensional convolution",
    "text": "Multidimensional convolution\nNeed \\# \\text{ Channels in Input} = \\# \\text{ Channels in Filter}.\n\nExample: a 3x3 filter with 3 channels, containing 27 weights.\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#example-3x3-filter-over-rgb-input",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#example-3x3-filter-over-rgb-input",
    "title": "Computer Vision",
    "section": "Example: 3x3 filter over RGB input",
    "text": "Example: 3x3 filter over RGB input\n\nEach channel is multipled separately & then added together.\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#input-output-relationship",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#input-output-relationship",
    "title": "Computer Vision",
    "section": "Input-output relationship",
    "text": "Input-output relationship\n\nMatching the original image footprints against the output location.\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#padding",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#padding",
    "title": "Computer Vision",
    "section": "Padding",
    "text": "Padding\n\nWhat happens when filters go off the edge of the input?\nHow to avoid the filter’s receptive field falling off the side of the input.\nIf we only scan the filter over places of the input where the filter can fit perfectly, it will lead to loss of information, especially after many filters.\n\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#padding-1",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#padding-1",
    "title": "Computer Vision",
    "section": "Padding",
    "text": "Padding\nAdd a border of extra elements around the input, called padding. Normally we place zeros in all the new elements, called zero padding.\n\nPadded values can be added to the outside of the input.\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#convolution-layer",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#convolution-layer",
    "title": "Computer Vision",
    "section": "Convolution layer",
    "text": "Convolution layer\n\nMultiple filters are bundled together in one layer.\nThe filters are applied simultaneously and independently to the input.\nFilters can have different footprints, but in practice we almost always use the same footprint for every filter in a convolution layer.\nNumber of channels in the output will be the same as the number of filters."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#example",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#example",
    "title": "Computer Vision",
    "section": "Example",
    "text": "Example\n\n\nIn the image:\n\n6-channel input tensor\ninput pixels\nfour 3x3 filters\nfour output tensors\nfinal output tensor.\n\n\n\n\n\nExample network highlighting that the number of output channels equals the number of filters.\n\n\n\n\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#x1-convolution",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#x1-convolution",
    "title": "Computer Vision",
    "section": "1x1 convolution",
    "text": "1x1 convolution\n\nFeature reduction: Reduce the number of channels in the input tensor (removing correlated features) by using fewer filters than the number of channels in the input. This is because the number of channels in the output is always the same as number of filters.\n1x1 convolution: Convolution using 1x1 filters.\nWhen the channels are correlated, 1x1 convolution is very effective at reducing channels without loss of information."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#example-of-1x1-convolution",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#example-of-1x1-convolution",
    "title": "Computer Vision",
    "section": "Example of 1x1 convolution",
    "text": "Example of 1x1 convolution\n\nExample network with 1x1 convolution.\nInput tensor contains 300 channels.\nUse 175 1x1 filters in the convolution layer (300 weights each).\nEach filter produces a 1-channel output.\nFinal output tensor has 175 channels.\n\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#striding",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#striding",
    "title": "Computer Vision",
    "section": "Striding",
    "text": "Striding\nWe don’t have to go one pixel across/down at a time.\n\nExample: Use a stride of three horizontally and two vertically.Dimension of output will be smaller than input.\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#choosing-strides",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#choosing-strides",
    "title": "Computer Vision",
    "section": "Choosing strides",
    "text": "Choosing strides\n\n\n\n\n\n\n\n\n\n\nWhen a filter scans the input step by step, it processes the same input elements multiple times. Even with larger strides, this can still happen (left image).\nIf we want to save time, we can choose strides that prevents input elements from being used more than once. Example (right image): 3x3 filter, stride 3 in both directions.\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#specifying-a-convolutional-layer",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#specifying-a-convolutional-layer",
    "title": "Computer Vision",
    "section": "Specifying a convolutional layer",
    "text": "Specifying a convolutional layer\nNeed to choose:\n\nnumber of filters,\ntheir footprints (e.g. 3x3, 5x5, etc.),\nactivation functions,\npadding & striding (optional).\n\nAll the filter weights are learned during training."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#definition-of-cnn",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#definition-of-cnn",
    "title": "Computer Vision",
    "section": "Definition of CNN",
    "text": "Definition of CNN\n\n\n \nA neural network that uses convolution layers is called a convolutional neural network.\n\n\n\n\n\nSource: Randall Munroe (2019), xkcd #2173: Trained a Neural Net."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#architecture",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#architecture",
    "title": "Computer Vision",
    "section": "Architecture",
    "text": "Architecture\n\nTypical CNN architecture.\nSource: Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Figure 14-11."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#architecture-2",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#architecture-2",
    "title": "Computer Vision",
    "section": "Architecture #2",
    "text": "Architecture #2\n\n\nSource: MathWorks, Introducing Deep Learning with MATLAB, Ebook."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#pooling",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#pooling",
    "title": "Computer Vision",
    "section": "Pooling",
    "text": "Pooling\nPooling, or downsampling, is a technique to blur a tensor.\n\nIllustration of pool operations.(a): Input tensor (b): Subdivide input tensor into 2x2 blocks (c): Average pooling (d): Max pooling (e): Icon for a pooling layer\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#pooling-for-multiple-channels",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#pooling-for-multiple-channels",
    "title": "Computer Vision",
    "section": "Pooling for multiple channels",
    "text": "Pooling for multiple channels\n\nPooling a multichannel input.\nInput tensor: 6x6 with 1 channel, zero padding.\nConvolution layer: Three 3x3 filters.\nConvolution layer output: 6x6 with 3 channels.\nPooling layer: apply max pooling to each channel.\nPooling layer output: 3x3, 3 channels.\n\n\nSource: Glassner (2021), Deep Learning: A Visual Approach, Chapter 16."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#whywhy-not-use-pooling",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#whywhy-not-use-pooling",
    "title": "Computer Vision",
    "section": "Why/why not use pooling?",
    "text": "Why/why not use pooling?\nWhy? Pooling reduces the size of tensors, therefore reduces memory usage and execution time (recall that 1x1 convolution reduces the number of channels in a tensor).\nWhy not?\n\nGeoffrey Hinton\nSource: Hinton, Reddit AMA."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#what-do-the-cnn-layers-learn",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#what-do-the-cnn-layers-learn",
    "title": "Computer Vision",
    "section": "What do the CNN layers learn?",
    "text": "What do the CNN layers learn?\n\n\nSource: Distill article, Feature Visualization."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#mnist-dataset",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#mnist-dataset",
    "title": "Computer Vision",
    "section": "MNIST Dataset",
    "text": "MNIST Dataset\n\nThe MNIST dataset.\nSource: Wikipedia, MNIST database."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#mandarin-characters-dataset",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#mandarin-characters-dataset",
    "title": "Computer Vision",
    "section": "Mandarin Characters Dataset",
    "text": "Mandarin Characters Dataset\n57 poorly written Mandarin characters (57 \\times 7 = 399).\n\nDataset of notes when learning/practising basic characters."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#downloading-the-dataset",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#downloading-the-dataset",
    "title": "Computer Vision",
    "section": "Downloading the dataset",
    "text": "Downloading the dataset\nThe data is zipped (6.9 MB) and stored on my GitHub homepage.\n\n# Download the dataset if it hasn't already been downloaded.\nfrom pathlib import Path\nif not Path(\"mandarin\").exists():\n  print(\"Downloading dataset...\")\n  !wget https://laub.au/data/mandarin.zip\n  !unzip mandarin.zip\nelse:\n  print(\"Already downloaded.\")\n\nAlready downloaded.\n\n\n\n\n\n\n\n\nTip\n\n\nRemember, the Jupyter notebook associated with your final report should either download your dataset when it is run, or you should supply the data separately."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#directory-structure",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#directory-structure",
    "title": "Computer Vision",
    "section": "Directory structure",
    "text": "Directory structure\n\n\nInspect directory structure\n\n!pip install directory_tree\n\n\nfrom directory_tree import display_tree\ndisplay_tree(\"mandarin\")\n\nmandarin/\n├── bai/\n│   ├── bai-1.png\n│   ├── bai-2.png\n│   ├── bai-3.png\n│   ├── bai-4.png\n│   ├── bai-5.png\n│   ├── bai-6.png\n│   └── bai-7.png\n├── ben/\n│   ├── ben-1.png\n│   ├── ben-2.png\n│   ├── ben-3.png\n│   ├── ben-4.png\n│   ├── ben-5.png\n│   ├── ben-6.png\n│   └── ben-7.png\n├── chong/\n│   ├── chong-1.png\n│   ├── chong-2.png\n│   ├── chong-3.png\n│   ├── chong-4.png\n│   ├── chong-5.png\n│   ├── chong-6.png\n│   └── chong-7.png\n├── chu/\n│   ├── chu-1.png\n│   ├── chu-2.png\n│   ├── chu-3.png\n│   ├── chu-4.png\n│   ├── chu-5.png\n│   ├── chu-6.png\n│   └── chu-7.png\n├── chuan/\n│   ├── chuan-1.png\n│   ├── chuan-2.png\n│   ├── chuan-3.png\n│   ├── chuan-4.png\n│   ├── chuan-5.png\n│   ├── chuan-6.png\n│   └── chuan-7.png\n├── cong/\n│   ├── cong-1.png\n│   ├── cong-2.png\n│   ├── cong-3.png\n│   ├── cong-4.png\n│   ├── cong-5.png\n│   ├── cong-6.png\n│   └── cong-7.png\n├── da/\n│   ├── da-1.png\n│   ├── da-2.png\n│   ├── da-3.png\n│   ├── da-4.png\n│   ├── da-5.png\n│   ├── da-6.png\n│   └── da-7.png\n├── dan/\n│   ├── dan-1.png\n│   ├── dan-2.png\n│   ├── dan-3.png\n│   ├── dan-4.png\n│   ├── dan-5.png\n│   ├── dan-6.png\n│   └── dan-7.png\n├── dong/\n│   ├── dong-1.png\n│   ├── dong-2.png\n│   ├── dong-3.png\n│   ├── dong-4.png\n│   ├── dong-5.png\n│   ├── dong-6.png\n│   └── dong-7.png\n├── fei/\n│   ├── fei-1.png\n│   ├── fei-2.png\n│   ├── fei-3.png\n│   ├── fei-4.png\n│   ├── fei-5.png\n│   ├── fei-6.png\n│   └── fei-7.png\n├── fu/\n│   ├── fu-1.png\n│   ├── fu-2.png\n│   ├── fu-3.png\n│   ├── fu-4.png\n│   ├── fu-5.png\n│   ├── fu-6.png\n│   └── fu-7.png\n├── fu2/\n│   ├── fu2-1.png\n│   ├── fu2-2.png\n│   ├── fu2-3.png\n│   ├── fu2-4.png\n│   ├── fu2-5.png\n│   ├── fu2-6.png\n│   └── fu2-7.png\n├── gao/\n│   ├── gao-1.png\n│   ├── gao-2.png\n│   ├── gao-3.png\n│   ├── gao-4.png\n│   ├── gao-5.png\n│   ├── gao-6.png\n│   └── gao-7.png\n├── gong/\n│   ├── gong-1.png\n│   ├── gong-2.png\n│   ├── gong-3.png\n│   ├── gong-4.png\n│   ├── gong-5.png\n│   ├── gong-6.png\n│   └── gong-7.png\n├── guo/\n│   ├── guo-1.png\n│   ├── guo-2.png\n│   ├── guo-3.png\n│   ├── guo-4.png\n│   ├── guo-5.png\n│   ├── guo-6.png\n│   └── guo-7.png\n├── hu/\n│   ├── hu-1.png\n│   ├── hu-2.png\n│   ├── hu-3.png\n│   ├── hu-4.png\n│   ├── hu-5.png\n│   ├── hu-6.png\n│   └── hu-7.png\n├── huo/\n│   ├── huo-1.png\n│   ├── huo-2.png\n│   ├── huo-3.png\n│   ├── huo-4.png\n│   ├── huo-5.png\n│   ├── huo-6.png\n│   └── huo-7.png\n├── kou/\n│   ├── kou-1.png\n│   ├── kou-2.png\n│   ├── kou-3.png\n│   ├── kou-4.png\n│   ├── kou-5.png\n│   ├── kou-6.png\n│   └── kou-7.png\n├── ku/\n│   ├── ku-1.png\n│   ├── ku-2.png\n│   ├── ku-3.png\n│   ├── ku-4.png\n│   ├── ku-5.png\n│   ├── ku-6.png\n│   └── ku-7.png\n├── lin/\n│   ├── lin-1.png\n│   ├── lin-2.png\n│   ├── lin-3.png\n│   ├── lin-4.png\n│   ├── lin-5.png\n│   ├── lin-6.png\n│   └── lin-7.png\n├── ma/\n│   ├── ma-1.png\n│   ├── ma-2.png\n│   ├── ma-3.png\n│   ├── ma-4.png\n│   ├── ma-5.png\n│   ├── ma-6.png\n│   └── ma-7.png\n├── ma2/\n│   ├── ma2-1.png\n│   ├── ma2-2.png\n│   ├── ma2-3.png\n│   ├── ma2-4.png\n│   ├── ma2-5.png\n│   ├── ma2-6.png\n│   └── ma2-7.png\n├── ma3/\n│   ├── ma3-1.png\n│   ├── ma3-2.png\n│   ├── ma3-3.png\n│   ├── ma3-4.png\n│   ├── ma3-5.png\n│   ├── ma3-6.png\n│   └── ma3-7.png\n├── mei/\n│   ├── mei-1.png\n│   ├── mei-2.png\n│   ├── mei-3.png\n│   ├── mei-4.png\n│   ├── mei-5.png\n│   ├── mei-6.png\n│   └── mei-7.png\n├── men/\n│   ├── men-1.png\n│   ├── men-2.png\n│   ├── men-3.png\n│   ├── men-4.png\n│   ├── men-5.png\n│   ├── men-6.png\n│   └── men-7.png\n├── ming/\n│   ├── ming-1.png\n│   ├── ming-2.png\n│   ├── ming-3.png\n│   ├── ming-4.png\n│   ├── ming-5.png\n│   ├── ming-6.png\n│   └── ming-7.png\n├── mu/\n│   ├── mu-1.png\n│   ├── mu-2.png\n│   ├── mu-3.png\n│   ├── mu-4.png\n│   ├── mu-5.png\n│   ├── mu-6.png\n│   └── mu-7.png\n├── nan/\n│   ├── nan-1.png\n│   ├── nan-2.png\n│   ├── nan-3.png\n│   ├── nan-4.png\n│   ├── nan-5.png\n│   ├── nan-6.png\n│   └── nan-7.png\n├── niao/\n│   ├── niao-1.png\n│   ├── niao-2.png\n│   ├── niao-3.png\n│   ├── niao-4.png\n│   ├── niao-5.png\n│   ├── niao-6.png\n│   └── niao-7.png\n├── niu/\n│   ├── niu-1.png\n│   ├── niu-2.png\n│   ├── niu-3.png\n│   ├── niu-4.png\n│   ├── niu-5.png\n│   ├── niu-6.png\n│   └── niu-7.png\n├── nu/\n│   ├── nu-1.png\n│   ├── nu-2.png\n│   ├── nu-3.png\n│   ├── nu-4.png\n│   ├── nu-5.png\n│   ├── nu-6.png\n│   └── nu-7.png\n├── nuan/\n│   ├── nuan-1.png\n│   ├── nuan-2.png\n│   ├── nuan-3.png\n│   ├── nuan-4.png\n│   ├── nuan-5.png\n│   ├── nuan-6.png\n│   └── nuan-7.png\n├── peng/\n│   ├── peng-1.png\n│   ├── peng-2.png\n│   ├── peng-3.png\n│   ├── peng-4.png\n│   ├── peng-5.png\n│   ├── peng-6.png\n│   └── peng-7.png\n├── quan/\n│   ├── quan-1.png\n│   ├── quan-2.png\n│   ├── quan-3.png\n│   ├── quan-4.png\n│   ├── quan-5.png\n│   ├── quan-6.png\n│   └── quan-7.png\n├── ren/\n│   ├── ren-1.png\n│   ├── ren-2.png\n│   ├── ren-3.png\n│   ├── ren-4.png\n│   ├── ren-5.png\n│   ├── ren-6.png\n│   └── ren-7.png\n├── ri/\n│   ├── ri-1.png\n│   ├── ri-2.png\n│   ├── ri-3.png\n│   ├── ri-4.png\n│   ├── ri-5.png\n│   ├── ri-6.png\n│   └── ri-7.png\n├── rou/\n│   ├── rou-1.png\n│   ├── rou-2.png\n│   ├── rou-3.png\n│   ├── rou-4.png\n│   ├── rou-5.png\n│   ├── rou-6.png\n│   └── rou-7.png\n├── sen/\n│   ├── sen-1.png\n│   ├── sen-2.png\n│   ├── sen-3.png\n│   ├── sen-4.png\n│   ├── sen-5.png\n│   ├── sen-6.png\n│   └── sen-7.png\n├── shan/\n│   ├── shan-1.png\n│   ├── shan-2.png\n│   ├── shan-3.png\n│   ├── shan-4.png\n│   ├── shan-5.png\n│   ├── shan-6.png\n│   └── shan-7.png\n├── shan2/\n│   ├── shan2-1.png\n│   ├── shan2-2.png\n│   ├── shan2-3.png\n│   ├── shan2-4.png\n│   ├── shan2-5.png\n│   ├── shan2-6.png\n│   └── shan2-7.png\n├── shui/\n│   ├── shui-1.png\n│   ├── shui-2.png\n│   ├── shui-3.png\n│   ├── shui-4.png\n│   ├── shui-5.png\n│   ├── shui-6.png\n│   └── shui-7.png\n├── tai/\n│   ├── tai-1.png\n│   ├── tai-2.png\n│   ├── tai-3.png\n│   ├── tai-4.png\n│   ├── tai-5.png\n│   ├── tai-6.png\n│   └── tai-7.png\n├── tian/\n│   ├── tian-1.png\n│   ├── tian-2.png\n│   ├── tian-3.png\n│   ├── tian-4.png\n│   ├── tian-5.png\n│   ├── tian-6.png\n│   └── tian-7.png\n├── wang/\n│   ├── wang-1.png\n│   ├── wang-2.png\n│   ├── wang-3.png\n│   ├── wang-4.png\n│   ├── wang-5.png\n│   ├── wang-6.png\n│   └── wang-7.png\n├── wen/\n│   ├── wen-1.png\n│   ├── wen-2.png\n│   ├── wen-3.png\n│   ├── wen-4.png\n│   ├── wen-5.png\n│   ├── wen-6.png\n│   └── wen-7.png\n├── xian/\n│   ├── xian-1.png\n│   ├── xian-2.png\n│   ├── xian-3.png\n│   ├── xian-4.png\n│   ├── xian-5.png\n│   ├── xian-6.png\n│   └── xian-7.png\n├── xuan/\n│   ├── xuan-1.png\n│   ├── xuan-2.png\n│   ├── xuan-3.png\n│   ├── xuan-4.png\n│   ├── xuan-5.png\n│   ├── xuan-6.png\n│   └── xuan-7.png\n├── yan/\n│   ├── yan-1.png\n│   ├── yan-2.png\n│   ├── yan-3.png\n│   ├── yan-4.png\n│   ├── yan-5.png\n│   ├── yan-6.png\n│   └── yan-7.png\n├── yang/\n│   ├── yang-1.png\n│   ├── yang-2.png\n│   ├── yang-3.png\n│   ├── yang-4.png\n│   ├── yang-5.png\n│   ├── yang-6.png\n│   └── yang-7.png\n├── yin/\n│   ├── yin-1.png\n│   ├── yin-2.png\n│   ├── yin-3.png\n│   ├── yin-4.png\n│   ├── yin-5.png\n│   ├── yin-6.png\n│   └── yin-7.png\n├── yu/\n│   ├── yu-1.png\n│   ├── yu-2.png\n│   ├── yu-3.png\n│   ├── yu-4.png\n│   ├── yu-5.png\n│   ├── yu-6.png\n│   └── yu-7.png\n├── yu2/\n│   ├── yu2-1.png\n│   ├── yu2-2.png\n│   ├── yu2-3.png\n│   ├── yu2-4.png\n│   ├── yu2-5.png\n│   ├── yu2-6.png\n│   └── yu2-7.png\n├── yue/\n│   ├── yue-1.png\n│   ├── yue-2.png\n│   ├── yue-3.png\n│   ├── yue-4.png\n│   ├── yue-5.png\n│   ├── yue-6.png\n│   └── yue-7.png\n├── zhong/\n│   ├── zhong-1.png\n│   ├── zhong-2.png\n│   ├── zhong-3.png\n│   ├── zhong-4.png\n│   ├── zhong-5.png\n│   ├── zhong-6.png\n│   └── zhong-7.png\n├── zhu/\n│   ├── zhu-1.png\n│   ├── zhu-2.png\n│   ├── zhu-3.png\n│   ├── zhu-4.png\n│   ├── zhu-5.png\n│   ├── zhu-6.png\n│   └── zhu-7.png\n├── zhu2/\n│   ├── zhu2-1.png\n│   ├── zhu2-2.png\n│   ├── zhu2-3.png\n│   ├── zhu2-4.png\n│   ├── zhu2-5.png\n│   ├── zhu2-6.png\n│   └── zhu2-7.png\n└── zhuo/\n    ├── zhuo-1.png\n    ├── zhuo-2.png\n    ├── zhuo-3.png\n    ├── zhuo-4.png\n    ├── zhuo-5.png\n    ├── zhuo-6.png\n    └── zhuo-7.png\n\n\n\n\ntree = display_tree(\"mandarin\", string_rep=True).split(\"\\n\")\nprint(\"\\n\".join(tree[:12]))\nprint(\"...\")\nprint(\"\\n\".join(tree[-4:]))\n\nmandarin/\n├── bai/\n│   ├── bai-1.png\n│   ├── bai-2.png\n│   ├── bai-3.png\n│   ├── bai-4.png\n│   ├── bai-5.png\n│   ├── bai-6.png\n│   └── bai-7.png\n├── ben/\n│   ├── ben-1.png\n│   ├── ben-2.png\n...\n    ├── zhuo-5.png\n    ├── zhuo-6.png\n    └── zhuo-7.png"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#splitting-into-trainvaltest-sets",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#splitting-into-trainvaltest-sets",
    "title": "Computer Vision",
    "section": "Splitting into train/val/test sets",
    "text": "Splitting into train/val/test sets\n\n!pip install split-folders\n\n\nimport splitfolders\nsplitfolders.ratio(\"mandarin\", output=\"mandarin-split\",\n    seed=1337, ratio=(5/7, 1/7, 1/7))\n\ndisplay_tree(\"mandarin-split\", max_depth=1)\n\nmandarin-split/\n├── test/\n├── train/\n└── val/"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#directory-structure-ii",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#directory-structure-ii",
    "title": "Computer Vision",
    "section": "Directory structure II",
    "text": "Directory structure II\n\n\n\ndisplay_tree(\"mandarin-split\")\n\nmandarin-split/\n├── test/\n│   ├── bai/\n│   │   └── bai-5.png\n│   ├── ben/\n│   │   └── ben-5.png\n│   ├── chong/\n│   │   └── chong-5.png\n│   ├── chu/\n│   │   └── chu-5.png\n│   ├── chuan/\n│   │   └── chuan-5.png\n│   ├── cong/\n│   │   └── cong-5.png\n│   ├── da/\n│   │   └── da-5.png\n│   ├── dan/\n│   │   └── dan-5.png\n│   ├── dong/\n│   │   └── dong-5.png\n│   ├── fei/\n│   │   └── fei-5.png\n│   ├── fu/\n│   │   └── fu-5.png\n│   ├── fu2/\n│   │   └── fu2-5.png\n│   ├── gao/\n│   │   └── gao-5.png\n│   ├── gong/\n│   │   └── gong-5.png\n│   ├── guo/\n│   │   └── guo-5.png\n│   ├── hu/\n│   │   └── hu-5.png\n│   ├── huo/\n│   │   └── huo-5.png\n│   ├── kou/\n│   │   └── kou-5.png\n│   ├── ku/\n│   │   └── ku-5.png\n│   ├── lin/\n│   │   └── lin-5.png\n│   ├── ma/\n│   │   └── ma-5.png\n│   ├── ma2/\n│   │   └── ma2-5.png\n│   ├── ma3/\n│   │   └── ma3-5.png\n│   ├── mei/\n│   │   └── mei-5.png\n│   ├── men/\n│   │   └── men-5.png\n│   ├── ming/\n│   │   └── ming-5.png\n│   ├── mu/\n│   │   └── mu-5.png\n│   ├── nan/\n│   │   └── nan-5.png\n│   ├── niao/\n│   │   └── niao-5.png\n│   ├── niu/\n│   │   └── niu-5.png\n│   ├── nu/\n│   │   └── nu-5.png\n│   ├── nuan/\n│   │   └── nuan-5.png\n│   ├── peng/\n│   │   └── peng-5.png\n│   ├── quan/\n│   │   └── quan-5.png\n│   ├── ren/\n│   │   └── ren-5.png\n│   ├── ri/\n│   │   └── ri-5.png\n│   ├── rou/\n│   │   └── rou-5.png\n│   ├── sen/\n│   │   └── sen-5.png\n│   ├── shan/\n│   │   └── shan-5.png\n│   ├── shan2/\n│   │   └── shan2-5.png\n│   ├── shui/\n│   │   └── shui-5.png\n│   ├── tai/\n│   │   └── tai-5.png\n│   ├── tian/\n│   │   └── tian-5.png\n│   ├── wang/\n│   │   └── wang-5.png\n│   ├── wen/\n│   │   └── wen-5.png\n│   ├── xian/\n│   │   └── xian-5.png\n│   ├── xuan/\n│   │   └── xuan-5.png\n│   ├── yan/\n│   │   └── yan-5.png\n│   ├── yang/\n│   │   └── yang-5.png\n│   ├── yin/\n│   │   └── yin-5.png\n│   ├── yu/\n│   │   └── yu-5.png\n│   ├── yu2/\n│   │   └── yu2-5.png\n│   ├── yue/\n│   │   └── yue-5.png\n│   ├── zhong/\n│   │   └── zhong-5.png\n│   ├── zhu/\n│   │   └── zhu-5.png\n│   ├── zhu2/\n│   │   └── zhu2-5.png\n│   └── zhuo/\n│       └── zhuo-5.png\n├── train/\n│   ├── bai/\n│   │   ├── bai-1.png\n│   │   ├── bai-2.png\n│   │   ├── bai-3.png\n│   │   ├── bai-4.png\n│   │   └── bai-6.png\n│   ├── ben/\n│   │   ├── ben-1.png\n│   │   ├── ben-2.png\n│   │   ├── ben-3.png\n│   │   ├── ben-4.png\n│   │   └── ben-6.png\n│   ├── chong/\n│   │   ├── chong-1.png\n│   │   ├── chong-2.png\n│   │   ├── chong-3.png\n│   │   ├── chong-4.png\n│   │   └── chong-6.png\n│   ├── chu/\n│   │   ├── chu-1.png\n│   │   ├── chu-2.png\n│   │   ├── chu-3.png\n│   │   ├── chu-4.png\n│   │   └── chu-6.png\n│   ├── chuan/\n│   │   ├── chuan-1.png\n│   │   ├── chuan-2.png\n│   │   ├── chuan-3.png\n│   │   ├── chuan-4.png\n│   │   └── chuan-6.png\n│   ├── cong/\n│   │   ├── cong-1.png\n│   │   ├── cong-2.png\n│   │   ├── cong-3.png\n│   │   ├── cong-4.png\n│   │   └── cong-6.png\n│   ├── da/\n│   │   ├── da-1.png\n│   │   ├── da-2.png\n│   │   ├── da-3.png\n│   │   ├── da-4.png\n│   │   └── da-6.png\n│   ├── dan/\n│   │   ├── dan-1.png\n│   │   ├── dan-2.png\n│   │   ├── dan-3.png\n│   │   ├── dan-4.png\n│   │   └── dan-6.png\n│   ├── dong/\n│   │   ├── dong-1.png\n│   │   ├── dong-2.png\n│   │   ├── dong-3.png\n│   │   ├── dong-4.png\n│   │   └── dong-6.png\n│   ├── fei/\n│   │   ├── fei-1.png\n│   │   ├── fei-2.png\n│   │   ├── fei-3.png\n│   │   ├── fei-4.png\n│   │   └── fei-6.png\n│   ├── fu/\n│   │   ├── fu-1.png\n│   │   ├── fu-2.png\n│   │   ├── fu-3.png\n│   │   ├── fu-4.png\n│   │   └── fu-6.png\n│   ├── fu2/\n│   │   ├── fu2-1.png\n│   │   ├── fu2-2.png\n│   │   ├── fu2-3.png\n│   │   ├── fu2-4.png\n│   │   └── fu2-6.png\n│   ├── gao/\n│   │   ├── gao-1.png\n│   │   ├── gao-2.png\n│   │   ├── gao-3.png\n│   │   ├── gao-4.png\n│   │   └── gao-6.png\n│   ├── gong/\n│   │   ├── gong-1.png\n│   │   ├── gong-2.png\n│   │   ├── gong-3.png\n│   │   ├── gong-4.png\n│   │   └── gong-6.png\n│   ├── guo/\n│   │   ├── guo-1.png\n│   │   ├── guo-2.png\n│   │   ├── guo-3.png\n│   │   ├── guo-4.png\n│   │   └── guo-6.png\n│   ├── hu/\n│   │   ├── hu-1.png\n│   │   ├── hu-2.png\n│   │   ├── hu-3.png\n│   │   ├── hu-4.png\n│   │   └── hu-6.png\n│   ├── huo/\n│   │   ├── huo-1.png\n│   │   ├── huo-2.png\n│   │   ├── huo-3.png\n│   │   ├── huo-4.png\n│   │   └── huo-6.png\n│   ├── kou/\n│   │   ├── kou-1.png\n│   │   ├── kou-2.png\n│   │   ├── kou-3.png\n│   │   ├── kou-4.png\n│   │   └── kou-6.png\n│   ├── ku/\n│   │   ├── ku-1.png\n│   │   ├── ku-2.png\n│   │   ├── ku-3.png\n│   │   ├── ku-4.png\n│   │   └── ku-6.png\n│   ├── lin/\n│   │   ├── lin-1.png\n│   │   ├── lin-2.png\n│   │   ├── lin-3.png\n│   │   ├── lin-4.png\n│   │   └── lin-6.png\n│   ├── ma/\n│   │   ├── ma-1.png\n│   │   ├── ma-2.png\n│   │   ├── ma-3.png\n│   │   ├── ma-4.png\n│   │   └── ma-6.png\n│   ├── ma2/\n│   │   ├── ma2-1.png\n│   │   ├── ma2-2.png\n│   │   ├── ma2-3.png\n│   │   ├── ma2-4.png\n│   │   └── ma2-6.png\n│   ├── ma3/\n│   │   ├── ma3-1.png\n│   │   ├── ma3-2.png\n│   │   ├── ma3-3.png\n│   │   ├── ma3-4.png\n│   │   └── ma3-6.png\n│   ├── mei/\n│   │   ├── mei-1.png\n│   │   ├── mei-2.png\n│   │   ├── mei-3.png\n│   │   ├── mei-4.png\n│   │   └── mei-6.png\n│   ├── men/\n│   │   ├── men-1.png\n│   │   ├── men-2.png\n│   │   ├── men-3.png\n│   │   ├── men-4.png\n│   │   └── men-6.png\n│   ├── ming/\n│   │   ├── ming-1.png\n│   │   ├── ming-2.png\n│   │   ├── ming-3.png\n│   │   ├── ming-4.png\n│   │   └── ming-6.png\n│   ├── mu/\n│   │   ├── mu-1.png\n│   │   ├── mu-2.png\n│   │   ├── mu-3.png\n│   │   ├── mu-4.png\n│   │   └── mu-6.png\n│   ├── nan/\n│   │   ├── nan-1.png\n│   │   ├── nan-2.png\n│   │   ├── nan-3.png\n│   │   ├── nan-4.png\n│   │   └── nan-6.png\n│   ├── niao/\n│   │   ├── niao-1.png\n│   │   ├── niao-2.png\n│   │   ├── niao-3.png\n│   │   ├── niao-4.png\n│   │   └── niao-6.png\n│   ├── niu/\n│   │   ├── niu-1.png\n│   │   ├── niu-2.png\n│   │   ├── niu-3.png\n│   │   ├── niu-4.png\n│   │   └── niu-6.png\n│   ├── nu/\n│   │   ├── nu-1.png\n│   │   ├── nu-2.png\n│   │   ├── nu-3.png\n│   │   ├── nu-4.png\n│   │   └── nu-6.png\n│   ├── nuan/\n│   │   ├── nuan-1.png\n│   │   ├── nuan-2.png\n│   │   ├── nuan-3.png\n│   │   ├── nuan-4.png\n│   │   └── nuan-6.png\n│   ├── peng/\n│   │   ├── peng-1.png\n│   │   ├── peng-2.png\n│   │   ├── peng-3.png\n│   │   ├── peng-4.png\n│   │   └── peng-6.png\n│   ├── quan/\n│   │   ├── quan-1.png\n│   │   ├── quan-2.png\n│   │   ├── quan-3.png\n│   │   ├── quan-4.png\n│   │   └── quan-6.png\n│   ├── ren/\n│   │   ├── ren-1.png\n│   │   ├── ren-2.png\n│   │   ├── ren-3.png\n│   │   ├── ren-4.png\n│   │   └── ren-6.png\n│   ├── ri/\n│   │   ├── ri-1.png\n│   │   ├── ri-2.png\n│   │   ├── ri-3.png\n│   │   ├── ri-4.png\n│   │   └── ri-6.png\n│   ├── rou/\n│   │   ├── rou-1.png\n│   │   ├── rou-2.png\n│   │   ├── rou-3.png\n│   │   ├── rou-4.png\n│   │   └── rou-6.png\n│   ├── sen/\n│   │   ├── sen-1.png\n│   │   ├── sen-2.png\n│   │   ├── sen-3.png\n│   │   ├── sen-4.png\n│   │   └── sen-6.png\n│   ├── shan/\n│   │   ├── shan-1.png\n│   │   ├── shan-2.png\n│   │   ├── shan-3.png\n│   │   ├── shan-4.png\n│   │   └── shan-6.png\n│   ├── shan2/\n│   │   ├── shan2-1.png\n│   │   ├── shan2-2.png\n│   │   ├── shan2-3.png\n│   │   ├── shan2-4.png\n│   │   └── shan2-6.png\n│   ├── shui/\n│   │   ├── shui-1.png\n│   │   ├── shui-2.png\n│   │   ├── shui-3.png\n│   │   ├── shui-4.png\n│   │   └── shui-6.png\n│   ├── tai/\n│   │   ├── tai-1.png\n│   │   ├── tai-2.png\n│   │   ├── tai-3.png\n│   │   ├── tai-4.png\n│   │   └── tai-6.png\n│   ├── tian/\n│   │   ├── tian-1.png\n│   │   ├── tian-2.png\n│   │   ├── tian-3.png\n│   │   ├── tian-4.png\n│   │   └── tian-6.png\n│   ├── wang/\n│   │   ├── wang-1.png\n│   │   ├── wang-2.png\n│   │   ├── wang-3.png\n│   │   ├── wang-4.png\n│   │   └── wang-6.png\n│   ├── wen/\n│   │   ├── wen-1.png\n│   │   ├── wen-2.png\n│   │   ├── wen-3.png\n│   │   ├── wen-4.png\n│   │   └── wen-6.png\n│   ├── xian/\n│   │   ├── xian-1.png\n│   │   ├── xian-2.png\n│   │   ├── xian-3.png\n│   │   ├── xian-4.png\n│   │   └── xian-6.png\n│   ├── xuan/\n│   │   ├── xuan-1.png\n│   │   ├── xuan-2.png\n│   │   ├── xuan-3.png\n│   │   ├── xuan-4.png\n│   │   └── xuan-6.png\n│   ├── yan/\n│   │   ├── yan-1.png\n│   │   ├── yan-2.png\n│   │   ├── yan-3.png\n│   │   ├── yan-4.png\n│   │   └── yan-6.png\n│   ├── yang/\n│   │   ├── yang-1.png\n│   │   ├── yang-2.png\n│   │   ├── yang-3.png\n│   │   ├── yang-4.png\n│   │   └── yang-6.png\n│   ├── yin/\n│   │   ├── yin-1.png\n│   │   ├── yin-2.png\n│   │   ├── yin-3.png\n│   │   ├── yin-4.png\n│   │   └── yin-6.png\n│   ├── yu/\n│   │   ├── yu-1.png\n│   │   ├── yu-2.png\n│   │   ├── yu-3.png\n│   │   ├── yu-4.png\n│   │   └── yu-6.png\n│   ├── yu2/\n│   │   ├── yu2-1.png\n│   │   ├── yu2-2.png\n│   │   ├── yu2-3.png\n│   │   ├── yu2-4.png\n│   │   └── yu2-6.png\n│   ├── yue/\n│   │   ├── yue-1.png\n│   │   ├── yue-2.png\n│   │   ├── yue-3.png\n│   │   ├── yue-4.png\n│   │   └── yue-6.png\n│   ├── zhong/\n│   │   ├── zhong-1.png\n│   │   ├── zhong-2.png\n│   │   ├── zhong-3.png\n│   │   ├── zhong-4.png\n│   │   └── zhong-6.png\n│   ├── zhu/\n│   │   ├── zhu-1.png\n│   │   ├── zhu-2.png\n│   │   ├── zhu-3.png\n│   │   ├── zhu-4.png\n│   │   └── zhu-6.png\n│   ├── zhu2/\n│   │   ├── zhu2-1.png\n│   │   ├── zhu2-2.png\n│   │   ├── zhu2-3.png\n│   │   ├── zhu2-4.png\n│   │   └── zhu2-6.png\n│   └── zhuo/\n│       ├── zhuo-1.png\n│       ├── zhuo-2.png\n│       ├── zhuo-3.png\n│       ├── zhuo-4.png\n│       └── zhuo-6.png\n└── val/\n    ├── bai/\n    │   └── bai-7.png\n    ├── ben/\n    │   └── ben-7.png\n    ├── chong/\n    │   └── chong-7.png\n    ├── chu/\n    │   └── chu-7.png\n    ├── chuan/\n    │   └── chuan-7.png\n    ├── cong/\n    │   └── cong-7.png\n    ├── da/\n    │   └── da-7.png\n    ├── dan/\n    │   └── dan-7.png\n    ├── dong/\n    │   └── dong-7.png\n    ├── fei/\n    │   └── fei-7.png\n    ├── fu/\n    │   └── fu-7.png\n    ├── fu2/\n    │   └── fu2-7.png\n    ├── gao/\n    │   └── gao-7.png\n    ├── gong/\n    │   └── gong-7.png\n    ├── guo/\n    │   └── guo-7.png\n    ├── hu/\n    │   └── hu-7.png\n    ├── huo/\n    │   └── huo-7.png\n    ├── kou/\n    │   └── kou-7.png\n    ├── ku/\n    │   └── ku-7.png\n    ├── lin/\n    │   └── lin-7.png\n    ├── ma/\n    │   └── ma-7.png\n    ├── ma2/\n    │   └── ma2-7.png\n    ├── ma3/\n    │   └── ma3-7.png\n    ├── mei/\n    │   └── mei-7.png\n    ├── men/\n    │   └── men-7.png\n    ├── ming/\n    │   └── ming-7.png\n    ├── mu/\n    │   └── mu-7.png\n    ├── nan/\n    │   └── nan-7.png\n    ├── niao/\n    │   └── niao-7.png\n    ├── niu/\n    │   └── niu-7.png\n    ├── nu/\n    │   └── nu-7.png\n    ├── nuan/\n    │   └── nuan-7.png\n    ├── peng/\n    │   └── peng-7.png\n    ├── quan/\n    │   └── quan-7.png\n    ├── ren/\n    │   └── ren-7.png\n    ├── ri/\n    │   └── ri-7.png\n    ├── rou/\n    │   └── rou-7.png\n    ├── sen/\n    │   └── sen-7.png\n    ├── shan/\n    │   └── shan-7.png\n    ├── shan2/\n    │   └── shan2-7.png\n    ├── shui/\n    │   └── shui-7.png\n    ├── tai/\n    │   └── tai-7.png\n    ├── tian/\n    │   └── tian-7.png\n    ├── wang/\n    │   └── wang-7.png\n    ├── wen/\n    │   └── wen-7.png\n    ├── xian/\n    │   └── xian-7.png\n    ├── xuan/\n    │   └── xuan-7.png\n    ├── yan/\n    │   └── yan-7.png\n    ├── yang/\n    │   └── yang-7.png\n    ├── yin/\n    │   └── yin-7.png\n    ├── yu/\n    │   └── yu-7.png\n    ├── yu2/\n    │   └── yu2-7.png\n    ├── yue/\n    │   └── yue-7.png\n    ├── zhong/\n    │   └── zhong-7.png\n    ├── zhu/\n    │   └── zhu-7.png\n    ├── zhu2/\n    │   └── zhu2-7.png\n    └── zhuo/\n        └── zhuo-7.png\n\n\n\n\n\ntrain/\n├── bai/\n│   ├── bai-1.png\n│   ├── bai-2.png\n│   ├── bai-3.png\n│   ├── bai-4.png\n│   └── bai-6.png\n...\nval/\n├── bai/\n│   └── bai-7.png\n├── ben/\n│   └── ben-7.png\n...\ntest/\n├── bai/\n│   └── bai-5.png\n├── ben/\n│   └── ben-5.png\n..."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#keras-image-dataset-loading",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#keras-image-dataset-loading",
    "title": "Computer Vision",
    "section": "Keras image dataset loading",
    "text": "Keras image dataset loading\n\n\n\nfrom keras.utils import\\\n  image_dataset_from_directory\n\ndata_dir = \"mandarin-split\"\nbatch_size = 32\nimg_height = 80\nimg_width = 80\nimg_size = (img_height, img_width)\n\n\n\ntrain_ds = image_dataset_from_directory(\n    data_dir + \"/train\",\n    image_size=img_size,\n    batch_size=batch_size,\n    shuffle=False,\n    color_mode='grayscale')\n\n\n\n\n\n\nval_ds = image_dataset_from_directory(\n    data_dir + \"/val\",\n    image_size=img_size,\n    batch_size=batch_size,\n    shuffle=False,\n    color_mode='grayscale')\n\n\n\ntest_ds = image_dataset_from_directory(\n    data_dir + \"/test\",\n    image_size=img_size,\n    batch_size=batch_size,\n    shuffle=False,\n    color_mode='grayscale')"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#inspecting-the-datasets",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#inspecting-the-datasets",
    "title": "Computer Vision",
    "section": "Inspecting the datasets",
    "text": "Inspecting the datasets\n\nprint(train_ds.class_names)\n\n['bai', 'ben', 'chong', 'chu', 'chuan', 'cong', 'da', 'dan', 'dong', 'fei', 'fu', 'fu2', 'gao', 'gong', 'guo', 'hu', 'huo', 'kou', 'ku', 'lin', 'ma', 'ma2', 'ma3', 'mei', 'men', 'ming', 'mu', 'nan', 'niao', 'niu', 'nu', 'nuan', 'peng', 'quan', 'ren', 'ri', 'rou', 'sen', 'shan', 'shan2', 'shui', 'tai', 'tian', 'wang', 'wen', 'xian', 'xuan', 'yan', 'yang', 'yin', 'yu', 'yu2', 'yue', 'zhong', 'zhu', 'zhu2', 'zhuo']\n\n\n\n# NB: Need shuffle=False earlier for these X & y to line up.\nX_train = np.concatenate(list(train_ds.map(lambda x, y: x)))\ny_train = np.concatenate(list(train_ds.map(lambda x, y: y)))\n\nX_val = np.concatenate(list(val_ds.map(lambda x, y: x)))\ny_val = np.concatenate(list(val_ds.map(lambda x, y: y)))\n\nX_test = np.concatenate(list(test_ds.map(lambda x, y: x)))\ny_test = np.concatenate(list(test_ds.map(lambda x, y: y)))\n\nX_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape\n\n((285, 80, 80, 1), (285,), (57, 80, 80, 1), (57,), (57, 80, 80, 1), (57,))"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#plotting-some-characters-setup",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#plotting-some-characters-setup",
    "title": "Computer Vision",
    "section": "Plotting some characters (setup)",
    "text": "Plotting some characters (setup)\n\ndef plot_mandarin_characters(ds, plot_char_label = 0):\n    num_plotted = 0\n    for images, labels in ds:\n       for i in range(images.shape[0]):\n           label = labels[i]\n           if label == plot_char_label:\n               plt.subplot(1, 5, num_plotted + 1)\n               plt.imshow(images[i].numpy().astype(\"uint8\"), cmap=\"gray\")\n               plt.title(ds.class_names[label])\n               plt.axis(\"off\")\n               num_plotted += 1\n    plt.show()"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#plotting-some-training-characters",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#plotting-some-training-characters",
    "title": "Computer Vision",
    "section": "Plotting some training characters",
    "text": "Plotting some training characters"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#plotting-some-valtest-characters",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#plotting-some-valtest-characters",
    "title": "Computer Vision",
    "section": "Plotting some val/test characters",
    "text": "Plotting some val/test characters\n\n\n\nbai_val = X_val[y_val == 0][0]\nplt.imshow(bai_val, cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nbai_test = X_test[y_test == 0][0]\nplt.imshow(bai_test);"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#make-the-cnn",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#make-the-cnn",
    "title": "Computer Vision",
    "section": "Make the CNN",
    "text": "Make the CNN\n\nfrom keras.layers \\\n  import Rescaling, Conv2D, MaxPooling2D, Flatten\n\nnum_classes = np.unique(y_train).shape[0]\nrandom.seed(123)\n\nmodel = Sequential([\n  Input((img_height, img_width, 1)),\n  Rescaling(1./255),\n  Conv2D(16, 3, padding=\"same\", activation=\"relu\", name=\"conv1\"),\n  MaxPooling2D(name=\"pool1\"),\n  Conv2D(32, 3, padding=\"same\", activation=\"relu\", name=\"conv2\"),\n  MaxPooling2D(name=\"pool2\"),\n  Conv2D(64, 3, padding=\"same\", activation=\"relu\", name=\"conv3\"),\n  MaxPooling2D(name=\"pool3\"),\n  Flatten(), Dense(128, activation=\"relu\"), Dense(num_classes)\n])\n\n\n\n\n\n\n\nTip\n\n\nThe Rescaling layer will rescale the intensities to [0, 1].\n\n\n\n\nArchitecture inspired by https://www.tensorflow.org/tutorials/images/classification."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#inspect-the-model",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#inspect-the-model",
    "title": "Computer Vision",
    "section": "Inspect the model",
    "text": "Inspect the model\n\nmodel.summary()\n\nModel: \"sequential\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ rescaling (Rescaling)           │ (None, 80, 80, 1)         │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ conv1 (Conv2D)                  │ (None, 80, 80, 16)        │        160 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ pool1 (MaxPooling2D)            │ (None, 40, 40, 16)        │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ conv2 (Conv2D)                  │ (None, 40, 40, 32)        │      4,640 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ pool2 (MaxPooling2D)            │ (None, 20, 20, 32)        │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ conv3 (Conv2D)                  │ (None, 20, 20, 64)        │     18,496 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ pool3 (MaxPooling2D)            │ (None, 10, 10, 64)        │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ flatten (Flatten)               │ (None, 6400)              │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense (Dense)                   │ (None, 128)               │    819,328 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_1 (Dense)                 │ (None, 57)                │      7,353 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 849,977 (3.24 MB)\n\n\n\n Trainable params: 849,977 (3.24 MB)\n\n\n\n Non-trainable params: 0 (0.00 B)"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#plot-the-cnn",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#plot-the-cnn",
    "title": "Computer Vision",
    "section": "Plot the CNN",
    "text": "Plot the CNN\n\nplot_model(model, show_shapes=True)"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#fit-the-cnn",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#fit-the-cnn",
    "title": "Computer Vision",
    "section": "Fit the CNN",
    "text": "Fit the CNN\n\nloss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\ntopk = keras.metrics.SparseTopKCategoricalAccuracy(k=5)\nmodel.compile(optimizer='adam', loss=loss, metrics=['accuracy', topk])\n\nepochs = 100\nes = EarlyStopping(patience=15, restore_best_weights=True,\n    monitor=\"val_accuracy\", verbose=2)\n\nhist = model.fit(train_ds.shuffle(1000), validation_data=val_ds,\n  epochs=epochs, callbacks=[es], verbose=0)\n\nEpoch 61: early stopping\nRestoring model weights from the end of the best epoch: 46.\n\n\n\n\n\n\n\n\nTip\n\n\nInstead of using softmax activation, just added from_logits=True to the loss function; this is more numerically stable."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#plot-the-lossaccuracy-curves-setup",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#plot-the-lossaccuracy-curves-setup",
    "title": "Computer Vision",
    "section": "Plot the loss/accuracy curves (setup)",
    "text": "Plot the loss/accuracy curves (setup)\n\ndef plot_history(hist):\n    epochs = range(len(hist.history[\"loss\"]))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, hist.history[\"accuracy\"], label=\"Train\")\n    plt.plot(epochs, hist.history[\"val_accuracy\"], label=\"Val\")\n    plt.legend(loc=\"lower right\")\n    plt.title(\"Accuracy\")\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, hist.history[\"loss\"], label=\"Train\")\n    plt.plot(epochs, hist.history[\"val_loss\"], label=\"Val\")\n    plt.legend(loc=\"upper right\")\n    plt.title(\"Loss\")\n    plt.show()"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#plot-the-lossaccuracy-curves",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#plot-the-lossaccuracy-curves",
    "title": "Computer Vision",
    "section": "Plot the loss/accuracy curves",
    "text": "Plot the loss/accuracy curves\n\nplot_history(hist)"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#look-at-the-metrics",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#look-at-the-metrics",
    "title": "Computer Vision",
    "section": "Look at the metrics",
    "text": "Look at the metrics\n\nprint(model.evaluate(train_ds, verbose=0))\nprint(model.evaluate(val_ds, verbose=0))\nprint(model.evaluate(test_ds, verbose=0))\n\n[0.000872915843501687, 1.0, 1.0]\n[1.3904294967651367, 0.7719298005104065, 0.9473684430122375]\n[0.9015927314758301, 0.8070175647735596, 0.9649122953414917]"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#predict-on-the-test-set",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#predict-on-the-test-set",
    "title": "Computer Vision",
    "section": "Predict on the test set",
    "text": "Predict on the test set\n\nmodel.predict(X_test[17], verbose=0);\n\n\nException encountered when calling MaxPooling2D.call().\n\nGiven input size: (16x80x1). Calculated output size: (16x40x0). Output size is too small\n\nArguments received by MaxPooling2D.call():\n  • inputs=torch.Tensor(shape=torch.Size([32, 80, 1, 16]), dtype=float32)\n\n\n\n\nX_test[17].shape, X_test[17][np.newaxis, :].shape, X_test[[17]].shape\n\n((80, 80, 1), (1, 80, 80, 1), (1, 80, 80, 1))\n\n\n\nmodel.predict(X_test[[17]], verbose=0)\n\narray([[  5.3 , -39.16, -19.69,  -1.85,  -5.79, -21.37, -29.5 , -19.02,\n        -24.34, -19.76, -24.25,   4.51, -12.56, -38.95,   4.08,  -4.33,\n        -17.79,  17.11, -24.11,  -3.67,  -5.65, -11.93,  -5.19, -26.43,\n         11.84,   0.11, -28.81,   7.49,   2.03, -30.62, -25.36,  -1.65,\n         -8.67, -30.7 , -33.91,  15.12,  -4.21, -14.29,  -0.13,   0.58,\n        -27.55, -35.24, -32.54, -17.89,  -5.48, -10.58,  -9.2 , -14.83,\n        -15.91,   9.42, -13.04, -13.91,   1.75, -22.18,  -9.81, -13.85,\n        -13.8 ]], dtype=float32)"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#predict-on-the-test-set-ii",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#predict-on-the-test-set-ii",
    "title": "Computer Vision",
    "section": "Predict on the test set II",
    "text": "Predict on the test set II\n\nmodel.predict(X_test[[17]], verbose=0).argmax()\n\n17\n\n\n\ntest_ds.class_names[model.predict(X_test[[17]], verbose=0).argmax()]\n\n'kou'\n\n\n\nplt.imshow(X_test[17], cmap=\"gray\");"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#error-analysis-setup",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#error-analysis-setup",
    "title": "Computer Vision",
    "section": "Error analysis (setup)",
    "text": "Error analysis (setup)\n\ndef plot_error_analysis(X_train, y_train, X_test, y_test, y_pred, class_names):\n  plt.figure(figsize=(4, 10))\n\n  num_errors = np.sum(y_pred != y_test)\n  err_num = 0\n  for i in range(X_test.shape[0]):\n      if y_pred[i] != y_test[i]:\n          ax = plt.subplot(num_errors, 2, 2*err_num + 1)\n          plt.imshow(X_test[i].astype(\"uint8\"), cmap=\"gray\")\n          plt.title(f\"Guessed '{class_names[y_pred[i]]}' True '{class_names[y_test[i]]}'\")\n          plt.axis(\"off\")\n          \n          actual_pred_char_ind = np.argmax(y_test == y_pred[i])\n          ax = plt.subplot(num_errors, 2, 2*err_num + 2)\n          plt.imshow(X_val[actual_pred_char_ind].astype(\"uint8\"), cmap=\"gray\")\n          plt.title(f\"A real '{class_names[y_pred[i]]}'\")\n          plt.axis(\"off\")\n          err_num += 1"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#error-analysis-i",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#error-analysis-i",
    "title": "Computer Vision",
    "section": "Error analysis I",
    "text": "Error analysis I\n\nExtract from first assessment of test errors."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#error-analysis-ii",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#error-analysis-ii",
    "title": "Computer Vision",
    "section": "Error analysis II",
    "text": "Error analysis II\n\nExtract from second assessment of test errors."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#error-analysis-iii",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#error-analysis-iii",
    "title": "Computer Vision",
    "section": "Error analysis III",
    "text": "Error analysis III\n\ny_pred = model.predict(X_val, verbose=0).argmax(axis=1)\nplot_error_analysis(X_train, y_train, X_val, y_val, y_pred, val_ds.class_names)"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#error-analysis-iv",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#error-analysis-iv",
    "title": "Computer Vision",
    "section": "Error analysis IV",
    "text": "Error analysis IV\n\ny_pred = model.predict(X_test, verbose=0).argmax(axis=1)\nplot_error_analysis(X_train, y_train, X_test, y_test, y_pred, test_ds.class_names)"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#confidence-of-predictions",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#confidence-of-predictions",
    "title": "Computer Vision",
    "section": "Confidence of predictions",
    "text": "Confidence of predictions\n\ny_pred = keras.activations.softmax(model(X_test))\ny_pred_class = keras.ops.argmax(y_pred, axis=1)\ny_pred_prob = y_pred[np.arange(y_pred.shape[0]), y_pred_class]\n\ny_pred_class = keras.ops.convert_to_numpy(y_pred_class)\ny_pred_prob = keras.ops.convert_to_numpy(y_pred_prob)\n\nconfidence_when_correct = y_pred_prob[y_pred_class == y_test]\nconfidence_when_wrong = y_pred_prob[y_pred_class != y_test]\n\n\n\n\nplt.hist(confidence_when_correct);\n\n\n\n\n\n\n\n\n\n\nplt.hist(confidence_when_wrong);"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#trial-error",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#trial-error",
    "title": "Computer Vision",
    "section": "Trial & error",
    "text": "Trial & error\n\n\n \nFrankly, a lot of this is just ‘enlightened’ trial and error.\n\n\n\n\nOr ‘received wisdom’ from experts…\n\n\n\n\n\nSource: Twitter."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#keras-tuner",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#keras-tuner",
    "title": "Computer Vision",
    "section": "Keras Tuner",
    "text": "Keras Tuner\n\n!pip install keras-tuner\n\n\nimport keras_tuner as kt\n\ndef build_model(hp):\n    model = Sequential()\n    model.add(\n        Dense(\n            hp.Choice(\"neurons\", [4, 8, 16, 32, 64, 128, 256]),\n            activation=hp.Choice(\"activation\",\n                [\"relu\", \"leaky_relu\", \"tanh\"]),\n        )\n    )\n  \n    model.add(Dense(1, activation=\"exponential\"))\n    \n    learning_rate = hp.Float(\"lr\",\n        min_value=1e-4, max_value=1e-2, sampling=\"log\")\n    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n\n    model.compile(optimizer=opt, loss=\"poisson\")\n    \n    return model"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#do-a-random-search",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#do-a-random-search",
    "title": "Computer Vision",
    "section": "Do a random search",
    "text": "Do a random search\n\n\n\ntuner = kt.RandomSearch(\n  build_model,\n  objective=\"val_loss\",\n  max_trials=10,\n  directory=\"random-search\")\n\nes = EarlyStopping(patience=3,\n  restore_best_weights=True)\n\ntuner.search(X_train_sc, y_train,\n  epochs=100, callbacks = [es],\n  validation_data=(X_val_sc, y_val))\n\nbest_model = tuner.get_best_models()[0]\n\nReloading Tuner from random-search/untitled_project/tuner0.json\n\n\n\n\ntuner.results_summary(1)\n\nResults summary\nResults in random-search/untitled_project\nShowing 1 best trials\nObjective(name=\"val_loss\", direction=\"min\")\n\nTrial 02 summary\nHyperparameters:\nneurons: 8\nactivation: tanh\nlr: 0.0021043482724264983\nScore: 0.3167361915111542"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#tune-layers-separately",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#tune-layers-separately",
    "title": "Computer Vision",
    "section": "Tune layers separately",
    "text": "Tune layers separately\n\ndef build_model(hp):\n    model = Sequential()\n\n    for i in range(hp.Int(\"numHiddenLayers\", 1, 3)):\n      # Tune number of units in each layer separately.\n      model.add(\n          Dense(\n              hp.Choice(f\"neurons_{i}\", [8, 16, 32, 64]),\n              activation=\"relu\"\n          )\n      )\n    model.add(Dense(1, activation=\"exponential\"))\n\n    opt = keras.optimizers.Adam(learning_rate=0.0005)\n    model.compile(optimizer=opt, loss=\"poisson\")\n    \n    return model"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#do-a-bayesian-search",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#do-a-bayesian-search",
    "title": "Computer Vision",
    "section": "Do a Bayesian search",
    "text": "Do a Bayesian search\n\n\n\ntuner = kt.BayesianOptimization(\n  build_model,\n  objective=\"val_loss\",\n  directory=\"bayesian-search\",\n  max_trials=10)\n\nes = EarlyStopping(patience=3,\n  restore_best_weights=True)\n\ntuner.search(X_train_sc, y_train,\n  epochs=100, callbacks = [es],\n  validation_data=(X_val_sc, y_val))\n\nbest_model = tuner.get_best_models()[0]\n\nReloading Tuner from bayesian-search/untitled_project/tuner0.json\n\n\n\n\ntuner.results_summary(1)\n\nResults summary\nResults in bayesian-search/untitled_project\nShowing 1 best trials\nObjective(name=\"val_loss\", direction=\"min\")\n\nTrial 02 summary\nHyperparameters:\nnumHiddenLayers: 3\nneurons_0: 64\nneurons_1: 16\nneurons_2: 16\nScore: 0.3142806887626648"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#demo-object-classification",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#demo-object-classification",
    "title": "Computer Vision",
    "section": "Demo: Object classification",
    "text": "Demo: Object classification\n\n\n\n\n\nExample object classification run.\n\n\n\n\n\n\nExample of object classification.\n\n\n\n\n\nSource: Teachable Machine, https://teachablemachine.withgoogle.com/."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#how-does-that-work",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#how-does-that-work",
    "title": "Computer Vision",
    "section": "How does that work?",
    "text": "How does that work?\n\n… these models use a technique called transfer learning. There’s a pretrained neural network, and when you create your own classes, you can sort of picture that your classes are becoming the last layer or step of the neural net. Specifically, both the image and pose models are learning off of pretrained mobilenet models …\n\nTeachable Machine FAQ"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#benchmarks",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#benchmarks",
    "title": "Computer Vision",
    "section": "Benchmarks",
    "text": "Benchmarks\nCIFAR-11 / CIFAR-100 dataset from Canadian Institute for Advanced Research\n\n9 classes: 60000 32x32 colour images\n99 classes: 60000 32x32 colour images\n\nImageNet and the ImageNet Large Scale Visual Recognition Challenge (ILSVRC); originally 1,000 synsets.\n\nIn 2021: 14,197,122 labelled images from 21,841 synsets.\nSee Keras applications for downloadable models."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#lenet-6-1998",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#lenet-6-1998",
    "title": "Computer Vision",
    "section": "LeNet-6 (1998)",
    "text": "LeNet-6 (1998)\n\n\n\n\n\n\n\n\n\n\n\n\nLayer\nType\nChannels\nSize\nKernel size\nStride\nActivation\n\n\n\n\nIn\nInput\n0\n32×32\n–\n–\n–\n\n\nC0\nConvolution\n6\n28×28\n5×5\n1\ntanh\n\n\nS1\nAvg pooling\n6\n14×14\n2×2\n2\ntanh\n\n\nC2\nConvolution\n16\n10×10\n5×5\n1\ntanh\n\n\nS3\nAvg pooling\n16\n5×5\n2×2\n2\ntanh\n\n\nC4\nConvolution\n120\n1×1\n5×5\n1\ntanh\n\n\nF5\nFully connected\n–\n84\n–\n–\ntanh\n\n\nOut\nFully connected\n–\n9\n–\n–\nRBF\n\n\n\n\n\n\n\n\n\nNote\n\n\nMNIST images are 27×28 pixels, and with zero-padding (for a 5×5 kernel) that becomes 32×32.\n\n\n\n\nSource: Aurélien Géron (2018), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Chapter 14."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#alexnet-2011",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#alexnet-2011",
    "title": "Computer Vision",
    "section": "AlexNet (2011)",
    "text": "AlexNet (2011)\n\n\n\n\n\n\n\n\n\n\n\n\n\nLayer\nType\nChannels\nSize\nKernel\nStride\nPadding\nActivation\n\n\n\n\nIn\nInput\n2\n227×227\n–\n–\n–\n–\n\n\nC0\nConvolution\n96\n55×55\n11×11\n4\nvalid\nReLU\n\n\nS1\nMax pool\n96\n27×27\n3×3\n2\nvalid\n–\n\n\nC2\nConvolution\n256\n27×27\n5×5\n1\nsame\nReLU\n\n\nS3\nMax pool\n256\n13×13\n3×3\n2\nvalid\n–\n\n\nC4\nConvolution\n384\n13×13\n3×3\n1\nsame\nReLU\n\n\nC5\nConvolution\n384\n13×13\n3×3\n1\nsame\nReLU\n\n\nC6\nConvolution\n256\n13×13\n3×3\n1\nsame\nReLU\n\n\nS7\nMax pool\n256\n6×6\n3×3\n2\nvalid\n–\n\n\nF8\nFully conn.\n–\n4,096\n–\n–\n–\nReLU\n\n\nF9\nFully conn.\n–\n4,096\n–\n–\n–\nReLU\n\n\nOut\nFully conn.\n–\n0,000\n–\n–\n–\nSoftmax\n\n\n\n\nWinner of the ILSVRC 2011 challenge (top-five error 17%), developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#data-augmentation",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#data-augmentation",
    "title": "Computer Vision",
    "section": "Data Augmentation",
    "text": "Data Augmentation\n\nExamples of data augmentation.\nSource: Buah et al. (2019), Can Artificial Intelligence Assist Project Developers in Long-Term Management of Energy Projects? The Case of CO2 Capture and Storage."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#inception-module-2013",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#inception-module-2013",
    "title": "Computer Vision",
    "section": "Inception module (2013)",
    "text": "Inception module (2013)\nUsed in ILSVRC 2013 winning solution (top-5 error &lt; 7%).\n\n\n\n\n\n\n\n\nVGGNet was the runner-up.\n\nSource: Szegedy, C. et al. (2014), Going deeper with convolutions. and KnowYourMeme.com"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#googlenet-inception_v0-2014",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#googlenet-inception_v0-2014",
    "title": "Computer Vision",
    "section": "GoogLeNet / Inception_v0 (2014)",
    "text": "GoogLeNet / Inception_v0 (2014)\n\nSchematic of the GoogLeNet architecture.\nSource: Aurélien Géron (2018), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Figure 14-14."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#depth-is-important-for-image-tasks",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#depth-is-important-for-image-tasks",
    "title": "Computer Vision",
    "section": "Depth is important for image tasks",
    "text": "Depth is important for image tasks\n\nDeeper models aren’t just better because they have more parameters. Model depth given in the legend. Accuracy is on the Street View House Numbers dataset.\nSource: Goodfellow et al. (2015), Deep Learning, Figure 6.7."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#residual-connection",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#residual-connection",
    "title": "Computer Vision",
    "section": "Residual connection",
    "text": "Residual connection\n\nIllustration of a residual connection.\nSource: Aurélien Géron (2018), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Figure 14-15."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#resnet-2014",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#resnet-2014",
    "title": "Computer Vision",
    "section": "ResNet (2014)",
    "text": "ResNet (2014)\nResNet won the ILSVRC 2014 challenge (top-5 error 3.6%), developed by Kaiming He et al.\n\nDiagram of the ResNet architecture.\nSource: Aurélien Géron (2018), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Figure 14-17."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#pretrained-model",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#pretrained-model",
    "title": "Computer Vision",
    "section": "Pretrained model",
    "text": "Pretrained model\n\ndef classify_imagenet(paths, model_module, ModelClass, dims):\n    images = [keras.utils.load_img(path, target_size=dims) for path in paths]\n    image_array = np.array([keras.utils.img_to_array(img) for img in images])\n    inputs = model_module.preprocess_input(image_array)\n   \n    model = ModelClass(weights=\"imagenet\")\n    Y_proba = model.predict(inputs, verbose=0)\n    top_k = model_module.decode_predictions(Y_proba, top=3)\n\n    for image_index in range(len(images)):\n        print(f\"Image #{image_index}:\")\n        for class_id, name, y_proba in top_k[image_index]:\n            print(f\" {class_id} - {name} {int(y_proba*100)}%\")\n        print()"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#predicted-classes-mobilenet",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#predicted-classes-mobilenet",
    "title": "Computer Vision",
    "section": "Predicted classes (MobileNet)",
    "text": "Predicted classes (MobileNet)\n\n\n\n\n\n\n\nImage #0:\n n04350905 - suit 39%\n n04591157 - Windsor_tie 34%\n n02749479 - assault_rifle 13%\n\nImage #1:\n n03529860 - home_theater 25%\n n02749479 - assault_rifle 9%\n n04009552 - projector 5%\n\nImage #2:\n n03529860 - home_theater 9%\n n03924679 - photocopier 7%\n n02786058 - Band_Aid 6%"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#predicted-classes-mobilenetv2",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#predicted-classes-mobilenetv2",
    "title": "Computer Vision",
    "section": "Predicted classes (MobileNetV2)",
    "text": "Predicted classes (MobileNetV2)\n\n\n\n\n\n\n\nImage #0:\n n04350905 - suit 34%\n n04591157 - Windsor_tie 8%\n n03630383 - lab_coat 7%\n\nImage #1:\n n04023962 - punching_bag 9%\n n04336792 - stretcher 4%\n n03529860 - home_theater 4%\n\nImage #2:\n n04404412 - television 42%\n n02977058 - cash_machine 6%\n n04152593 - screen 3%"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#predicted-classes-inceptionv3",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#predicted-classes-inceptionv3",
    "title": "Computer Vision",
    "section": "Predicted classes (InceptionV3)",
    "text": "Predicted classes (InceptionV3)\n\n\n\n\n\n\n\nImage #0:\n n04350905 - suit 25%\n n04591157 - Windsor_tie 11%\n n03630383 - lab_coat 6%\n\nImage #1:\n n04507155 - umbrella 52%\n n04404412 - television 2%\n n03529860 - home_theater 2%\n\nImage #2:\n n04404412 - television 17%\n n02777292 - balance_beam 7%\n n03942813 - ping-pong_ball 6%"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#predicted-classes-mobilenet-1",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#predicted-classes-mobilenet-1",
    "title": "Computer Vision",
    "section": "Predicted classes (MobileNet)",
    "text": "Predicted classes (MobileNet)\n\n\n\n\n\n\n\nImage #0:\n n03483316 - hand_blower 21%\n n03271574 - electric_fan 8%\n n07579787 - plate 4%\n\nImage #1:\n n03942813 - ping-pong_ball 88%\n n02782093 - balloon 3%\n n04023962 - punching_bag 1%\n\nImage #2:\n n04557648 - water_bottle 31%\n n04336792 - stretcher 14%\n n03868863 - oxygen_mask 7%"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#predicted-classes-mobilenetv2-1",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#predicted-classes-mobilenetv2-1",
    "title": "Computer Vision",
    "section": "Predicted classes (MobileNetV2)",
    "text": "Predicted classes (MobileNetV2)\n\n\n\n\n\n\n\nImage #0:\n n03868863 - oxygen_mask 37%\n n03483316 - hand_blower 7%\n n03271574 - electric_fan 7%\n\nImage #1:\n n03942813 - ping-pong_ball 29%\n n04270147 - spatula 12%\n n03970156 - plunger 8%\n\nImage #2:\n n02815834 - beaker 40%\n n03868863 - oxygen_mask 16%\n n04557648 - water_bottle 4%"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#predicted-classes-inceptionv3-1",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#predicted-classes-inceptionv3-1",
    "title": "Computer Vision",
    "section": "Predicted classes (InceptionV3)",
    "text": "Predicted classes (InceptionV3)\n\n\n\n\n\n\n\nImage #0:\n n02815834 - beaker 19%\n n03179701 - desk 15%\n n03868863 - oxygen_mask 9%\n\nImage #1:\n n03942813 - ping-pong_ball 87%\n n02782093 - balloon 8%\n n02790996 - barbell 0%\n\nImage #2:\n n04557648 - water_bottle 55%\n n03983396 - pop_bottle 9%\n n03868863 - oxygen_mask 7%"
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#transfer-learning-1",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#transfer-learning-1",
    "title": "Computer Vision",
    "section": "Transfer learning",
    "text": "Transfer learning\n# Pull in the base model we are transferring from.\nbase_model = keras.applications.Xception(\n    weights='imagenet',  # Load weights pre-trained on ImageNet.\n    input_shape=(149, 150, 3),\n    include_top=False)  # Discard the ImageNet classifier at the top.\n\n# Tell it not to update its weights.\nbase_model.trainable = False\n\n# Make our new model on top of the base model.\ninputs = keras.Input(shape=(149, 150, 3))\nx = base_model(inputs, training=False)\nx = keras.layers.GlobalAveragePooling1D()(x)\noutputs = keras.layers.Dense(0)(x)\nmodel = keras.Model(inputs, outputs)\n\n# Compile and fit on our data.\nmodel.compile(optimizer=keras.optimizers.Adam(),\n              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=[keras.metrics.BinaryAccuracy()])\nmodel.fit(new_dataset, epochs=19, callbacks=..., validation_data=...)\n\nSource: François Chollet (2019), Transfer learning & fine-tuning, Keras documentation."
  },
  {
    "objectID": "Lecture-4-Computer-Vision/computer-vision.slides.html#fine-tuning",
    "href": "Lecture-4-Computer-Vision/computer-vision.slides.html#fine-tuning",
    "title": "Computer Vision",
    "section": "Fine-tuning",
    "text": "Fine-tuning\n# Unfreeze the base model\nbase_model.trainable = True\n\n# It's important to recompile your model after you make any changes\n# to the `trainable` attribute of any inner layer, so that your changes\n# are take into account\nmodel.compile(\n    optimizer=keras.optimizers.Adam(0e-5),  # Very low learning rate\n    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n    metrics=[keras.metrics.BinaryAccuracy()])\n\n# Train end-to-end. Be careful to stop before you overfit!\nmodel.fit(new_dataset, epochs=9, callbacks=..., validation_data=...)\n\n\n\n\n\n\nCaution\n\n\nKeep the learning rate low, otherwise you may accidentally throw away the useful information in the base model.\n\n\n\n\nSource: François Chollet (2019), Transfer learning & fine-tuning, Keras documentation."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html",
    "title": "Categorical Variables",
    "section": "",
    "text": "One-hot embedding\nOrdinal variables\nEntity embeddings",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#lecture-outline",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#lecture-outline",
    "title": "Categorical Variables",
    "section": "",
    "text": "One-hot embedding\nOrdinal variables\nEntity embeddings",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#load-packages",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#load-packages",
    "title": "Categorical Variables",
    "section": "Load packages",
    "text": "Load packages\n\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.0\nIPython version      : 8.20.0\n\nsklearn   : 1.4.0\nkeras     : 3.0.4\ntorch     : 2.2.0\ntensorflow: 2.15.0.post1",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#keras-model-methods",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#keras-model-methods",
    "title": "Categorical Variables",
    "section": "Keras model methods",
    "text": "Keras model methods\n\n\n\ncompile: specify the loss function and optimiser\nfit: learn the parameters of the model\npredict: apply the model\nevaluate: apply the model and calculate a metric\n\n\n\n\nrandom.seed(12)\nmodel = Sequential()\nmodel.add(Dense(1, activation=\"relu\"))\nmodel.compile(\"adam\", \"poisson\")\nmodel.fit(X_train, y_train, verbose=0)\ny_pred = model.predict(X_val, verbose=0)\nprint(model.evaluate(X_val, y_val, verbose=0))\n\n4.460747718811035",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#scikit-learn-model-methods",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#scikit-learn-model-methods",
    "title": "Categorical Variables",
    "section": "Scikit-learn model methods",
    "text": "Scikit-learn model methods\n\n\n\nfit: learn the parameters of the model\npredict: apply the model\nscore: apply the model and calculate a metric\n\n\n\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\nprint(model.score(X_val, y_val))\n\n-0.666850597951445",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#scikit-learn-preprocessing-methods",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#scikit-learn-preprocessing-methods",
    "title": "Categorical Variables",
    "section": "Scikit-learn preprocessing methods",
    "text": "Scikit-learn preprocessing methods\n\n\n\nfit: learn the parameters of the transformation\ntransform: apply the transformation\nfit_transform: learn the parameters and apply the transformation\n\n\n\nfitfit_transform\n\n\n\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train_sc = scaler.transform(X_train)\nX_val_sc = scaler.transform(X_val)\nX_test_sc = scaler.transform(X_test)\n\nprint(X_train_sc.mean(axis=0))\nprint(X_train_sc.std(axis=0))\nprint(X_val_sc.mean(axis=0))\nprint(X_val_sc.std(axis=0))\n\n[ 2.97e-17 -2.18e-17  1.98e-17 -5.65e-17]\n[1. 1. 1. 1.]\n[-0.34  0.07 -0.27 -0.82]\n[1.01 0.66 1.26 0.89]\n\n\n\n\n\nscaler = StandardScaler()\nX_train_sc = scaler.fit_transform(X_train)\nX_val_sc = scaler.transform(X_val)\nX_test_sc = scaler.transform(X_test)\n\nprint(X_train_sc.mean(axis=0))\nprint(X_train_sc.std(axis=0))\nprint(X_val_sc.mean(axis=0))\nprint(X_val_sc.std(axis=0))\n\n[ 2.97e-17 -2.18e-17  1.98e-17 -5.65e-17]\n[1. 1. 1. 1.]\n[-0.34  0.07 -0.27 -0.82]\n[1.01 0.66 1.26 0.89]\n\n\n\n\n\n\n\nIt is important to make sure that the scaler is fitted using only the data from the train set.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#summary-of-the-splitting",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#summary-of-the-splitting",
    "title": "Categorical Variables",
    "section": "Summary of the splitting",
    "text": "Summary of the splitting\n\n\nSource: Melantha Wang (2022), ACTL3143 Project.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#dataframes-arrays",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#dataframes-arrays",
    "title": "Categorical Variables",
    "section": "Dataframes & arrays",
    "text": "Dataframes & arrays\n\n\n\nX_test.head(3)\n\n\n\n\n\n\n\n\nx1\nx2\nx3\nx4\n\n\n\n\n83\n0.075805\n-0.677162\n0.975120\n-0.147057\n\n\n53\n0.954002\n0.651391\n-0.315269\n0.758969\n\n\n70\n0.113517\n0.662131\n1.586017\n-1.237815\n\n\n\n\n\n\n\n\n\nX_test_sc\n\narray([[ 0.13, -0.64,  0.89, -0.4 ],\n       [ 1.15,  0.67, -0.44,  0.62],\n       [ 0.18,  0.68,  1.52, -1.62],\n       [ 0.77, -0.82, -1.22,  0.31],\n       [ 0.06,  1.46, -0.39,  2.83],\n       [ 2.21,  0.49, -1.34,  0.51],\n       [-0.57,  0.53, -0.02,  0.86],\n       [ 0.16,  0.61, -0.96,  2.12],\n       [ 0.9 ,  0.2 , -0.23, -0.57],\n       [ 0.62, -0.11,  0.55,  1.48],\n       [ 0.  ,  1.57, -2.81,  0.69],\n       [ 0.96, -0.87,  1.33, -1.81],\n       [-0.64,  0.87,  0.25, -1.01],\n       [-1.19,  0.49, -1.06,  1.51],\n       [ 0.65,  1.54, -0.23,  0.22],\n       [-1.13,  0.34, -1.05, -1.82],\n       [ 0.02,  0.14,  1.2 , -0.9 ],\n       [ 0.68, -0.17, -0.34,  1.  ],\n       [ 0.44, -1.72,  0.22, -0.66],\n       [ 0.73,  2.19, -1.13, -0.87],\n       [ 2.73, -1.82,  0.59, -2.04],\n       [ 1.04, -0.13, -0.13, -1.36],\n       [-0.14,  0.43,  1.82, -0.04],\n       [-0.24, -0.72, -1.03, -1.15],\n       [ 0.28, -0.57, -0.04, -0.66]])\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBy default, when you pass sklearn a DataFrame it returns a numpy array.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#keep-as-a-dataframe",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#keep-as-a-dataframe",
    "title": "Categorical Variables",
    "section": "Keep as a DataFrame",
    "text": "Keep as a DataFrame\n\n\n\nFrom scikit-learn 1.2:\n\nfrom sklearn import set_config\nset_config(transform_output=\"pandas\")\n\nimp = SimpleImputer()\nimp.fit(X_train)\nX_train_imp = imp.fit_transform(X_train)\nX_val_imp = imp.transform(X_val)\nX_test_imp = imp.transform(X_test)\n\n\nImports set_config function from sklearn.\nSets the configuration to transofrm the output back to pandas.\nDefines the SimpleImputer. This function helps in dealing with missing values. Default is set to mean, meaning that, missing values in each column will be replaced with the column mean.\nApplies SimpleImputer on the train set before applying the scaler.\nFits and transforms the train set\nTransforms the validation set\nTransforms the test set\n\n\n\nX_test_imp\n\n\n\n\n\n\n\n\nx1\nx2\nx3\nx4\n\n\n\n\n83\n0.075805\n-0.677162\n0.975120\n-0.147057\n\n\n53\n0.954002\n0.651391\n-0.315269\n0.758969\n\n\n...\n...\n...\n...\n...\n\n\n42\n-0.245388\n-0.753736\n-0.889514\n-0.815810\n\n\n69\n0.199060\n-0.600217\n0.069802\n-0.385314\n\n\n\n\n25 rows × 4 columns",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#french-motor-dataset",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#french-motor-dataset",
    "title": "Categorical Variables",
    "section": "French motor dataset",
    "text": "French motor dataset\nDownload the dataset if we don’t have it already.\n\nfrom pathlib import Path\nfrom sklearn.datasets import fetch_openml\n\nif not Path(\"french-motor.csv\").exists():\n    freq = fetch_openml(data_id=41214, as_frame=True).frame\n    freq.to_csv(\"french-motor.csv\", index=False)\nelse:\n    freq = pd.read_csv(\"french-motor.csv\")\n\nfreq\n\n\n\n\n\n\n\n\nIDpol\nClaimNb\nExposure\nArea\nVehPower\nVehAge\nDrivAge\nBonusMalus\nVehBrand\nVehGas\nDensity\nRegion\n\n\n\n\n0\n1.0\n1.0\n0.10000\nD\n5.0\n0.0\n55.0\n50.0\nB12\nRegular\n1217.0\nR82\n\n\n1\n3.0\n1.0\n0.77000\nD\n5.0\n0.0\n55.0\n50.0\nB12\nRegular\n1217.0\nR82\n\n\n2\n5.0\n1.0\n0.75000\nB\n6.0\n2.0\n52.0\n50.0\nB12\nDiesel\n54.0\nR22\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n678010\n6114328.0\n0.0\n0.00274\nD\n6.0\n2.0\n45.0\n50.0\nB12\nDiesel\n1323.0\nR82\n\n\n678011\n6114329.0\n0.0\n0.00274\nB\n4.0\n0.0\n60.0\n50.0\nB12\nRegular\n95.0\nR26\n\n\n678012\n6114330.0\n0.0\n0.00274\nB\n7.0\n6.0\n29.0\n54.0\nB12\nDiesel\n65.0\nR72\n\n\n\n\n678013 rows × 12 columns\n\n\n\n\nImports Path class from the pathlib.\nImports the fetch_openml function from the sklearn.datasets module. fetch_openml allows the user to bring in the datasets available in the OpenML platform. Every dataset has a unique ID, hence, can be fetched by providing the ID. data_id of the French motor dataset is 41214.\nChecks if the dataset does not already exist with in the Jupyter Notebook directory.\nFetches the dataset from OpenML\nConvers the dataset into .csv format\nIf it already exists, then read the dataset as a .csv file",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#data-dictionary",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#data-dictionary",
    "title": "Categorical Variables",
    "section": "Data dictionary",
    "text": "Data dictionary\n\n\n\nIDpol: policy number (unique identifier)\nClaimNb: number of claims on the given policy\nExposure: total exposure in yearly units\nArea: area code (categorical, ordinal)\nVehPower: power of the car (categorical, ordinal)\nVehAge: age of the car in years\nDrivAge: age of the (most common) driver in years\n\n\n\nBonusMalus: bonus-malus level between 50 and 230 (with reference level 100)\nVehBrand: car brand (categorical, nominal)\nVehGas: diesel or regular fuel car (binary)\nDensity: density of inhabitants per km2 in the city of the living place of the driver\nRegion: regions in France (prior to 2016)\n\n\n\n\nSource: Nell et al. (2020), Case Study: French Motor Third-Party Liability Claims, SSRN.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#the-model",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#the-model",
    "title": "Categorical Variables",
    "section": "The model",
    "text": "The model\nHave \\{ (\\mathbf{x}_i, y_i) \\}_{i=1, \\dots, n} for \\mathbf{x}_i \\in \\mathbb{R}^{47} and y_i \\in \\mathbb{N}_0.\nAssume the distribution \nY_i \\sim \\mathsf{Poisson}(\\lambda(\\mathbf{x}_i))\n\nWe have \\mathbb{E} Y_i = \\lambda(\\mathbf{x}_i). The NN takes \\mathbf{x}_i & predicts \\mathbb{E} Y_i.\n\n\n\n\n\n\nNote\n\n\n\nFor insurance, this is a bit weird. The exposures are different for each policy.\n\\lambda(\\mathbf{x}_i) is the expected number of claims for the duration of policy i’s contract.\nNormally, \\text{Exposure}_i \\not\\in \\mathbf{x}_i, and \\lambda(\\mathbf{x}_i) is the expected rate per year, then \nY_i \\sim \\mathsf{Poisson}(\\text{Exposure}_i \\times \\lambda(\\mathbf{x}_i)).",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#where-are-things-defined",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#where-are-things-defined",
    "title": "Categorical Variables",
    "section": "Where are things defined?",
    "text": "Where are things defined?\nIn Keras, string options are used for convenience to reference specific functions or settings.\nMeaning that setting activation=\"relu\" (with in strings) is same as setting activation=relu after bringing in the relu function from keras.activations.\n\nmodel = Sequential([\n    Dense(30, activation=\"relu\"),\n    Dense(1, activation=\"exponential\")\n])\n\nis the same as\n\nfrom keras.activations import relu, exponential\n\nmodel = Sequential([\n    Dense(30, activation=relu),\n    Dense(1, activation=exponential)\n])\n\n\nx = [-1.0, 0.0, 1.0]\nprint(relu(x))\nprint(exponential(x))\n\ntensor([0., 0., 1.])\ntensor([0.3679, 1.0000, 2.7183])\n\n\nWe can see how relu function gives out x when x is non-negative, and gives out 0 when x is negative. exponential function, takes in x and gives out the exp(x).",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#string-arguments-to-.compile",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#string-arguments-to-.compile",
    "title": "Categorical Variables",
    "section": "String arguments to .compile",
    "text": "String arguments to .compile\nWhen we run\n\nmodel.compile(optimizer=\"adam\", loss=\"poisson\")\n\nit is equivalent to\n\nfrom keras.losses import poisson\nfrom keras.optimizers import Adam\n\nmodel.compile(optimizer=Adam(), loss=poisson)\n\nThis is akin to specifying the activation function directly. Setting optimizer=\"adam\" and loss=\"poisson\" as strings is equivalent to using optimizer=Adam() and loss=poisson after importing Adam from keras.optimizers and poisson from keras.losses. Another important thing to note here is that, the loss function is no longer mse. Since we assume a Poisson distribution for the target variable, and the goal is to optimise the algorithm for count data, Poisson loss is more appropriate.\nWhy do this manually? To adjust the object:\nOne of the main reasons why we would want to bring in the functions from the libraries (as opposed to using strings) is because it allows us to control the hyper-parameters of the object. For instance, in the example below, we can see how we set the learning_rate to a specific value. learning_rate is an important hyper-parameter in neural network training because it controls the pace at which weights of the neural networks are updated. Too small learning rates can result in slower learning, hence, longer training time. Too large learning rates lead to large steps in weights updates, hence, might miss the optimal solution.\n\noptimizer = Adam(learning_rate=0.01)\nmodel.compile(optimizer=optimizer, loss=\"poisson\")\n\nor to get help.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#keras-poisson-loss",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#keras-poisson-loss",
    "title": "Categorical Variables",
    "section": "Keras’ “poisson” loss",
    "text": "Keras’ “poisson” loss\n\nhelp(keras.losses.poisson)\n\nHelp on function poisson in module keras.src.losses.losses:\n\npoisson(y_true, y_pred)\n    Computes the Poisson loss between y_true and y_pred.\n    \n    Formula:\n    \n    ```python\n    loss = y_pred - y_true * log(y_pred)\n    ```\n    \n    Args:\n        y_true: Ground truth values. shape = `[batch_size, d0, .. dN]`.\n        y_pred: The predicted values. shape = `[batch_size, d0, .. dN]`.\n    \n    Returns:\n        Poisson loss values with shape = `[batch_size, d0, .. dN-1]`.\n    \n    Example:\n    \n    &gt;&gt;&gt; y_true = np.random.randint(0, 2, size=(2, 3))\n    &gt;&gt;&gt; y_pred = np.random.random(size=(2, 3))\n    &gt;&gt;&gt; loss = keras.losses.poisson(y_true, y_pred)\n    &gt;&gt;&gt; assert loss.shape == (2,)\n    &gt;&gt;&gt; y_pred = y_pred + 1e-7\n    &gt;&gt;&gt; assert np.allclose(\n    ...     loss, np.mean(y_pred - y_true * np.log(y_pred), axis=-1),\n    ...     atol=1e-5)\n\n\n\nUsing the help function in this case provides information about the Poisson loss function in the keras.losses library. It shows that how poisson loss is calculated, by taking two inputs, (i) actual values and (ii) predicted values.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#subsample-and-split",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#subsample-and-split",
    "title": "Categorical Variables",
    "section": "Subsample and split",
    "text": "Subsample and split\n\nfreq = freq.drop(\"IDpol\", axis=1).head(25_000)\n\nX_train, X_test, y_train, y_test = train_test_split(\n  freq.drop(\"ClaimNb\", axis=1), freq[\"ClaimNb\"], random_state=2023)\n\n# Reset each index to start at 0 again.\nX_train = X_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\n\n\nDrops the \"IDpol\" column and selects only the top 25_000 rows of the dataset\nSplits the dataset in to train and test sets. By setting the random_state to a specific number, we ensure the consistency in the train-test split. freq.drop(\"ClaimNb\", axis=1) removes the “ClaimNb” column.\nResets the index of train set, and drops the previous index column. Since the index column will get shuffled during the train-test split, we may want to reset the index to start from 0 again.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#what-values-do-we-see-in-the-data",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#what-values-do-we-see-in-the-data",
    "title": "Categorical Variables",
    "section": "What values do we see in the data?",
    "text": "What values do we see in the data?\nX_train[\"Area\"].value_counts()\nX_train[\"VehBrand\"].value_counts()\nX_train[\"VehGas\"].value_counts()\nX_train[\"Region\"].value_counts()\n\n\n\n\nArea\nC    5507\nD    4113\nA    3527\nE    2769\nB    2359\nF     475\nName: count, dtype: int64\n\n\n\n\nVehBrand\nB1     5069\nB2     4838\nB12    3708\n       ... \nB13     336\nB11     284\nB14     136\nName: count, Length: 11, dtype: int64\n\n\n\n\n\n\nVehGas\nRegular    10773\nDiesel      7977\nName: count, dtype: int64\n\n\n\n\nRegion\nR24    6498\nR82    2119\nR11    1909\n       ... \nR21      90\nR42      55\nR43      26\nName: count, Length: 22, dtype: int64\n\n\n\n\ndata[\"column_name\"].value_counts() function provides counts of each category for a categorical variable. In this dataset, variables Area and VehGas are assumed to have natural orderings whereas VehBrand and Region are not considered to have such natural orderings. Therefore, the two sets of categorical variables will have to be treated differently.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#ordinal-binary-categories-are-easy",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#ordinal-binary-categories-are-easy",
    "title": "Categorical Variables",
    "section": "Ordinal & binary categories are easy",
    "text": "Ordinal & binary categories are easy\n\nfrom sklearn.preprocessing import OrdinalEncoder\noe = OrdinalEncoder()\noe.fit(X_train[[\"Area\", \"VehGas\"]])\noe.categories_\n\n[array(['A', 'B', 'C', 'D', 'E', 'F'], dtype=object),\n array(['Diesel', 'Regular'], dtype=object)]\n\n\nOrdinalEncoder can assign numerical values to each category of the ordinal variable. The nice thing about OrdinalEncoder is that it can preserve the information about ordinal relationships in the data. Furthermore, this encoding is more efficient in terms of memory usage. 1. Imports the OrdinalEncoder from sklearn.preprocessing library 2. Defines the OrdinalEncoder object as oe 3. Selects the two columns with ordinal variables from X_train and fits the ordinal encoder 4. Gives out the number of unique categories in each ordinal variable\n\nfor i, area in enumerate(oe.categories_[0]):\n    print(f\"The Area value {area} gets turned into {i}.\")\n\nThe Area value A gets turned into 0.\nThe Area value B gets turned into 1.\nThe Area value C gets turned into 2.\nThe Area value D gets turned into 3.\nThe Area value E gets turned into 4.\nThe Area value F gets turned into 5.\n\n\n\nfor i, gas in enumerate(oe.categories_[1]):\n    print(f\"The VehGas value {gas} gets turned into {i}.\")\n\nThe VehGas value Diesel gets turned into 0.\nThe VehGas value Regular gets turned into 1.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#ordinal-encoded-values",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#ordinal-encoded-values",
    "title": "Categorical Variables",
    "section": "Ordinal encoded values",
    "text": "Ordinal encoded values\nNote that fitting an ordinal encoder (oe.fit) only establishes the mapping between numerical values and ordinal variable levels. To actually convert the values in the ordinal columns, we must also apply the oe.transform function. Following lines of code shows how we consistently apply the transform function to both train and test sets. To avoid inconsistencies in encoding, we use oe.fit function only to the train set.\n\nX_train_ord = oe.transform(X_train[[\"Area\", \"VehGas\"]])\nX_test_ord = oe.transform(X_test[[\"Area\", \"VehGas\"]])\n\n\n\n\nX_train[[\"Area\", \"VehGas\"]].head()\n\n\n\n\n\n\n\n\nArea\nVehGas\n\n\n\n\n0\nC\nDiesel\n\n\n1\nC\nRegular\n\n\n2\nE\nRegular\n\n\n3\nD\nDiesel\n\n\n4\nA\nRegular\n\n\n\n\n\n\n\n\n\nX_train_ord.head()\n\n\n\n\n\n\n\n\nArea\nVehGas\n\n\n\n\n0\n2.0\n0.0\n\n\n1\n2.0\n1.0\n\n\n2\n4.0\n1.0\n\n\n3\n3.0\n0.0\n\n\n4\n0.0\n1.0",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#train-on-ordinal-encoded-values",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#train-on-ordinal-encoded-values",
    "title": "Categorical Variables",
    "section": "Train on ordinal encoded values",
    "text": "Train on ordinal encoded values\nIf we would like to see whether we can train a neural network only on the ordinal variables, we can try the following code.\n\nrandom.seed(12)\nmodel = Sequential([\n  Dense(1, activation=\"exponential\")\n])\n\nmodel.compile(optimizer=\"adam\", loss=\"poisson\")\n\nes = EarlyStopping(verbose=True)\nhist = model.fit(X_train_ord, y_train, epochs=100, verbose=0,\n    validation_split=0.2, callbacks=[es])\nhist.history[\"val_loss\"][-1]\n\nEpoch 12: early stopping\n\n\n0.7821161150932312\n\n\n\nSets the random state for reproducibility\nConstructs a neural network with 1 Dense layer, 1 neuron and an exponential activation function\nCompiles the model by defining the optimizer and loss function\nDefines the early stopping object (Note that the early stopping object only works if we have a validation set. If we do not define a validation set, there will be no validation loss, hence, no metric to compare the training loss with.)\nFits the model only with the encoded columns as input data. The command validation_split=0.2 tells the neural network to treat the last 20% of input data as the validation set. This is an alternative way of defining the validation set.\nReturns the validation loss at the final epoch of training\n\n\nWhat about adding the continuous variables back in? Use a sklearn column transformer for that.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#preprocess-ordinal-continuous",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#preprocess-ordinal-continuous",
    "title": "Categorical Variables",
    "section": "Preprocess ordinal & continuous",
    "text": "Preprocess ordinal & continuous\n\nfrom sklearn.compose import make_column_transformer\n\nct = make_column_transformer(\n  (OrdinalEncoder(), [\"Area\", \"VehGas\"]),\n  (\"drop\", [\"VehBrand\", \"Region\"]),\n  remainder=StandardScaler()\n)\n\nX_train_ct = ct.fit_transform(X_train)\n\n\nImports the make_column_transformer class that can carry out data preparation selectively\nStarts defining the column transformer object\nSelects the ordinal columns and apply ordinal encoding\nDrops the nominal columns\nApplies StandardScaler transformation to the remaining numerical columns\nFits and transforms the train set using the defined column transformer object\n\n\n\n\nX_train.head(3)\n\n\n\n\n\n\n\n\nExposure\nArea\nVehPower\nVehAge\nDrivAge\nBonusMalus\nVehBrand\nVehGas\nDensity\nRegion\n\n\n\n\n0\n1.00\nC\n6.0\n2.0\n66.0\n50.0\nB2\nDiesel\n124.0\nR24\n\n\n1\n0.36\nC\n4.0\n10.0\n22.0\n100.0\nB1\nRegular\n377.0\nR93\n\n\n2\n0.02\nE\n12.0\n8.0\n44.0\n60.0\nB3\nRegular\n5628.0\nR11\n\n\n\n\n\n\n\n\n\nX_train_ct.head(3)\n\n\n\n\n\n\n\n\nordinalencoder__Area\nordinalencoder__VehGas\nremainder__Exposure\nremainder__VehPower\nremainder__VehAge\nremainder__DrivAge\nremainder__BonusMalus\nremainder__Density\n\n\n\n\n0\n2.0\n0.0\n1.126979\n-0.165005\n-0.844589\n1.451036\n-0.637179\n-0.366980\n\n\n1\n2.0\n1.0\n-0.590896\n-1.228181\n0.586255\n-1.548692\n2.303010\n-0.302700\n\n\n2\n4.0\n1.0\n-1.503517\n3.024524\n0.228544\n-0.048828\n-0.049141\n1.031432\n\n\n\n\n\n\n\n\n\nX_train_ct.head(3) returns a dataset with column names replaced according to a strange setting. To avoid that, we can use the verbose_feature_names_out=False command. Following code shows how the command results in a better looking X_train_ct data set.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#preprocess-ordinal-continuous-ii",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#preprocess-ordinal-continuous-ii",
    "title": "Categorical Variables",
    "section": "Preprocess ordinal & continuous II",
    "text": "Preprocess ordinal & continuous II\n\nfrom sklearn.compose import make_column_transformer\n\nct = make_column_transformer(\n  (OrdinalEncoder(), [\"Area\", \"VehGas\"]),\n  (\"drop\", [\"VehBrand\", \"Region\"]),\n  remainder=StandardScaler(),\n  verbose_feature_names_out=False\n)\nX_train_ct = ct.fit_transform(X_train)\n\n\n\n\nX_train.head(3)\n\n\n\n\n\n\n\n\nExposure\nArea\nVehPower\nVehAge\nDrivAge\nBonusMalus\nVehBrand\nVehGas\nDensity\nRegion\n\n\n\n\n0\n1.00\nC\n6.0\n2.0\n66.0\n50.0\nB2\nDiesel\n124.0\nR24\n\n\n1\n0.36\nC\n4.0\n10.0\n22.0\n100.0\nB1\nRegular\n377.0\nR93\n\n\n2\n0.02\nE\n12.0\n8.0\n44.0\n60.0\nB3\nRegular\n5628.0\nR11\n\n\n\n\n\n\n\n\n\nX_train_ct.head(3)\n\n\n\n\n\n\n\n\nArea\nVehGas\nExposure\nVehPower\nVehAge\nDrivAge\nBonusMalus\nDensity\n\n\n\n\n0\n2.0\n0.0\n1.126979\n-0.165005\n-0.844589\n1.451036\n-0.637179\n-0.366980\n\n\n1\n2.0\n1.0\n-0.590896\n-1.228181\n0.586255\n-1.548692\n2.303010\n-0.302700\n\n\n2\n4.0\n1.0\n-1.503517\n3.024524\n0.228544\n-0.048828\n-0.049141\n1.031432\n\n\n\n\n\n\n\n\n\nAn important thing to notice here is that, the order of columns have changed. They are rearranged according to the order in which we specify the transformations inside the column transformer.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#region-column",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#region-column",
    "title": "Categorical Variables",
    "section": "Region column",
    "text": "Region column\n\n\n\nFrench Administrative Regions\n\n\n\nSource: Nell et al. (2020), Case Study: French Motor Third-Party Liability Claims, SSRN.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#one-hot-encoding",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#one-hot-encoding",
    "title": "Categorical Variables",
    "section": "One-hot encoding",
    "text": "One-hot encoding\n\noe = OneHotEncoder(sparse_output=False)\nX_train_oh = oe.fit_transform(X_train[[\"Region\"]])\nX_test_oh = oe.transform(X_test[[\"Region\"]])\nprint(list(X_train[\"Region\"][:5]))\nX_train_oh.head()\n\n['R24', 'R93', 'R11', 'R42', 'R24']\n\n\n\n\n\n\n\n\n\nRegion_R11\nRegion_R21\nRegion_R22\nRegion_R23\nRegion_R24\nRegion_R25\nRegion_R26\nRegion_R31\nRegion_R41\nRegion_R42\n...\nRegion_R53\nRegion_R54\nRegion_R72\nRegion_R73\nRegion_R74\nRegion_R82\nRegion_R83\nRegion_R91\nRegion_R93\nRegion_R94\n\n\n\n\n0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n3\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n5 rows × 22 columns\n\n\n\nOne hot encoding is a way to assign numerical values to nominal variables. One hot encoding is different from ordinal encoding in the way in which it transforms the data. Ordinal encoding assigns a numerical integer to each unique category of the data column and returns one integer column. In contrast, one hot encoding returns a binary vector for each unique category. As a result, what we get from one hot encoding is not a single column vector, but a matrix with number of columns equal to the number of unique categories in that nominal data column.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#train-on-one-hot-inputs",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#train-on-one-hot-inputs",
    "title": "Categorical Variables",
    "section": "Train on one-hot inputs",
    "text": "Train on one-hot inputs\n\nnum_regions = len(oe.categories_[0])\n\nrandom.seed(12)\nmodel = Sequential([\n  Dense(2, input_dim=num_regions),\n  Dense(1, activation=\"exponential\")\n])\n\nmodel.compile(optimizer=\"adam\", loss=\"poisson\")\n\nes = EarlyStopping(verbose=True)\nhist = model.fit(X_train_oh, y_train, epochs=100, verbose=0,\n    validation_split=0.2, callbacks=[es])                       \nhist.history[\"val_loss\"][-1]\n\n/home/plaub/miniconda3/envs/ai/lib/python3.11/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n\n\nEpoch 9: early stopping\n\n\n0.7528033256530762\n\n\nThe above code shows how we can train a neural network using only the one-hot encoded variables. The example is similar to the case of training neural networks for ordinal encoding. 1. Computes the number of unique categories in the encoded column and store it in num_regions 2. Constructs the neural network. This time, it is a neural network with 1 hidden layer and 1 output layer. Dense(2, input_dim=num_regions) takes in an input matrix of with columns = num_regions and transofrmas it down to an output with 2 neurons Steps 3-6 is similar to what we saw during training with ordinal encoded variables.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#consider-the-first-layer",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#consider-the-first-layer",
    "title": "Categorical Variables",
    "section": "Consider the first layer",
    "text": "Consider the first layer\n\nevery_category = pd.DataFrame(np.eye(num_regions), columns=oe.categories_[0])\nevery_category.head(3)\n\n\n\n\n\n\n\n\nR11\nR21\nR22\nR23\nR24\nR25\nR26\nR31\nR41\nR42\n...\nR53\nR54\nR72\nR73\nR74\nR82\nR83\nR91\nR93\nR94\n\n\n\n\n0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n2\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n3 rows × 22 columns\n\n\n\n\n# Put this through the first layer of the model\nX = every_category.to_numpy()\nmodel.layers[0](X)\n\ntensor([[-0.0676, -0.2313],\n        [ 0.0578,  0.0541],\n        [-0.3354, -0.2603],\n        [ 0.0401, -0.3331],\n        [ 0.3537, -0.2513],\n        [ 0.0741, -0.3928],\n        [ 0.2834, -0.3078],\n        [ 0.1339,  0.3076],\n        [ 0.6641, -0.4717],\n        [ 0.2073, -0.0367],\n        [-0.0931, -0.4851],\n        [ 0.7988, -0.2612],\n        [ 0.4994, -0.0385],\n        [ 0.7135, -0.3665],\n        [-0.2302, -0.1524],\n        [-0.2581, -0.0808],\n        [ 0.7971,  0.0962],\n        [ 0.5428, -0.1990],\n        [-0.1908, -0.5027],\n        [ 0.1098,  0.1983],\n        [ 0.0318,  0.1482],\n        [ 0.3183,  0.5048]], grad_fn=&lt;AddBackward0&gt;)\n\n\nWe can extract each layer separately from a trained neural network and observe its output given a specific input. 1. Converts the dataframe to a numpy array 2. Takes out the first layer and feeds in the numpy array X. This returns an array with 2 columns",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#the-first-layer",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#the-first-layer",
    "title": "Categorical Variables",
    "section": "The first layer",
    "text": "The first layer\n\nlayer = model.layers[0]\nW, b = layer.get_weights()\nX.shape, W.shape, b.shape\n\n((22, 22), (22, 2), (2,))\n\n\nWe can also extract the layer, get its wieghts and compute manually. 1. Extracts the layer 2. Gets the weights and biases and stores the weights in W and biases in b 3. Returns the shapes of the matrices\n\n\n\nX @ W + b\n\narray([[-0.07, -0.23],\n       [ 0.06,  0.05],\n       [-0.34, -0.26],\n       [ 0.04, -0.33],\n       [ 0.35, -0.25],\n       [ 0.07, -0.39],\n       [ 0.28, -0.31],\n       [ 0.13,  0.31],\n       [ 0.66, -0.47],\n       [ 0.21, -0.04],\n       [-0.09, -0.49],\n       [ 0.8 , -0.26],\n       [ 0.5 , -0.04],\n       [ 0.71, -0.37],\n       [-0.23, -0.15],\n       [-0.26, -0.08],\n       [ 0.8 ,  0.1 ],\n       [ 0.54, -0.2 ],\n       [-0.19, -0.5 ],\n       [ 0.11,  0.2 ],\n       [ 0.03,  0.15],\n       [ 0.32,  0.5 ]])\n\n\n\n\nW + b\n\narray([[-0.07, -0.23],\n       [ 0.06,  0.05],\n       [-0.34, -0.26],\n       [ 0.04, -0.33],\n       [ 0.35, -0.25],\n       [ 0.07, -0.39],\n       [ 0.28, -0.31],\n       [ 0.13,  0.31],\n       [ 0.66, -0.47],\n       [ 0.21, -0.04],\n       [-0.09, -0.49],\n       [ 0.8 , -0.26],\n       [ 0.5 , -0.04],\n       [ 0.71, -0.37],\n       [-0.23, -0.15],\n       [-0.26, -0.08],\n       [ 0.8 ,  0.1 ],\n       [ 0.54, -0.2 ],\n       [-0.19, -0.5 ],\n       [ 0.11,  0.2 ],\n       [ 0.03,  0.15],\n       [ 0.32,  0.5 ]], dtype=float32)\n\n\n\n\nThe above codes manually compute and returns the same answers as before.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#just-a-look-up-operation",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#just-a-look-up-operation",
    "title": "Categorical Variables",
    "section": "Just a look-up operation",
    "text": "Just a look-up operation\n\n\n\ndisplay(list(oe.categories_[0]))\n\n['R11',\n 'R21',\n 'R22',\n 'R23',\n 'R24',\n 'R25',\n 'R26',\n 'R31',\n 'R41',\n 'R42',\n 'R43',\n 'R52',\n 'R53',\n 'R54',\n 'R72',\n 'R73',\n 'R74',\n 'R82',\n 'R83',\n 'R91',\n 'R93',\n 'R94']\n\n\n\n\nW + b\n\narray([[-0.07, -0.23],\n       [ 0.06,  0.05],\n       [-0.34, -0.26],\n       [ 0.04, -0.33],\n       [ 0.35, -0.25],\n       [ 0.07, -0.39],\n       [ 0.28, -0.31],\n       [ 0.13,  0.31],\n       [ 0.66, -0.47],\n       [ 0.21, -0.04],\n       [-0.09, -0.49],\n       [ 0.8 , -0.26],\n       [ 0.5 , -0.04],\n       [ 0.71, -0.37],\n       [-0.23, -0.15],\n       [-0.26, -0.08],\n       [ 0.8 ,  0.1 ],\n       [ 0.54, -0.2 ],\n       [-0.19, -0.5 ],\n       [ 0.11,  0.2 ],\n       [ 0.03,  0.15],\n       [ 0.32,  0.5 ]], dtype=float32)\n\n\n\n\nThe above outputs show that the neural network thinks the best way to represent “R11” for this particular problem is using the vector [-0.2, -0.12].",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#turn-the-region-into-an-index",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#turn-the-region-into-an-index",
    "title": "Categorical Variables",
    "section": "Turn the region into an index",
    "text": "Turn the region into an index\n\noe = OrdinalEncoder()\nX_train_reg = oe.fit_transform(X_train[[\"Region\"]])\nX_test_reg = oe.transform(X_test[[\"Region\"]])\n\nfor i, reg in enumerate(oe.categories_[0][:3]):\n  print(f\"The Region value {reg} gets turned into {i}.\")\n\nThe Region value R11 gets turned into 0.\nThe Region value R21 gets turned into 1.\nThe Region value R22 gets turned into 2.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#embedding",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#embedding",
    "title": "Categorical Variables",
    "section": "Embedding",
    "text": "Embedding\n\nfrom keras.layers import Embedding\nnum_regions = len(np.unique(X_train[[\"Region\"]]))\n\nrandom.seed(12)\nmodel = Sequential([\n  Embedding(input_dim=num_regions, output_dim=2),\n  Dense(1, activation=\"exponential\")\n])\n\nmodel.compile(optimizer=\"adam\", loss=\"poisson\")",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#fitting-that-model",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#fitting-that-model",
    "title": "Categorical Variables",
    "section": "Fitting that model",
    "text": "Fitting that model\n\nes = EarlyStopping(verbose=True)\nhist = model.fit(X_train_reg, y_train, epochs=100, verbose=0,\n    validation_split=0.2, callbacks=[es])\nhist.history[\"val_loss\"][-1]\n\nEpoch 4: early stopping\n\n\n0.7523981332778931\n\n\n\nmodel.layers\n\n[&lt;Embedding name=embedding, built=True&gt;, &lt;Dense name=dense_8, built=True&gt;]\n\n\nEmbedding layer can learn the optimal representation for a category of a categorical variable, during training. In the above example, encoding the variable Region using ordinal encoding and passing it through an embedding layer learns the optimal representation for the region during training. Ordinal encoding followed with an embedding layer is a better alternative to one-hot encoding. It is computationally less expensive (compared to generating large matrices in one-hot encoding) particularly when the number of categories is high.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#keras-embedding-layer",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#keras-embedding-layer",
    "title": "Categorical Variables",
    "section": "Keras’ Embedding Layer",
    "text": "Keras’ Embedding Layer\n\n\n\nmodel.layers[0].get_weights()[0]\n\narray([[ 0.05, -0.08],\n       [-0.  ,  0.02],\n       [-0.04, -0.02],\n       [ 0.11, -0.14],\n       [ 0.22, -0.2 ],\n       [ 0.15, -0.18],\n       [ 0.2 , -0.2 ],\n       [-0.04,  0.08],\n       [ 0.39, -0.36],\n       [ 0.07, -0.06],\n       [ 0.08, -0.14],\n       [ 0.38, -0.32],\n       [ 0.21, -0.15],\n       [ 0.37, -0.33],\n       [-0.05,  0.01],\n       [-0.07,  0.04],\n       [ 0.26, -0.16],\n       [ 0.27, -0.22],\n       [ 0.07, -0.13],\n       [-0.  ,  0.04],\n       [-0.04,  0.06],\n       [-0.04,  0.13]], dtype=float32)\n\n\n\n\nX_train[\"Region\"].head(4)\n\n0    R24\n1    R93\n2    R11\n3    R42\nName: Region, dtype: object\n\n\n\nX_sample = X_train_reg[:4].to_numpy()\nX_sample\n\narray([[ 4.],\n       [20.],\n       [ 0.],\n       [ 9.]])\n\n\n\nenc_tensor = model.layers[0](X_sample)\nkeras.ops.convert_to_numpy(enc_tensor).squeeze()\n\narray([[ 0.22, -0.2 ],\n       [-0.04,  0.06],\n       [ 0.05, -0.08],\n       [ 0.07, -0.06]], dtype=float32)\n\n\n\n\n\nReturns the weights of the Embedding layer. The function model.layers[0].get_weights()[0] returns a 22 \\times 2 weights matrix with optimal representations for each category. Here 22 corresponds to the number of unique categories, and 2 corresponds to the size of the lower dimensional space using which we represent each category.\nReturns the first 4 rows of train set\nConverts first 4 rows to a numpy array\nSends the numpy array through the Embedding layer to retrieve corresponding weights We can observe how the last code returns a numpy array with representations corresponding to R24, R93, R11 and R42.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#the-learned-embeddings",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#the-learned-embeddings",
    "title": "Categorical Variables",
    "section": "The learned embeddings",
    "text": "The learned embeddings\nIf we only have two-dimensional embeddings we can plot them.\n\npoints = model.layers[0].get_weights()[0]\nplt.scatter(points[:,0], points[:,1])\nfor i in range(num_regions):\n  plt.text(points[i,0]+0.01, points[i,1] , s=oe.categories_[0][i])\n\n\n\n\n\n\n\n\nWhile it not always the case, entity embeddings can at times be meaningful instead of just being useful representations. The above figure shows how plotting the learned embeddings help reveal regions which might be similar (e.g. coastal areas, hilly areas etc.).",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#entity-embeddings",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#entity-embeddings",
    "title": "Categorical Variables",
    "section": "Entity embeddings",
    "text": "Entity embeddings\n\n\n\nEmbeddings will gradually improve during training.\n\n\n\nSource: Marcus Lautier (2022).",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#embeddings-other-inputs",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#embeddings-other-inputs",
    "title": "Categorical Variables",
    "section": "Embeddings & other inputs",
    "text": "Embeddings & other inputs\nOften times, we deal with both categorical and numerical variables together. The following diagram shows a recommended way of inputting numerical and categorical data in to the neural network. Numerical variables are inherently numeric hence, do not require entity embedding. On the other hand, categorical variables must undergo entity embedding to convert to number format.\n\n\n\nIllustration of a neural network with both continuous and categorical inputs.\n\n\nWe can’t do this with Sequential models…\n\nSource: LotusLabs Blog, Accurate insurance claims prediction with Deep Learning.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#converting-sequential-models",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#converting-sequential-models",
    "title": "Categorical Variables",
    "section": "Converting Sequential models",
    "text": "Converting Sequential models\n\nfrom keras.models import Model\nfrom keras.layers import Input\n\n\n\n\nrandom.seed(12)\n\nmodel = Sequential([\n  Dense(30, \"relu\"),\n  Dense(1, \"exponential\")\n])\n\nmodel.compile(\n  optimizer=\"adam\",\n  loss=\"poisson\")\n\nhist = model.fit(\n  X_train_ord, y_train,\n  epochs=1, verbose=0,\n  validation_split=0.2)\nhist.history[\"val_loss\"][-1]\n\n0.8046959042549133\n\n\n\n\nrandom.seed(12)\n\ninputs = Input(shape=(2,))\nx = Dense(30, \"relu\")(inputs)\nout = Dense(1, \"exponential\")(x)\nmodel = Model(inputs, out)\n\nmodel.compile(\n  optimizer=\"adam\",\n  loss=\"poisson\")\n\nhist = model.fit(\n  X_train_ord, y_train,\n  epochs=1, verbose=0,\n  validation_split=0.2)\nhist.history[\"val_loss\"][-1]\n\n0.8048074245452881\n\n\n\n\nCf. one-length tuples.\nThe above code shows how to construct the same neural network using sequential models and Keras functional API. There are some differences in the construction. In the functional API approach, we must specify the shape of the input layer, and explicitly define the inputs and outputs of a layer. model = Model(inputs, out) function specifies the input and output of the model. This manner of specifying the inputs and outputs of the model allow the user to combine several inputs (inputs which are preprocessed in different ways) to finally build the model. One example would be combining entity embedded categorical variables, and scaled numerical variables.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#wide-deep-network",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#wide-deep-network",
    "title": "Categorical Variables",
    "section": "Wide & Deep network",
    "text": "Wide & Deep network\n\n\n\n\n\nAn illustration of the wide & deep network architecture.\n\n\n\nAdd a skip connection from input to output layers.\n\nfrom keras.layers \\\n    import Concatenate\n\ninp = Input(shape=X_train.shape[1:])\nhidden1 = Dense(30, \"relu\")(inp)\nhidden2 = Dense(30, \"relu\")(hidden1)\nconcat = Concatenate()(\n  [inp, hidden2])\noutput = Dense(1)(concat)\nmodel = Model(\n    inputs=[inp],\n    outputs=[output])\n\n\n\n\nSources: Marcus Lautier (2022) & Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Chapter 10 code snippet.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#naming-the-layers",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#naming-the-layers",
    "title": "Categorical Variables",
    "section": "Naming the layers",
    "text": "Naming the layers\nFor complex networks, it is often useful to give meaningul names to the layers.\n\ninput_ = Input(shape=X_train.shape[1:], name=\"input\")\nhidden1 = Dense(30, activation=\"relu\", name=\"hidden1\")(input_)\nhidden2 = Dense(30, activation=\"relu\", name=\"hidden2\")(hidden1)\nconcat = Concatenate(name=\"combined\")([input_, hidden2])\noutput = Dense(1, name=\"output\")(concat)\nmodel = Model(inputs=[input_], outputs=[output])",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#inspecting-a-complex-model",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#inspecting-a-complex-model",
    "title": "Categorical Variables",
    "section": "Inspecting a complex model",
    "text": "Inspecting a complex model\n\nfrom keras.utils import plot_model\n\n\n\n\nplot_model(model, show_layer_names=True)\n\n\n\n\n\n\n\n\n\n\n\nmodel.summary(line_length=75)\n\nModel: \"functional_10\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n┃                     ┃                   ┃  Param ┃                      ┃\n┃ Layer (type)        ┃ Output Shape      ┃      # ┃ Connected to         ┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n│ input (InputLayer)  │ (None, 10)        │      0 │ -                    │\n├─────────────────────┼───────────────────┼────────┼──────────────────────┤\n│ hidden1 (Dense)     │ (None, 30)        │    330 │ input[0][0]          │\n├─────────────────────┼───────────────────┼────────┼──────────────────────┤\n│ hidden2 (Dense)     │ (None, 30)        │    930 │ hidden1[0][0]        │\n├─────────────────────┼───────────────────┼────────┼──────────────────────┤\n│ combined            │ (None, 40)        │      0 │ input[0][0],         │\n│ (Concatenate)       │                   │        │ hidden2[0][0]        │\n├─────────────────────┼───────────────────┼────────┼──────────────────────┤\n│ output (Dense)      │ (None, 1)         │     41 │ combined[0][0]       │\n└─────────────────────┴───────────────────┴────────┴──────────────────────┘\n\n\n\n Total params: 1,301 (5.08 KB)\n\n\n\n Trainable params: 1,301 (5.08 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#the-desired-architecture",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#the-desired-architecture",
    "title": "Categorical Variables",
    "section": "The desired architecture",
    "text": "The desired architecture\n\n\n\nIllustration of a neural network with both continuous and categorical inputs.\n\n\n\nSource: LotusLabs Blog, Accurate insurance claims prediction with Deep Learning.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#preprocess-all-french-motor-inputs",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#preprocess-all-french-motor-inputs",
    "title": "Categorical Variables",
    "section": "Preprocess all French motor inputs",
    "text": "Preprocess all French motor inputs\nTransform the categorical variables to integers:\n\nnum_brands, num_regions = X_train.nunique()[[\"VehBrand\", \"Region\"]]\n\nct = make_column_transformer(\n  (OrdinalEncoder(), [\"VehBrand\", \"Region\", \"Area\", \"VehGas\"]),\n  remainder=StandardScaler(),\n  verbose_feature_names_out=False\n)\nX_train_ct = ct.fit_transform(X_train)\nX_test_ct = ct.transform(X_test)\n\n\nStores separately the number of unique categorical in the nominal variables, as would require these values later for entity embedding\nContructs columns transformer by first ordinally encoding all categorical variables. Ordinal variables are ordinal encoded because it is the sensible thing. Nominal variables are ordinal encoded as an intermediate step before passing through an entity embedding layer\nApplies standard scaling to all other numerical variables\nverbose_feature_names_out=False stops unnecessarily printing out the outputs of the process\nFits the column transformer to the train set and transforms it\nTransforms the test set using the column transformer fitted using the train set\n\nSplit the brand and region data apart from the rest:\n\nX_train_brand = X_train_ct[\"VehBrand\"]; X_test_brand = X_test_ct[\"VehBrand\"]\nX_train_region = X_train_ct[\"Region\"]; X_test_region = X_test_ct[\"Region\"]\nX_train_rest = X_train_ct.drop([\"VehBrand\", \"Region\"], axis=1)\nX_test_rest = X_test_ct.drop([\"VehBrand\", \"Region\"], axis=1)",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#organise-the-inputs",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#organise-the-inputs",
    "title": "Categorical Variables",
    "section": "Organise the inputs",
    "text": "Organise the inputs\nMake a Keras Input for: vehicle brand, region, & others.\n\nveh_brand = Input(shape=(1,), name=\"vehBrand\")\nregion = Input(shape=(1,), name=\"region\")\nother_inputs = Input(shape=X_train_rest.shape[1:], name=\"otherInputs\")\n\nCreate embeddings and join them with the other inputs.\n\nfrom keras.layers import Reshape\n\nrandom.seed(1337)\nveh_brand_ee = Embedding(input_dim=num_brands, output_dim=2,\n    name=\"vehBrandEE\")(veh_brand)                                \nveh_brand_ee = Reshape(target_shape=(2,))(veh_brand_ee)\n\nregion_ee = Embedding(input_dim=num_regions, output_dim=2,\n    name=\"regionEE\")(region)\nregion_ee = Reshape(target_shape=(2,))(region_ee)\n\nx = Concatenate(name=\"combined\")([veh_brand_ee, region_ee, other_inputs])\n\n\nImports Reshape class from keras.layers library\nConstructs the embedding layer by specifying the input dimension (the number of unique categories) and output dimension (the number of dimensions we want the input to be summarised in to)\nReshapes the output to match the format required at the model building step\nConstructs the embedding layer by specifying the input dimension (the number of unique categories) and output dimension\nReshapes the output to match the format required at the model building step\nCombines the entity embedded matrices and other inputs together",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#complete-the-model-and-fit-it",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#complete-the-model-and-fit-it",
    "title": "Categorical Variables",
    "section": "Complete the model and fit it",
    "text": "Complete the model and fit it\nFeed the combined embeddings & continuous inputs to some normal dense layers.\n\nx = Dense(30, \"relu\", name=\"hidden\")(x)\nout = Dense(1, \"exponential\", name=\"out\")(x)\n\nmodel = Model([veh_brand, region, other_inputs], out)\nmodel.compile(optimizer=\"adam\", loss=\"poisson\")\n\nhist = model.fit((X_train_brand, X_train_region, X_train_rest),\n    y_train, epochs=100, verbose=0,\n    callbacks=[EarlyStopping(patience=5)], validation_split=0.2)\nnp.min(hist.history[\"val_loss\"])\n\n0.6686854362487793\n\n\n\nModel building stage requires all inputs to be passed in together\nPasses in the three sets of data, since the format defined at the model building stage requires 3 data sets",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#plotting-this-model",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#plotting-this-model",
    "title": "Categorical Variables",
    "section": "Plotting this model",
    "text": "Plotting this model\n\nplot_model(model, show_layer_names=True)",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#why-we-need-to-reshape",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#why-we-need-to-reshape",
    "title": "Categorical Variables",
    "section": "Why we need to reshape",
    "text": "Why we need to reshape\n\nplot_model(model, show_layer_names=True, show_shapes=True)\n\n\n\n\n\n\n\n\nThe plotted model shows how, for example, region starts off as a matrix with (None,1) shape. This indicates that, region was a column matrix with some number of rows. Entity embedding the region variable resulted in a 3D array of shape ((None,1,2)) which is not the required format for concatenating. Therefore, we reshape it using the Reshape function. This results in column array of shape, (None,2) which is what we need for concatenating.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#two-different-models",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#two-different-models",
    "title": "Categorical Variables",
    "section": "Two different models",
    "text": "Two different models\nHave \\{ (\\mathbf{x}_i, y_i) \\}_{i=1, \\dots, n} for \\mathbf{x}_i \\in \\mathbb{R}^{47} and y_i \\in \\mathbb{N}_0.\nModel 1: Say Y_i \\sim \\mathsf{Poisson}(\\lambda(\\mathbf{x}_i)).\nBut, the exposures are different for each policy. \\lambda(\\mathbf{x}_i) is the expected number of claims for the duration of policy i’s contract.\nModel 2: Say Y_i \\sim \\mathsf{Poisson}(\\text{Exposure}_i \\times \\lambda(\\mathbf{x}_i)).\nNow, \\text{Exposure}_i \\not\\in \\mathbf{x}_i, and \\lambda(\\mathbf{x}_i) is the rate per year.",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#just-take-continuous-variables",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#just-take-continuous-variables",
    "title": "Categorical Variables",
    "section": "Just take continuous variables",
    "text": "Just take continuous variables\nFor convenience, following code only considers the numerical variables during this implementation.\n\nct = make_column_transformer(\n  (\"passthrough\", [\"Exposure\"]),\n  (\"drop\", [\"VehBrand\", \"Region\", \"Area\", \"VehGas\"]),\n  remainder=StandardScaler(),\n  verbose_feature_names_out=False\n)\nX_train_ct = ct.fit_transform(X_train)\nX_test_ct = ct.transform(X_test)\n\n\nStarts defining the column transformer\nLets Exposure passthrough the neural network as it is without peprocessing\nDrops the categorical variables (for the ease of implementation)\nScales the remaining variables\nAvoids printing unnecessary outputs\nFits and transforms the train set\nOnly transforms the test set\n\nSplit exposure apart from the rest:\n\nX_train_exp = X_train_ct[\"Exposure\"]; X_test_exp = X_test_ct[\"Exposure\"]\nX_train_rest = X_train_ct.drop(\"Exposure\", axis=1)\nX_test_rest = X_test_ct.drop(\"Exposure\", axis=1)\n\n\nTakes out Exposure seperately\nDrops Exposure from train set\nDrops Exposure from test set\n\nOrganise the inputs:\n\nexposure = Input(shape=(1,), name=\"exposure\")\nother_inputs = Input(shape=X_train_rest.shape[1:], name=\"otherInputs\")",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#make-fit-the-model",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#make-fit-the-model",
    "title": "Categorical Variables",
    "section": "Make & fit the model",
    "text": "Make & fit the model\nFeed the continuous inputs to some normal dense layers.\n\nrandom.seed(1337)\nx = Dense(30, \"relu\", name=\"hidden1\")(other_inputs)\nx = Dense(30, \"relu\", name=\"hidden2\")(x)\nlambda_ = Dense(1, \"exponential\", name=\"lambda\")(x)\n\n\nfrom keras.layers import Multiply\n\nout = Multiply(name=\"out\")([lambda_, exposure])\nmodel = Model([exposure, other_inputs], out)\nmodel.compile(optimizer=\"adam\", loss=\"poisson\")\n\nes = EarlyStopping(patience=10, restore_best_weights=True, verbose=1)\nhist = model.fit((X_train_exp, X_train_rest),\n    y_train, epochs=100, verbose=0,\n    callbacks=[es], validation_split=0.2)\nnp.min(hist.history[\"val_loss\"])\n\nEpoch 33: early stopping\nRestoring model weights from the end of the best epoch: 23.\n\n\n0.8773847818374634",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.html#plot-the-model",
    "href": "Lecture-3-Tabular-Data/categorical-variables.html#plot-the-model",
    "title": "Categorical Variables",
    "section": "Plot the model",
    "text": "Plot the model\n\nplot_model(model, show_layer_names=True)",
    "crumbs": [
      "Module 3",
      "Categorical Variables"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#lecture-outline",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#lecture-outline",
    "title": "Categorical Variables",
    "section": "Lecture outline",
    "text": "Lecture outline\n\nOne-hot embedding\nOrdinal variables\nEntity embeddings"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#load-packages",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#load-packages",
    "title": "Categorical Variables",
    "section": "Load packages",
    "text": "Load packages\n\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.0\nIPython version      : 8.20.0\n\nsklearn   : 1.4.0\nkeras     : 3.0.4\ntorch     : 2.2.0\ntensorflow: 2.15.0.post1"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#keras-model-methods",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#keras-model-methods",
    "title": "Categorical Variables",
    "section": "Keras model methods",
    "text": "Keras model methods\n\n\n\ncompile: specify the loss function and optimiser\nfit: learn the parameters of the model\npredict: apply the model\nevaluate: apply the model and calculate a metric\n\n\n\n\nrandom.seed(12)\nmodel = Sequential()\nmodel.add(Dense(1, activation=\"relu\"))\nmodel.compile(\"adam\", \"poisson\")\nmodel.fit(X_train, y_train, verbose=0)\ny_pred = model.predict(X_val, verbose=0)\nprint(model.evaluate(X_val, y_val, verbose=0))\n\n4.460747718811035"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#scikit-learn-model-methods",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#scikit-learn-model-methods",
    "title": "Categorical Variables",
    "section": "Scikit-learn model methods",
    "text": "Scikit-learn model methods\n\n\n\nfit: learn the parameters of the model\npredict: apply the model\nscore: apply the model and calculate a metric\n\n\n\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_val)\nprint(model.score(X_val, y_val))\n\n-0.666850597951445"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#scikit-learn-preprocessing-methods",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#scikit-learn-preprocessing-methods",
    "title": "Categorical Variables",
    "section": "Scikit-learn preprocessing methods",
    "text": "Scikit-learn preprocessing methods\n\n\n\nfit: learn the parameters of the transformation\ntransform: apply the transformation\nfit_transform: learn the parameters and apply the transformation\n\n\n\nfitfit_transform\n\n\n\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train_sc = scaler.transform(X_train)\nX_val_sc = scaler.transform(X_val)\nX_test_sc = scaler.transform(X_test)\n\nprint(X_train_sc.mean(axis=0))\nprint(X_train_sc.std(axis=0))\nprint(X_val_sc.mean(axis=0))\nprint(X_val_sc.std(axis=0))\n\n[ 2.97e-17 -2.18e-17  1.98e-17 -5.65e-17]\n[1. 1. 1. 1.]\n[-0.34  0.07 -0.27 -0.82]\n[1.01 0.66 1.26 0.89]\n\n\n\n\n\nscaler = StandardScaler()\nX_train_sc = scaler.fit_transform(X_train)\nX_val_sc = scaler.transform(X_val)\nX_test_sc = scaler.transform(X_test)\n\nprint(X_train_sc.mean(axis=0))\nprint(X_train_sc.std(axis=0))\nprint(X_val_sc.mean(axis=0))\nprint(X_val_sc.std(axis=0))\n\n[ 2.97e-17 -2.18e-17  1.98e-17 -5.65e-17]\n[1. 1. 1. 1.]\n[-0.34  0.07 -0.27 -0.82]\n[1.01 0.66 1.26 0.89]"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#summary-of-the-splitting",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#summary-of-the-splitting",
    "title": "Categorical Variables",
    "section": "Summary of the splitting",
    "text": "Summary of the splitting\n\n\nSource: Melantha Wang (2022), ACTL3143 Project."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#dataframes-arrays",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#dataframes-arrays",
    "title": "Categorical Variables",
    "section": "Dataframes & arrays",
    "text": "Dataframes & arrays\n\n\n\nX_test.head(3)\n\n\n\n\n\n\n\n\nx1\nx2\nx3\nx4\n\n\n\n\n83\n0.075805\n-0.677162\n0.975120\n-0.147057\n\n\n53\n0.954002\n0.651391\n-0.315269\n0.758969\n\n\n70\n0.113517\n0.662131\n1.586017\n-1.237815\n\n\n\n\n\n\n\n\n\nX_test_sc\n\narray([[ 0.13, -0.64,  0.89, -0.4 ],\n       [ 1.15,  0.67, -0.44,  0.62],\n       [ 0.18,  0.68,  1.52, -1.62],\n       [ 0.77, -0.82, -1.22,  0.31],\n       [ 0.06,  1.46, -0.39,  2.83],\n       [ 2.21,  0.49, -1.34,  0.51],\n       [-0.57,  0.53, -0.02,  0.86],\n       [ 0.16,  0.61, -0.96,  2.12],\n       [ 0.9 ,  0.2 , -0.23, -0.57],\n       [ 0.62, -0.11,  0.55,  1.48],\n       [ 0.  ,  1.57, -2.81,  0.69],\n       [ 0.96, -0.87,  1.33, -1.81],\n       [-0.64,  0.87,  0.25, -1.01],\n       [-1.19,  0.49, -1.06,  1.51],\n       [ 0.65,  1.54, -0.23,  0.22],\n       [-1.13,  0.34, -1.05, -1.82],\n       [ 0.02,  0.14,  1.2 , -0.9 ],\n       [ 0.68, -0.17, -0.34,  1.  ],\n       [ 0.44, -1.72,  0.22, -0.66],\n       [ 0.73,  2.19, -1.13, -0.87],\n       [ 2.73, -1.82,  0.59, -2.04],\n       [ 1.04, -0.13, -0.13, -1.36],\n       [-0.14,  0.43,  1.82, -0.04],\n       [-0.24, -0.72, -1.03, -1.15],\n       [ 0.28, -0.57, -0.04, -0.66]])\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nBy default, when you pass sklearn a DataFrame it returns a numpy array."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#keep-as-a-dataframe",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#keep-as-a-dataframe",
    "title": "Categorical Variables",
    "section": "Keep as a DataFrame",
    "text": "Keep as a DataFrame\n\n\n\nFrom scikit-learn 1.2:\n\nfrom sklearn import set_config\nset_config(transform_output=\"pandas\")\n\nimp = SimpleImputer()\nimp.fit(X_train)\nX_train_imp = imp.fit_transform(X_train)\nX_val_imp = imp.transform(X_val)\nX_test_imp = imp.transform(X_test)\n\n\n\nX_test_imp\n\n\n\n\n\n\n\n\nx1\nx2\nx3\nx4\n\n\n\n\n83\n0.075805\n-0.677162\n0.975120\n-0.147057\n\n\n53\n0.954002\n0.651391\n-0.315269\n0.758969\n\n\n...\n...\n...\n...\n...\n\n\n42\n-0.245388\n-0.753736\n-0.889514\n-0.815810\n\n\n69\n0.199060\n-0.600217\n0.069802\n-0.385314\n\n\n\n\n25 rows × 4 columns"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#french-motor-dataset",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#french-motor-dataset",
    "title": "Categorical Variables",
    "section": "French motor dataset",
    "text": "French motor dataset\nDownload the dataset if we don’t have it already.\n\nfrom pathlib import Path\nfrom sklearn.datasets import fetch_openml\n\nif not Path(\"french-motor.csv\").exists():\n    freq = fetch_openml(data_id=41214, as_frame=True).frame\n    freq.to_csv(\"french-motor.csv\", index=False)\nelse:\n    freq = pd.read_csv(\"french-motor.csv\")\n\nfreq"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#french-motor-dataset-output",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#french-motor-dataset-output",
    "title": "Categorical Variables",
    "section": "French motor dataset",
    "text": "French motor dataset\n\n\n\n\n\n\n\n\nIDpol\nClaimNb\nExposure\nArea\nVehPower\nVehAge\nDrivAge\nBonusMalus\nVehBrand\nVehGas\nDensity\nRegion\n\n\n\n\n0\n1.0\n1.0\n0.10000\nD\n5.0\n0.0\n55.0\n50.0\nB12\nRegular\n1217.0\nR82\n\n\n1\n3.0\n1.0\n0.77000\nD\n5.0\n0.0\n55.0\n50.0\nB12\nRegular\n1217.0\nR82\n\n\n2\n5.0\n1.0\n0.75000\nB\n6.0\n2.0\n52.0\n50.0\nB12\nDiesel\n54.0\nR22\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n678010\n6114328.0\n0.0\n0.00274\nD\n6.0\n2.0\n45.0\n50.0\nB12\nDiesel\n1323.0\nR82\n\n\n678011\n6114329.0\n0.0\n0.00274\nB\n4.0\n0.0\n60.0\n50.0\nB12\nRegular\n95.0\nR26\n\n\n678012\n6114330.0\n0.0\n0.00274\nB\n7.0\n6.0\n29.0\n54.0\nB12\nDiesel\n65.0\nR72\n\n\n\n\n678013 rows × 12 columns"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#data-dictionary",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#data-dictionary",
    "title": "Categorical Variables",
    "section": "Data dictionary",
    "text": "Data dictionary\n\n\n\nIDpol: policy number (unique identifier)\nClaimNb: number of claims on the given policy\nExposure: total exposure in yearly units\nArea: area code (categorical, ordinal)\nVehPower: power of the car (categorical, ordinal)\nVehAge: age of the car in years\nDrivAge: age of the (most common) driver in years\n\n\n\nBonusMalus: bonus-malus level between 50 and 230 (with reference level 100)\nVehBrand: car brand (categorical, nominal)\nVehGas: diesel or regular fuel car (binary)\nDensity: density of inhabitants per km2 in the city of the living place of the driver\nRegion: regions in France (prior to 2016)\n\n\n\n\nSource: Nell et al. (2020), Case Study: French Motor Third-Party Liability Claims, SSRN."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#the-model",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#the-model",
    "title": "Categorical Variables",
    "section": "The model",
    "text": "The model\nHave \\{ (\\mathbf{x}_i, y_i) \\}_{i=1, \\dots, n} for \\mathbf{x}_i \\in \\mathbb{R}^{47} and y_i \\in \\mathbb{N}_0.\nAssume the distribution \nY_i \\sim \\mathsf{Poisson}(\\lambda(\\mathbf{x}_i))\n\nWe have \\mathbb{E} Y_i = \\lambda(\\mathbf{x}_i). The NN takes \\mathbf{x}_i & predicts \\mathbb{E} Y_i.\n\n\n\n\n\n\nNote\n\n\nFor insurance, this is a bit weird. The exposures are different for each policy.\n\\lambda(\\mathbf{x}_i) is the expected number of claims for the duration of policy i’s contract.\nNormally, \\text{Exposure}_i \\not\\in \\mathbf{x}_i, and \\lambda(\\mathbf{x}_i) is the expected rate per year, then \nY_i \\sim \\mathsf{Poisson}(\\text{Exposure}_i \\times \\lambda(\\mathbf{x}_i))."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#where-are-things-defined",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#where-are-things-defined",
    "title": "Categorical Variables",
    "section": "Where are things defined?",
    "text": "Where are things defined?\nIn Keras, string options are used for convenience to reference specific functions or settings.\n\nmodel = Sequential([\n    Dense(30, activation=\"relu\"),\n    Dense(1, activation=\"exponential\")\n])\n\nis the same as\n\nfrom keras.activations import relu, exponential\n\nmodel = Sequential([\n    Dense(30, activation=relu),\n    Dense(1, activation=exponential)\n])\n\n\nx = [-1.0, 0.0, 1.0]\nprint(relu(x))\nprint(exponential(x))\n\ntensor([0., 0., 1.])\ntensor([0.3679, 1.0000, 2.7183])"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#string-arguments-to-.compile",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#string-arguments-to-.compile",
    "title": "Categorical Variables",
    "section": "String arguments to .compile",
    "text": "String arguments to .compile\nWhen we run\n\nmodel.compile(optimizer=\"adam\", loss=\"poisson\")\n\nit is equivalent to\n\nfrom keras.losses import poisson\nfrom keras.optimizers import Adam\n\nmodel.compile(optimizer=Adam(), loss=poisson)\n\nWhy do this manually? To adjust the object:\n\noptimizer = Adam(learning_rate=0.01)\nmodel.compile(optimizer=optimizer, loss=\"poisson\")\n\nor to get help."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#keras-poisson-loss",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#keras-poisson-loss",
    "title": "Categorical Variables",
    "section": "Keras’ “poisson” loss",
    "text": "Keras’ “poisson” loss\n\nhelp(keras.losses.poisson)\n\nHelp on function poisson in module keras.src.losses.losses:\n\npoisson(y_true, y_pred)\n    Computes the Poisson loss between y_true and y_pred.\n    \n    Formula:\n    \n    ```python\n    loss = y_pred - y_true * log(y_pred)\n    ```\n    \n    Args:\n        y_true: Ground truth values. shape = `[batch_size, d0, .. dN]`.\n        y_pred: The predicted values. shape = `[batch_size, d0, .. dN]`.\n    \n    Returns:\n        Poisson loss values with shape = `[batch_size, d0, .. dN-1]`.\n    \n    Example:\n    \n    &gt;&gt;&gt; y_true = np.random.randint(0, 2, size=(2, 3))\n    &gt;&gt;&gt; y_pred = np.random.random(size=(2, 3))\n    &gt;&gt;&gt; loss = keras.losses.poisson(y_true, y_pred)\n    &gt;&gt;&gt; assert loss.shape == (2,)\n    &gt;&gt;&gt; y_pred = y_pred + 1e-7\n    &gt;&gt;&gt; assert np.allclose(\n    ...     loss, np.mean(y_pred - y_true * np.log(y_pred), axis=-1),\n    ...     atol=1e-5)"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#subsample-and-split",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#subsample-and-split",
    "title": "Categorical Variables",
    "section": "Subsample and split",
    "text": "Subsample and split\n\nfreq = freq.drop(\"IDpol\", axis=1).head(25_000)\n\nX_train, X_test, y_train, y_test = train_test_split(\n  freq.drop(\"ClaimNb\", axis=1), freq[\"ClaimNb\"], random_state=2023)\n\n# Reset each index to start at 0 again.\nX_train = X_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#what-values-do-we-see-in-the-data",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#what-values-do-we-see-in-the-data",
    "title": "Categorical Variables",
    "section": "What values do we see in the data?",
    "text": "What values do we see in the data?\nX_train[\"Area\"].value_counts()\nX_train[\"VehBrand\"].value_counts()\nX_train[\"VehGas\"].value_counts()\nX_train[\"Region\"].value_counts()\n\n\n\n\nArea\nC    5507\nD    4113\nA    3527\nE    2769\nB    2359\nF     475\nName: count, dtype: int64\n\n\n\n\nVehBrand\nB1     5069\nB2     4838\nB12    3708\n       ... \nB13     336\nB11     284\nB14     136\nName: count, Length: 11, dtype: int64\n\n\n\n\n\n\nVehGas\nRegular    10773\nDiesel      7977\nName: count, dtype: int64\n\n\n\n\nRegion\nR24    6498\nR82    2119\nR11    1909\n       ... \nR21      90\nR42      55\nR43      26\nName: count, Length: 22, dtype: int64"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#ordinal-binary-categories-are-easy",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#ordinal-binary-categories-are-easy",
    "title": "Categorical Variables",
    "section": "Ordinal & binary categories are easy",
    "text": "Ordinal & binary categories are easy\n\nfrom sklearn.preprocessing import OrdinalEncoder\noe = OrdinalEncoder()\noe.fit(X_train[[\"Area\", \"VehGas\"]])\noe.categories_\n\n[array(['A', 'B', 'C', 'D', 'E', 'F'], dtype=object),\n array(['Diesel', 'Regular'], dtype=object)]\n\n\n\nfor i, area in enumerate(oe.categories_[0]):\n    print(f\"The Area value {area} gets turned into {i}.\")\n\nThe Area value A gets turned into 0.\nThe Area value B gets turned into 1.\nThe Area value C gets turned into 2.\nThe Area value D gets turned into 3.\nThe Area value E gets turned into 4.\nThe Area value F gets turned into 5.\n\n\n\nfor i, gas in enumerate(oe.categories_[1]):\n    print(f\"The VehGas value {gas} gets turned into {i}.\")\n\nThe VehGas value Diesel gets turned into 0.\nThe VehGas value Regular gets turned into 1."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#ordinal-encoded-values",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#ordinal-encoded-values",
    "title": "Categorical Variables",
    "section": "Ordinal encoded values",
    "text": "Ordinal encoded values\n\nX_train_ord = oe.transform(X_train[[\"Area\", \"VehGas\"]])\nX_test_ord = oe.transform(X_test[[\"Area\", \"VehGas\"]])\n\n\n\n\nX_train[[\"Area\", \"VehGas\"]].head()\n\n\n\n\n\n\n\n\nArea\nVehGas\n\n\n\n\n0\nC\nDiesel\n\n\n1\nC\nRegular\n\n\n2\nE\nRegular\n\n\n3\nD\nDiesel\n\n\n4\nA\nRegular\n\n\n\n\n\n\n\n\n\nX_train_ord.head()\n\n\n\n\n\n\n\n\nArea\nVehGas\n\n\n\n\n0\n2.0\n0.0\n\n\n1\n2.0\n1.0\n\n\n2\n4.0\n1.0\n\n\n3\n3.0\n0.0\n\n\n4\n0.0\n1.0"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#train-on-ordinal-encoded-values",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#train-on-ordinal-encoded-values",
    "title": "Categorical Variables",
    "section": "Train on ordinal encoded values",
    "text": "Train on ordinal encoded values\n\nrandom.seed(12)\nmodel = Sequential([\n  Dense(1, activation=\"exponential\")\n])\n\nmodel.compile(optimizer=\"adam\", loss=\"poisson\")\n\nes = EarlyStopping(verbose=True)\nhist = model.fit(X_train_ord, y_train, epochs=100, verbose=0,\n    validation_split=0.2, callbacks=[es])\nhist.history[\"val_loss\"][-1]\n\nEpoch 12: early stopping\n\n\n0.7821161150932312\n\n\n\nWhat about adding the continuous variables back in? Use a sklearn column transformer for that."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#preprocess-ordinal-continuous",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#preprocess-ordinal-continuous",
    "title": "Categorical Variables",
    "section": "Preprocess ordinal & continuous",
    "text": "Preprocess ordinal & continuous\n\nfrom sklearn.compose import make_column_transformer\n\nct = make_column_transformer(\n  (OrdinalEncoder(), [\"Area\", \"VehGas\"]),\n  (\"drop\", [\"VehBrand\", \"Region\"]),\n  remainder=StandardScaler()\n)\n\nX_train_ct = ct.fit_transform(X_train)\n\n\n\n\nX_train.head(3)\n\n\n\n\n\n\n\n\nExposure\nArea\nVehPower\nVehAge\nDrivAge\nBonusMalus\nVehBrand\nVehGas\nDensity\nRegion\n\n\n\n\n0\n1.00\nC\n6.0\n2.0\n66.0\n50.0\nB2\nDiesel\n124.0\nR24\n\n\n1\n0.36\nC\n4.0\n10.0\n22.0\n100.0\nB1\nRegular\n377.0\nR93\n\n\n2\n0.02\nE\n12.0\n8.0\n44.0\n60.0\nB3\nRegular\n5628.0\nR11\n\n\n\n\n\n\n\n\n\nX_train_ct.head(3)\n\n\n\n\n\n\n\n\nordinalencoder__Area\nordinalencoder__VehGas\nremainder__Exposure\nremainder__VehPower\nremainder__VehAge\nremainder__DrivAge\nremainder__BonusMalus\nremainder__Density\n\n\n\n\n0\n2.0\n0.0\n1.126979\n-0.165005\n-0.844589\n1.451036\n-0.637179\n-0.366980\n\n\n1\n2.0\n1.0\n-0.590896\n-1.228181\n0.586255\n-1.548692\n2.303010\n-0.302700\n\n\n2\n4.0\n1.0\n-1.503517\n3.024524\n0.228544\n-0.048828\n-0.049141\n1.031432"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#preprocess-ordinal-continuous-ii",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#preprocess-ordinal-continuous-ii",
    "title": "Categorical Variables",
    "section": "Preprocess ordinal & continuous II",
    "text": "Preprocess ordinal & continuous II\n\nfrom sklearn.compose import make_column_transformer\n\nct = make_column_transformer(\n  (OrdinalEncoder(), [\"Area\", \"VehGas\"]),\n  (\"drop\", [\"VehBrand\", \"Region\"]),\n  remainder=StandardScaler(),\n  verbose_feature_names_out=False\n)\nX_train_ct = ct.fit_transform(X_train)\n\n\n\n\nX_train.head(3)\n\n\n\n\n\n\n\n\nExposure\nArea\nVehPower\nVehAge\nDrivAge\nBonusMalus\nVehBrand\nVehGas\nDensity\nRegion\n\n\n\n\n0\n1.00\nC\n6.0\n2.0\n66.0\n50.0\nB2\nDiesel\n124.0\nR24\n\n\n1\n0.36\nC\n4.0\n10.0\n22.0\n100.0\nB1\nRegular\n377.0\nR93\n\n\n2\n0.02\nE\n12.0\n8.0\n44.0\n60.0\nB3\nRegular\n5628.0\nR11\n\n\n\n\n\n\n\n\n\nX_train_ct.head(3)\n\n\n\n\n\n\n\n\nArea\nVehGas\nExposure\nVehPower\nVehAge\nDrivAge\nBonusMalus\nDensity\n\n\n\n\n0\n2.0\n0.0\n1.126979\n-0.165005\n-0.844589\n1.451036\n-0.637179\n-0.366980\n\n\n1\n2.0\n1.0\n-0.590896\n-1.228181\n0.586255\n-1.548692\n2.303010\n-0.302700\n\n\n2\n4.0\n1.0\n-1.503517\n3.024524\n0.228544\n-0.048828\n-0.049141\n1.031432"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#region-column",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#region-column",
    "title": "Categorical Variables",
    "section": "Region column",
    "text": "Region column\n\nFrench Administrative Regions\nSource: Nell et al. (2020), Case Study: French Motor Third-Party Liability Claims, SSRN."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#one-hot-encoding",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#one-hot-encoding",
    "title": "Categorical Variables",
    "section": "One-hot encoding",
    "text": "One-hot encoding\n\noe = OneHotEncoder(sparse_output=False)\nX_train_oh = oe.fit_transform(X_train[[\"Region\"]])\nX_test_oh = oe.transform(X_test[[\"Region\"]])\nprint(list(X_train[\"Region\"][:5]))\nX_train_oh.head()\n\n['R24', 'R93', 'R11', 'R42', 'R24']\n\n\n\n\n\n\n\n\n\nRegion_R11\nRegion_R21\nRegion_R22\nRegion_R23\nRegion_R24\nRegion_R25\nRegion_R26\nRegion_R31\nRegion_R41\nRegion_R42\n...\nRegion_R53\nRegion_R54\nRegion_R72\nRegion_R73\nRegion_R74\nRegion_R82\nRegion_R83\nRegion_R91\nRegion_R93\nRegion_R94\n\n\n\n\n0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n2\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n3\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n5 rows × 22 columns"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#train-on-one-hot-inputs",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#train-on-one-hot-inputs",
    "title": "Categorical Variables",
    "section": "Train on one-hot inputs",
    "text": "Train on one-hot inputs\n\nnum_regions = len(oe.categories_[0])\n\nrandom.seed(12)\nmodel = Sequential([\n  Dense(2, input_dim=num_regions),\n  Dense(1, activation=\"exponential\")\n])\n\nmodel.compile(optimizer=\"adam\", loss=\"poisson\")\n\nes = EarlyStopping(verbose=True)\nhist = model.fit(X_train_oh, y_train, epochs=100, verbose=0,\n    validation_split=0.2, callbacks=[es])                       \nhist.history[\"val_loss\"][-1]\n\nEpoch 9: early stopping\n\n\n0.7528033256530762"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#consider-the-first-layer",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#consider-the-first-layer",
    "title": "Categorical Variables",
    "section": "Consider the first layer",
    "text": "Consider the first layer\n\nevery_category = pd.DataFrame(np.eye(num_regions), columns=oe.categories_[0])\nevery_category.head(3)\n\n\n\n\n\n\n\n\nR11\nR21\nR22\nR23\nR24\nR25\nR26\nR31\nR41\nR42\n...\nR53\nR54\nR72\nR73\nR74\nR82\nR83\nR91\nR93\nR94\n\n\n\n\n0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n2\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n3 rows × 22 columns\n\n\n\n\n# Put this through the first layer of the model\nX = every_category.to_numpy()\nmodel.layers[0](X)\n\ntensor([[-0.0676, -0.2313],\n        [ 0.0578,  0.0541],\n        [-0.3354, -0.2603],\n        [ 0.0401, -0.3331],\n        [ 0.3537, -0.2513],\n        [ 0.0741, -0.3928],\n        [ 0.2834, -0.3078],\n        [ 0.1339,  0.3076],\n        [ 0.6641, -0.4717],\n        [ 0.2073, -0.0367],\n        [-0.0931, -0.4851],\n        [ 0.7988, -0.2612],\n        [ 0.4994, -0.0385],\n        [ 0.7135, -0.3665],\n        [-0.2302, -0.1524],\n        [-0.2581, -0.0808],\n        [ 0.7971,  0.0962],\n        [ 0.5428, -0.1990],\n        [-0.1908, -0.5027],\n        [ 0.1098,  0.1983],\n        [ 0.0318,  0.1482],\n        [ 0.3183,  0.5048]], grad_fn=&lt;AddBackward0&gt;)"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#the-first-layer",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#the-first-layer",
    "title": "Categorical Variables",
    "section": "The first layer",
    "text": "The first layer\n\nlayer = model.layers[0]\nW, b = layer.get_weights()\nX.shape, W.shape, b.shape\n\n((22, 22), (22, 2), (2,))\n\n\n\n\n\nX @ W + b\n\narray([[-0.07, -0.23],\n       [ 0.06,  0.05],\n       [-0.34, -0.26],\n       [ 0.04, -0.33],\n       [ 0.35, -0.25],\n       [ 0.07, -0.39],\n       [ 0.28, -0.31],\n       [ 0.13,  0.31],\n       [ 0.66, -0.47],\n       [ 0.21, -0.04],\n       [-0.09, -0.49],\n       [ 0.8 , -0.26],\n       [ 0.5 , -0.04],\n       [ 0.71, -0.37],\n       [-0.23, -0.15],\n       [-0.26, -0.08],\n       [ 0.8 ,  0.1 ],\n       [ 0.54, -0.2 ],\n       [-0.19, -0.5 ],\n       [ 0.11,  0.2 ],\n       [ 0.03,  0.15],\n       [ 0.32,  0.5 ]])\n\n\n\n\nW + b\n\narray([[-0.07, -0.23],\n       [ 0.06,  0.05],\n       [-0.34, -0.26],\n       [ 0.04, -0.33],\n       [ 0.35, -0.25],\n       [ 0.07, -0.39],\n       [ 0.28, -0.31],\n       [ 0.13,  0.31],\n       [ 0.66, -0.47],\n       [ 0.21, -0.04],\n       [-0.09, -0.49],\n       [ 0.8 , -0.26],\n       [ 0.5 , -0.04],\n       [ 0.71, -0.37],\n       [-0.23, -0.15],\n       [-0.26, -0.08],\n       [ 0.8 ,  0.1 ],\n       [ 0.54, -0.2 ],\n       [-0.19, -0.5 ],\n       [ 0.11,  0.2 ],\n       [ 0.03,  0.15],\n       [ 0.32,  0.5 ]], dtype=float32)"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#just-a-look-up-operation",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#just-a-look-up-operation",
    "title": "Categorical Variables",
    "section": "Just a look-up operation",
    "text": "Just a look-up operation\n\n\n\ndisplay(list(oe.categories_[0]))\n\n['R11',\n 'R21',\n 'R22',\n 'R23',\n 'R24',\n 'R25',\n 'R26',\n 'R31',\n 'R41',\n 'R42',\n 'R43',\n 'R52',\n 'R53',\n 'R54',\n 'R72',\n 'R73',\n 'R74',\n 'R82',\n 'R83',\n 'R91',\n 'R93',\n 'R94']\n\n\n\n\nW + b\n\narray([[-0.07, -0.23],\n       [ 0.06,  0.05],\n       [-0.34, -0.26],\n       [ 0.04, -0.33],\n       [ 0.35, -0.25],\n       [ 0.07, -0.39],\n       [ 0.28, -0.31],\n       [ 0.13,  0.31],\n       [ 0.66, -0.47],\n       [ 0.21, -0.04],\n       [-0.09, -0.49],\n       [ 0.8 , -0.26],\n       [ 0.5 , -0.04],\n       [ 0.71, -0.37],\n       [-0.23, -0.15],\n       [-0.26, -0.08],\n       [ 0.8 ,  0.1 ],\n       [ 0.54, -0.2 ],\n       [-0.19, -0.5 ],\n       [ 0.11,  0.2 ],\n       [ 0.03,  0.15],\n       [ 0.32,  0.5 ]], dtype=float32)"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#turn-the-region-into-an-index",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#turn-the-region-into-an-index",
    "title": "Categorical Variables",
    "section": "Turn the region into an index",
    "text": "Turn the region into an index\n\noe = OrdinalEncoder()\nX_train_reg = oe.fit_transform(X_train[[\"Region\"]])\nX_test_reg = oe.transform(X_test[[\"Region\"]])\n\nfor i, reg in enumerate(oe.categories_[0][:3]):\n  print(f\"The Region value {reg} gets turned into {i}.\")\n\nThe Region value R11 gets turned into 0.\nThe Region value R21 gets turned into 1.\nThe Region value R22 gets turned into 2."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#embedding",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#embedding",
    "title": "Categorical Variables",
    "section": "Embedding",
    "text": "Embedding\n\nfrom keras.layers import Embedding\nnum_regions = len(np.unique(X_train[[\"Region\"]]))\n\nrandom.seed(12)\nmodel = Sequential([\n  Embedding(input_dim=num_regions, output_dim=2),\n  Dense(1, activation=\"exponential\")\n])\n\nmodel.compile(optimizer=\"adam\", loss=\"poisson\")"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#fitting-that-model",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#fitting-that-model",
    "title": "Categorical Variables",
    "section": "Fitting that model",
    "text": "Fitting that model\n\nes = EarlyStopping(verbose=True)\nhist = model.fit(X_train_reg, y_train, epochs=100, verbose=0,\n    validation_split=0.2, callbacks=[es])\nhist.history[\"val_loss\"][-1]\n\nEpoch 4: early stopping\n\n\n0.7523981332778931\n\n\n\nmodel.layers\n\n[&lt;Embedding name=embedding, built=True&gt;, &lt;Dense name=dense_8, built=True&gt;]"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#keras-embedding-layer",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#keras-embedding-layer",
    "title": "Categorical Variables",
    "section": "Keras’ Embedding Layer",
    "text": "Keras’ Embedding Layer\n\n\n\nmodel.layers[0].get_weights()[0]\n\narray([[ 0.05, -0.08],\n       [-0.  ,  0.02],\n       [-0.04, -0.02],\n       [ 0.11, -0.14],\n       [ 0.22, -0.2 ],\n       [ 0.15, -0.18],\n       [ 0.2 , -0.2 ],\n       [-0.04,  0.08],\n       [ 0.39, -0.36],\n       [ 0.07, -0.06],\n       [ 0.08, -0.14],\n       [ 0.38, -0.32],\n       [ 0.21, -0.15],\n       [ 0.37, -0.33],\n       [-0.05,  0.01],\n       [-0.07,  0.04],\n       [ 0.26, -0.16],\n       [ 0.27, -0.22],\n       [ 0.07, -0.13],\n       [-0.  ,  0.04],\n       [-0.04,  0.06],\n       [-0.04,  0.13]], dtype=float32)\n\n\n\n\nX_train[\"Region\"].head(4)\n\n0    R24\n1    R93\n2    R11\n3    R42\nName: Region, dtype: object\n\n\n\nX_sample = X_train_reg[:4].to_numpy()\nX_sample\n\narray([[ 4.],\n       [20.],\n       [ 0.],\n       [ 9.]])\n\n\n\nenc_tensor = model.layers[0](X_sample)\nkeras.ops.convert_to_numpy(enc_tensor).squeeze()\n\narray([[ 0.22, -0.2 ],\n       [-0.04,  0.06],\n       [ 0.05, -0.08],\n       [ 0.07, -0.06]], dtype=float32)"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#the-learned-embeddings",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#the-learned-embeddings",
    "title": "Categorical Variables",
    "section": "The learned embeddings",
    "text": "The learned embeddings\n\npoints = model.layers[0].get_weights()[0]\nplt.scatter(points[:,0], points[:,1])\nfor i in range(num_regions):\n  plt.text(points[i,0]+0.01, points[i,1] , s=oe.categories_[0][i])"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#entity-embeddings",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#entity-embeddings",
    "title": "Categorical Variables",
    "section": "Entity embeddings",
    "text": "Entity embeddings\n\nEmbeddings will gradually improve during training.\nSource: Marcus Lautier (2022)."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#embeddings-other-inputs",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#embeddings-other-inputs",
    "title": "Categorical Variables",
    "section": "Embeddings & other inputs",
    "text": "Embeddings & other inputs\n\nIllustration of a neural network with both continuous and categorical inputs.We can’t do this with Sequential models…\n\nSource: LotusLabs Blog, Accurate insurance claims prediction with Deep Learning."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#converting-sequential-models",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#converting-sequential-models",
    "title": "Categorical Variables",
    "section": "Converting Sequential models",
    "text": "Converting Sequential models\n\nfrom keras.models import Model\nfrom keras.layers import Input\n\n\n\n\nrandom.seed(12)\n\nmodel = Sequential([\n  Dense(30, \"relu\"),\n  Dense(1, \"exponential\")\n])\n\nmodel.compile(\n  optimizer=\"adam\",\n  loss=\"poisson\")\n\nhist = model.fit(\n  X_train_ord, y_train,\n  epochs=1, verbose=0,\n  validation_split=0.2)\nhist.history[\"val_loss\"][-1]\n\n0.8046959042549133\n\n\n\n\nrandom.seed(12)\n\ninputs = Input(shape=(2,))\nx = Dense(30, \"relu\")(inputs)\nout = Dense(1, \"exponential\")(x)\nmodel = Model(inputs, out)\n\nmodel.compile(\n  optimizer=\"adam\",\n  loss=\"poisson\")\n\nhist = model.fit(\n  X_train_ord, y_train,\n  epochs=1, verbose=0,\n  validation_split=0.2)\nhist.history[\"val_loss\"][-1]\n\n0.8048074245452881\n\n\n\n\nCf. one-length tuples."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#wide-deep-network",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#wide-deep-network",
    "title": "Categorical Variables",
    "section": "Wide & Deep network",
    "text": "Wide & Deep network\n\n\n\n\n\nAn illustration of the wide & deep network architecture.\n\n\n\nAdd a skip connection from input to output layers.\n\nfrom keras.layers \\\n    import Concatenate\n\ninp = Input(shape=X_train.shape[1:])\nhidden1 = Dense(30, \"relu\")(inp)\nhidden2 = Dense(30, \"relu\")(hidden1)\nconcat = Concatenate()(\n  [inp, hidden2])\noutput = Dense(1)(concat)\nmodel = Model(\n    inputs=[inp],\n    outputs=[output])\n\n\n\n\nSources: Marcus Lautier (2022) & Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Chapter 10 code snippet."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#naming-the-layers",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#naming-the-layers",
    "title": "Categorical Variables",
    "section": "Naming the layers",
    "text": "Naming the layers\nFor complex networks, it is often useful to give meaningul names to the layers.\n\ninput_ = Input(shape=X_train.shape[1:], name=\"input\")\nhidden1 = Dense(30, activation=\"relu\", name=\"hidden1\")(input_)\nhidden2 = Dense(30, activation=\"relu\", name=\"hidden2\")(hidden1)\nconcat = Concatenate(name=\"combined\")([input_, hidden2])\noutput = Dense(1, name=\"output\")(concat)\nmodel = Model(inputs=[input_], outputs=[output])"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#inspecting-a-complex-model",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#inspecting-a-complex-model",
    "title": "Categorical Variables",
    "section": "Inspecting a complex model",
    "text": "Inspecting a complex model\n\nfrom keras.utils import plot_model\n\n\n\n\nplot_model(model, show_layer_names=True)\n\n\n\n\n\n\n\n\n\n\n\nmodel.summary(line_length=75)\n\nModel: \"functional_10\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n┃                     ┃                   ┃  Param ┃                      ┃\n┃ Layer (type)        ┃ Output Shape      ┃      # ┃ Connected to         ┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n│ input (InputLayer)  │ (None, 10)        │      0 │ -                    │\n├─────────────────────┼───────────────────┼────────┼──────────────────────┤\n│ hidden1 (Dense)     │ (None, 30)        │    330 │ input[0][0]          │\n├─────────────────────┼───────────────────┼────────┼──────────────────────┤\n│ hidden2 (Dense)     │ (None, 30)        │    930 │ hidden1[0][0]        │\n├─────────────────────┼───────────────────┼────────┼──────────────────────┤\n│ combined            │ (None, 40)        │      0 │ input[0][0],         │\n│ (Concatenate)       │                   │        │ hidden2[0][0]        │\n├─────────────────────┼───────────────────┼────────┼──────────────────────┤\n│ output (Dense)      │ (None, 1)         │     41 │ combined[0][0]       │\n└─────────────────────┴───────────────────┴────────┴──────────────────────┘\n\n\n\n Total params: 1,301 (5.08 KB)\n\n\n\n Trainable params: 1,301 (5.08 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#the-desired-architecture",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#the-desired-architecture",
    "title": "Categorical Variables",
    "section": "The desired architecture",
    "text": "The desired architecture\n\nIllustration of a neural network with both continuous and categorical inputs.\nSource: LotusLabs Blog, Accurate insurance claims prediction with Deep Learning."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#preprocess-all-french-motor-inputs",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#preprocess-all-french-motor-inputs",
    "title": "Categorical Variables",
    "section": "Preprocess all French motor inputs",
    "text": "Preprocess all French motor inputs\nTransform the categorical variables to integers:\n\nnum_brands, num_regions = X_train.nunique()[[\"VehBrand\", \"Region\"]]\n\nct = make_column_transformer(\n  (OrdinalEncoder(), [\"VehBrand\", \"Region\", \"Area\", \"VehGas\"]),\n  remainder=StandardScaler(),\n  verbose_feature_names_out=False\n)\nX_train_ct = ct.fit_transform(X_train)\nX_test_ct = ct.transform(X_test)\n\nSplit the brand and region data apart from the rest:\n\nX_train_brand = X_train_ct[\"VehBrand\"]; X_test_brand = X_test_ct[\"VehBrand\"]\nX_train_region = X_train_ct[\"Region\"]; X_test_region = X_test_ct[\"Region\"]\nX_train_rest = X_train_ct.drop([\"VehBrand\", \"Region\"], axis=1)\nX_test_rest = X_test_ct.drop([\"VehBrand\", \"Region\"], axis=1)"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#organise-the-inputs",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#organise-the-inputs",
    "title": "Categorical Variables",
    "section": "Organise the inputs",
    "text": "Organise the inputs\nMake a Keras Input for: vehicle brand, region, & others.\n\nveh_brand = Input(shape=(1,), name=\"vehBrand\")\nregion = Input(shape=(1,), name=\"region\")\nother_inputs = Input(shape=X_train_rest.shape[1:], name=\"otherInputs\")\n\nCreate embeddings and join them with the other inputs.\n\nfrom keras.layers import Reshape\n\nrandom.seed(1337)\nveh_brand_ee = Embedding(input_dim=num_brands, output_dim=2,\n    name=\"vehBrandEE\")(veh_brand)                                \nveh_brand_ee = Reshape(target_shape=(2,))(veh_brand_ee)\n\nregion_ee = Embedding(input_dim=num_regions, output_dim=2,\n    name=\"regionEE\")(region)\nregion_ee = Reshape(target_shape=(2,))(region_ee)\n\nx = Concatenate(name=\"combined\")([veh_brand_ee, region_ee, other_inputs])"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#complete-the-model-and-fit-it",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#complete-the-model-and-fit-it",
    "title": "Categorical Variables",
    "section": "Complete the model and fit it",
    "text": "Complete the model and fit it\nFeed the combined embeddings & continuous inputs to some normal dense layers.\n\nx = Dense(30, \"relu\", name=\"hidden\")(x)\nout = Dense(1, \"exponential\", name=\"out\")(x)\n\nmodel = Model([veh_brand, region, other_inputs], out)\nmodel.compile(optimizer=\"adam\", loss=\"poisson\")\n\nhist = model.fit((X_train_brand, X_train_region, X_train_rest),\n    y_train, epochs=100, verbose=0,\n    callbacks=[EarlyStopping(patience=5)], validation_split=0.2)\nnp.min(hist.history[\"val_loss\"])\n\n0.6686854362487793"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#plotting-this-model",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#plotting-this-model",
    "title": "Categorical Variables",
    "section": "Plotting this model",
    "text": "Plotting this model\n\nplot_model(model, show_layer_names=True)"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#why-we-need-to-reshape",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#why-we-need-to-reshape",
    "title": "Categorical Variables",
    "section": "Why we need to reshape",
    "text": "Why we need to reshape\n\nplot_model(model, show_layer_names=True, show_shapes=True)"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#two-different-models",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#two-different-models",
    "title": "Categorical Variables",
    "section": "Two different models",
    "text": "Two different models\nHave \\{ (\\mathbf{x}_i, y_i) \\}_{i=1, \\dots, n} for \\mathbf{x}_i \\in \\mathbb{R}^{47} and y_i \\in \\mathbb{N}_0.\nModel 1: Say Y_i \\sim \\mathsf{Poisson}(\\lambda(\\mathbf{x}_i)).\nBut, the exposures are different for each policy. \\lambda(\\mathbf{x}_i) is the expected number of claims for the duration of policy i’s contract.\nModel 2: Say Y_i \\sim \\mathsf{Poisson}(\\text{Exposure}_i \\times \\lambda(\\mathbf{x}_i)).\nNow, \\text{Exposure}_i \\not\\in \\mathbf{x}_i, and \\lambda(\\mathbf{x}_i) is the rate per year."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#just-take-continuous-variables",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#just-take-continuous-variables",
    "title": "Categorical Variables",
    "section": "Just take continuous variables",
    "text": "Just take continuous variables\n\nct = make_column_transformer(\n  (\"passthrough\", [\"Exposure\"]),\n  (\"drop\", [\"VehBrand\", \"Region\", \"Area\", \"VehGas\"]),\n  remainder=StandardScaler(),\n  verbose_feature_names_out=False\n)\nX_train_ct = ct.fit_transform(X_train)\nX_test_ct = ct.transform(X_test)\n\nSplit exposure apart from the rest:\n\nX_train_exp = X_train_ct[\"Exposure\"]; X_test_exp = X_test_ct[\"Exposure\"]\nX_train_rest = X_train_ct.drop(\"Exposure\", axis=1)\nX_test_rest = X_test_ct.drop(\"Exposure\", axis=1)\n\nOrganise the inputs:\n\nexposure = Input(shape=(1,), name=\"exposure\")\nother_inputs = Input(shape=X_train_rest.shape[1:], name=\"otherInputs\")"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#make-fit-the-model",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#make-fit-the-model",
    "title": "Categorical Variables",
    "section": "Make & fit the model",
    "text": "Make & fit the model\nFeed the continuous inputs to some normal dense layers.\n\nrandom.seed(1337)\nx = Dense(30, \"relu\", name=\"hidden1\")(other_inputs)\nx = Dense(30, \"relu\", name=\"hidden2\")(x)\nlambda_ = Dense(1, \"exponential\", name=\"lambda\")(x)\n\n\nfrom keras.layers import Multiply\n\nout = Multiply(name=\"out\")([lambda_, exposure])\nmodel = Model([exposure, other_inputs], out)\nmodel.compile(optimizer=\"adam\", loss=\"poisson\")\n\nes = EarlyStopping(patience=10, restore_best_weights=True, verbose=1)\nhist = model.fit((X_train_exp, X_train_rest),\n    y_train, epochs=100, verbose=0,\n    callbacks=[es], validation_split=0.2)\nnp.min(hist.history[\"val_loss\"])\n\nEpoch 33: early stopping\nRestoring model weights from the end of the best epoch: 23.\n\n\n0.8773847818374634"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/categorical-variables.slides.html#plot-the-model",
    "href": "Lecture-3-Tabular-Data/categorical-variables.slides.html#plot-the-model",
    "title": "Categorical Variables",
    "section": "Plot the model",
    "text": "Plot the model\n\nplot_model(model, show_layer_names=True)"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html",
    "title": "Deep Learning with Keras",
    "section": "",
    "text": "Neural networks\nRegression demo with Keras",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#lecture-outline",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#lecture-outline",
    "title": "Deep Learning with Keras",
    "section": "",
    "text": "Neural networks\nRegression demo with Keras",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#how-do-real-neurons-work",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#how-do-real-neurons-work",
    "title": "Deep Learning with Keras",
    "section": "How do real neurons work?",
    "text": "How do real neurons work?",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#a-neuron-firing",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#a-neuron-firing",
    "title": "Deep Learning with Keras",
    "section": "A neuron ‘firing’",
    "text": "A neuron ‘firing’\nSimilar to a biological neuron, an artificial neuron ‘fires’ when the combined input information exceeds a certain threshold. This activation can be seen as a step function. The difference is that the artificial neuron uses mathematical rules (e.g. weighted sum) to ‘fire’ whereas ‘firing’ in the biological neurons is far more complex and dynamic.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#an-artificial-neuron",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#an-artificial-neuron",
    "title": "Deep Learning with Keras",
    "section": "An artificial neuron",
    "text": "An artificial neuron\n\n\n\nA neuron in a neural network with a ReLU activation.\n\n\nThe figure shows how we first compute the weighted sum of inputs, and then evaluate the summation using the step function. If the weighted sum is greater than the pre-set threshold, the neuron `fires’.\n\nSource: Marcus Lautier (2022).",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#one-neuron",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#one-neuron",
    "title": "Deep Learning with Keras",
    "section": "One neuron",
    "text": "One neuron\n\n\n \\begin{aligned}\n  z~=~&x_1 \\times w_1 + \\\\\n    &x_2 \\times w_2 + \\\\\n    &x_3 \\times w_3 .\n  \\end{aligned}\n\n\n  a = \\begin{cases}\n    z & \\text{if } z &gt; 0 \\\\\n    0 & \\text{if } z \\leq 0\n    \\end{cases}\n\nHere, x_1, x_2, x_3 is just some fixed data.\n\n\n\n\nA neuron in a neural network with a ReLU activation.\n\n\n\n\nThe weights w_1, w_2, w_3 should be ‘learned’.\n\nSource: Marcus Lautier (2022).",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#one-neuron-with-bias",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#one-neuron-with-bias",
    "title": "Deep Learning with Keras",
    "section": "One neuron with bias",
    "text": "One neuron with bias\nThe bias is a constant term added to the product of inputs and weights. It helps in shifting the entire activation function to either the negative or positive side. This shifting can either accelerate or delay the activation. For example, if the bias is negative, it will shift the entire curve to the right, making the activation harder. This is similar to delaying the activation.\n\n\n \\begin{aligned}\n  z~=~&x_1 \\times w_1 + \\\\\n    &x_2 \\times w_2 + \\\\\n    &x_3 \\times w_3 + b .\n  \\end{aligned}\n\n\n  a = \\begin{cases}\n    z & \\text{if } z &gt; 0 \\\\\n    0 & \\text{if } z \\leq 0\n    \\end{cases}\n\nThe weights w_1, w_2, w_3 and bias b should be ‘learned’.\n\n\nBias = -404",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#a-basic-neural-network",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#a-basic-neural-network",
    "title": "Deep Learning with Keras",
    "section": "A basic neural network",
    "text": "A basic neural network\n\n\n\nA basic fully-connected/dense network.\n\n\nThis neural network consists of an input layer with 2 neurons (x_1, x_2), an output layer with 3 neurons, and 1 hidden layer with 4 neurons. Since every neuron is linked to every other neuron, this is called a fully connected neural network. Since we have 2 inputs and 1 bias in the input layer, each neuron in the hidden layer has 2+1=3 parameters to learn. Similarly, there are 4 neurons and 1 bias in the hidden layer. Hence, each neuron in the output layer has 4+1=5 parameters to learn.\n\nSource: Marcus Lautier (2022).",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#step-function-activation",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#step-function-activation",
    "title": "Deep Learning with Keras",
    "section": "Step-function activation",
    "text": "Step-function activation\n\nPerceptrons\nBrains and computers are binary, so make a perceptron with binary data. Seemed reasonable, impossible to train.\n\n\nModern neural network\nReplace binary state with continuous state. Still rather slow to train.\n\n\n\n\n\n\nNote\n\n\n\nIt’s a neural network made of neurons, not a “neuron network”.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#try-different-activation-functions",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#try-different-activation-functions",
    "title": "Deep Learning with Keras",
    "section": "Try different activation functions",
    "text": "Try different activation functions\n\n\n\n\n\n\n\n\n\nActivation functions are essential for a neural network design. They provide the mathematical rule for ‘firing’ the neuron. There are many activation functions, and the choice of the activation function depends on the problem we are trying to solve. Note: If we use the ‘linear’ activation function at every neuron, then the regression learning problem becomes a simple linear regression. But if we use ‘ReLu’, ‘tanh’, or any other non-linear function, then, we can introduce non-linearity into the model so that the model can learn complex non-linear patterns in the data. There are activation functions in both the hidden layers and the output layer. The activation function in the hidden layer controls how the neural network learns complex non-linear patterns in the training data. The choice of activation function in the output layer determines the type of predictions we get.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#flexible",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#flexible",
    "title": "Deep Learning with Keras",
    "section": "Flexible",
    "text": "Flexible\n\nOne can show that an MLP is a universal approximator, meaning it can model any suitably smooth function, given enough hidden units, to any desired level of accuracy (Hornik 1991). One can either make the model be “wide” or “deep”; the latter has some advantages…\n\n\nSource: Murphy (2012), Machine Learning: A Probabilistic Perspective, 1st Ed, p. 566.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#feature-engineering",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#feature-engineering",
    "title": "Deep Learning with Keras",
    "section": "Feature engineering",
    "text": "Feature engineering\n\n\n\n\n \n\n\nA major part of traditional machine learning (TML) involves conducting feature engineering to extract relevant features manually. In contrast, representational learning does not involve heavy manual feature engineering, rather, it learns relevant features automatically from data during the task. Therefore, the effort spent on feature engineering in representational learning is minimal compared to TML.\n\nSources: Marcus Lautier (2022) & Fenjiro (2019), Face Id: Deep Learning for Face Recognition, Medium.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#the-deep-learning-hammer",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#the-deep-learning-hammer",
    "title": "Deep Learning with Keras",
    "section": "The deep learning hammer",
    "text": "The deep learning hammer\nDeep learning is not always the answer!\n\n\n\nThe map of data science.\n\n\n\nSource: Serge Masis (2022), LinkedIn post.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#quiz",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#quiz",
    "title": "Deep Learning with Keras",
    "section": "Quiz",
    "text": "Quiz\nIn this ANN, how many of the following are there:\n\n\n\nfeatures,\ntargets,\nweights,\nbiases, and\nparameters?\n\nWhat is the depth?\n\n\n\n\nAn artificial neural network.\n\n\n\n\nThere are three inputs, hence, three features. There is one neuron in the output layer, hence, one target. There are 3 \\times 4 + 4 \\times 4 + 4\\times 1 = 32 arrows, hence, there are 32 weights in total. Since there is 1 bias for each neuron, there are 9 biases in total. The number of total parameters to learn equals to the sum of weights and biases, hence, there are 32+9=41 parameters in total.\n\nSource: Dertat (2017), Applied Deep Learning - Part 1: Artificial Neural Networks, Medium.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#import-the-data",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#import-the-data",
    "title": "Deep Learning with Keras",
    "section": "Import the data",
    "text": "Import the data\n\n1from sklearn.datasets import fetch_california_housing\n\nfeatures, target = fetch_california_housing(\n2    as_frame=True, return_X_y=True)\nfeatures                                                                        \n\n\n1\n\nImports California house prices from sklearn.datasets library\n\n2\n\nAssigns features and target from the dataset to two variables ‘features’ and ‘target’ and returns two separate data frames. The command return_X_y=True ensures that there will be two separate data frames, one for the features and the other for the target\n\n\n\n\n\n\n\n\n\n\n\nMedInc\nHouseAge\nAveRooms\nAveBedrms\nPopulation\nAveOccup\nLatitude\nLongitude\n\n\n\n\n0\n8.3252\n41.0\n6.984127\n1.023810\n322.0\n2.555556\n37.88\n-122.23\n\n\n1\n8.3014\n21.0\n6.238137\n0.971880\n2401.0\n2.109842\n37.86\n-122.22\n\n\n2\n7.2574\n52.0\n8.288136\n1.073446\n496.0\n2.802260\n37.85\n-122.24\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20637\n1.7000\n17.0\n5.205543\n1.120092\n1007.0\n2.325635\n39.43\n-121.22\n\n\n20638\n1.8672\n18.0\n5.329513\n1.171920\n741.0\n2.123209\n39.43\n-121.32\n\n\n20639\n2.3886\n16.0\n5.254717\n1.162264\n1387.0\n2.616981\n39.37\n-121.24\n\n\n\n\n20640 rows × 8 columns",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#what-is-the-target",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#what-is-the-target",
    "title": "Deep Learning with Keras",
    "section": "What is the target?",
    "text": "What is the target?\n\ntarget\n\n0        4.526\n1        3.585\n2        3.521\n         ...  \n20637    0.923\n20638    0.847\n20639    0.894\nName: MedHouseVal, Length: 20640, dtype: float64",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#the-dataset",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#the-dataset",
    "title": "Deep Learning with Keras",
    "section": "The dataset",
    "text": "The dataset\n\nThe target variable is the median house value for California districts, expressed in hundreds of thousands of dollars ($100,000).\nThis dataset was derived from the 1990 U.S. census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).\n\n\nSource: Scikit-learn documentation.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#columns",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#columns",
    "title": "Deep Learning with Keras",
    "section": "Columns",
    "text": "Columns\n\nMedInc median income in block group\nHouseAge median house age in block group\nAveRooms average number of rooms per household\nAveBedrms average # of bedrooms per household\nPopulation block group population\nAveOccup average number of household members\nLatitude block group latitude\nLongitude block group longitude\n\n\nSource: Scikit-learn documentation.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#an-entire-ml-project",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#an-entire-ml-project",
    "title": "Deep Learning with Keras",
    "section": "An entire ML project",
    "text": "An entire ML project\n\n\n\nML life cycle\n\n\nThe course focuses more on the modelling part of the life cycle.\n\nSource: Actuaries Institute, Do Data Better.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#questions-to-answer-in-ml-project",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#questions-to-answer-in-ml-project",
    "title": "Deep Learning with Keras",
    "section": "Questions to answer in ML project",
    "text": "Questions to answer in ML project\nYou fit a few models to the training set, then ask:\n\n(Selection) Which of these models is the best?\n(Future Performance) How good should we expect the final model to be on unseen data?",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#set-aside-a-fraction-for-a-test-set",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#set-aside-a-fraction-for-a-test-set",
    "title": "Deep Learning with Keras",
    "section": "Set aside a fraction for a test set",
    "text": "Set aside a fraction for a test set\n\n1from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    features, target, random_state=42\n2)\n\n\n1\n\nImports train_test_split class from sklearn.model_selection library\n\n2\n\nSplits the dataset into train and the test sets\n\n\n\n\nFirst, we split the data into the train set and the test set using a random selection. By defining the random state, using the random_state=42 command, we can ensure that the split is reproducible. We set aside the test data, assuming it represents new, unseen data. Then, we fit many models on the train data and select the one with the lowest train error. Thereafter we assess the performance of that model using the unseen test data.\n\n\n\n\n\nIllustration of a typical training/test split.\n\n\n\nNote: Compare X_/y_ names, capitals & lowercase.\n\n\n\n\n\nOur use of sklearn.\n\n\n\n\n\nAdapted from: Heaton (2022), Applications of Deep Learning, Part 2.1: Introduction to Pandas, and this random site.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#basic-ml-workflow",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#basic-ml-workflow",
    "title": "Deep Learning with Keras",
    "section": "Basic ML workflow",
    "text": "Basic ML workflow\n\n\n\nSplitting the data.\n\n\n\nFor each model, fit it to the training set.\nCompute the error for each model on the validation set.\nSelect the model with the lowest validation error.\nCompute the error of the final model on the test set.\n\n\nSource: Wikipedia.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#split-three-ways",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#split-three-ways",
    "title": "Deep Learning with Keras",
    "section": "Split three ways",
    "text": "Split three ways\n\n# Thanks https://datascience.stackexchange.com/a/15136\nX_main, X_test, y_main, y_test = train_test_split(\n    features, target, test_size=0.2, random_state=1\n1)\n\n# As 0.25 x 0.8 = 0.2\nX_train, X_val, y_train, y_val = train_test_split(\n    X_main, y_main, test_size=0.25, random_state=1\n2)\n\nX_train.shape, X_val.shape, X_test.shape\n\n\n1\n\nSplits the entire dataset into two parts. Sets aside 20\\% of the data as the test set.\n\n2\n\nSplits the first 80\\% of the data (X_main and y_main) further into train and validation sets. Sets aside 25\\% as the validation set\n\n\n\n\n((12384, 8), (4128, 8), (4128, 8))\n\n\nThis results in 60:20:20 three way split. While this is not a strict rule, it is widely used.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#why-not-use-test-set-for-both",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#why-not-use-test-set-for-both",
    "title": "Deep Learning with Keras",
    "section": "Why not use test set for both?",
    "text": "Why not use test set for both?\nThought experiment: have m classifiers: f_1(\\mathbf{x}), \\dots, f_m(\\mathbf{x}).\nThey are just as good as each other in the long run \n\\mathbb{P}(\\, f_i(\\mathbf{X}) = Y \\,)\\ =\\ 90\\% , \\quad \\text{for } i=1,\\dots,m .\n\n\n\nEvaluate each model on the test set, some will be better than others.\n\n\n\n\n\n\n\n\n\n\n\n\nTake the best, you’d think it has \\approx 98\\% accuracy!\nUsing the same dataset for both validating and testing purposes can result in a data leakage. The information from supposedly ‘unseen’ data is now used by the model during its tuning. This results in a situation where the model is now ‘learning’ from the test data, and it could lead to overly optimistic results in the model evaluation stage.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#the-training-set",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#the-training-set",
    "title": "Deep Learning with Keras",
    "section": "The training set",
    "text": "The training set\n\nX_train\n\n\n\n\n\n\n\n\nMedInc\nHouseAge\nAveRooms\nAveBedrms\nPopulation\nAveOccup\nLatitude\nLongitude\n\n\n\n\n9107\n4.1573\n19.0\n6.162630\n1.048443\n1677.0\n2.901384\n34.63\n-118.18\n\n\n13999\n0.4999\n10.0\n6.740000\n2.040000\n108.0\n2.160000\n34.69\n-116.90\n\n\n5610\n2.0458\n27.0\n3.619048\n1.062771\n1723.0\n3.729437\n33.78\n-118.26\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n8539\n4.0727\n18.0\n3.957845\n1.079625\n2276.0\n2.665105\n33.90\n-118.36\n\n\n2155\n2.3190\n41.0\n5.366265\n1.113253\n1129.0\n2.720482\n36.78\n-119.79\n\n\n13351\n5.5632\n9.0\n7.241087\n0.996604\n2280.0\n3.870968\n34.02\n-117.62\n\n\n\n\n12384 rows × 8 columns",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#location",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#location",
    "title": "Deep Learning with Keras",
    "section": "Location",
    "text": "Location\nPython’s matplotlib package \\approx R’s basic plots.\n\nimport matplotlib.pyplot as plt\n\nplt.scatter(features[\"Longitude\"], features[\"Latitude\"])",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#location-2",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#location-2",
    "title": "Deep Learning with Keras",
    "section": "Location #2",
    "text": "Location #2\nPython’s seaborn package \\approx R’s ggplot2.\n\nimport seaborn as sns\n\nsns.scatterplot(x=\"Longitude\", y=\"Latitude\", data=features);",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#features",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#features",
    "title": "Deep Learning with Keras",
    "section": "Features",
    "text": "Features\n\nprint(list(features.columns))\n\n['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n\n\nHow many?\n\nnum_features = len(features.columns)\nnum_features\n\n8\n\n\nOr\n\nnum_features = features.shape[1]\nfeatures.shape\n\n(20640, 8)",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#linear-regression",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#linear-regression",
    "title": "Deep Learning with Keras",
    "section": "Linear Regression",
    "text": "Linear Regression\n \\hat{y} = w_0 + \\sum_{i=1}^N w_i x_i .\n\n1from sklearn.linear_model import LinearRegression\n\n2lr = LinearRegression()\n3lr.fit(X_train, y_train);\n\n\n1\n\nImports the LinearRegression class from the sklearn.linear_model module\n\n2\n\nDefines the object lr which represents the linear regression function\n\n3\n\nFits a linear regression model using train data. lr.fit computes the coefficients of the regression model\n\n\n\n\nThe w_0 is in lr.intercept_ and the others are in\n\nprint(lr.coef_)\n\n[ 4.34267965e-01  9.88284781e-03 -9.39592954e-02  5.86373944e-01\n -1.58360948e-06 -3.59968968e-03 -4.26013498e-01 -4.41779336e-01]",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#make-some-predictions",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#make-some-predictions",
    "title": "Deep Learning with Keras",
    "section": "Make some predictions",
    "text": "Make some predictions\n\nX_train.head(3)\n\n\n\n\n\n\n\n\nMedInc\nHouseAge\nAveRooms\nAveBedrms\nPopulation\nAveOccup\nLatitude\nLongitude\n\n\n\n\n9107\n4.1573\n19.0\n6.162630\n1.048443\n1677.0\n2.901384\n34.63\n-118.18\n\n\n13999\n0.4999\n10.0\n6.740000\n2.040000\n108.0\n2.160000\n34.69\n-116.90\n\n\n5610\n2.0458\n27.0\n3.619048\n1.062771\n1723.0\n3.729437\n33.78\n-118.26\n\n\n\n\n\n\n\nX_train.head(3) returns the first three rows of the dataset X_train.\n\ny_pred = lr.predict(X_train.head(3))\ny_pred\n\narray([1.81699287, 0.0810446 , 1.62089363])\n\n\nlr.predict(X_train.head(3)) returns the predictions for the first three rows of the dataset X_train.\nWe can manually calculate predictions using the linear regression model to verify the output of the lr.predict() function. In the following code, we first define w_0 as the intercept of the lr function (initial value for the prediction calculation), and then keep on adding the w_i \\times x_i terms\n\n1prediction = lr.intercept_\n2for w_i, x_i in zip(lr.coef_, X_train.iloc[0]):\n3    prediction += w_i * x_i\nprediction                                              \n\n\n1\n\nSpecifies the value of the intercept from the fitted regression as prediction\n\n2\n\nIterates over the first observation from the train data (X_train) and the corresponding weight coefficients from the fitted linear regression\n\n3\n\nUpdates the prediction value\n\n\n\n\n1.8169928680677785",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#plot-the-predictions",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#plot-the-predictions",
    "title": "Deep Learning with Keras",
    "section": "Plot the predictions",
    "text": "Plot the predictions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can see how both plots have a dispersion to either sides of the fitted line.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#calculate-mean-squared-error",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#calculate-mean-squared-error",
    "title": "Deep Learning with Keras",
    "section": "Calculate mean squared error",
    "text": "Calculate mean squared error\n\nimport pandas as pd\n\ny_pred = lr.predict(X_train)\ndf = pd.DataFrame({\"Predictions\": y_pred, \"True values\": y_train})\ndf[\"Squared Error\"] = (df[\"Predictions\"] - df[\"True values\"]) ** 2\ndf.head(4)\n\n\n\n\n\n\n\n\nPredictions\nTrue values\nSquared Error\n\n\n\n\n9107\n1.816993\n2.281\n0.215303\n\n\n13999\n0.081045\n0.550\n0.219919\n\n\n5610\n1.620894\n1.745\n0.015402\n\n\n13533\n1.168949\n1.199\n0.000903\n\n\n\n\n\n\n\n\ndf[\"Squared Error\"].mean()\n\n0.5291948207479792",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#using-mean_squared_error",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#using-mean_squared_error",
    "title": "Deep Learning with Keras",
    "section": "Using mean_squared_error",
    "text": "Using mean_squared_error\n\ndf[\"Squared Error\"].mean()\n\n0.5291948207479792\n\n\nWe can compute the mean squared error to evaluate, on average, the accuracy of the predictions. To do this, we first create a data frame using pandas DataFrame function. It will have two columns, one with the predicted values and the other with the actual values. Next, we add another column to the same data frame using df[\"Squared Error\"] that computes and stores the squared error for each row. Using the function df[\"Squared Error\"].mean(), we extract the column ‘Squared Error’ from the data frame ‘df’ and calculate the ‘mean’.\n\nfrom sklearn.metrics import mean_squared_error as mse\n\nmse(y_train, y_pred)\n\n0.5291948207479792\n\n\nWe can also use the function mean_squared_error from sklearn.metrics library to calculate the same.\nStore the results in a dictionary:\n\nmse_lr_train = mse(y_train, lr.predict(X_train))\nmse_lr_val = mse(y_val, lr.predict(X_val))\n\nmse_train = {\"Linear Regression\": mse_lr_train}\nmse_val = {\"Linear Regression\": mse_lr_val}\n\nStoring results in data structures like dictionaries is a good practice that can help in managing and handling data efficiently.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#what-are-keras-and-tensorflow",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#what-are-keras-and-tensorflow",
    "title": "Deep Learning with Keras",
    "section": "What are Keras and TensorFlow?",
    "text": "What are Keras and TensorFlow?\nKeras is common way of specifying, training, and using neural networks. It gives a simple interface to various backend libraries, including Tensorflow.\n\n\n\nKeras as a independent interface, and Keras as part of Tensorflow.\n\n\n\nSource: Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Figure 10-10.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#create-a-keras-ann-model",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#create-a-keras-ann-model",
    "title": "Deep Learning with Keras",
    "section": "Create a Keras ANN model",
    "text": "Create a Keras ANN model\nDecide on the architecture: a simple fully-connected network with one hidden layer with 30 neurons.\nCreate the model:\n\n1from keras.models import Sequential\n2from keras.layers import Dense, Input\n\nmodel = Sequential(\n    [Input((num_features,)),\n     Dense(30, activation=\"relu\"),\n     Dense(1)]\n3)\n\n\n1\n\nImports Sequential from keras.models\n\n2\n\nImports Dense from keras.layers\n\n3\n\nDefines the model architecture using Sequential() function\n\n\n\n\nThis neural network architecture includes one hidden layer with 30 neurons and an output layer with 1 neuron. While there is an activation function specified (relu) for the hidden layer, there is no activation function specified for the output layer. In situations where there is no specification, the output layer assumes a linear activation.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#inspect-the-model",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#inspect-the-model",
    "title": "Deep Learning with Keras",
    "section": "Inspect the model",
    "text": "Inspect the model\n\nmodel.summary()\n\nModel: \"sequential\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ dense (Dense)                   │ (None, 30)                │        270 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_1 (Dense)                 │ (None, 1)                 │         31 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 301 (1.18 KB)\n\n\n\n Trainable params: 301 (1.18 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#the-model-is-initialised-randomly",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#the-model-is-initialised-randomly",
    "title": "Deep Learning with Keras",
    "section": "The model is initialised randomly",
    "text": "The model is initialised randomly\n\nmodel = Sequential([Dense(30, activation=\"relu\"), Dense(1)])\nmodel.predict(X_val.head(3), verbose=0)\n\narray([[-737.19183],\n       [-446.8675 ],\n       [ -20.18185]], dtype=float32)\n\n\n\nmodel = Sequential([Dense(30, activation=\"relu\"), Dense(1)])\nmodel.predict(X_val.head(3), verbose=0)\n\narray([[-566.09283 ],\n       [-336.90277 ],\n       [ -35.532364]], dtype=float32)\n\n\nWe can see how rerunning the same code with the same input data results in significantly different predictions. This is due to the random initialization.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#controlling-the-randomness",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#controlling-the-randomness",
    "title": "Deep Learning with Keras",
    "section": "Controlling the randomness",
    "text": "Controlling the randomness\n\nimport random\n\nrandom.seed(123)\n\nmodel = Sequential([Dense(30, activation=\"relu\"), Dense(1)])\n\ndisplay(model.predict(X_val.head(3), verbose=0))\n\nrandom.seed(123)\nmodel = Sequential([Dense(30, activation=\"relu\"), Dense(1)])\n\ndisplay(model.predict(X_val.head(3), verbose=0))\n\narray([[-513.13403 ],\n       [-302.182   ],\n       [ -17.794556]], dtype=float32)\n\n\narray([[-513.13403 ],\n       [-302.182   ],\n       [ -17.794556]], dtype=float32)\n\n\nBy setting the seed, we can control for the randomness.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#fit-the-model",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#fit-the-model",
    "title": "Deep Learning with Keras",
    "section": "Fit the model",
    "text": "Fit the model\n\nrandom.seed(123)\n\nmodel = Sequential([\n    Dense(30, activation=\"relu\"),\n    Dense(1)\n])\n\nmodel.compile(\"adam\", \"mse\")\n%time hist = model.fit(X_train, y_train, epochs=5, verbose=False)\nhist.history[\"loss\"]\n\nCPU times: user 2.97 s, sys: 349 ms, total: 3.32 s\nWall time: 2.91 s\n\n\n[1294.4464111328125,\n 2.6999993324279785,\n 1.6647465229034424,\n 1.4132969379425049,\n 1.031407356262207]\n\n\nThe above code explains how we would fit a basic neural network. First, we define the seed for reproducibility. Next, we define the architecture of the model. Thereafter, we compile the model. Compiling involves giving instructions on how we want the model to be trained. At the least, we must define the optimizer and loss function. The optimizer explains how the model should learn (how the model should update the weights), and the loss function states the objective that the model needs to optimize. In the above code, we use adam as the optimizer and mse (mean squared error) as the loss function. After compilation, we fit the model. The fit() function takes in the training data, and runs the entire dataset through 5 epochs before training completes. What this means is that the model is run through the entire dataset 5 times. Suppose we start the training process with the random initialization, run the model through the entire data, calculate the mse (after 1 epoch), and update the weights using the adam optimizer. Then we run the model through the entire dataset once again with the updated weights, to calculate the mse at the end of the second epoch. Likewise, we would run the model 5 times before the training completes. hist.history() function returns the calculate mse at each step.\n\n%time command computes and prints the amount of time spend on training. By setting verbose=False we can avoid printing of intermediate results during training. Setting verbose=True is useful when we want to observe how the neural network is training.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#make-predictions",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#make-predictions",
    "title": "Deep Learning with Keras",
    "section": "Make predictions",
    "text": "Make predictions\n\ny_pred = model.predict(X_train[:3], verbose=0)\ny_pred\n\narray([[ 1.8308794],\n       [-0.3535612],\n       [ 1.0657732]], dtype=float32)\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe .predict gives us a ‘matrix’ not a ‘vector’. Calling .flatten() will convert it to a ‘vector’.\n\nprint(f\"Original shape: {y_pred.shape}\")\ny_pred = y_pred.flatten()\nprint(f\"Flattened shape: {y_pred.shape}\")\ny_pred\n\nOriginal shape: (3, 1)\nFlattened shape: (3,)\n\n\narray([ 1.8308794, -0.3535612,  1.0657732], dtype=float32)",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#plot-the-predictions-1",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#plot-the-predictions-1",
    "title": "Deep Learning with Keras",
    "section": "Plot the predictions",
    "text": "Plot the predictions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOne problem with the predictions is that lots of predictions include negative values, which is unrealistic for house prices. We might have to rethink the activation function in the output layer.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#assess-the-model",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#assess-the-model",
    "title": "Deep Learning with Keras",
    "section": "Assess the model",
    "text": "Assess the model\n\ny_pred = model.predict(X_val, verbose=0)\nmse(y_val, y_pred)\n\n0.8456477940379458\n\n\n\nmse_train[\"Basic ANN\"] = mse(\n    y_train, model.predict(X_train, verbose=0)\n)\nmse_val[\"Basic ANN\"] = mse(y_val, model.predict(X_val, verbose=0))\n\nSome predictions are negative:\n\ny_pred = model.predict(X_val, verbose=0)\ny_pred.min(), y_pred.max()\n\n(-6.280052, 10.888557)\n\n\n\ny_val.min(), y_val.max()\n\n(0.225, 5.00001)",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#try-running-for-longer",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#try-running-for-longer",
    "title": "Deep Learning with Keras",
    "section": "Try running for longer",
    "text": "Try running for longer\n\nrandom.seed(123)\n\nmodel = Sequential([\n    Dense(30, activation=\"relu\"),\n    Dense(1)\n])\n\nmodel.compile(\"adam\", \"mse\")\n\n%time hist = model.fit(X_train, y_train, \\\n    epochs=50, verbose=False)\n\nCPU times: user 28.8 s, sys: 2.27 ms, total: 28.8 s\nWall time: 28.8 s\n\n\nWe will train the same neural network architecture with more epochs (epochs=50) to see if the results improve.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#loss-curve",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#loss-curve",
    "title": "Deep Learning with Keras",
    "section": "Loss curve",
    "text": "Loss curve\n\nplt.plot(range(1, 51), hist.history[\"loss\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"MSE\");\n\n\n\n\n\n\n\n\nThe loss curve experiences a sudden drop even before finishing 5 epochs and remains consistently low. This indicates that increasing the number of epochs from 5 to 50 does not significantly increase the accuracy.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#loss-curve-1",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#loss-curve-1",
    "title": "Deep Learning with Keras",
    "section": "Loss curve",
    "text": "Loss curve\n\nplt.plot(range(2, 51), hist.history[\"loss\"][1:])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"MSE\");\n\n\n\n\n\n\n\n\nThe above code filters out the MSE value from the first epoch. It plots the vector of MSE values starting from the 2nd epoch. By doing so, we can observe the fluctuations in the MSE values across different epochs more clearly. Results show that the model does not benefit from increasing the epochs.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#predictions",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#predictions",
    "title": "Deep Learning with Keras",
    "section": "Predictions",
    "text": "Predictions\n\ny_pred = model.predict(X_val, verbose=0)\nprint(f\"Min prediction: {y_pred.min():.2f}\")\nprint(f\"Max prediction: {y_pred.max():.2f}\")\n\nMin prediction: -18.77\nMax prediction: 7.70\n\n\n\n\n\nplt.scatter(y_pred, y_val)\nplt.xlabel(\"Predictions\")\nplt.ylabel(\"True values\")\nadd_diagonal_line()\n\n\n\nmse_train[\"Long run ANN\"] = mse(\n    y_train, model.predict(X_train, verbose=0)\n)\nmse_val[\"Long run ANN\"] = mse(y_val, model.predict(X_val, verbose=0))",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#try-different-activation-functions-1",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#try-different-activation-functions-1",
    "title": "Deep Learning with Keras",
    "section": "Try different activation functions",
    "text": "Try different activation functions\n\n\n\n\n\n\n\n\n\nWe should be mindful when selecting the activation function. Both tanh and sigmoid functions restrict the output values to the range of [0,1]. This is not sensible for house price modelling. relu does not have that problem. Also, relu ensures the output is positive which is realistic for house prices.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#enforce-positive-outputs-relu",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#enforce-positive-outputs-relu",
    "title": "Deep Learning with Keras",
    "section": "Enforce positive outputs (ReLU)",
    "text": "Enforce positive outputs (ReLU)\n\nrandom.seed(123)\n\nmodel = Sequential([\n    Dense(30, activation=\"relu\"),\n    Dense(1, activation=\"relu\")\n])\n\nmodel.compile(\"adam\", \"mse\")\n\n%time hist = model.fit(X_train, y_train, epochs=50, \\\n    verbose=False)\n\nimport numpy as np\nlosses = np.round(hist.history[\"loss\"], 2)\nprint(losses[:5], \"...\", losses[-5:])\n\nCPU times: user 28.8 s, sys: 1.36 ms, total: 28.9 s\nWall time: 28.8 s\n[5.65 5.64 5.64 5.64 5.64] ... [5.64 5.64 5.64 5.64 5.64]",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#plot-the-predictions-2",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#plot-the-predictions-2",
    "title": "Deep Learning with Keras",
    "section": "Plot the predictions",
    "text": "Plot the predictions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlots illustrate how all the outputs were stuck at zero. Irrespective of how many epochs we run, the output would always be zero.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#enforce-positive-outputs-mathrmex",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#enforce-positive-outputs-mathrmex",
    "title": "Deep Learning with Keras",
    "section": "Enforce positive outputs (\\mathrm{e}^{\\,x})",
    "text": "Enforce positive outputs (\\mathrm{e}^{\\,x})\n\nrandom.seed(123)\n\nmodel = Sequential([\n    Dense(30, activation=\"relu\"),\n    Dense(1, activation=\"exponential\")\n])\n\nmodel.compile(\"adam\", \"mse\")\n\n%time hist = model.fit(X_train, y_train, epochs=5, verbose=False)\n\nlosses = hist.history[\"loss\"]\nprint(losses)\n\nCPU times: user 2.89 s, sys: 4.02 ms, total: 2.89 s\nWall time: 2.89 s\n[25.2047176361084, 5.639228820800781, 5.653268814086914, 5.639529705047607, 5.6393961906433105]\n\n\nTraining the model again with an exponential activation function will give nan values. This is because the results then can explode easily.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#re-scaling-the-inputs",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#re-scaling-the-inputs",
    "title": "Deep Learning with Keras",
    "section": "Re-scaling the inputs",
    "text": "Re-scaling the inputs\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nscaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train_sc = scaler.transform(X_train)\nX_val_sc = scaler.transform(X_val)\nX_test_sc = scaler.transform(X_test)\n\nNote: We apply both the fit and transform operations on the train data. However, we only apply transform on the validation and test data.\n\n\n\nplt.hist(X_train.iloc[:, 0])\nplt.hist(X_train_sc[:, 0])\nplt.legend([\"Original\", \"Scaled\"]);\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can see how the original values for the input varied between 0 and 10, and how the scaled input values are now between -2 and 2.5. Neural networks prefer if the inputs range between -1 and 1.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#same-model-with-scaled-inputs",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#same-model-with-scaled-inputs",
    "title": "Deep Learning with Keras",
    "section": "Same model with scaled inputs",
    "text": "Same model with scaled inputs\n\nrandom.seed(123)\n\nmodel = Sequential([\n    Dense(30, activation=\"relu\"),\n    Dense(1, activation=\"exponential\")\n])\n\nmodel.compile(\"adam\", \"mse\")\n\n%time hist = model.fit( \\\n    X_train_sc, \\\n    y_train, \\\n    epochs=50, \\\n    verbose=False)\n\nCPU times: user 29.1 s, sys: 7.37 ms, total: 29.1 s\nWall time: 29.1 s",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#loss-curve-2",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#loss-curve-2",
    "title": "Deep Learning with Keras",
    "section": "Loss curve",
    "text": "Loss curve\n\nplt.plot(range(1, 51), hist.history[\"loss\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"MSE\");",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#loss-curve-3",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#loss-curve-3",
    "title": "Deep Learning with Keras",
    "section": "Loss curve",
    "text": "Loss curve\n\nplt.plot(range(2, 51), hist.history[\"loss\"][1:])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"MSE\");",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#predictions-1",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#predictions-1",
    "title": "Deep Learning with Keras",
    "section": "Predictions",
    "text": "Predictions\n\ny_pred = model.predict(X_val_sc, verbose=0)\nprint(f\"Min prediction: {y_pred.min():.2f}\")\nprint(f\"Max prediction: {y_pred.max():.2f}\")\n\nMin prediction: 0.00\nMax prediction: 8.58\n\n\n\n\n\nplt.scatter(y_pred, y_val)\nplt.xlabel(\"Predictions\")\nplt.ylabel(\"True values\")\nadd_diagonal_line()\n\n\n\nmse_train[\"Exp ANN\"] = mse(\n    y_train, model.predict(X_train_sc, verbose=0)\n)\nmse_val[\"Exp ANN\"] = mse(y_val, model.predict(X_val_sc, verbose=0))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow the predictions are always non-negative.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#comparing-mse-smaller-is-better",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#comparing-mse-smaller-is-better",
    "title": "Deep Learning with Keras",
    "section": "Comparing MSE (smaller is better)",
    "text": "Comparing MSE (smaller is better)\nOn training data:\n\nmse_train\n\n{'Linear Regression': 0.5291948207479792,\n 'Basic ANN': 1.0832468030855924,\n 'Long run ANN': 0.7799112197400799,\n 'Exp ANN': 0.3280935061435783}\n\n\nOn validation data (expect worse, i.e. bigger):\n\nmse_val\n\n{'Linear Regression': 0.5059420205381367,\n 'Basic ANN': 0.8456477940379458,\n 'Long run ANN': 0.7851678744241668,\n 'Exp ANN': 0.3301015952055857}\n\n\nNote: The error on the validation set is usually higher than the training set.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#comparing-models-train",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#comparing-models-train",
    "title": "Deep Learning with Keras",
    "section": "Comparing models (train)",
    "text": "Comparing models (train)\n\ntrain_results = pd.DataFrame(\n    {\"Model\": mse_train.keys(), \"MSE\": mse_train.values()}\n)\ntrain_results.sort_values(\"MSE\", ascending=False)\n\n\n\n\n\n\n\n\nModel\nMSE\n\n\n\n\n1\nBasic ANN\n1.083247\n\n\n2\nLong run ANN\n0.779911\n\n\n0\nLinear Regression\n0.529195\n\n\n3\nExp ANN\n0.328094",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#comparing-models-validation",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#comparing-models-validation",
    "title": "Deep Learning with Keras",
    "section": "Comparing models (validation)",
    "text": "Comparing models (validation)\n\nval_results = pd.DataFrame(\n    {\"Model\": mse_val.keys(), \"MSE\": mse_val.values()}\n)\nval_results.sort_values(\"MSE\", ascending=False)\n\n\n\n\n\n\n\n\nModel\nMSE\n\n\n\n\n1\nBasic ANN\n0.845648\n\n\n2\nLong run ANN\n0.785168\n\n\n0\nLinear Regression\n0.505942\n\n\n3\nExp ANN\n0.330102",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#choosing-when-to-stop-training",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#choosing-when-to-stop-training",
    "title": "Deep Learning with Keras",
    "section": "Choosing when to stop training",
    "text": "Choosing when to stop training\n\n\n\nIllustrative loss curves over time.\n\n\nEarly stopping can be seen as a regularization technique to avoid overfitting. The plot shows that both training error and validation error decrease at the beginning of training process. However, after a while, validation error starts to increase while training error keeps on decreasing. This is an indication of overfitting. Overfitting leads to poor performance on the unseen data, which is seen here through the gradual increase of validation error. Early stopping can track the model’s performance through the training process and stop the training at the right time.\n\nSource: Heaton (2022), Applications of Deep Learning, Part 3.4: Early Stopping.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#try-early-stopping",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#try-early-stopping",
    "title": "Deep Learning with Keras",
    "section": "Try early stopping",
    "text": "Try early stopping\nHinton calls it a “beautiful free lunch”\n\n1from keras.callbacks import EarlyStopping\n\n2random.seed(123)\n3model = Sequential([\n    Dense(30, activation=\"relu\"),\n    Dense(1, activation=\"exponential\")\n])\n4model.compile(\"adam\", \"mse\")\n\n5es = EarlyStopping(restore_best_weights=True, patience=15)\n\n%time hist = model.fit(X_train_sc, y_train, epochs=1_000, \\\n6    callbacks=[es], validation_data=(X_val_sc, y_val), verbose=False)\n7print(f\"Keeping model at epoch #{len(hist.history['loss'])-10}.\")\n\n\n1\n\nImports EarlyStopping from keras.callbacks\n\n2\n\nSets the random seed\n\n3\n\nConstructs the sequential model\n\n4\n\nConfigures the training process with optimiser and loss function\n\n5\n\nDefines the early stopping object. Here, the patience parameter tells how many epochs the neural network has to wait without no improvement before the process stops. patience=15 indicates that the neural network will wait for 15 epochs without any improvement before it stops training. restore_best_weights=True ensures that model’s weights will be restored to the best model, i.e., the model we saw before 15 epochs\n\n6\n\nFits the model with early stopping object passed in\n\n7\n\nPrints the outs\n\n\n\n\nCPU times: user 1min 20s, sys: 8.16 ms, total: 1min 20s\nWall time: 1min 20s\nKeeping model at epoch #101.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#loss-curve-4",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#loss-curve-4",
    "title": "Deep Learning with Keras",
    "section": "Loss curve",
    "text": "Loss curve\n\nplt.plot(hist.history[\"loss\"])\nplt.plot(hist.history[\"val_loss\"])\nplt.legend([\"Training\", \"Validation\"]);",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#loss-curve-ii",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#loss-curve-ii",
    "title": "Deep Learning with Keras",
    "section": "Loss curve II",
    "text": "Loss curve II\n\nplt.plot(hist.history[\"loss\"])\nplt.plot(hist.history[\"val_loss\"])\nplt.ylim([0, 8])\nplt.legend([\"Training\", \"Validation\"]);",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#predictions-2",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#predictions-2",
    "title": "Deep Learning with Keras",
    "section": "Predictions",
    "text": "Predictions",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#comparing-models-validation-1",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#comparing-models-validation-1",
    "title": "Deep Learning with Keras",
    "section": "Comparing models (validation)",
    "text": "Comparing models (validation)\n\n\n\n\n\n\n\n\n\nModel\nMSE\n\n\n\n\n1\nBasic ANN\n0.845648\n\n\n2\nLong run ANN\n0.785168\n\n\n0\nLinear Regression\n0.505942\n\n\n3\nExp ANN\n0.330102\n\n\n4\nEarly stop ANN\n0.294328\n\n\n\n\n\n\n\nMSE error on the validation set has improved from the ANN model without early stopping (0.354653) to the one with early stopping (0.326440).",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#the-test-set",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#the-test-set",
    "title": "Deep Learning with Keras",
    "section": "The test set",
    "text": "The test set\nEvaluate only the final/selected model on the test set.\n\nmse(y_test, model.predict(X_test_sc, verbose=0))\n\n0.3123165514245335\n\n\n\nmodel.evaluate(X_test_sc, y_test, verbose=False)\n\n0.31231650710105896\n\n\nEvaluating the model on the unseen test set provides an unbiased view on how the model will perform. Since we configured the model to track ‘mse’ as the loss function, we can simply use model.evaluate() function on the test set and get the same answer.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#another-useful-callback",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.html#another-useful-callback",
    "title": "Deep Learning with Keras",
    "section": "Another useful callback",
    "text": "Another useful callback\n\nfrom pathlib import Path\nfrom keras.callbacks import ModelCheckpoint\n\nrandom.seed(123)\nmodel = Sequential(\n    [Dense(30, activation=\"relu\"), Dense(1, activation=\"exponential\")]\n)\nmodel.compile(\"adam\", \"mse\")\nmc = ModelCheckpoint(\n    \"best-model.keras\", monitor=\"val_loss\", save_best_only=True\n)\nes = EarlyStopping(restore_best_weights=True, patience=5)\nhist = model.fit(\n    X_train_sc,\n    y_train,\n    epochs=100,\n    validation_split=0.1,\n    callbacks=[mc, es],\n    verbose=False,\n)\nPath(\"best-model.keras\").stat().st_size\n\n19195\n\n\nModelCheckpoint is also another useful callback function that can be used to save the model at some intervals during training. This is useful when training large datasets. If the training process gets interrupted at some point, last saved set of weights from model checkpoints can be used to resume the training process instead of starting from the beginning.",
    "crumbs": [
      "Module 2",
      "Deep Learning with Keras"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#lecture-outline",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#lecture-outline",
    "title": "Deep Learning with Keras",
    "section": "Lecture Outline",
    "text": "Lecture Outline\n\nNeural networks\nRegression demo with Keras"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#how-do-real-neurons-work",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#how-do-real-neurons-work",
    "title": "Deep Learning with Keras",
    "section": "How do real neurons work?",
    "text": "How do real neurons work?"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#a-neuron-firing",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#a-neuron-firing",
    "title": "Deep Learning with Keras",
    "section": "A neuron ‘firing’",
    "text": "A neuron ‘firing’"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#an-artificial-neuron",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#an-artificial-neuron",
    "title": "Deep Learning with Keras",
    "section": "An artificial neuron",
    "text": "An artificial neuron\n\nA neuron in a neural network with a ReLU activation.\nSource: Marcus Lautier (2022)."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#one-neuron",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#one-neuron",
    "title": "Deep Learning with Keras",
    "section": "One neuron",
    "text": "One neuron\n\n\n \\begin{aligned}\n  z~=~&x_1 \\times w_1 + \\\\\n    &x_2 \\times w_2 + \\\\\n    &x_3 \\times w_3 .\n  \\end{aligned}\n\n\n  a = \\begin{cases}\n    z & \\text{if } z &gt; 0 \\\\\n    0 & \\text{if } z \\leq 0\n    \\end{cases}\n\nHere, x_1, x_2, x_3 is just some fixed data.\n\n\n\n\nA neuron in a neural network with a ReLU activation.\n\n\n\n\nThe weights w_1, w_2, w_3 should be ‘learned’.\n\nSource: Marcus Lautier (2022)."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#one-neuron-with-bias",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#one-neuron-with-bias",
    "title": "Deep Learning with Keras",
    "section": "One neuron with bias",
    "text": "One neuron with bias\n\n\n \\begin{aligned}\n  z~=~&x_1 \\times w_1 + \\\\\n    &x_2 \\times w_2 + \\\\\n    &x_3 \\times w_3 + b .\n  \\end{aligned}\n\n\n  a = \\begin{cases}\n    z & \\text{if } z &gt; 0 \\\\\n    0 & \\text{if } z \\leq 0\n    \\end{cases}\n\nThe weights w_1, w_2, w_3 and bias b should be ‘learned’.\n\n\nBias = -404"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#a-basic-neural-network",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#a-basic-neural-network",
    "title": "Deep Learning with Keras",
    "section": "A basic neural network",
    "text": "A basic neural network\n\nA basic fully-connected/dense network.\nSource: Marcus Lautier (2022)."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#step-function-activation",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#step-function-activation",
    "title": "Deep Learning with Keras",
    "section": "Step-function activation",
    "text": "Step-function activation\nPerceptrons\nBrains and computers are binary, so make a perceptron with binary data. Seemed reasonable, impossible to train.\nModern neural network\nReplace binary state with continuous state. Still rather slow to train.\n\n\n\n\n\n\nNote\n\n\nIt’s a neural network made of neurons, not a “neuron network”."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#try-different-activation-functions",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#try-different-activation-functions",
    "title": "Deep Learning with Keras",
    "section": "Try different activation functions",
    "text": "Try different activation functions"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#flexible",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#flexible",
    "title": "Deep Learning with Keras",
    "section": "Flexible",
    "text": "Flexible\n\nOne can show that an MLP is a universal approximator, meaning it can model any suitably smooth function, given enough hidden units, to any desired level of accuracy (Hornik 1991). One can either make the model be “wide” or “deep”; the latter has some advantages…\n\n\nSource: Murphy (2012), Machine Learning: A Probabilistic Perspective, 1st Ed, p. 566."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#feature-engineering",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#feature-engineering",
    "title": "Deep Learning with Keras",
    "section": "Feature engineering",
    "text": "Feature engineering\n\n\n\n\n \n\n\n\nSources: Marcus Lautier (2022) & Fenjiro (2019), Face Id: Deep Learning for Face Recognition, Medium."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#the-deep-learning-hammer",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#the-deep-learning-hammer",
    "title": "Deep Learning with Keras",
    "section": "The deep learning hammer",
    "text": "The deep learning hammer\nDeep learning is not always the answer!\n\nThe map of data science.\nSource: Serge Masis (2022), LinkedIn post."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#quiz",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#quiz",
    "title": "Deep Learning with Keras",
    "section": "Quiz",
    "text": "Quiz\nIn this ANN, how many of the following are there:\n\n\n\nfeatures,\ntargets,\nweights,\nbiases, and\nparameters?\n\nWhat is the depth?\n\n\n\n\nAn artificial neural network.\n\n\n\n\n\nSource: Dertat (2017), Applied Deep Learning - Part 1: Artificial Neural Networks, Medium."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#import-the-data",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#import-the-data",
    "title": "Deep Learning with Keras",
    "section": "Import the data",
    "text": "Import the data\n\nfrom sklearn.datasets import fetch_california_housing\n\nfeatures, target = fetch_california_housing(\n    as_frame=True, return_X_y=True)\nfeatures                                                                        \n\n\n\n\n\n\n\n\nMedInc\nHouseAge\nAveRooms\nAveBedrms\nPopulation\nAveOccup\nLatitude\nLongitude\n\n\n\n\n0\n8.3252\n41.0\n6.984127\n1.023810\n322.0\n2.555556\n37.88\n-122.23\n\n\n1\n8.3014\n21.0\n6.238137\n0.971880\n2401.0\n2.109842\n37.86\n-122.22\n\n\n2\n7.2574\n52.0\n8.288136\n1.073446\n496.0\n2.802260\n37.85\n-122.24\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20637\n1.7000\n17.0\n5.205543\n1.120092\n1007.0\n2.325635\n39.43\n-121.22\n\n\n20638\n1.8672\n18.0\n5.329513\n1.171920\n741.0\n2.123209\n39.43\n-121.32\n\n\n20639\n2.3886\n16.0\n5.254717\n1.162264\n1387.0\n2.616981\n39.37\n-121.24\n\n\n\n\n20640 rows × 8 columns"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#what-is-the-target",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#what-is-the-target",
    "title": "Deep Learning with Keras",
    "section": "What is the target?",
    "text": "What is the target?\n\ntarget\n\n0        4.526\n1        3.585\n2        3.521\n         ...  \n20637    0.923\n20638    0.847\n20639    0.894\nName: MedHouseVal, Length: 20640, dtype: float64"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#the-dataset",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#the-dataset",
    "title": "Deep Learning with Keras",
    "section": "The dataset",
    "text": "The dataset\n\nThe target variable is the median house value for California districts, expressed in hundreds of thousands of dollars ($100,000).\nThis dataset was derived from the 1990 U.S. census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).\n\n\nSource: Scikit-learn documentation."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#columns",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#columns",
    "title": "Deep Learning with Keras",
    "section": "Columns",
    "text": "Columns\n\nMedInc median income in block group\nHouseAge median house age in block group\nAveRooms average number of rooms per household\nAveBedrms average # of bedrooms per household\nPopulation block group population\nAveOccup average number of household members\nLatitude block group latitude\nLongitude block group longitude\n\n\nSource: Scikit-learn documentation."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#an-entire-ml-project",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#an-entire-ml-project",
    "title": "Deep Learning with Keras",
    "section": "An entire ML project",
    "text": "An entire ML project\n\nML life cycle\nSource: Actuaries Institute, Do Data Better."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#questions-to-answer-in-ml-project",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#questions-to-answer-in-ml-project",
    "title": "Deep Learning with Keras",
    "section": "Questions to answer in ML project",
    "text": "Questions to answer in ML project\nYou fit a few models to the training set, then ask:\n\n(Selection) Which of these models is the best?\n(Future Performance) How good should we expect the final model to be on unseen data?"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#set-aside-a-fraction-for-a-test-set",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#set-aside-a-fraction-for-a-test-set",
    "title": "Deep Learning with Keras",
    "section": "Set aside a fraction for a test set",
    "text": "Set aside a fraction for a test set\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    features, target, random_state=42\n)\n\n\n\n\n\n\nIllustration of a typical training/test split.\n\n\n\nNote: Compare X_/y_ names, capitals & lowercase.\n\n\n\n\n\nOur use of sklearn.\n\n\n\n\n\nAdapted from: Heaton (2022), Applications of Deep Learning, Part 2.1: Introduction to Pandas, and this random site."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#basic-ml-workflow",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#basic-ml-workflow",
    "title": "Deep Learning with Keras",
    "section": "Basic ML workflow",
    "text": "Basic ML workflow\n\nSplitting the data.\nFor each model, fit it to the training set.\nCompute the error for each model on the validation set.\nSelect the model with the lowest validation error.\nCompute the error of the final model on the test set.\n\n\nSource: Wikipedia."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#split-three-ways",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#split-three-ways",
    "title": "Deep Learning with Keras",
    "section": "Split three ways",
    "text": "Split three ways\n\n# Thanks https://datascience.stackexchange.com/a/15136\nX_main, X_test, y_main, y_test = train_test_split(\n    features, target, test_size=0.2, random_state=1\n)\n\n# As 0.25 x 0.8 = 0.2\nX_train, X_val, y_train, y_val = train_test_split(\n    X_main, y_main, test_size=0.25, random_state=1\n)\n\nX_train.shape, X_val.shape, X_test.shape\n\n((12384, 8), (4128, 8), (4128, 8))"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#why-not-use-test-set-for-both",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#why-not-use-test-set-for-both",
    "title": "Deep Learning with Keras",
    "section": "Why not use test set for both?",
    "text": "Why not use test set for both?\nThought experiment: have m classifiers: f_1(\\mathbf{x}), \\dots, f_m(\\mathbf{x}).\nThey are just as good as each other in the long run \n\\mathbb{P}(\\, f_i(\\mathbf{X}) = Y \\,)\\ =\\ 90\\% , \\quad \\text{for } i=1,\\dots,m .\n\n\n\nEvaluate each model on the test set, some will be better than others.\n\n\n\n\n\n\n\n\n\n\n\n\nTake the best, you’d think it has \\approx 98\\% accuracy!"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#the-training-set",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#the-training-set",
    "title": "Deep Learning with Keras",
    "section": "The training set",
    "text": "The training set\n\nX_train\n\n\n\n\n\n\n\n\nMedInc\nHouseAge\nAveRooms\nAveBedrms\nPopulation\nAveOccup\nLatitude\nLongitude\n\n\n\n\n9107\n4.1573\n19.0\n6.162630\n1.048443\n1677.0\n2.901384\n34.63\n-118.18\n\n\n13999\n0.4999\n10.0\n6.740000\n2.040000\n108.0\n2.160000\n34.69\n-116.90\n\n\n5610\n2.0458\n27.0\n3.619048\n1.062771\n1723.0\n3.729437\n33.78\n-118.26\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n8539\n4.0727\n18.0\n3.957845\n1.079625\n2276.0\n2.665105\n33.90\n-118.36\n\n\n2155\n2.3190\n41.0\n5.366265\n1.113253\n1129.0\n2.720482\n36.78\n-119.79\n\n\n13351\n5.5632\n9.0\n7.241087\n0.996604\n2280.0\n3.870968\n34.02\n-117.62\n\n\n\n\n12384 rows × 8 columns"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#location",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#location",
    "title": "Deep Learning with Keras",
    "section": "Location",
    "text": "Location\nPython’s matplotlib package \\approx R’s basic plots.\n\nimport matplotlib.pyplot as plt\n\nplt.scatter(features[\"Longitude\"], features[\"Latitude\"])"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#location-2",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#location-2",
    "title": "Deep Learning with Keras",
    "section": "Location #2",
    "text": "Location #2\nPython’s seaborn package \\approx R’s ggplot2.\n\nimport seaborn as sns\n\nsns.scatterplot(x=\"Longitude\", y=\"Latitude\", data=features);"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#features",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#features",
    "title": "Deep Learning with Keras",
    "section": "Features",
    "text": "Features\n\nprint(list(features.columns))\n\n['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n\n\nHow many?\n\nnum_features = len(features.columns)\nnum_features\n\n8\n\n\nOr\n\nnum_features = features.shape[1]\nfeatures.shape\n\n(20640, 8)"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#linear-regression",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#linear-regression",
    "title": "Deep Learning with Keras",
    "section": "Linear Regression",
    "text": "Linear Regression\n \\hat{y} = w_0 + \\sum_{i=1}^N w_i x_i .\n\nfrom sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\nlr.fit(X_train, y_train);\n\nThe w_0 is in lr.intercept_ and the others are in\n\nprint(lr.coef_)\n\n[ 4.34267965e-01  9.88284781e-03 -9.39592954e-02  5.86373944e-01\n -1.58360948e-06 -3.59968968e-03 -4.26013498e-01 -4.41779336e-01]"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#make-some-predictions",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#make-some-predictions",
    "title": "Deep Learning with Keras",
    "section": "Make some predictions",
    "text": "Make some predictions\n\nX_train.head(3)\n\n\n\n\n\n\n\n\nMedInc\nHouseAge\nAveRooms\nAveBedrms\nPopulation\nAveOccup\nLatitude\nLongitude\n\n\n\n\n9107\n4.1573\n19.0\n6.162630\n1.048443\n1677.0\n2.901384\n34.63\n-118.18\n\n\n13999\n0.4999\n10.0\n6.740000\n2.040000\n108.0\n2.160000\n34.69\n-116.90\n\n\n5610\n2.0458\n27.0\n3.619048\n1.062771\n1723.0\n3.729437\n33.78\n-118.26\n\n\n\n\n\n\n\n\ny_pred = lr.predict(X_train.head(3))\ny_pred\n\narray([1.81699287, 0.0810446 , 1.62089363])\n\n\n\nprediction = lr.intercept_\nfor w_i, x_i in zip(lr.coef_, X_train.iloc[0]):\n    prediction += w_i * x_i\nprediction                                              \n\n1.8169928680677785"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#plot-the-predictions",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#plot-the-predictions",
    "title": "Deep Learning with Keras",
    "section": "Plot the predictions",
    "text": "Plot the predictions"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#calculate-mean-squared-error",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#calculate-mean-squared-error",
    "title": "Deep Learning with Keras",
    "section": "Calculate mean squared error",
    "text": "Calculate mean squared error\n\nimport pandas as pd\n\ny_pred = lr.predict(X_train)\ndf = pd.DataFrame({\"Predictions\": y_pred, \"True values\": y_train})\ndf[\"Squared Error\"] = (df[\"Predictions\"] - df[\"True values\"]) ** 2\ndf.head(4)\n\n\n\n\n\n\n\n\nPredictions\nTrue values\nSquared Error\n\n\n\n\n9107\n1.816993\n2.281\n0.215303\n\n\n13999\n0.081045\n0.550\n0.219919\n\n\n5610\n1.620894\n1.745\n0.015402\n\n\n13533\n1.168949\n1.199\n0.000903\n\n\n\n\n\n\n\n\ndf[\"Squared Error\"].mean()\n\n0.5291948207479792"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#using-mean_squared_error",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#using-mean_squared_error",
    "title": "Deep Learning with Keras",
    "section": "Using mean_squared_error",
    "text": "Using mean_squared_error\n\ndf[\"Squared Error\"].mean()\n\n0.5291948207479792\n\n\n\nfrom sklearn.metrics import mean_squared_error as mse\n\nmse(y_train, y_pred)\n\n0.5291948207479792\n\n\nStore the results in a dictionary:\n\nmse_lr_train = mse(y_train, lr.predict(X_train))\nmse_lr_val = mse(y_val, lr.predict(X_val))\n\nmse_train = {\"Linear Regression\": mse_lr_train}\nmse_val = {\"Linear Regression\": mse_lr_val}"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#what-are-keras-and-tensorflow",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#what-are-keras-and-tensorflow",
    "title": "Deep Learning with Keras",
    "section": "What are Keras and TensorFlow?",
    "text": "What are Keras and TensorFlow?\nKeras is common way of specifying, training, and using neural networks. It gives a simple interface to various backend libraries, including Tensorflow.\n\nKeras as a independent interface, and Keras as part of Tensorflow.\nSource: Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Figure 10-10."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#create-a-keras-ann-model",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#create-a-keras-ann-model",
    "title": "Deep Learning with Keras",
    "section": "Create a Keras ANN model",
    "text": "Create a Keras ANN model\nDecide on the architecture: a simple fully-connected network with one hidden layer with 30 neurons.\nCreate the model:\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input\n\nmodel = Sequential(\n    [Input((num_features,)),\n     Dense(30, activation=\"relu\"),\n     Dense(1)]\n)"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#inspect-the-model",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#inspect-the-model",
    "title": "Deep Learning with Keras",
    "section": "Inspect the model",
    "text": "Inspect the model\n\nmodel.summary()\n\nModel: \"sequential\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ dense (Dense)                   │ (None, 30)                │        270 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_1 (Dense)                 │ (None, 1)                 │         31 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 301 (1.18 KB)\n\n\n\n Trainable params: 301 (1.18 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#the-model-is-initialised-randomly",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#the-model-is-initialised-randomly",
    "title": "Deep Learning with Keras",
    "section": "The model is initialised randomly",
    "text": "The model is initialised randomly\n\nmodel = Sequential([Dense(30, activation=\"relu\"), Dense(1)])\nmodel.predict(X_val.head(3), verbose=0)\n\narray([[-737.19183],\n       [-446.8675 ],\n       [ -20.18185]], dtype=float32)\n\n\n\nmodel = Sequential([Dense(30, activation=\"relu\"), Dense(1)])\nmodel.predict(X_val.head(3), verbose=0)\n\narray([[-566.09283 ],\n       [-336.90277 ],\n       [ -35.532364]], dtype=float32)"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#controlling-the-randomness",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#controlling-the-randomness",
    "title": "Deep Learning with Keras",
    "section": "Controlling the randomness",
    "text": "Controlling the randomness\n\nimport random\n\nrandom.seed(123)\n\nmodel = Sequential([Dense(30, activation=\"relu\"), Dense(1)])\n\ndisplay(model.predict(X_val.head(3), verbose=0))\n\nrandom.seed(123)\nmodel = Sequential([Dense(30, activation=\"relu\"), Dense(1)])\n\ndisplay(model.predict(X_val.head(3), verbose=0))\n\narray([[-513.13403 ],\n       [-302.182   ],\n       [ -17.794556]], dtype=float32)\n\n\narray([[-513.13403 ],\n       [-302.182   ],\n       [ -17.794556]], dtype=float32)"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#fit-the-model",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#fit-the-model",
    "title": "Deep Learning with Keras",
    "section": "Fit the model",
    "text": "Fit the model\n\nrandom.seed(123)\n\nmodel = Sequential([\n    Dense(30, activation=\"relu\"),\n    Dense(1)\n])\n\nmodel.compile(\"adam\", \"mse\")\n%time hist = model.fit(X_train, y_train, epochs=5, verbose=False)\nhist.history[\"loss\"]\n\nCPU times: user 2.98 s, sys: 308 ms, total: 3.29 s\nWall time: 2.9 s\n\n\n[1294.4464111328125,\n 2.6999993324279785,\n 1.6647465229034424,\n 1.4132969379425049,\n 1.031407356262207]"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#make-predictions",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#make-predictions",
    "title": "Deep Learning with Keras",
    "section": "Make predictions",
    "text": "Make predictions\n\ny_pred = model.predict(X_train[:3], verbose=0)\ny_pred\n\narray([[ 1.8308794],\n       [-0.3535612],\n       [ 1.0657732]], dtype=float32)\n\n\n\n\n\n\n\n\nNote\n\n\nThe .predict gives us a ‘matrix’ not a ‘vector’. Calling .flatten() will convert it to a ‘vector’.\n\nprint(f\"Original shape: {y_pred.shape}\")\ny_pred = y_pred.flatten()\nprint(f\"Flattened shape: {y_pred.shape}\")\ny_pred\n\nOriginal shape: (3, 1)\nFlattened shape: (3,)\n\n\narray([ 1.8308794, -0.3535612,  1.0657732], dtype=float32)"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#plot-the-predictions-1",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#plot-the-predictions-1",
    "title": "Deep Learning with Keras",
    "section": "Plot the predictions",
    "text": "Plot the predictions"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#assess-the-model",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#assess-the-model",
    "title": "Deep Learning with Keras",
    "section": "Assess the model",
    "text": "Assess the model\n\ny_pred = model.predict(X_val, verbose=0)\nmse(y_val, y_pred)\n\n0.8456477940379458\n\n\n\nmse_train[\"Basic ANN\"] = mse(\n    y_train, model.predict(X_train, verbose=0)\n)\nmse_val[\"Basic ANN\"] = mse(y_val, model.predict(X_val, verbose=0))\n\nSome predictions are negative:\n\ny_pred = model.predict(X_val, verbose=0)\ny_pred.min(), y_pred.max()\n\n(-6.280052, 10.888557)\n\n\n\ny_val.min(), y_val.max()\n\n(0.225, 5.00001)"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#try-running-for-longer",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#try-running-for-longer",
    "title": "Deep Learning with Keras",
    "section": "Try running for longer",
    "text": "Try running for longer\n\nrandom.seed(123)\n\nmodel = Sequential([\n    Dense(30, activation=\"relu\"),\n    Dense(1)\n])\n\nmodel.compile(\"adam\", \"mse\")\n\n%time hist = model.fit(X_train, y_train, \\\n    epochs=50, verbose=False)\n\nCPU times: user 28.9 s, sys: 0 ns, total: 28.9 s\nWall time: 28.9 s"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#loss-curve",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#loss-curve",
    "title": "Deep Learning with Keras",
    "section": "Loss curve",
    "text": "Loss curve\n\nplt.plot(range(1, 51), hist.history[\"loss\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"MSE\");"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#loss-curve-1",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#loss-curve-1",
    "title": "Deep Learning with Keras",
    "section": "Loss curve",
    "text": "Loss curve\n\nplt.plot(range(2, 51), hist.history[\"loss\"][1:])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"MSE\");"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#predictions",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#predictions",
    "title": "Deep Learning with Keras",
    "section": "Predictions",
    "text": "Predictions\n\ny_pred = model.predict(X_val, verbose=0)\nprint(f\"Min prediction: {y_pred.min():.2f}\")\nprint(f\"Max prediction: {y_pred.max():.2f}\")\n\nMin prediction: -18.77\nMax prediction: 7.70\n\n\n\n\n\nplt.scatter(y_pred, y_val)\nplt.xlabel(\"Predictions\")\nplt.ylabel(\"True values\")\nadd_diagonal_line()\n\n\n\nmse_train[\"Long run ANN\"] = mse(\n    y_train, model.predict(X_train, verbose=0)\n)\nmse_val[\"Long run ANN\"] = mse(y_val, model.predict(X_val, verbose=0))"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#try-different-activation-functions-1",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#try-different-activation-functions-1",
    "title": "Deep Learning with Keras",
    "section": "Try different activation functions",
    "text": "Try different activation functions"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#enforce-positive-outputs-relu",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#enforce-positive-outputs-relu",
    "title": "Deep Learning with Keras",
    "section": "Enforce positive outputs (ReLU)",
    "text": "Enforce positive outputs (ReLU)\n\nrandom.seed(123)\n\nmodel = Sequential([\n    Dense(30, activation=\"relu\"),\n    Dense(1, activation=\"relu\")\n])\n\nmodel.compile(\"adam\", \"mse\")\n\n%time hist = model.fit(X_train, y_train, epochs=50, \\\n    verbose=False)\n\nimport numpy as np\nlosses = np.round(hist.history[\"loss\"], 2)\nprint(losses[:5], \"...\", losses[-5:])\n\nCPU times: user 29.2 s, sys: 2.74 ms, total: 29.2 s\nWall time: 29.2 s\n[5.65 5.64 5.64 5.64 5.64] ... [5.64 5.64 5.64 5.64 5.64]"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#plot-the-predictions-2",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#plot-the-predictions-2",
    "title": "Deep Learning with Keras",
    "section": "Plot the predictions",
    "text": "Plot the predictions"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#enforce-positive-outputs-mathrmex",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#enforce-positive-outputs-mathrmex",
    "title": "Deep Learning with Keras",
    "section": "Enforce positive outputs (\\mathrm{e}^{\\,x})",
    "text": "Enforce positive outputs (\\mathrm{e}^{\\,x})\n\nrandom.seed(123)\n\nmodel = Sequential([\n    Dense(30, activation=\"relu\"),\n    Dense(1, activation=\"exponential\")\n])\n\nmodel.compile(\"adam\", \"mse\")\n\n%time hist = model.fit(X_train, y_train, epochs=5, verbose=False)\n\nlosses = hist.history[\"loss\"]\nprint(losses)\n\nCPU times: user 2.89 s, sys: 4.12 ms, total: 2.89 s\nWall time: 2.89 s\n[25.2047176361084, 5.639228820800781, 5.653268814086914, 5.639529705047607, 5.6393961906433105]"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#re-scaling-the-inputs",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#re-scaling-the-inputs",
    "title": "Deep Learning with Keras",
    "section": "Re-scaling the inputs",
    "text": "Re-scaling the inputs\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nscaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train_sc = scaler.transform(X_train)\nX_val_sc = scaler.transform(X_val)\nX_test_sc = scaler.transform(X_test)\n\n\n\n\nplt.hist(X_train.iloc[:, 0])\nplt.hist(X_train_sc[:, 0])\nplt.legend([\"Original\", \"Scaled\"]);"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#same-model-with-scaled-inputs",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#same-model-with-scaled-inputs",
    "title": "Deep Learning with Keras",
    "section": "Same model with scaled inputs",
    "text": "Same model with scaled inputs\n\nrandom.seed(123)\n\nmodel = Sequential([\n    Dense(30, activation=\"relu\"),\n    Dense(1, activation=\"exponential\")\n])\n\nmodel.compile(\"adam\", \"mse\")\n\n%time hist = model.fit( \\\n    X_train_sc, \\\n    y_train, \\\n    epochs=50, \\\n    verbose=False)\n\nCPU times: user 28.8 s, sys: 0 ns, total: 28.8 s\nWall time: 28.8 s"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#loss-curve-2",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#loss-curve-2",
    "title": "Deep Learning with Keras",
    "section": "Loss curve",
    "text": "Loss curve\n\nplt.plot(range(1, 51), hist.history[\"loss\"])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"MSE\");"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#loss-curve-3",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#loss-curve-3",
    "title": "Deep Learning with Keras",
    "section": "Loss curve",
    "text": "Loss curve\n\nplt.plot(range(2, 51), hist.history[\"loss\"][1:])\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"MSE\");"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#predictions-1",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#predictions-1",
    "title": "Deep Learning with Keras",
    "section": "Predictions",
    "text": "Predictions\n\ny_pred = model.predict(X_val_sc, verbose=0)\nprint(f\"Min prediction: {y_pred.min():.2f}\")\nprint(f\"Max prediction: {y_pred.max():.2f}\")\n\nMin prediction: 0.00\nMax prediction: 8.58\n\n\n\n\n\nplt.scatter(y_pred, y_val)\nplt.xlabel(\"Predictions\")\nplt.ylabel(\"True values\")\nadd_diagonal_line()\n\n\n\nmse_train[\"Exp ANN\"] = mse(\n    y_train, model.predict(X_train_sc, verbose=0)\n)\nmse_val[\"Exp ANN\"] = mse(y_val, model.predict(X_val_sc, verbose=0))"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#comparing-mse-smaller-is-better",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#comparing-mse-smaller-is-better",
    "title": "Deep Learning with Keras",
    "section": "Comparing MSE (smaller is better)",
    "text": "Comparing MSE (smaller is better)\nOn training data:\n\nmse_train\n\n{'Linear Regression': 0.5291948207479792,\n 'Basic ANN': 1.0832468030855924,\n 'Long run ANN': 0.7799112197400799,\n 'Exp ANN': 0.3280935061435783}\n\n\nOn validation data (expect worse, i.e. bigger):\n\nmse_val\n\n{'Linear Regression': 0.5059420205381367,\n 'Basic ANN': 0.8456477940379458,\n 'Long run ANN': 0.7851678744241668,\n 'Exp ANN': 0.3301015952055857}"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#comparing-models-train",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#comparing-models-train",
    "title": "Deep Learning with Keras",
    "section": "Comparing models (train)",
    "text": "Comparing models (train)\n\ntrain_results = pd.DataFrame(\n    {\"Model\": mse_train.keys(), \"MSE\": mse_train.values()}\n)\ntrain_results.sort_values(\"MSE\", ascending=False)\n\n\n\n\n\n\n\n\nModel\nMSE\n\n\n\n\n1\nBasic ANN\n1.083247\n\n\n2\nLong run ANN\n0.779911\n\n\n0\nLinear Regression\n0.529195\n\n\n3\nExp ANN\n0.328094"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#comparing-models-validation",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#comparing-models-validation",
    "title": "Deep Learning with Keras",
    "section": "Comparing models (validation)",
    "text": "Comparing models (validation)\n\nval_results = pd.DataFrame(\n    {\"Model\": mse_val.keys(), \"MSE\": mse_val.values()}\n)\nval_results.sort_values(\"MSE\", ascending=False)\n\n\n\n\n\n\n\n\nModel\nMSE\n\n\n\n\n1\nBasic ANN\n0.845648\n\n\n2\nLong run ANN\n0.785168\n\n\n0\nLinear Regression\n0.505942\n\n\n3\nExp ANN\n0.330102"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#choosing-when-to-stop-training",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#choosing-when-to-stop-training",
    "title": "Deep Learning with Keras",
    "section": "Choosing when to stop training",
    "text": "Choosing when to stop training\n\nIllustrative loss curves over time.\nSource: Heaton (2022), Applications of Deep Learning, Part 3.4: Early Stopping."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#try-early-stopping",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#try-early-stopping",
    "title": "Deep Learning with Keras",
    "section": "Try early stopping",
    "text": "Try early stopping\nHinton calls it a “beautiful free lunch”\n\nfrom keras.callbacks import EarlyStopping\n\nrandom.seed(123)\nmodel = Sequential([\n    Dense(30, activation=\"relu\"),\n    Dense(1, activation=\"exponential\")\n])\nmodel.compile(\"adam\", \"mse\")\n\nes = EarlyStopping(restore_best_weights=True, patience=15)\n\n%time hist = model.fit(X_train_sc, y_train, epochs=1_000, \\\n    callbacks=[es], validation_data=(X_val_sc, y_val), verbose=False)\nprint(f\"Keeping model at epoch #{len(hist.history['loss'])-10}.\")\n\nCPU times: user 1min 20s, sys: 15.1 ms, total: 1min 20s\nWall time: 1min 20s\nKeeping model at epoch #101."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#loss-curve-4",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#loss-curve-4",
    "title": "Deep Learning with Keras",
    "section": "Loss curve",
    "text": "Loss curve\n\nplt.plot(hist.history[\"loss\"])\nplt.plot(hist.history[\"val_loss\"])\nplt.legend([\"Training\", \"Validation\"]);"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#loss-curve-ii",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#loss-curve-ii",
    "title": "Deep Learning with Keras",
    "section": "Loss curve II",
    "text": "Loss curve II\n\nplt.plot(hist.history[\"loss\"])\nplt.plot(hist.history[\"val_loss\"])\nplt.ylim([0, 8])\nplt.legend([\"Training\", \"Validation\"]);"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#predictions-2",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#predictions-2",
    "title": "Deep Learning with Keras",
    "section": "Predictions",
    "text": "Predictions"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#comparing-models-validation-1",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#comparing-models-validation-1",
    "title": "Deep Learning with Keras",
    "section": "Comparing models (validation)",
    "text": "Comparing models (validation)\n\n\n\n\n\n\n\n\n\nModel\nMSE\n\n\n\n\n1\nBasic ANN\n0.845648\n\n\n2\nLong run ANN\n0.785168\n\n\n0\nLinear Regression\n0.505942\n\n\n3\nExp ANN\n0.330102\n\n\n4\nEarly stop ANN\n0.294328"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#the-test-set",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#the-test-set",
    "title": "Deep Learning with Keras",
    "section": "The test set",
    "text": "The test set\nEvaluate only the final/selected model on the test set.\n\nmse(y_test, model.predict(X_test_sc, verbose=0))\n\n0.3123165514245335\n\n\n\nmodel.evaluate(X_test_sc, y_test, verbose=False)\n\n0.31231650710105896"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#another-useful-callback",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#another-useful-callback",
    "title": "Deep Learning with Keras",
    "section": "Another useful callback",
    "text": "Another useful callback\n\nfrom pathlib import Path\nfrom keras.callbacks import ModelCheckpoint\n\nrandom.seed(123)\nmodel = Sequential(\n    [Dense(30, activation=\"relu\"), Dense(1, activation=\"exponential\")]\n)\nmodel.compile(\"adam\", \"mse\")\nmc = ModelCheckpoint(\n    \"best-model.keras\", monitor=\"val_loss\", save_best_only=True\n)\nes = EarlyStopping(restore_best_weights=True, patience=5)\nhist = model.fit(\n    X_train_sc,\n    y_train,\n    epochs=100,\n    validation_split=0.1,\n    callbacks=[mc, es],\n    verbose=False,\n)\nPath(\"best-model.keras\").stat().st_size\n\n19195"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#critique-this-regression-code",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#critique-this-regression-code",
    "title": "Deep Learning with Keras",
    "section": "Critique this 💩 regression code",
    "text": "Critique this 💩 regression code\n\nX_train = features[:80]; X_test = features[81:]\ny_train = targets[:80]; y_test = targets[81:]\n\n\nmodel = Sequential([\n   Input((2,)),\n  Dense(32, activation='relu'),\n   Dense(32, activation='relu'),\n  Dense(1, activation='sigmoid')\n])\nmodel.compile(optimizer=\"adam\", loss='mse')\nes = EarlyStopping(patience=10)\nfitted_model = model.fit(X_train, y_train, epochs=5,\n  callbacks=[es], verbose=False)\n\n\ntrainMAE = model.evaluate(X_train, y_train, verbose=False)\nhist = model.fit(X_test, y_test, epochs=5,\n  callbacks=[es], verbose=False)\nhist.history[\"loss\"]\ntestMAE = model.evaluate(X_test, y_test, verbose=False)\n\n\nf\"Train MAE: {testMAE:.2f} Test MAE: {trainMAE:.2f}\"\n\n'Train MAE: 4.85 Test MAE: 4.16'"
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#the-data",
    "href": "Lecture-2-Deep-Learning-Keras/deep-learning-keras.slides.html#the-data",
    "title": "Deep Learning with Keras",
    "section": "The data",
    "text": "The data\n\n\n\nsns.scatterplot(\n  x=\"$x_1$\", y=\"$x_2$\",\n  c=targets, data=features);\n\n\n\n\n\n\n\n\n\n\nsns.displot(targets, kde=True, stat=\"density\");"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.html",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.html",
    "title": "Course Overview",
    "section": "",
    "text": "My name is Patrick Laub. My background:\n\nBachelor in Software engineering / Mathematics (UQ)\nPhD in Applied Probability (Denmark & UQ)\nPost-doc in Lyon, France\nPost-doc in Melbourne, Australia",
    "crumbs": [
      "Module 1",
      "Course Overview"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.html#your-lecturer",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.html#your-lecturer",
    "title": "Course Overview",
    "section": "",
    "text": "My name is Patrick Laub. My background:\n\nBachelor in Software engineering / Mathematics (UQ)\nPhD in Applied Probability (Denmark & UQ)\nPost-doc in Lyon, France\nPost-doc in Melbourne, Australia",
    "crumbs": [
      "Module 1",
      "Course Overview"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.html#course-objectives",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.html#course-objectives",
    "title": "Course Overview",
    "section": "Course objectives",
    "text": "Course objectives\nArtificial intelligence and deep learning for actuaries.\nYou will be able to:\n\nexplain common neural network architectures,\ncreate deep learning models (in Keras) to solve actuarial data science problems,\ngain experience with practical computational tools (e.g. Python).",
    "crumbs": [
      "Module 1",
      "Course Overview"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.html#moodle-ed-forum",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.html#moodle-ed-forum",
    "title": "Course Overview",
    "section": "Moodle & Ed Forum",
    "text": "Moodle & Ed Forum\nThree Moodle pages (3143, 5111, & combined).\nThese have:\n\nlecture slides & recordings,\nassessment details,\nEd forum.\n\nPlease ask questions on the Ed forum.\nIf it is something confidential, then email me.",
    "crumbs": [
      "Module 1",
      "Course Overview"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.html#lecture-plans",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.html#lecture-plans",
    "title": "Course Overview",
    "section": "Lecture plans",
    "text": "Lecture plans\n\n\n\nArtificial Intelligence & Python\nDeep Learning with Keras\n(Pub. Hol.) Tabular Data\nComputer Vision\nNatural Language Processing\n\n\n\nAway for flexibility week\nInterpretability & Uncertainty\nRecurrent Neural Networks\nGenerative Networks\nAdvanced Topics\n\n\n\nIn Week 3, attend or watch on Tuesday.",
    "crumbs": [
      "Module 1",
      "Course Overview"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.html#contact-hours",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.html#contact-hours",
    "title": "Course Overview",
    "section": "Contact hours",
    "text": "Contact hours\nThe lectures are 2 hours each week.\nThe tutorials are a mix of ‘tutorials’ and ‘labs’. Tutorials will cover more of the theory and are examinable. Labs will cover practical Python and computational topics which are useful for deep learning.\nOffice hours can be arranged if needed.",
    "crumbs": [
      "Module 1",
      "Course Overview"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.html#tutorial-plans",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.html#tutorial-plans",
    "title": "Course Overview",
    "section": "Tutorial plans",
    "text": "Tutorial plans\n\n\n\nLab: Introduction to Python\nTut: Forward pass and batch optimisation\nLab: Git and GitHub\nTut: Backpropagation\nLab: Data visualisation\n\n\n\nAway for flexibility week\nTut: Interpretability & Uncertainty\nLab: Project help\nLab: Project help\nTut: Exam preparation",
    "crumbs": [
      "Module 1",
      "Course Overview"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.html#assessment",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.html#assessment",
    "title": "Course Overview",
    "section": "Assessment",
    "text": "Assessment\n\nStoryWall (30%)\nProject (40%)\nExam (30%)",
    "crumbs": [
      "Module 1",
      "Course Overview"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.html#storywall",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.html#storywall",
    "title": "Course Overview",
    "section": "StoryWall",
    "text": "StoryWall\n\nStoryWall #0 is to introduce yourself, due on Friday in Week 1 worth 2.5%.\nStoryWall #1 to #7 are 5% each, with the best 5 of 7 being counted.\nStoryWall #8 is a reflection, due on Friday in Week 10 worth 2.5%.\n\nEach is pass/fail. Questions released on a Monday and normally due the one or two weeks later on a Monday.",
    "crumbs": [
      "Module 1",
      "Course Overview"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.html#example-storywall",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.html#example-storywall",
    "title": "Course Overview",
    "section": "Example StoryWall",
    "text": "Example StoryWall\n\n\n\n\n\n\nChess AI\n\n\n\n\n\nFrench Motor Claims\n\n\n\n\n\n\n\n\nUndamaged\n\n\n\n\n\nDamaged\n\n\n\n\n\n\n\n\nOriginal\n\n\n\n\n\nColourised",
    "crumbs": [
      "Module 1",
      "Course Overview"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.html#a-complete-deep-learning-project",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.html#a-complete-deep-learning-project",
    "title": "Course Overview",
    "section": "A complete deep learning project",
    "text": "A complete deep learning project\nIndividual project over the term. You will:\n\nspecify a supervised learning problem,\ncollect and clean the data,\nperform an exploratory data analysis (EDA),\ncreate a simple (non-deep learning) benchmark model,\nfit two different deep learning architectures,\nperform hyperparameter tuning,\nwrite a discussion of the results.",
    "crumbs": [
      "Module 1",
      "Course Overview"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.html#project-components",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.html#project-components",
    "title": "Course Overview",
    "section": "Project components",
    "text": "Project components\nThe deliverables for the project will include:\n\ndraft due at noon on Friday in Week 5 (10%),\nrecorded presentation due at noon on Friday in Week 8 (15%),\nfinal report due at noon on Monday of Week 10 (15%).",
    "crumbs": [
      "Module 1",
      "Course Overview"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.html#exam",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.html#exam",
    "title": "Course Overview",
    "section": "Exam",
    "text": "Exam\nThe exam will test the concepts presented in the lectures. For example, you will be expected to:\n\nprovide definitions for various deep learning terminology,\nsuggest neural network designs to solve risk and actuarial problems,\ngive advice to mock deep learning engineers whose projects have hit common roadblocks,\nfind/explain common bugs in deep learning Python code.",
    "crumbs": [
      "Module 1",
      "Course Overview"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.html#copying-code",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.html#copying-code",
    "title": "Course Overview",
    "section": "Copying code…",
    "text": "Copying code…\n\n\nIf you copy, tag it:\n# Suppress endless warnings from Keras.\n# Source: https://stackoverflow.com/a/38645250\nimport tensorflow as tf\ntf.get_logger().setLevel('INFO')\nEven if you then edit it a little:\n# Create a basic Convolutional Network.\n# Adapted from: https://www.tensorflow.org/tutorials/images/cnn\nmodel = models.Sequential()\nmodel.add(layers.Input((32, 32, 3)))\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10))\n\n\n\n\nRecommended reading.\n\n\n\n\n\nSource: Anonymous (2016), Essential Copying and Pasting from Stack Overflow.",
    "crumbs": [
      "Module 1",
      "Course Overview"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#your-lecturer",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#your-lecturer",
    "title": "Course Overview",
    "section": "Your lecturer",
    "text": "Your lecturer\nMy name is Patrick Laub. My background:\n\nBachelor in Software engineering / Mathematics (UQ)\nPhD in Applied Probability (Denmark & UQ)\nPost-doc in Lyon, France\nPost-doc in Melbourne, Australia"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#course-objectives",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#course-objectives",
    "title": "Course Overview",
    "section": "Course objectives",
    "text": "Course objectives\nArtificial intelligence and deep learning for actuaries.\nYou will be able to:\n\nexplain common neural network architectures,\ncreate deep learning models (in Keras) to solve actuarial data science problems,\ngain experience with practical computational tools (e.g. Python)."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#moodle-ed-forum",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#moodle-ed-forum",
    "title": "Course Overview",
    "section": "Moodle & Ed Forum",
    "text": "Moodle & Ed Forum\nThree Moodle pages (3143, 5111, & combined).\nThese have:\n\nlecture slides & recordings,\nassessment details,\nEd forum.\n\nPlease ask questions on the Ed forum.\nIf it is something confidential, then email me."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#lecture-plans",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#lecture-plans",
    "title": "Course Overview",
    "section": "Lecture plans",
    "text": "Lecture plans\n\n\n\nArtificial Intelligence & Python\nDeep Learning with Keras\n(Pub. Hol.) Tabular Data\nComputer Vision\nNatural Language Processing\n\n\n\nAway for flexibility week\nInterpretability & Uncertainty\nRecurrent Neural Networks\nGenerative Networks\nAdvanced Topics\n\n\n\nIn Week 3, attend or watch on Tuesday."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#contact-hours",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#contact-hours",
    "title": "Course Overview",
    "section": "Contact hours",
    "text": "Contact hours\nThe lectures are 2 hours each week.\nThe tutorials are a mix of ‘tutorials’ and ‘labs’. Tutorials will cover more of the theory and are examinable. Labs will cover practical Python and computational topics which are useful for deep learning.\nOffice hours can be arranged if needed."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#tutorial-plans",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#tutorial-plans",
    "title": "Course Overview",
    "section": "Tutorial plans",
    "text": "Tutorial plans\n\n\n\nLab: Introduction to Python\nTut: Forward pass and batch optimisation\nLab: Git and GitHub\nTut: Backpropagation\nLab: Data visualisation\n\n\n\nAway for flexibility week\nTut: Interpretability & Uncertainty\nLab: Project help\nLab: Project help\nTut: Exam preparation"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#assessment",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#assessment",
    "title": "Course Overview",
    "section": "Assessment",
    "text": "Assessment\n\nStoryWall (30%)\nProject (40%)\nExam (30%)"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#storywall",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#storywall",
    "title": "Course Overview",
    "section": "StoryWall",
    "text": "StoryWall\n\nStoryWall #0 is to introduce yourself, due on Friday in Week 1 worth 2.5%.\nStoryWall #1 to #7 are 5% each, with the best 5 of 7 being counted.\nStoryWall #8 is a reflection, due on Friday in Week 10 worth 2.5%.\n\nEach is pass/fail. Questions released on a Monday and normally due the one or two weeks later on a Monday."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#example-storywall",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#example-storywall",
    "title": "Course Overview",
    "section": "Example StoryWall",
    "text": "Example StoryWall\n\n\n\n\n\n\nChess AI\n\n\n\n\n\nFrench Motor Claims\n\n\n\n\n\n\n\n\nUndamaged\n\n\n\n\n\nDamaged\n\n\n\n\n\n\n\n\nOriginal\n\n\n\n\n\nColourised"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#a-complete-deep-learning-project",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#a-complete-deep-learning-project",
    "title": "Course Overview",
    "section": "A complete deep learning project",
    "text": "A complete deep learning project\nIndividual project over the term. You will:\n\nspecify a supervised learning problem,\ncollect and clean the data,\nperform an exploratory data analysis (EDA),\ncreate a simple (non-deep learning) benchmark model,\nfit two different deep learning architectures,\nperform hyperparameter tuning,\nwrite a discussion of the results."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#project-components",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#project-components",
    "title": "Course Overview",
    "section": "Project components",
    "text": "Project components\nThe deliverables for the project will include:\n\ndraft due at noon on Friday in Week 5 (10%),\nrecorded presentation due at noon on Friday in Week 8 (15%),\nfinal report due at noon on Monday of Week 10 (15%)."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#exam",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#exam",
    "title": "Course Overview",
    "section": "Exam",
    "text": "Exam\nThe exam will test the concepts presented in the lectures. For example, you will be expected to:\n\nprovide definitions for various deep learning terminology,\nsuggest neural network designs to solve risk and actuarial problems,\ngive advice to mock deep learning engineers whose projects have hit common roadblocks,\nfind/explain common bugs in deep learning Python code."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#copying-code",
    "href": "Lecture-1-Artificial-Intelligence/course-overview.slides.html#copying-code",
    "title": "Course Overview",
    "section": "Copying code…",
    "text": "Copying code…\n\n\nIf you copy, tag it:\n# Suppress endless warnings from Keras.\n# Source: https://stackoverflow.com/a/38645250\nimport tensorflow as tf\ntf.get_logger().setLevel('INFO')\nEven if you then edit it a little:\n# Create a basic Convolutional Network.\n# Adapted from: https://www.tensorflow.org/tutorials/images/cnn\nmodel = models.Sequential()\nmodel.add(layers.Input((32, 32, 3)))\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(10))\n\n\n\n\nRecommended reading.\n\n\n\n\n\nSource: Anonymous (2016), Essential Copying and Pasting from Stack Overflow."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#about-python",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#about-python",
    "title": "Python",
    "section": "About Python",
    "text": "About Python\n\n\n\n\n\nFree book Automate the Boring Stuff with Python\n\n\n\nIt is general purpose language\nPython powers:\n\nInstagram\nSpotify\nNetflix\nUber\nReddit…\n\nPython is on Mars.\n\n\n\nSources: Blog post and Github."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#stack-overflow-2021-dev.-survey",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#stack-overflow-2021-dev.-survey",
    "title": "Python",
    "section": "Stack Overflow 2021 Dev. Survey",
    "text": "Stack Overflow 2021 Dev. Survey\n\n\n\nPython is 3rd most popular language\nPython is the most wanted language\nIn ‘Other frameworks and libraries’, they note that “several data science libraries for Python make strong showings”.\n\n\n\n\n\nPopular languages."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#githubs-2021-state-of-the-octoverse",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#githubs-2021-state-of-the-octoverse",
    "title": "Python",
    "section": "Github’s 2021 State of the Octoverse",
    "text": "Github’s 2021 State of the Octoverse\n\nTop languages over the years\nSource: Kaggle (2021), State of Machine Learning and Data Science."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#python-and-machine-learning",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#python-and-machine-learning",
    "title": "Python",
    "section": "Python and machine learning",
    "text": "Python and machine learning\n\n…[T]he entire machine learning and data science industry has been dominated by these two approaches: deep learning and gradient boosted trees… Users of gradient boosted trees tend to use Scikit-learn, XGBoost, or LightGBM. Meanwhile, most practitioners of deep learning use Keras, often in combination with its parent framework TensorFlow. The common point of these tools is they’re all Python libraries: Python is by far the most widely used language for machine learning and data science.\n\n\nSource: François Chollet (2021), Deep Learning with Python, Second Edition, Section 1.2.7."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#python-for-data-science",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#python-for-data-science",
    "title": "Python",
    "section": "Python for data science",
    "text": "Python for data science\n\n\nIn R you can run:\npchisq(3, 10)\n\nIn Python it is\nfrom scipy import stats\nstats.chi2(10).cdf(3)\n\n\n\nIn Leganto"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#google-colaboratory",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#google-colaboratory",
    "title": "Python",
    "section": "Google Colaboratory",
    "text": "Google Colaboratory\n\nAn example notebook in Google Colaboratory.http://colab.research.google.com"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#variables-and-basic-types",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#variables-and-basic-types",
    "title": "Python",
    "section": "Variables and basic types",
    "text": "Variables and basic types\n\n\n\n1 + 2\n\n3\n\n\n\nx = 1\nx + 2.0\n\n3.0\n\n\n\ntype(2.0)\n\nfloat\n\n\n\ntype(1), type(x)\n\n(int, int)\n\n\n\n\ndoes_math_work = 1 + 1 == 2\nprint(does_math_work)\ntype(does_math_work)\n\nTrue\n\n\nbool\n\n\n\ncontradiction = 1 != 1\ncontradiction\n\nFalse"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#shorthand-assignments",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#shorthand-assignments",
    "title": "Python",
    "section": "Shorthand assignments",
    "text": "Shorthand assignments\nIf we want to add 2 to a variable x:\n\n\n\nx = 1\nx = x + 2\nx\n\n3\n\n\n\n\nx = 1\nx += 2\nx\n\n3\n\n\n\n\nSame for:\n\nx -= 2 : take 2 from the current value of x ,\nx *= 2 : double the current value of x,\nx /= 2 : halve the current value of x."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#strings",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#strings",
    "title": "Python",
    "section": "Strings",
    "text": "Strings\n\nname = \"Patrick\"\nsurname = 'Laub'\n\n\ncoffee = \"This is Patrick's coffee\"\nquote = 'And then he said \"I need a coffee!\"'\n\n\nname + surname\n\n'PatrickLaub'\n\n\n\ngreeting = f\"Hello {name} {surname}\"\ngreeting\n\n'Hello Patrick Laub'\n\n\n\n\"Patrick\" in greeting\n\nTrue"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#and-or",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#and-or",
    "title": "Python",
    "section": "and & or",
    "text": "and & or\n\nname = \"Patrick\"\nsurname = \"Laub\"\nname.istitle() and surname.istitle()\n\nTrue\n\n\n\nfull_name = \"Dr Patrick Laub\"\nfull_name.startswith(\"Dr \") or full_name.endswith(\" PhD\")\n\nTrue\n\n\n\n\n\n\n\n\nImportant\n\n\nThe dot is used denote methods, it can’t be used inside a variable name.\n\ni.am.an.unfortunate.R.users = True\n\nNameError: name 'i' is not defined"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#help-to-get-more-details",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#help-to-get-more-details",
    "title": "Python",
    "section": "help to get more details",
    "text": "help to get more details\n\nhelp(name.istitle)\n\nHelp on built-in function istitle:\n\nistitle() method of builtins.str instance\n    Return True if the string is a title-cased string, False otherwise.\n    \n    In a title-cased string, upper- and title-case characters may only\n    follow uncased characters and lowercase characters only cased ones."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#f-strings",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#f-strings",
    "title": "Python",
    "section": "f-strings",
    "text": "f-strings\n\nprint(f\"Five squared is {5*5} and five cubed is {5**3}\")\nprint(\"Five squared is {5*5} and five cubed is {5**3}\")\n\nFive squared is 25 and five cubed is 125\nFive squared is {5*5} and five cubed is {5**3}\n\n\n\nUse f-strings and avoid the older alternatives:\n\nprint(f\"Hello {name} {surname}\")\nprint(\"Hello \" + name + \" \" + surname)\nprint(\"Hello {} {}\".format(name, surname))\nprint(\"Hello %s %s\" % (name, surname))\n\nHello Patrick Laub\nHello Patrick Laub\nHello Patrick Laub\nHello Patrick Laub"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#converting-types",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#converting-types",
    "title": "Python",
    "section": "Converting types",
    "text": "Converting types\n\ndigit = 3\ndigit\n\n3\n\n\n\ntype(digit)\n\nint\n\n\n\nnum = float(digit)\nnum\n\n3.0\n\n\n\ntype(num)\n\nfloat\n\n\n\nnum_str = str(num)\nnum_str\n\n'3.0'"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#quiz",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#quiz",
    "title": "Python",
    "section": "Quiz",
    "text": "Quiz\nWhat is the output of:\n\nx = 1\ny = 1.0\nprint(f\"{x == y} and {type(x) == type(y)}\")\n\n\n\n\nTrue and False\n\n\n\n\nWhat would you add before line 3 to get “True and True”?\n\n\n\nx = 1\ny = 1.0\nx = float(x)  # or y = int(y)\nprint(f\"{x == y} and {type(x) == type(y)}\")\n\nTrue and True"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#lists",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#lists",
    "title": "Python",
    "section": "Lists",
    "text": "Lists\n\ndesires = [\"Coffee\", \"Cake\", \"Sleep\"]\ndesires\n\n['Coffee', 'Cake', 'Sleep']\n\n\n\nlen(desires)\n\n3\n\n\n\ndesires[0]\n\n'Coffee'\n\n\n\ndesires[-1]\n\n'Sleep'\n\n\n\ndesires[2] = \"Nap\"\ndesires\n\n['Coffee', 'Cake', 'Nap']"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#slicing-lists",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#slicing-lists",
    "title": "Python",
    "section": "Slicing lists",
    "text": "Slicing lists\n\nprint([0, 1, 2])\ndesires\n\n[0, 1, 2]\n\n\n['Coffee', 'Cake', 'Nap']\n\n\n\ndesires[0:2]\n\n['Coffee', 'Cake']\n\n\n\ndesires[0:1]\n\n['Coffee']\n\n\n\ndesires[:2]\n\n['Coffee', 'Cake']"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#a-common-indexing-error",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#a-common-indexing-error",
    "title": "Python",
    "section": "A common indexing error",
    "text": "A common indexing error\n\ndesires[1.0]\n\nTypeError: list indices must be integers or slices, not float\n\n\n\ndesires[: len(desires) / 2]\n\nTypeError: slice indices must be integers or None or have an __index__ method\n\n\n\nlen(desires) / 2, len(desires) // 2\n\n(1.5, 1)\n\n\n\ndesires[: len(desires) // 2]\n\n['Coffee']"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#editing-lists",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#editing-lists",
    "title": "Python",
    "section": "Editing lists",
    "text": "Editing lists\n\ndesires = [\"Coffee\", \"Cake\", \"Sleep\"]\ndesires.append(\"Gadget\")\ndesires\n\n['Coffee', 'Cake', 'Sleep', 'Gadget']\n\n\n\ndesires.pop()\n\n'Gadget'\n\n\n\ndesires\n\n['Coffee', 'Cake', 'Sleep']\n\n\n\ndesires.sort()\ndesires\n\n['Cake', 'Coffee', 'Sleep']\n\n\n\ndesires[3] = \"Croissant\"\n\nIndexError: list assignment index out of range"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#none",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#none",
    "title": "Python",
    "section": "None",
    "text": "None\n\ndesires = [\"Coffee\", \"Cake\", \"Sleep\", \"Gadget\"]\nsorted_list = desires.sort()\nsorted_list\n\n\ntype(sorted_list)\n\nNoneType\n\n\n\nsorted_list is None\n\nTrue\n\n\n\nbool(sorted_list)\n\nFalse\n\n\n\ndesires = [\"Coffee\", \"Cake\", \"Sleep\", \"Gadget\"]\nsorted_list = sorted(desires)\nprint(desires)\nsorted_list\n\n['Coffee', 'Cake', 'Sleep', 'Gadget']\n\n\n['Cake', 'Coffee', 'Gadget', 'Sleep']"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#tuples-immutable-lists",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#tuples-immutable-lists",
    "title": "Python",
    "section": "Tuples (‘immutable’ lists)",
    "text": "Tuples (‘immutable’ lists)\n\nweather = (\"Sunny\", \"Cloudy\", \"Rainy\")\nprint(type(weather))\nprint(len(weather))\nprint(weather[-1])\n\n&lt;class 'tuple'&gt;\n3\nRainy\n\n\n\nweather.append(\"Snowy\")\n\nAttributeError: 'tuple' object has no attribute 'append'\n\n\n\nweather[2] = \"Snowy\"\n\nTypeError: 'tuple' object does not support item assignment"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#one-length-tuples",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#one-length-tuples",
    "title": "Python",
    "section": "One-length tuples",
    "text": "One-length tuples\n\nusing_brackets_in_math = (2 + 4) * 3\nusing_brackets_to_simplify = (1 + 1 == 2)\n\n\nfailure_of_atuple = (\"Snowy\")\ntype(failure_of_atuple)\n\nstr\n\n\n\nhappy_solo_tuple = (\"Snowy\",)\ntype(happy_solo_tuple)\n\ntuple\n\n\n\ncheeky_solo_list = [\"Snowy\"]\ntype(cheeky_solo_list)\n\nlist"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#dictionaries",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#dictionaries",
    "title": "Python",
    "section": "Dictionaries",
    "text": "Dictionaries\n\nphone_book = {\"Patrick\": \"+61 1234\", \"Café\": \"(02) 5678\"}\nphone_book[\"Patrick\"]\n\n'+61 1234'\n\n\n\nphone_book[\"Café\"] = \"+61400 000 000\"\nphone_book\n\n{'Patrick': '+61 1234', 'Café': '+61400 000 000'}\n\n\n\nphone_book.keys()\n\ndict_keys(['Patrick', 'Café'])\n\n\n\nphone_book.values()\n\ndict_values(['+61 1234', '+61400 000 000'])\n\n\n\nfactorial = {0: 1, 1: 1, 2: 2, 3: 6, 4: 24, 5: 120, 6: 720, 7: 5040}\nfactorial[4]\n\n24"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#quiz-1",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#quiz-1",
    "title": "Python",
    "section": "Quiz",
    "text": "Quiz\n\nanimals = [\"dog\", \"cat\", \"bird\"]\nanimals.append(\"teddy bear\")\nanimals.pop()\nanimals.pop()\nanimals.append(\"koala\")\nanimals.append(\"kangaroo\")\nprint(f\"{len(animals)} and {len(animals[-2])}\")\n\n\n\n\n4 and 5"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#if-and-else",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#if-and-else",
    "title": "Python",
    "section": "if and else",
    "text": "if and else\n\nage = 50\n\n\nif age &gt;= 30:\n    print(\"Gosh you're old\")\n\nGosh you're old\n\n\n\nif age &gt;= 30:\n    print(\"Gosh you're old\")\nelse:\n    print(\"You're still young\")\n\nGosh you're old"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#the-weird-part-about-python",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#the-weird-part-about-python",
    "title": "Python",
    "section": "The weird part about Python…",
    "text": "The weird part about Python…\n\nif age &gt;= 30:\n    print(\"Gosh you're old\")\nelse:\nprint(\"You're still young\")\n\nIndentationError: expected an indented block after 'else' statement on line 3 (2212277638.py, line 4)\n\n\n\n\n\n\n\n\nWarning\n\n\nWatch out for mixing tabs and spaces!"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#an-example-of-aging",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#an-example-of-aging",
    "title": "Python",
    "section": "An example of aging",
    "text": "An example of aging\n\nage = 16\n\nif age &lt; 18:\n    friday_evening_schedule = \"School things\"\nif age &lt; 30:\n    friday_evening_schedule = \"Party 🥳🍾\"\nif age &gt;= 30:\n    friday_evening_schedule = \"Work\"\n\n\n\nprint(friday_evening_schedule)\n\nParty 🥳🍾"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#using-elif",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#using-elif",
    "title": "Python",
    "section": "Using elif",
    "text": "Using elif\n\nage = 16\n\nif age &lt; 18:\n    friday_evening_schedule = \"School things\"\nelif age &lt; 30:\n    friday_evening_schedule = \"Party 🥳🍾\"\nelse:\n    friday_evening_schedule = \"Work\"\n\nprint(friday_evening_schedule)\n\nSchool things"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#for-loops",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#for-loops",
    "title": "Python",
    "section": "for Loops",
    "text": "for Loops\n\ndesires = [\"coffee\", \"cake\", \"sleep\"]\nfor desire in desires:\n    print(f\"Patrick really wants a {desire}.\")\n\nPatrick really wants a coffee.\nPatrick really wants a cake.\nPatrick really wants a sleep.\n\n\n\n\n\nfor i in range(3):\n    print(i)\n\n0\n1\n2\n\n\n\nfor i in range(3, 6):\n    print(i)\n\n3\n4\n5\n\n\n\n\nrange(5)\n\nrange(0, 5)\n\n\n\ntype(range(5))\n\nrange\n\n\n\nlist(range(5))\n\n[0, 1, 2, 3, 4]"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#advanced-for-loops",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#advanced-for-loops",
    "title": "Python",
    "section": "Advanced for loops",
    "text": "Advanced for loops\n\nfor i, desire in enumerate(desires):\n    print(f\"Patrick wants a {desire}, it is priority #{i+1}.\")\n\nPatrick wants a coffee, it is priority #1.\nPatrick wants a cake, it is priority #2.\nPatrick wants a sleep, it is priority #3.\n\n\n\ndesires = [\"coffee\", \"cake\", \"nap\"]\ntimes = [\"in the morning\", \"at lunch\", \"during a boring lecture\"]\n\nfor desire, time in zip(desires, times):\n    print(f\"Patrick enjoys a {desire} {time}.\")\n\nPatrick enjoys a coffee in the morning.\nPatrick enjoys a cake at lunch.\nPatrick enjoys a nap during a boring lecture."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#list-comprehensions",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#list-comprehensions",
    "title": "Python",
    "section": "List comprehensions",
    "text": "List comprehensions\n\n[x**2 for x in range(10)]\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n\n\n[x**2 for x in range(10) if x % 2 == 0]\n\n[0, 4, 16, 36, 64]\n\n\nThey can get more complicated:\n\n[x*y for x in range(4) for y in range(4)]\n\n[0, 0, 0, 0, 0, 1, 2, 3, 0, 2, 4, 6, 0, 3, 6, 9]\n\n\n\n[[x*y for x in range(4)] for y in range(4)]\n\n[[0, 0, 0, 0], [0, 1, 2, 3], [0, 2, 4, 6], [0, 3, 6, 9]]\n\n\nbut I’d recommend just using for loops at that point."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#while-loops",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#while-loops",
    "title": "Python",
    "section": "While Loops",
    "text": "While Loops\nSay that we want to simulate (X \\,\\mid\\, X \\ge 100) where X \\sim \\mathrm{Pareto}(1). Assuming we have simulate_pareto, a function to generate \\mathrm{Pareto}(1) variables:\n\nsamples = []\nwhile len(samples) &lt; 5:\n    x = simulate_pareto()\n    if x &gt;= 100:\n        samples.append(x)\n\nsamples\n\n[125.28600493316272,\n 186.04974709289712,\n 154.45723763510398,\n 101.08310878885993,\n 2852.8305399214996]"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#breaking-out-of-a-loop",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#breaking-out-of-a-loop",
    "title": "Python",
    "section": "Breaking out of a loop",
    "text": "Breaking out of a loop\n\nwhile True:\n    user_input = input(\"&gt;&gt; What would you like to do? \")\n\n    if user_input == \"order cake\":\n        print(\"Here's your cake! 🎂\")\n\n    elif user_input == \"order coffee\":\n        print(\"Here's your coffee! ☕️\")\n\n    elif user_input == \"quit\":\n        break\n\n\n\n&gt;&gt; What would you like to do? order cake\nHere's your cake! 🎂\n&gt;&gt; What would you like to do? order coffee\nHere's your coffee! ☕️\n&gt;&gt; What would you like to do? order cake\nHere's your cake! 🎂\n&gt;&gt; What would you like to do? quit"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#quiz-2",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#quiz-2",
    "title": "Python",
    "section": "Quiz",
    "text": "Quiz\nWhat does this print out?\n\nif 1 / 3 + 1 / 3 + 1 / 3 == 1:\n    if 2**3 == 6:\n        print(\"Math really works!\")\n    else:\n        print(\"Math sometimes works..\")\nelse:\n    print(\"Math doesn't work\")\n\n\n\n\nMath sometimes works..\n\n\n\nWhat does this print out?\n\ncount = 0\nfor i in range(1, 10):\n    count += i\n    if i &gt; 3:\n        break\nprint(count)\n\n\n\n\n10"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#debugging-the-quiz-code",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#debugging-the-quiz-code",
    "title": "Python",
    "section": "Debugging the quiz code",
    "text": "Debugging the quiz code\n\ncount = 0\nfor i in range(1, 10):\n    count += i\n    print(f\"After i={i} count={count}\")\n    if i &gt; 3:\n        break\n\nAfter i=1 count=1\nAfter i=2 count=3\nAfter i=3 count=6\nAfter i=4 count=10"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#making-a-function",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#making-a-function",
    "title": "Python",
    "section": "Making a function",
    "text": "Making a function\n\ndef add_one(x):\n    return x + 1\n\ndef greet_a_student(name):\n    print(f\"Hi {name}, welcome to the AI class!\")\n\n\nadd_one(10)\n\n11\n\n\n\ngreet_a_student(\"Josephine\")\n\nHi Josephine, welcome to the AI class!\n\n\n\ngreet_a_student(\"Joseph\")\n\nHi Joseph, welcome to the AI class!\n\n\n\nHere, name is a parameter and the value supplied is an argument."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#default-arguments",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#default-arguments",
    "title": "Python",
    "section": "Default arguments",
    "text": "Default arguments\nAssuming we have simulate_standard_normal, a function to generate \\mathrm{Normal}(0, 1) variables:\n\ndef simulate_normal(mean=0, std=1):\n    return mean + std * simulate_standard_normal()\n\n\nsimulate_normal()  # same as 'simulate_normal(0, 1)'\n\n0.47143516373249306\n\n\n\nsimulate_normal(1_000)  # same as 'simulate_normal(1_000, 1)'\n\n998.8090243052935\n\n\n\n\n\n\n\n\nNote\n\n\nWe’ll cover random numbers next week (using numpy)."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#use-explicit-parameter-name",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#use-explicit-parameter-name",
    "title": "Python",
    "section": "Use explicit parameter name",
    "text": "Use explicit parameter name\n\nsimulate_normal(mean=1_000)  # same as 'simulate_normal(1_000, 1)'\n\n1001.4327069684261\n\n\n\nsimulate_normal(std=1_000)  # same as 'simulate_normal(0, 1_000)'\n\n-312.6518960917129\n\n\n\nsimulate_normal(10, std=0.001)  # same as 'simulate_normal(10, 0.001)'\n\n9.999279411266635\n\n\n\nsimulate_normal(std=10, 1_000)\n\nSyntaxError: positional argument follows keyword argument (1723181129.py, line 1)"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#why-would-we-need-that",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#why-would-we-need-that",
    "title": "Python",
    "section": "Why would we need that?",
    "text": "Why would we need that?\nE.g. to fit a Keras model, we use the .fit method:\n\nmodel.fit(x=None, y=None, batch_size=None, epochs=1, verbose='auto',\n        callbacks=None, validation_split=0.0, validation_data=None,\n        shuffle=True, class_weight=None, sample_weight=None,\n        initial_epoch=0, steps_per_epoch=None, validation_steps=None,\n        validation_batch_size=None, validation_freq=1,\n        max_queue_size=10, workers=1, use_multiprocessing=False)\n\nSay we want all the defaults except changing use_multiprocessing=True:\n\nmodel.fit(None, None, None, 1, 'auto', None, 0.0, None, True, None,\n        None, 0, None, None, None, 1, 10, 1, True)\n\nbut it is much nicer to just have:\n\nmodel.fit(use_multiprocessing=True)"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#quiz-3",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#quiz-3",
    "title": "Python",
    "section": "Quiz",
    "text": "Quiz\nWhat does the following print out?\n\ndef get_half_of_list(numbers, first=True):\n    if first:\n        return numbers[: len(numbers) // 2]\n    else:\n        return numbers[len(numbers) // 2 :]\n\nnums = [1, 2, 3, 4, 5, 6]\nchunk = get_half_of_list(nums, False)\nsecond_chunk = get_half_of_list(chunk)\nprint(second_chunk)\n\n\n\n\n[4]\n\n\n\n\n\nf\"nums ~&gt; {nums[:len(nums)//2]} and {nums[len(nums)//2:]}\"\n\n'nums ~&gt; [1, 2, 3] and [4, 5, 6]'\n\n\n\nf\"chunk ~&gt; {chunk[:len(chunk)//2]} and {chunk[len(chunk)//2:]}\"\n\n'chunk ~&gt; [4] and [5, 6]'"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#multiple-return-values",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#multiple-return-values",
    "title": "Python",
    "section": "Multiple return values",
    "text": "Multiple return values\n\ndef limits(numbers):\n    return min(numbers), max(numbers)\n\nlimits([1, 2, 3, 4, 5])\n\n(1, 5)\n\n\n\ntype(limits([1, 2, 3, 4, 5]))\n\ntuple\n\n\n\nmin_num, max_num = limits([1, 2, 3, 4, 5])\nprint(f\"The numbers are between {min_num} and {max_num}.\")\n\nThe numbers are between 1 and 5.\n\n\n\n_, max_num = limits([1, 2, 3, 4, 5])\nprint(f\"The maximum is {max_num}.\")\n\nThe maximum is 5.\n\n\n\nprint(f\"The maximum is {limits([1, 2, 3, 4, 5])[1]}.\")\n\nThe maximum is 5."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#tuple-unpacking",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#tuple-unpacking",
    "title": "Python",
    "section": "Tuple unpacking",
    "text": "Tuple unpacking\n\nlims = limits([1, 2, 3, 4, 5])\nsmallest_num = lims[0]\nlargest_num = lims[1]\nprint(f\"The numbers are between {smallest_num} and {largest_num}.\")\n\nThe numbers are between 1 and 5.\n\n\n\nsmallest_num, largest_num = limits([1, 2, 3, 4, 5])\nprint(f\"The numbers are between {smallest_num} and {largest_num}.\")\n\nThe numbers are between 1 and 5.\n\n\nThis doesn’t just work for functions with multiple return values:\n\nRESOLUTION = (1920, 1080)\nWIDTH, HEIGHT = RESOLUTION\nprint(f\"The resolution is {WIDTH} wide and {HEIGHT} tall.\")\n\nThe resolution is 1920 wide and 1080 tall."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#short-circuiting",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#short-circuiting",
    "title": "Python",
    "section": "Short-circuiting",
    "text": "Short-circuiting\n\ndef is_positive(x):\n    print(\"Called is_positive\")\n    return x &gt; 0\n\ndef is_negative(x):\n    print(\"Called is_negative\")\n    return x &lt; 0\n\nx = 10\n\n\n\n\nx_is_positive = is_positive(x)\nx_is_positive\n\nCalled is_positive\n\n\nTrue\n\n\n\n\nx_is_negative = is_negative(x)\nx_is_negative\n\nCalled is_negative\n\n\nFalse\n\n\n\n\n\nx_not_zero = is_positive(x) or is_negative(x)\nx_not_zero\n\nCalled is_positive\n\n\nTrue"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#python-standard-library",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#python-standard-library",
    "title": "Python",
    "section": "Python standard library",
    "text": "Python standard library\n\nimport os\nimport time\n\n\ntime.sleep(0.1)\n\n\nos.getlogin()\n\n'plaub'\n\n\n\nos.getcwd()\n\n'/home/plaub/Dropbox/Lecturing/ACTL3143/DeepLearningForActuaries/Lecture-1-Artificial-Intelligence'"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#import-a-few-functions",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#import-a-few-functions",
    "title": "Python",
    "section": "Import a few functions",
    "text": "Import a few functions\n\nfrom os import getcwd, getlogin\nfrom time import sleep\n\n\nsleep(0.1)\n\n\ngetlogin()\n\n'plaub'\n\n\n\ngetcwd()\n\n'/home/plaub/Dropbox/Lecturing/ACTL3143/DeepLearningForActuaries/Lecture-1-Artificial-Intelligence'"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#timing-using-pure-python",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#timing-using-pure-python",
    "title": "Python",
    "section": "Timing using pure Python",
    "text": "Timing using pure Python\n\nfrom time import time\n\nstart_time = time()\n\ncounting = 0\nfor i in range(1_000_000):\n    counting += 1\n\nend_time = time()\n\nelapsed = end_time - start_time\nprint(f\"Elapsed time: {elapsed} secs\")\n\nElapsed time: 0.030005931854248047 secs"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#data-science-packages",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#data-science-packages",
    "title": "Python",
    "section": "Data science packages",
    "text": "Data science packages\n\nCommon data science packages\nSource: Learnbay.co, Python libraries for data analysis and modeling in Data science, Medium."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#importing-using-as",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#importing-using-as",
    "title": "Python",
    "section": "Importing using as",
    "text": "Importing using as\n\n\n\nimport pandas\n\npandas.DataFrame(\n    {\n        \"x\": [1, 2, 3],\n        \"y\": [4, 5, 6],\n    }\n)\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n1\n4\n\n\n1\n2\n5\n\n\n2\n3\n6\n\n\n\n\n\n\n\n\n\nimport pandas as pd\n\npd.DataFrame(\n    {\n        \"x\": [1, 2, 3],\n        \"y\": [4, 5, 6],\n    }\n)\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n1\n4\n\n\n1\n2\n5\n\n\n2\n3\n6"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#importing-from-a-subdirectory",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#importing-from-a-subdirectory",
    "title": "Python",
    "section": "Importing from a subdirectory",
    "text": "Importing from a subdirectory\nWant keras.models.Sequential().\n\nimport keras \n\nmodel = keras.models.Sequential()\n\nAlternatives using from:\n\nfrom keras import models\n\nmodel = models.Sequential()\n\n\nfrom keras.models import Sequential\n\nmodel = Sequential()"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#anonymous-lambda-functions",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#anonymous-lambda-functions",
    "title": "Python",
    "section": "Anonymous ‘lambda’ functions",
    "text": "Anonymous ‘lambda’ functions\nExample: how to sort strings by their second letter?\n\nnames = [\"Josephine\", \"Patrick\", \"Bert\"]\n\nIf you try help(sorted) you’ll find the key parameter.\n\nfor name in names:\n    print(f\"The length of '{name}' is {len(name)}.\")\n\nThe length of 'Josephine' is 9.\nThe length of 'Patrick' is 7.\nThe length of 'Bert' is 4.\n\n\n\nsorted(names, key=len)\n\n['Bert', 'Patrick', 'Josephine']"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#anonymous-lambda-functions-1",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#anonymous-lambda-functions-1",
    "title": "Python",
    "section": "Anonymous ‘lambda’ functions",
    "text": "Anonymous ‘lambda’ functions\nExample: how to sort strings by their second letter?\n\nnames = [\"Josephine\", \"Patrick\", \"Bert\"]\n\nIf you try help(sorted) you’ll find the key parameter.\n\ndef second_letter(name):\n    return name[1]\n\n\nfor name in names:\n    print(f\"The second letter of '{name}' is '{second_letter(name)}'.\")\n\nThe second letter of 'Josephine' is 'o'.\nThe second letter of 'Patrick' is 'a'.\nThe second letter of 'Bert' is 'e'.\n\n\n\nsorted(names, key=second_letter)\n\n['Patrick', 'Bert', 'Josephine']"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#anonymous-lambda-functions-2",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#anonymous-lambda-functions-2",
    "title": "Python",
    "section": "Anonymous ‘lambda’ functions",
    "text": "Anonymous ‘lambda’ functions\nExample: how to sort strings by their second letter?\n\nnames = [\"Josephine\", \"Patrick\", \"Bert\"]\n\nIf you try help(sorted) you’ll find the key parameter.\n\nsorted(names, key=lambda name: name[1])\n\n['Patrick', 'Bert', 'Josephine']\n\n\n\n\n\n\n\n\n\nCaution\n\n\nDon’t use lambda as a variable name! You commonly see lambd or lambda_ or λ."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#with-keyword",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#with-keyword",
    "title": "Python",
    "section": "with keyword",
    "text": "with keyword\nExample, opening a file:\n\n\nMost basic way is:\n\nf = open(\"haiku1.txt\", \"r\")\nprint(f.read())\nf.close()\n\nChaos reigns within.\nReflect, repent, and reboot.\nOrder shall return.\n\n\n\nInstead, use:\n\nwith open(\"haiku2.txt\", \"r\") as f:\n    print(f.read())\n\nThe Web site you seek\nCannot be located, but\nCountless more exist.\n\n\n\n\n\nHaikus from http://www.libertybasicuniversity.com/lbnews/nl107/haiku.htm"
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.slides.html#links",
    "href": "Lecture-1-Artificial-Intelligence/python.slides.html#links",
    "title": "Python",
    "section": "Links",
    "text": "Links\nIf you came from C (i.e. are a joint computer science student), and were super interested in Python’s internals, maybe you’d be interested in this How variables work in Python video."
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html",
    "href": "Lecture-1-Artificial-Intelligence/python.html",
    "title": "Python",
    "section": "",
    "text": "Free book Automate the Boring Stuff with Python\n\n\n\nIt is general purpose language\nPython powers:\n\nInstagram\nSpotify\nNetflix\nUber\nReddit…\n\nPython is on Mars.\n\n\n\nSources: Blog post and Github.\n\n\n\n\n\n\n\nPython is 3rd most popular language\nPython is the most wanted language\nIn ‘Other frameworks and libraries’, they note that “several data science libraries for Python make strong showings”.\n\n\n\n\n\nPopular languages.\n\n\n\n\n\n\n\n\n\n\nTop languages over the years\n\n\n\nSource: Kaggle (2021), State of Machine Learning and Data Science.\n\n\n\n\n\n…[T]he entire machine learning and data science industry has been dominated by these two approaches: deep learning and gradient boosted trees… Users of gradient boosted trees tend to use Scikit-learn, XGBoost, or LightGBM. Meanwhile, most practitioners of deep learning use Keras, often in combination with its parent framework TensorFlow. The common point of these tools is they’re all Python libraries: Python is by far the most widely used language for machine learning and data science.\n\n\nSource: François Chollet (2021), Deep Learning with Python, Second Edition, Section 1.2.7.\n\n\n\n\n\n\nIn R you can run:\npchisq(3, 10)\n\nIn Python it is\nfrom scipy import stats\nstats.chi2(10).cdf(3)\n\n\n\n\n\nIn Leganto\n\n\n\n\n\n\n\n\nAn example notebook in Google Colaboratory.\n\n\nhttp://colab.research.google.com",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#about-python",
    "href": "Lecture-1-Artificial-Intelligence/python.html#about-python",
    "title": "Python",
    "section": "",
    "text": "Free book Automate the Boring Stuff with Python\n\n\n\nIt is general purpose language\nPython powers:\n\nInstagram\nSpotify\nNetflix\nUber\nReddit…\n\nPython is on Mars.\n\n\n\nSources: Blog post and Github.",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#stack-overflow-2021-dev.-survey",
    "href": "Lecture-1-Artificial-Intelligence/python.html#stack-overflow-2021-dev.-survey",
    "title": "Python",
    "section": "",
    "text": "Python is 3rd most popular language\nPython is the most wanted language\nIn ‘Other frameworks and libraries’, they note that “several data science libraries for Python make strong showings”.\n\n\n\n\n\nPopular languages.",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#githubs-2021-state-of-the-octoverse",
    "href": "Lecture-1-Artificial-Intelligence/python.html#githubs-2021-state-of-the-octoverse",
    "title": "Python",
    "section": "",
    "text": "Top languages over the years\n\n\n\nSource: Kaggle (2021), State of Machine Learning and Data Science.",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#python-and-machine-learning",
    "href": "Lecture-1-Artificial-Intelligence/python.html#python-and-machine-learning",
    "title": "Python",
    "section": "",
    "text": "…[T]he entire machine learning and data science industry has been dominated by these two approaches: deep learning and gradient boosted trees… Users of gradient boosted trees tend to use Scikit-learn, XGBoost, or LightGBM. Meanwhile, most practitioners of deep learning use Keras, often in combination with its parent framework TensorFlow. The common point of these tools is they’re all Python libraries: Python is by far the most widely used language for machine learning and data science.\n\n\nSource: François Chollet (2021), Deep Learning with Python, Second Edition, Section 1.2.7.",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#python-for-data-science",
    "href": "Lecture-1-Artificial-Intelligence/python.html#python-for-data-science",
    "title": "Python",
    "section": "",
    "text": "In R you can run:\npchisq(3, 10)\n\nIn Python it is\nfrom scipy import stats\nstats.chi2(10).cdf(3)\n\n\n\n\n\nIn Leganto",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#google-colaboratory",
    "href": "Lecture-1-Artificial-Intelligence/python.html#google-colaboratory",
    "title": "Python",
    "section": "",
    "text": "An example notebook in Google Colaboratory.\n\n\nhttp://colab.research.google.com",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#variables-and-basic-types",
    "href": "Lecture-1-Artificial-Intelligence/python.html#variables-and-basic-types",
    "title": "Python",
    "section": "Variables and basic types",
    "text": "Variables and basic types\n\n\n\n1 + 2\n\n3\n\n\n\nx = 1\nx + 2.0\n\n3.0\n\n\n\ntype(2.0)\n\nfloat\n\n\n\ntype(1), type(x)\n\n(int, int)\n\n\n\n\ndoes_math_work = 1 + 1 == 2\nprint(does_math_work)\ntype(does_math_work)\n\nTrue\n\n\nbool\n\n\n\ncontradiction = 1 != 1\ncontradiction\n\nFalse",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#shorthand-assignments",
    "href": "Lecture-1-Artificial-Intelligence/python.html#shorthand-assignments",
    "title": "Python",
    "section": "Shorthand assignments",
    "text": "Shorthand assignments\nIf we want to add 2 to a variable x:\n\n\n\nx = 1\nx = x + 2\nx\n\n3\n\n\n\n\nx = 1\nx += 2\nx\n\n3\n\n\n\n\nSame for:\n\nx -= 2 : take 2 from the current value of x ,\nx *= 2 : double the current value of x,\nx /= 2 : halve the current value of x.",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#strings",
    "href": "Lecture-1-Artificial-Intelligence/python.html#strings",
    "title": "Python",
    "section": "Strings",
    "text": "Strings\n\nname = \"Patrick\"\nsurname = 'Laub'\n\n\ncoffee = \"This is Patrick's coffee\"\nquote = 'And then he said \"I need a coffee!\"'\n\n\nname + surname\n\n'PatrickLaub'\n\n\n\ngreeting = f\"Hello {name} {surname}\"\ngreeting\n\n'Hello Patrick Laub'\n\n\n\n\"Patrick\" in greeting\n\nTrue",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#and-or",
    "href": "Lecture-1-Artificial-Intelligence/python.html#and-or",
    "title": "Python",
    "section": "and & or",
    "text": "and & or\n\nname = \"Patrick\"\nsurname = \"Laub\"\nname.istitle() and surname.istitle()\n\nTrue\n\n\n\nfull_name = \"Dr Patrick Laub\"\nfull_name.startswith(\"Dr \") or full_name.endswith(\" PhD\")\n\nTrue\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe dot is used denote methods, it can’t be used inside a variable name.\n\ni.am.an.unfortunate.R.users = True\n\nNameError: name 'i' is not defined",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#help-to-get-more-details",
    "href": "Lecture-1-Artificial-Intelligence/python.html#help-to-get-more-details",
    "title": "Python",
    "section": "help to get more details",
    "text": "help to get more details\n\nhelp(name.istitle)\n\nHelp on built-in function istitle:\n\nistitle() method of builtins.str instance\n    Return True if the string is a title-cased string, False otherwise.\n    \n    In a title-cased string, upper- and title-case characters may only\n    follow uncased characters and lowercase characters only cased ones.",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#f-strings",
    "href": "Lecture-1-Artificial-Intelligence/python.html#f-strings",
    "title": "Python",
    "section": "f-strings",
    "text": "f-strings\n\nprint(f\"Five squared is {5*5} and five cubed is {5**3}\")\nprint(\"Five squared is {5*5} and five cubed is {5**3}\")\n\nFive squared is 25 and five cubed is 125\nFive squared is {5*5} and five cubed is {5**3}\n\n\n\nUse f-strings and avoid the older alternatives:\n\nprint(f\"Hello {name} {surname}\")\nprint(\"Hello \" + name + \" \" + surname)\nprint(\"Hello {} {}\".format(name, surname))\nprint(\"Hello %s %s\" % (name, surname))\n\nHello Patrick Laub\nHello Patrick Laub\nHello Patrick Laub\nHello Patrick Laub",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#converting-types",
    "href": "Lecture-1-Artificial-Intelligence/python.html#converting-types",
    "title": "Python",
    "section": "Converting types",
    "text": "Converting types\n\ndigit = 3\ndigit\n\n3\n\n\n\ntype(digit)\n\nint\n\n\n\nnum = float(digit)\nnum\n\n3.0\n\n\n\ntype(num)\n\nfloat\n\n\n\nnum_str = str(num)\nnum_str\n\n'3.0'",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#quiz",
    "href": "Lecture-1-Artificial-Intelligence/python.html#quiz",
    "title": "Python",
    "section": "Quiz",
    "text": "Quiz\nWhat is the output of:\n\nx = 1\ny = 1.0\nprint(f\"{x == y} and {type(x) == type(y)}\")\n\n\n\n\nTrue and False\n\n\n\n\nWhat would you add before line 3 to get “True and True”?\n\n\n\nx = 1\ny = 1.0\nx = float(x)  # or y = int(y)\nprint(f\"{x == y} and {type(x) == type(y)}\")\n\nTrue and True",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#lists",
    "href": "Lecture-1-Artificial-Intelligence/python.html#lists",
    "title": "Python",
    "section": "Lists",
    "text": "Lists\n\ndesires = [\"Coffee\", \"Cake\", \"Sleep\"]\ndesires\n\n['Coffee', 'Cake', 'Sleep']\n\n\n\nlen(desires)\n\n3\n\n\n\ndesires[0]\n\n'Coffee'\n\n\n\ndesires[-1]\n\n'Sleep'\n\n\n\ndesires[2] = \"Nap\"\ndesires\n\n['Coffee', 'Cake', 'Nap']",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#slicing-lists",
    "href": "Lecture-1-Artificial-Intelligence/python.html#slicing-lists",
    "title": "Python",
    "section": "Slicing lists",
    "text": "Slicing lists\n\nprint([0, 1, 2])\ndesires\n\n[0, 1, 2]\n\n\n['Coffee', 'Cake', 'Nap']\n\n\n\ndesires[0:2]\n\n['Coffee', 'Cake']\n\n\n\ndesires[0:1]\n\n['Coffee']\n\n\n\ndesires[:2]\n\n['Coffee', 'Cake']",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#a-common-indexing-error",
    "href": "Lecture-1-Artificial-Intelligence/python.html#a-common-indexing-error",
    "title": "Python",
    "section": "A common indexing error",
    "text": "A common indexing error\n\ndesires[1.0]\n\nTypeError: list indices must be integers or slices, not float\n\n\n\ndesires[: len(desires) / 2]\n\nTypeError: slice indices must be integers or None or have an __index__ method\n\n\n\nlen(desires) / 2, len(desires) // 2\n\n(1.5, 1)\n\n\n\ndesires[: len(desires) // 2]\n\n['Coffee']",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#editing-lists",
    "href": "Lecture-1-Artificial-Intelligence/python.html#editing-lists",
    "title": "Python",
    "section": "Editing lists",
    "text": "Editing lists\n\ndesires = [\"Coffee\", \"Cake\", \"Sleep\"]\ndesires.append(\"Gadget\")\ndesires\n\n['Coffee', 'Cake', 'Sleep', 'Gadget']\n\n\n\ndesires.pop()\n\n'Gadget'\n\n\n\ndesires\n\n['Coffee', 'Cake', 'Sleep']\n\n\n\ndesires.sort()\ndesires\n\n['Cake', 'Coffee', 'Sleep']\n\n\n\ndesires[3] = \"Croissant\"\n\nIndexError: list assignment index out of range",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#none",
    "href": "Lecture-1-Artificial-Intelligence/python.html#none",
    "title": "Python",
    "section": "None",
    "text": "None\n\ndesires = [\"Coffee\", \"Cake\", \"Sleep\", \"Gadget\"]\nsorted_list = desires.sort()\nsorted_list\n\n\ntype(sorted_list)\n\nNoneType\n\n\n\nsorted_list is None\n\nTrue\n\n\n\nbool(sorted_list)\n\nFalse\n\n\n\ndesires = [\"Coffee\", \"Cake\", \"Sleep\", \"Gadget\"]\nsorted_list = sorted(desires)\nprint(desires)\nsorted_list\n\n['Coffee', 'Cake', 'Sleep', 'Gadget']\n\n\n['Cake', 'Coffee', 'Gadget', 'Sleep']",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#tuples-immutable-lists",
    "href": "Lecture-1-Artificial-Intelligence/python.html#tuples-immutable-lists",
    "title": "Python",
    "section": "Tuples (‘immutable’ lists)",
    "text": "Tuples (‘immutable’ lists)\n\nweather = (\"Sunny\", \"Cloudy\", \"Rainy\")\nprint(type(weather))\nprint(len(weather))\nprint(weather[-1])\n\n&lt;class 'tuple'&gt;\n3\nRainy\n\n\n\nweather.append(\"Snowy\")\n\nAttributeError: 'tuple' object has no attribute 'append'\n\n\n\nweather[2] = \"Snowy\"\n\nTypeError: 'tuple' object does not support item assignment",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#one-length-tuples",
    "href": "Lecture-1-Artificial-Intelligence/python.html#one-length-tuples",
    "title": "Python",
    "section": "One-length tuples",
    "text": "One-length tuples\n\nusing_brackets_in_math = (2 + 4) * 3\nusing_brackets_to_simplify = (1 + 1 == 2)\n\n\nfailure_of_atuple = (\"Snowy\")\ntype(failure_of_atuple)\n\nstr\n\n\n\nhappy_solo_tuple = (\"Snowy\",)\ntype(happy_solo_tuple)\n\ntuple\n\n\n\ncheeky_solo_list = [\"Snowy\"]\ntype(cheeky_solo_list)\n\nlist",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#dictionaries",
    "href": "Lecture-1-Artificial-Intelligence/python.html#dictionaries",
    "title": "Python",
    "section": "Dictionaries",
    "text": "Dictionaries\n\nphone_book = {\"Patrick\": \"+61 1234\", \"Café\": \"(02) 5678\"}\nphone_book[\"Patrick\"]\n\n'+61 1234'\n\n\n\nphone_book[\"Café\"] = \"+61400 000 000\"\nphone_book\n\n{'Patrick': '+61 1234', 'Café': '+61400 000 000'}\n\n\n\nphone_book.keys()\n\ndict_keys(['Patrick', 'Café'])\n\n\n\nphone_book.values()\n\ndict_values(['+61 1234', '+61400 000 000'])\n\n\n\nfactorial = {0: 1, 1: 1, 2: 2, 3: 6, 4: 24, 5: 120, 6: 720, 7: 5040}\nfactorial[4]\n\n24",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#quiz-1",
    "href": "Lecture-1-Artificial-Intelligence/python.html#quiz-1",
    "title": "Python",
    "section": "Quiz",
    "text": "Quiz\n\nanimals = [\"dog\", \"cat\", \"bird\"]\nanimals.append(\"teddy bear\")\nanimals.pop()\nanimals.pop()\nanimals.append(\"koala\")\nanimals.append(\"kangaroo\")\nprint(f\"{len(animals)} and {len(animals[-2])}\")\n\n\n\n\n4 and 5",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#if-and-else",
    "href": "Lecture-1-Artificial-Intelligence/python.html#if-and-else",
    "title": "Python",
    "section": "if and else",
    "text": "if and else\n\nage = 50\n\n\nif age &gt;= 30:\n    print(\"Gosh you're old\")\n\nGosh you're old\n\n\n\nif age &gt;= 30:\n    print(\"Gosh you're old\")\nelse:\n    print(\"You're still young\")\n\nGosh you're old",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#the-weird-part-about-python",
    "href": "Lecture-1-Artificial-Intelligence/python.html#the-weird-part-about-python",
    "title": "Python",
    "section": "The weird part about Python…",
    "text": "The weird part about Python…\n\nif age &gt;= 30:\n    print(\"Gosh you're old\")\nelse:\nprint(\"You're still young\")\n\nIndentationError: expected an indented block after 'else' statement on line 3 (2212277638.py, line 4)\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWatch out for mixing tabs and spaces!",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#an-example-of-aging",
    "href": "Lecture-1-Artificial-Intelligence/python.html#an-example-of-aging",
    "title": "Python",
    "section": "An example of aging",
    "text": "An example of aging\n\nage = 16\n\nif age &lt; 18:\n    friday_evening_schedule = \"School things\"\nif age &lt; 30:\n    friday_evening_schedule = \"Party 🥳🍾\"\nif age &gt;= 30:\n    friday_evening_schedule = \"Work\"\n\n\n\nprint(friday_evening_schedule)\n\nParty 🥳🍾",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#using-elif",
    "href": "Lecture-1-Artificial-Intelligence/python.html#using-elif",
    "title": "Python",
    "section": "Using elif",
    "text": "Using elif\n\nage = 16\n\nif age &lt; 18:\n    friday_evening_schedule = \"School things\"\nelif age &lt; 30:\n    friday_evening_schedule = \"Party 🥳🍾\"\nelse:\n    friday_evening_schedule = \"Work\"\n\nprint(friday_evening_schedule)\n\nSchool things",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#for-loops",
    "href": "Lecture-1-Artificial-Intelligence/python.html#for-loops",
    "title": "Python",
    "section": "for Loops",
    "text": "for Loops\n\ndesires = [\"coffee\", \"cake\", \"sleep\"]\nfor desire in desires:\n    print(f\"Patrick really wants a {desire}.\")\n\nPatrick really wants a coffee.\nPatrick really wants a cake.\nPatrick really wants a sleep.\n\n\n\n\n\nfor i in range(3):\n    print(i)\n\n0\n1\n2\n\n\n\nfor i in range(3, 6):\n    print(i)\n\n3\n4\n5\n\n\n\n\nrange(5)\n\nrange(0, 5)\n\n\n\ntype(range(5))\n\nrange\n\n\n\nlist(range(5))\n\n[0, 1, 2, 3, 4]",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#advanced-for-loops",
    "href": "Lecture-1-Artificial-Intelligence/python.html#advanced-for-loops",
    "title": "Python",
    "section": "Advanced for loops",
    "text": "Advanced for loops\n\nfor i, desire in enumerate(desires):\n    print(f\"Patrick wants a {desire}, it is priority #{i+1}.\")\n\nPatrick wants a coffee, it is priority #1.\nPatrick wants a cake, it is priority #2.\nPatrick wants a sleep, it is priority #3.\n\n\n\ndesires = [\"coffee\", \"cake\", \"nap\"]\ntimes = [\"in the morning\", \"at lunch\", \"during a boring lecture\"]\n\nfor desire, time in zip(desires, times):\n    print(f\"Patrick enjoys a {desire} {time}.\")\n\nPatrick enjoys a coffee in the morning.\nPatrick enjoys a cake at lunch.\nPatrick enjoys a nap during a boring lecture.",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#list-comprehensions",
    "href": "Lecture-1-Artificial-Intelligence/python.html#list-comprehensions",
    "title": "Python",
    "section": "List comprehensions",
    "text": "List comprehensions\n\n[x**2 for x in range(10)]\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n\n\n[x**2 for x in range(10) if x % 2 == 0]\n\n[0, 4, 16, 36, 64]\n\n\nThey can get more complicated:\n\n[x*y for x in range(4) for y in range(4)]\n\n[0, 0, 0, 0, 0, 1, 2, 3, 0, 2, 4, 6, 0, 3, 6, 9]\n\n\n\n[[x*y for x in range(4)] for y in range(4)]\n\n[[0, 0, 0, 0], [0, 1, 2, 3], [0, 2, 4, 6], [0, 3, 6, 9]]\n\n\nbut I’d recommend just using for loops at that point.",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#while-loops",
    "href": "Lecture-1-Artificial-Intelligence/python.html#while-loops",
    "title": "Python",
    "section": "While Loops",
    "text": "While Loops\nSay that we want to simulate (X \\,\\mid\\, X \\ge 100) where X \\sim \\mathrm{Pareto}(1). Assuming we have simulate_pareto, a function to generate \\mathrm{Pareto}(1) variables:\n\nsamples = []\nwhile len(samples) &lt; 5:\n    x = simulate_pareto()\n    if x &gt;= 100:\n        samples.append(x)\n\nsamples\n\n[125.28600493316272,\n 186.04974709289712,\n 154.45723763510398,\n 101.08310878885993,\n 2852.8305399214996]",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#breaking-out-of-a-loop",
    "href": "Lecture-1-Artificial-Intelligence/python.html#breaking-out-of-a-loop",
    "title": "Python",
    "section": "Breaking out of a loop",
    "text": "Breaking out of a loop\n\nwhile True:\n    user_input = input(\"&gt;&gt; What would you like to do? \")\n\n    if user_input == \"order cake\":\n        print(\"Here's your cake! 🎂\")\n\n    elif user_input == \"order coffee\":\n        print(\"Here's your coffee! ☕️\")\n\n    elif user_input == \"quit\":\n        break\n\n\n\n&gt;&gt; What would you like to do? order cake\nHere's your cake! 🎂\n&gt;&gt; What would you like to do? order coffee\nHere's your coffee! ☕️\n&gt;&gt; What would you like to do? order cake\nHere's your cake! 🎂\n&gt;&gt; What would you like to do? quit",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#quiz-2",
    "href": "Lecture-1-Artificial-Intelligence/python.html#quiz-2",
    "title": "Python",
    "section": "Quiz",
    "text": "Quiz\nWhat does this print out?\n\nif 1 / 3 + 1 / 3 + 1 / 3 == 1:\n    if 2**3 == 6:\n        print(\"Math really works!\")\n    else:\n        print(\"Math sometimes works..\")\nelse:\n    print(\"Math doesn't work\")\n\n\n\n\nMath sometimes works..\n\n\n\nWhat does this print out?\n\ncount = 0\nfor i in range(1, 10):\n    count += i\n    if i &gt; 3:\n        break\nprint(count)\n\n\n\n\n10",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#debugging-the-quiz-code",
    "href": "Lecture-1-Artificial-Intelligence/python.html#debugging-the-quiz-code",
    "title": "Python",
    "section": "Debugging the quiz code",
    "text": "Debugging the quiz code\n\ncount = 0\nfor i in range(1, 10):\n    count += i\n    print(f\"After i={i} count={count}\")\n    if i &gt; 3:\n        break\n\nAfter i=1 count=1\nAfter i=2 count=3\nAfter i=3 count=6\nAfter i=4 count=10",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#making-a-function",
    "href": "Lecture-1-Artificial-Intelligence/python.html#making-a-function",
    "title": "Python",
    "section": "Making a function",
    "text": "Making a function\n\ndef add_one(x):\n    return x + 1\n\ndef greet_a_student(name):\n    print(f\"Hi {name}, welcome to the AI class!\")\n\n\nadd_one(10)\n\n11\n\n\n\ngreet_a_student(\"Josephine\")\n\nHi Josephine, welcome to the AI class!\n\n\n\ngreet_a_student(\"Joseph\")\n\nHi Joseph, welcome to the AI class!\n\n\n\nHere, name is a parameter and the value supplied is an argument.",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#default-arguments",
    "href": "Lecture-1-Artificial-Intelligence/python.html#default-arguments",
    "title": "Python",
    "section": "Default arguments",
    "text": "Default arguments\nAssuming we have simulate_standard_normal, a function to generate \\mathrm{Normal}(0, 1) variables:\n\ndef simulate_normal(mean=0, std=1):\n    return mean + std * simulate_standard_normal()\n\n\nsimulate_normal()  # same as 'simulate_normal(0, 1)'\n\n0.47143516373249306\n\n\n\nsimulate_normal(1_000)  # same as 'simulate_normal(1_000, 1)'\n\n998.8090243052935\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe’ll cover random numbers next week (using numpy).",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#use-explicit-parameter-name",
    "href": "Lecture-1-Artificial-Intelligence/python.html#use-explicit-parameter-name",
    "title": "Python",
    "section": "Use explicit parameter name",
    "text": "Use explicit parameter name\n\nsimulate_normal(mean=1_000)  # same as 'simulate_normal(1_000, 1)'\n\n1001.4327069684261\n\n\n\nsimulate_normal(std=1_000)  # same as 'simulate_normal(0, 1_000)'\n\n-312.6518960917129\n\n\n\nsimulate_normal(10, std=0.001)  # same as 'simulate_normal(10, 0.001)'\n\n9.999279411266635\n\n\n\nsimulate_normal(std=10, 1_000)\n\nSyntaxError: positional argument follows keyword argument (1723181129.py, line 1)",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#why-would-we-need-that",
    "href": "Lecture-1-Artificial-Intelligence/python.html#why-would-we-need-that",
    "title": "Python",
    "section": "Why would we need that?",
    "text": "Why would we need that?\nE.g. to fit a Keras model, we use the .fit method:\n\nmodel.fit(x=None, y=None, batch_size=None, epochs=1, verbose='auto',\n        callbacks=None, validation_split=0.0, validation_data=None,\n        shuffle=True, class_weight=None, sample_weight=None,\n        initial_epoch=0, steps_per_epoch=None, validation_steps=None,\n        validation_batch_size=None, validation_freq=1,\n        max_queue_size=10, workers=1, use_multiprocessing=False)\n\nSay we want all the defaults except changing use_multiprocessing=True:\n\nmodel.fit(None, None, None, 1, 'auto', None, 0.0, None, True, None,\n        None, 0, None, None, None, 1, 10, 1, True)\n\nbut it is much nicer to just have:\n\nmodel.fit(use_multiprocessing=True)",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#quiz-3",
    "href": "Lecture-1-Artificial-Intelligence/python.html#quiz-3",
    "title": "Python",
    "section": "Quiz",
    "text": "Quiz\nWhat does the following print out?\n\ndef get_half_of_list(numbers, first=True):\n    if first:\n        return numbers[: len(numbers) // 2]\n    else:\n        return numbers[len(numbers) // 2 :]\n\nnums = [1, 2, 3, 4, 5, 6]\nchunk = get_half_of_list(nums, False)\nsecond_chunk = get_half_of_list(chunk)\nprint(second_chunk)\n\n\n\n\n[4]\n\n\n\n\n\nf\"nums ~&gt; {nums[:len(nums)//2]} and {nums[len(nums)//2:]}\"\n\n'nums ~&gt; [1, 2, 3] and [4, 5, 6]'\n\n\n\nf\"chunk ~&gt; {chunk[:len(chunk)//2]} and {chunk[len(chunk)//2:]}\"\n\n'chunk ~&gt; [4] and [5, 6]'",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#multiple-return-values",
    "href": "Lecture-1-Artificial-Intelligence/python.html#multiple-return-values",
    "title": "Python",
    "section": "Multiple return values",
    "text": "Multiple return values\n\ndef limits(numbers):\n    return min(numbers), max(numbers)\n\nlimits([1, 2, 3, 4, 5])\n\n(1, 5)\n\n\n\ntype(limits([1, 2, 3, 4, 5]))\n\ntuple\n\n\n\nmin_num, max_num = limits([1, 2, 3, 4, 5])\nprint(f\"The numbers are between {min_num} and {max_num}.\")\n\nThe numbers are between 1 and 5.\n\n\n\n_, max_num = limits([1, 2, 3, 4, 5])\nprint(f\"The maximum is {max_num}.\")\n\nThe maximum is 5.\n\n\n\nprint(f\"The maximum is {limits([1, 2, 3, 4, 5])[1]}.\")\n\nThe maximum is 5.",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#tuple-unpacking",
    "href": "Lecture-1-Artificial-Intelligence/python.html#tuple-unpacking",
    "title": "Python",
    "section": "Tuple unpacking",
    "text": "Tuple unpacking\n\nlims = limits([1, 2, 3, 4, 5])\nsmallest_num = lims[0]\nlargest_num = lims[1]\nprint(f\"The numbers are between {smallest_num} and {largest_num}.\")\n\nThe numbers are between 1 and 5.\n\n\n\nsmallest_num, largest_num = limits([1, 2, 3, 4, 5])\nprint(f\"The numbers are between {smallest_num} and {largest_num}.\")\n\nThe numbers are between 1 and 5.\n\n\nThis doesn’t just work for functions with multiple return values:\n\nRESOLUTION = (1920, 1080)\nWIDTH, HEIGHT = RESOLUTION\nprint(f\"The resolution is {WIDTH} wide and {HEIGHT} tall.\")\n\nThe resolution is 1920 wide and 1080 tall.",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#short-circuiting",
    "href": "Lecture-1-Artificial-Intelligence/python.html#short-circuiting",
    "title": "Python",
    "section": "Short-circuiting",
    "text": "Short-circuiting\n\ndef is_positive(x):\n    print(\"Called is_positive\")\n    return x &gt; 0\n\ndef is_negative(x):\n    print(\"Called is_negative\")\n    return x &lt; 0\n\nx = 10\n\n\n\n\nx_is_positive = is_positive(x)\nx_is_positive\n\nCalled is_positive\n\n\nTrue\n\n\n\n\nx_is_negative = is_negative(x)\nx_is_negative\n\nCalled is_negative\n\n\nFalse\n\n\n\n\n\nx_not_zero = is_positive(x) or is_negative(x)\nx_not_zero\n\nCalled is_positive\n\n\nTrue",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#python-standard-library",
    "href": "Lecture-1-Artificial-Intelligence/python.html#python-standard-library",
    "title": "Python",
    "section": "Python standard library",
    "text": "Python standard library\n\nimport os\nimport time\n\n\ntime.sleep(0.1)\n\n\nos.getlogin()\n\n'plaub'\n\n\n\nos.getcwd()\n\n'/home/plaub/Dropbox/Lecturing/ACTL3143/DeepLearningForActuaries/Lecture-1-Artificial-Intelligence'",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#import-a-few-functions",
    "href": "Lecture-1-Artificial-Intelligence/python.html#import-a-few-functions",
    "title": "Python",
    "section": "Import a few functions",
    "text": "Import a few functions\n\nfrom os import getcwd, getlogin\nfrom time import sleep\n\n\nsleep(0.1)\n\n\ngetlogin()\n\n'plaub'\n\n\n\ngetcwd()\n\n'/home/plaub/Dropbox/Lecturing/ACTL3143/DeepLearningForActuaries/Lecture-1-Artificial-Intelligence'",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#timing-using-pure-python",
    "href": "Lecture-1-Artificial-Intelligence/python.html#timing-using-pure-python",
    "title": "Python",
    "section": "Timing using pure Python",
    "text": "Timing using pure Python\n\nfrom time import time\n\nstart_time = time()\n\ncounting = 0\nfor i in range(1_000_000):\n    counting += 1\n\nend_time = time()\n\nelapsed = end_time - start_time\nprint(f\"Elapsed time: {elapsed} secs\")\n\nElapsed time: 0.030005931854248047 secs",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#data-science-packages",
    "href": "Lecture-1-Artificial-Intelligence/python.html#data-science-packages",
    "title": "Python",
    "section": "Data science packages",
    "text": "Data science packages\n\n\n\nCommon data science packages\n\n\n\nSource: Learnbay.co, Python libraries for data analysis and modeling in Data science, Medium.",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#importing-using-as",
    "href": "Lecture-1-Artificial-Intelligence/python.html#importing-using-as",
    "title": "Python",
    "section": "Importing using as",
    "text": "Importing using as\n\n\n\nimport pandas\n\npandas.DataFrame(\n    {\n        \"x\": [1, 2, 3],\n        \"y\": [4, 5, 6],\n    }\n)\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n1\n4\n\n\n1\n2\n5\n\n\n2\n3\n6\n\n\n\n\n\n\n\n\n\nimport pandas as pd\n\npd.DataFrame(\n    {\n        \"x\": [1, 2, 3],\n        \"y\": [4, 5, 6],\n    }\n)\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n1\n4\n\n\n1\n2\n5\n\n\n2\n3\n6",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#importing-from-a-subdirectory",
    "href": "Lecture-1-Artificial-Intelligence/python.html#importing-from-a-subdirectory",
    "title": "Python",
    "section": "Importing from a subdirectory",
    "text": "Importing from a subdirectory\nWant keras.models.Sequential().\n\nimport keras \n\nmodel = keras.models.Sequential()\n\nAlternatives using from:\n\nfrom keras import models\n\nmodel = models.Sequential()\n\n\nfrom keras.models import Sequential\n\nmodel = Sequential()",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#anonymous-lambda-functions",
    "href": "Lecture-1-Artificial-Intelligence/python.html#anonymous-lambda-functions",
    "title": "Python",
    "section": "Anonymous ‘lambda’ functions",
    "text": "Anonymous ‘lambda’ functions\nExample: how to sort strings by their second letter?\n\nnames = [\"Josephine\", \"Patrick\", \"Bert\"]\n\nIf you try help(sorted) you’ll find the key parameter.\n\nfor name in names:\n    print(f\"The length of '{name}' is {len(name)}.\")\n\nThe length of 'Josephine' is 9.\nThe length of 'Patrick' is 7.\nThe length of 'Bert' is 4.\n\n\n\nsorted(names, key=len)\n\n['Bert', 'Patrick', 'Josephine']",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#anonymous-lambda-functions-1",
    "href": "Lecture-1-Artificial-Intelligence/python.html#anonymous-lambda-functions-1",
    "title": "Python",
    "section": "Anonymous ‘lambda’ functions",
    "text": "Anonymous ‘lambda’ functions\nExample: how to sort strings by their second letter?\n\nnames = [\"Josephine\", \"Patrick\", \"Bert\"]\n\nIf you try help(sorted) you’ll find the key parameter.\n\ndef second_letter(name):\n    return name[1]\n\n\nfor name in names:\n    print(f\"The second letter of '{name}' is '{second_letter(name)}'.\")\n\nThe second letter of 'Josephine' is 'o'.\nThe second letter of 'Patrick' is 'a'.\nThe second letter of 'Bert' is 'e'.\n\n\n\nsorted(names, key=second_letter)\n\n['Patrick', 'Bert', 'Josephine']",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#anonymous-lambda-functions-2",
    "href": "Lecture-1-Artificial-Intelligence/python.html#anonymous-lambda-functions-2",
    "title": "Python",
    "section": "Anonymous ‘lambda’ functions",
    "text": "Anonymous ‘lambda’ functions\nExample: how to sort strings by their second letter?\n\nnames = [\"Josephine\", \"Patrick\", \"Bert\"]\n\nIf you try help(sorted) you’ll find the key parameter.\n\nsorted(names, key=lambda name: name[1])\n\n['Patrick', 'Bert', 'Josephine']\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nDon’t use lambda as a variable name! You commonly see lambd or lambda_ or λ.",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#with-keyword",
    "href": "Lecture-1-Artificial-Intelligence/python.html#with-keyword",
    "title": "Python",
    "section": "with keyword",
    "text": "with keyword\nExample, opening a file:\n\n\nMost basic way is:\n\nf = open(\"haiku1.txt\", \"r\")\nprint(f.read())\nf.close()\n\nChaos reigns within.\nReflect, repent, and reboot.\nOrder shall return.\n\n\n\nInstead, use:\n\nwith open(\"haiku2.txt\", \"r\") as f:\n    print(f.read())\n\nThe Web site you seek\nCannot be located, but\nCountless more exist.\n\n\n\n\n\nHaikus from http://www.libertybasicuniversity.com/lbnews/nl107/haiku.htm",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-1-Artificial-Intelligence/python.html#links",
    "href": "Lecture-1-Artificial-Intelligence/python.html#links",
    "title": "Python",
    "section": "Links",
    "text": "Links\nIf you came from C (i.e. are a joint computer science student), and were super interested in Python’s internals, maybe you’d be interested in this How variables work in Python video.",
    "crumbs": [
      "Module 1",
      "Python"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.slides.html#a-complete-deep-learning-project",
    "href": "Lecture-2-Deep-Learning-Keras/project.slides.html#a-complete-deep-learning-project",
    "title": "Project Details",
    "section": "A complete deep learning project",
    "text": "A complete deep learning project\nIndividual project over the term. You will:\n\nspecify a supervised learning problem,\ncollect and clean the data,\nperform an exploratory data analysis (EDA),\ncreate a simple (non-deep learning) benchmark model,\nfit two different deep learning architectures,\nperform hyperparameter tuning,\nwrite a discussion of the results."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.slides.html#project-components",
    "href": "Lecture-2-Deep-Learning-Keras/project.slides.html#project-components",
    "title": "Project Details",
    "section": "Project components",
    "text": "Project components\nThe deliverables for the project will include:\n\ndraft due at noon on Friday in Week 5 (10%),\nrecorded presentation due at noon on Friday in Week 8 (15%),\nfinal report due at noon on Monday of Week 10 (15%)."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.slides.html#project-draft-10",
    "href": "Lecture-2-Deep-Learning-Keras/project.slides.html#project-draft-10",
    "title": "Project Details",
    "section": "Project draft (10%)",
    "text": "Project draft (10%)\nDraft should show that you have:\n\nspecified your supervised learning problem,\ncollected and cleaned the data,\nperformed a basic exploratory data analysis,\ncreate a simple (non-deep learning) benchmark model.\n\nUpload to Moodle by noon on Friday in Week 5, no late submissions."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.slides.html#presentation",
    "href": "Lecture-2-Deep-Learning-Keras/project.slides.html#presentation",
    "title": "Project Details",
    "section": "Presentation",
    "text": "Presentation\nCreate a 3–5 minute recording covering:\n\nthe problem you are investigating,\nthe source of the data,\nthe deep learning approaches you are using, and\npreliminary results you have (table of metrics).\n\nDeliverable: YouTube link (public or unlisted) to a special StoryWall page. Presentations will be “public” to the class.\nSuggestions: aim to be fully public and give peer feedback."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.slides.html#presentation-marking-scheme",
    "href": "Lecture-2-Deep-Learning-Keras/project.slides.html#presentation-marking-scheme",
    "title": "Project Details",
    "section": "Presentation marking scheme",
    "text": "Presentation marking scheme\n\nContent (6%): did you cover the four points on previous slide?\nStyle (6%): are your slides/figures professional and do they enhance the presentation?\nDelivery (3%): is the presentation interesting and within the time limit?\n\n\n\n\n\n\n\nTip\n\n\nIt is a critical skill to be able to condense a complicated project into a short pitch. The project report is where you will give us all the details."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.slides.html#presentation-tips",
    "href": "Lecture-2-Deep-Learning-Keras/project.slides.html#presentation-tips",
    "title": "Project Details",
    "section": "Presentation tips",
    "text": "Presentation tips\n\nEach project is different, you decide which parts to focus on.\nNot necessary to film yourself.\nNice to briefly show the data (look at my lecture slides for example).\nDon’t go overboard on EDA. Mention the most important 1–2 facts (if any!) about the data. E.g. imbalanced classes for classification.\nYou can avoid adding ‘UNSW’ & the course code."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.slides.html#report-requirements",
    "href": "Lecture-2-Deep-Learning-Keras/project.slides.html#report-requirements",
    "title": "Project Details",
    "section": "Report requirements",
    "text": "Report requirements\nYou are asked to cover the four requirements in the draft, and also:\n\nfit two different deep learning architectures,\nperform hyperparameter tuning,\nwrite a discussion of the results and any potential ethical concerns.\n\nDeliverable: Report (PDF file), Jupyter Notebook, and dataset (e.g. CSV or ZIP file). Submission not public, probably to Moodle."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.slides.html#report-marking-criteria",
    "href": "Lecture-2-Deep-Learning-Keras/project.slides.html#report-marking-criteria",
    "title": "Project Details",
    "section": "Report marking criteria",
    "text": "Report marking criteria\n\nContent (8%): did you cover the seven points in the ML workflow?\nStyle (5%): does your report look professional, are your plots/tables useful and unpixelated, do you have spelling or grammar errors, are you within the page limit, and is the text easy to read?\nCode (2%): is your code clean and well-commented, have useless cells been pruned, does it give errors when the “Run All” button is pressed?\n\nAvoid screenshots & code in the report."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.slides.html#some-comments-on-the-report",
    "href": "Lecture-2-Deep-Learning-Keras/project.slides.html#some-comments-on-the-report",
    "title": "Project Details",
    "section": "Some comments on the report",
    "text": "Some comments on the report\n\nFocus on deep learning: I’m most interested in seeing your ability to use and explain your neural networks. For example, your mastery of the Lee–Carter model is less important to demonstrate.\nHyperparameter tuning: The tuning is one significant change from the weekly StoryWall tasks. Add a table (for each neural network) showing (at least) two hyperparameters that you tuned.\nUse appendices: If you run out of space, use appendices which are not counted in the page limit. E.g., the less urgent parts of your EDA can go in here."
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.html",
    "href": "Lecture-2-Deep-Learning-Keras/project.html",
    "title": "Project Details",
    "section": "",
    "text": "Individual project over the term. You will:\n\nspecify a supervised learning problem,\ncollect and clean the data,\nperform an exploratory data analysis (EDA),\ncreate a simple (non-deep learning) benchmark model,\nfit two different deep learning architectures,\nperform hyperparameter tuning,\nwrite a discussion of the results.",
    "crumbs": [
      "Module 2",
      "Project Details"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.html#a-complete-deep-learning-project",
    "href": "Lecture-2-Deep-Learning-Keras/project.html#a-complete-deep-learning-project",
    "title": "Project Details",
    "section": "",
    "text": "Individual project over the term. You will:\n\nspecify a supervised learning problem,\ncollect and clean the data,\nperform an exploratory data analysis (EDA),\ncreate a simple (non-deep learning) benchmark model,\nfit two different deep learning architectures,\nperform hyperparameter tuning,\nwrite a discussion of the results.",
    "crumbs": [
      "Module 2",
      "Project Details"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.html#project-components",
    "href": "Lecture-2-Deep-Learning-Keras/project.html#project-components",
    "title": "Project Details",
    "section": "Project components",
    "text": "Project components\nThe deliverables for the project will include:\n\ndraft due at noon on Friday in Week 5 (10%),\nrecorded presentation due at noon on Friday in Week 8 (15%),\nfinal report due at noon on Monday of Week 10 (15%).",
    "crumbs": [
      "Module 2",
      "Project Details"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.html#project-draft-10",
    "href": "Lecture-2-Deep-Learning-Keras/project.html#project-draft-10",
    "title": "Project Details",
    "section": "Project draft (10%)",
    "text": "Project draft (10%)\nDraft should show that you have:\n\nspecified your supervised learning problem,\ncollected and cleaned the data,\nperformed a basic exploratory data analysis,\ncreate a simple (non-deep learning) benchmark model.\n\nUpload to Moodle by noon on Friday in Week 5, no late submissions.",
    "crumbs": [
      "Module 2",
      "Project Details"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.html#presentation",
    "href": "Lecture-2-Deep-Learning-Keras/project.html#presentation",
    "title": "Project Details",
    "section": "Presentation",
    "text": "Presentation\nCreate a 3–5 minute recording covering:\n\nthe problem you are investigating,\nthe source of the data,\nthe deep learning approaches you are using, and\npreliminary results you have (table of metrics).\n\nDeliverable: YouTube link (public or unlisted) to a special StoryWall page. Presentations will be “public” to the class.\nSuggestions: aim to be fully public and give peer feedback.",
    "crumbs": [
      "Module 2",
      "Project Details"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.html#presentation-marking-scheme",
    "href": "Lecture-2-Deep-Learning-Keras/project.html#presentation-marking-scheme",
    "title": "Project Details",
    "section": "Presentation marking scheme",
    "text": "Presentation marking scheme\n\nContent (6%): did you cover the four points on previous slide?\nStyle (6%): are your slides/figures professional and do they enhance the presentation?\nDelivery (3%): is the presentation interesting and within the time limit?\n\n\n\n\n\n\n\nTip\n\n\n\nIt is a critical skill to be able to condense a complicated project into a short pitch. The project report is where you will give us all the details.",
    "crumbs": [
      "Module 2",
      "Project Details"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.html#presentation-tips",
    "href": "Lecture-2-Deep-Learning-Keras/project.html#presentation-tips",
    "title": "Project Details",
    "section": "Presentation tips",
    "text": "Presentation tips\n\nEach project is different, you decide which parts to focus on.\nNot necessary to film yourself.\nNice to briefly show the data (look at my lecture slides for example).\nDon’t go overboard on EDA. Mention the most important 1–2 facts (if any!) about the data. E.g. imbalanced classes for classification.\nYou can avoid adding ‘UNSW’ & the course code.",
    "crumbs": [
      "Module 2",
      "Project Details"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.html#report-requirements",
    "href": "Lecture-2-Deep-Learning-Keras/project.html#report-requirements",
    "title": "Project Details",
    "section": "Report requirements",
    "text": "Report requirements\nYou are asked to cover the four requirements in the draft, and also:\n\nfit two different deep learning architectures,\nperform hyperparameter tuning,\nwrite a discussion of the results and any potential ethical concerns.\n\nDeliverable: Report (PDF file), Jupyter Notebook, and dataset (e.g. CSV or ZIP file). Submission not public, probably to Moodle.",
    "crumbs": [
      "Module 2",
      "Project Details"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.html#report-marking-criteria",
    "href": "Lecture-2-Deep-Learning-Keras/project.html#report-marking-criteria",
    "title": "Project Details",
    "section": "Report marking criteria",
    "text": "Report marking criteria\n\nContent (8%): did you cover the seven points in the ML workflow?\nStyle (5%): does your report look professional, are your plots/tables useful and unpixelated, do you have spelling or grammar errors, are you within the page limit, and is the text easy to read?\nCode (2%): is your code clean and well-commented, have useless cells been pruned, does it give errors when the “Run All” button is pressed?\n\nAvoid screenshots & code in the report.",
    "crumbs": [
      "Module 2",
      "Project Details"
    ]
  },
  {
    "objectID": "Lecture-2-Deep-Learning-Keras/project.html#some-comments-on-the-report",
    "href": "Lecture-2-Deep-Learning-Keras/project.html#some-comments-on-the-report",
    "title": "Project Details",
    "section": "Some comments on the report",
    "text": "Some comments on the report\n\nFocus on deep learning: I’m most interested in seeing your ability to use and explain your neural networks. For example, your mastery of the Lee–Carter model is less important to demonstrate.\nHyperparameter tuning: The tuning is one significant change from the weekly StoryWall tasks. Add a table (for each neural network) showing (at least) two hyperparameters that you tuned.\nUse appendices: If you run out of space, use appendices which are not counted in the page limit. E.g., the less urgent parts of your EDA can go in here.",
    "crumbs": [
      "Module 2",
      "Project Details"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#load-packages",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#load-packages",
    "title": "Classification",
    "section": "Load packages",
    "text": "Load packages\n\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input\nfrom keras.callbacks import EarlyStopping\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn import set_config\n\nset_config(transform_output=\"pandas\")\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.0\nIPython version      : 8.20.0\n\nsklearn   : 1.4.0\nkeras     : 3.0.4\ntorch     : 2.2.0\ntensorflow: 2.15.0.post1"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#iris-dataset",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#iris-dataset",
    "title": "Classification",
    "section": "Iris dataset",
    "text": "Iris dataset\n\nfrom sklearn.datasets import load_iris\niris = load_iris()\nnames = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]\nfeatures = pd.DataFrame(iris.data, columns = names)\nfeatures\n\n\n\n\n\n\n\n\nSepalLength\nSepalWidth\nPetalLength\nPetalWidth\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\n\n\n1\n4.9\n3.0\n1.4\n0.2\n\n\n...\n...\n...\n...\n...\n\n\n148\n6.2\n3.4\n5.4\n2.3\n\n\n149\n5.9\n3.0\n5.1\n1.8\n\n\n\n\n150 rows × 4 columns"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#target-variable",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#target-variable",
    "title": "Classification",
    "section": "Target variable",
    "text": "Target variable\n\n\n\niris.target_names\n\narray(['setosa', 'versicolor', 'virginica'], dtype='&lt;U10')\n\n\n\niris.target[:8]\n\narray([0, 0, 0, 0, 0, 0, 0, 0])\n\n\n\ntarget = iris.target\ntarget = target.reshape(-1, 1)\ntarget[:8]\n\narray([[0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0]])\n\n\n\n\nclasses, counts = np.unique(\n        target,\n        return_counts=True\n)\nprint(classes)\nprint(counts)\n\n[0 1 2]\n[50 50 50]\n\n\n\niris.target_names[\n  target[[0, 30, 60]]\n]\n\narray([['setosa'],\n       ['setosa'],\n       ['versicolor']], dtype='&lt;U10')"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#split-the-data-into-train-and-test",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#split-the-data-into-train-and-test",
    "title": "Classification",
    "section": "Split the data into train and test",
    "text": "Split the data into train and test\n\nX_train, X_test, y_train, y_test = train_test_split(features, target, random_state=24)\nX_train\n\n\n\n\n\n\n\n\nSepalLength\nSepalWidth\nPetalLength\nPetalWidth\n\n\n\n\n53\n5.5\n2.3\n4.0\n1.3\n\n\n58\n6.6\n2.9\n4.6\n1.3\n\n\n95\n5.7\n3.0\n4.2\n1.2\n\n\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\n\n\n87\n6.3\n2.3\n4.4\n1.3\n\n\n131\n7.9\n3.8\n6.4\n2.0\n\n\n\n\n112 rows × 4 columns\n\n\n\n\nX_test.shape, y_test.shape\n\n((38, 4), (38, 1))"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#a-basic-classifier-network",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#a-basic-classifier-network",
    "title": "Classification",
    "section": "A basic classifier network",
    "text": "A basic classifier network\n\nA basic network for classifying into three categories.\nSource: Marcus Lautier (2022)."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#create-a-classifier-model",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#create-a-classifier-model",
    "title": "Classification",
    "section": "Create a classifier model",
    "text": "Create a classifier model\n\nNUM_FEATURES = len(features.columns)\nNUM_CATS = len(np.unique(target))\n\nprint(\"Number of features:\", NUM_FEATURES)\nprint(\"Number of categories:\", NUM_CATS)\n\nNumber of features: 4\nNumber of categories: 3\n\n\nMake a function to return a Keras model:\n\ndef build_model(seed=42):\n    random.seed(seed)\n    return Sequential([\n        Dense(30, activation=\"relu\"),\n        Dense(NUM_CATS, activation=\"softmax\")\n    ])"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#fit-the-model",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#fit-the-model",
    "title": "Classification",
    "section": "Fit the model",
    "text": "Fit the model\n\nmodel = build_model()\nmodel.compile(\"adam\", \"sparse_categorical_crossentropy\")\n\nmodel.fit(X_train, y_train, epochs=5, verbose=2);\n\nEpoch 1/5\n4/4 - 0s - 2ms/step - loss: 1.3886\nEpoch 2/5\n4/4 - 0s - 2ms/step - loss: 1.2849\nEpoch 3/5\n4/4 - 0s - 2ms/step - loss: 1.2266\nEpoch 4/5\n4/4 - 0s - 2ms/step - loss: 1.1645\nEpoch 5/5\n4/4 - 0s - 2ms/step - loss: 1.0954"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#track-accuracy-as-the-model-trains",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#track-accuracy-as-the-model-trains",
    "title": "Classification",
    "section": "Track accuracy as the model trains",
    "text": "Track accuracy as the model trains\n\nmodel = build_model()\nmodel.compile(\"adam\", \"sparse_categorical_crossentropy\", \\\n        metrics=[\"accuracy\"])\nmodel.fit(X_train, y_train, epochs=5, verbose=2);\n\nEpoch 1/5\n4/4 - 0s - 2ms/step - accuracy: 0.2857 - loss: 1.3655\nEpoch 2/5\n4/4 - 0s - 2ms/step - accuracy: 0.2857 - loss: 1.2959\nEpoch 3/5\n4/4 - 0s - 2ms/step - accuracy: 0.2857 - loss: 1.2011\nEpoch 4/5\n4/4 - 0s - 2ms/step - accuracy: 0.3036 - loss: 1.1415\nEpoch 5/5\n4/4 - 0s - 2ms/step - accuracy: 0.4286 - loss: 1.1115"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#run-a-long-fit",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#run-a-long-fit",
    "title": "Classification",
    "section": "Run a long fit",
    "text": "Run a long fit\n\nmodel = build_model()\nmodel.compile(\"adam\", \"sparse_categorical_crossentropy\", \\\n        metrics=[\"accuracy\"])\n%time hist = model.fit(X_train, y_train, epochs=500, \\\n        validation_split=0.25, verbose=False)\n\nCPU times: user 3.4 s, sys: 3.08 ms, total: 3.4 s\nWall time: 3.4 s\n\n\nEvaluation now returns both loss and accuracy.\n\nmodel.evaluate(X_test, y_test, verbose=False)\n\n[0.1766415387392044, 0.9736841917037964]"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#add-early-stopping",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#add-early-stopping",
    "title": "Classification",
    "section": "Add early stopping",
    "text": "Add early stopping\n\nmodel = build_model()\nmodel.compile(\"adam\", \"sparse_categorical_crossentropy\", \\\n        metrics=[\"accuracy\"])\n\nes = EarlyStopping(restore_best_weights=True, patience=50,\n        monitor=\"val_accuracy\")                                         \n%time hist_es = model.fit(X_train, y_train, epochs=500, \\\n        validation_split=0.25, callbacks=[es], verbose=False);\n\nprint(f\"Stopped after {len(hist_es.history['loss'])} epochs.\")\n\nCPU times: user 476 ms, sys: 1.99 ms, total: 478 ms\nWall time: 477 ms\nStopped after 68 epochs.\n\n\nEvaluation on test set:\n\nmodel.evaluate(X_test, y_test, verbose=False)\n\n[0.8394696712493896, 0.9473684430122375]"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#fitting-metrics",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#fitting-metrics",
    "title": "Classification",
    "section": "Fitting metrics",
    "text": "Fitting metrics"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#what-is-the-softmax-activation",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#what-is-the-softmax-activation",
    "title": "Classification",
    "section": "What is the softmax activation?",
    "text": "What is the softmax activation?\nIt creates a “probability” vector: \\text{Softmax}(\\boldsymbol{x}) = \\frac{\\mathrm{e}^x_i}{\\sum_j \\mathrm{e}^x_j} \\,.\nIn NumPy:\n\nout = np.array([5, -1, 6])\n(np.exp(out) / np.exp(out).sum()).round(3)\n\narray([0.269, 0.001, 0.731])\n\n\nIn Keras:\n\nout = keras.ops.convert_to_tensor([[5.0, -1.0, 6.0]])\nkeras.ops.round(keras.ops.softmax(out), 3)\n\ntensor([[0.2690, 0.0010, 0.7310]])"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#prediction-using-classifiers",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#prediction-using-classifiers",
    "title": "Classification",
    "section": "Prediction using classifiers",
    "text": "Prediction using classifiers\n\ny_test[:4]\n\narray([[2],\n       [2],\n       [1],\n       [1]])\n\n\n\ny_pred = model.predict(X_test.head(4), verbose=0)\ny_pred\n\narray([[0.1651735 , 0.41306472, 0.4217618 ],\n       [0.1688867 , 0.30969042, 0.52142286],\n       [0.27956602, 0.41347983, 0.30695412],\n       [0.24625233, 0.38838378, 0.36536384]], dtype=float32)\n\n\n\n# Add 'keepdims=True' to get a column vector.\nnp.argmax(y_pred, axis=1)\n\narray([2, 2, 1, 1])\n\n\n\niris.target_names[np.argmax(y_pred, axis=1)]\n\narray(['virginica', 'virginica', 'versicolor', 'versicolor'], dtype='&lt;U10')"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#cross-entropy-loss-eli5",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#cross-entropy-loss-eli5",
    "title": "Classification",
    "section": "Cross-entropy loss: ELI5",
    "text": "Cross-entropy loss: ELI5"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#why-use-cross-entropy-loss",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#why-use-cross-entropy-loss",
    "title": "Classification",
    "section": "Why use cross-entropy loss?",
    "text": "Why use cross-entropy loss?\n\np = np.linspace(0, 1, 100)\nplt.plot(p, (1-p)**2)\nplt.plot(p, -np.log(p))\nplt.legend([\"MSE\", \"Cross-entropy\"]);"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#one-hot-encoding",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#one-hot-encoding",
    "title": "Classification",
    "section": "One-hot encoding",
    "text": "One-hot encoding\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nenc = OneHotEncoder(sparse_output=False)\n\ny_train_oh = enc.fit_transform(y_train)\ny_test_oh = enc.transform(y_test)\n\n\n\n\ny_train[:5]\n\narray([[1],\n       [1],\n       [1],\n       [0],\n       [0]])\n\n\n\n\ny_train_oh[:5]\n\n\n\n\n\n\n\n\nx0_0\nx0_1\nx0_2\n\n\n\n\n0\n0.0\n1.0\n0.0\n\n\n1\n0.0\n1.0\n0.0\n\n\n2\n0.0\n1.0\n0.0\n\n\n3\n1.0\n0.0\n0.0\n\n\n4\n1.0\n0.0\n0.0"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#classifier-given-one-hot-outputs",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#classifier-given-one-hot-outputs",
    "title": "Classification",
    "section": "Classifier given one-hot outputs",
    "text": "Classifier given one-hot outputs\nCreate the model (new loss function):\n\nmodel = build_model()\nmodel.compile(\"adam\", \"categorical_crossentropy\", \\\n    metrics=[\"accuracy\"])\n\nFit the model (new target variables):\n\nmodel.fit(X_train, y_train_oh, epochs=100, verbose=False);\n\nEvaluate the model (new target variables):\n\nmodel.evaluate(X_test, y_test_oh, verbose=False)\n\n[0.3633193075656891, 0.9473684430122375]"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#the-data",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#the-data",
    "title": "Classification",
    "section": "The data",
    "text": "The data\nDataset source: Kaggle Stroke Prediction Dataset.\n\ndata = pd.read_csv(\"stroke.csv\")\ndata.head()\n\n\n\n\n\n\n\n\nid\ngender\nage\nhypertension\nheart_disease\never_married\nwork_type\nResidence_type\navg_glucose_level\nbmi\nsmoking_status\nstroke\n\n\n\n\n0\n9046\nMale\n67.0\n0\n1\nYes\nPrivate\nUrban\n228.69\n36.6\nformerly smoked\n1\n\n\n1\n51676\nFemale\n61.0\n0\n0\nYes\nSelf-employed\nRural\n202.21\nNaN\nnever smoked\n1\n\n\n2\n31112\nMale\n80.0\n0\n1\nYes\nPrivate\nRural\n105.92\n32.5\nnever smoked\n1\n\n\n3\n60182\nFemale\n49.0\n0\n0\nYes\nPrivate\nUrban\n171.23\n34.4\nsmokes\n1\n\n\n4\n1665\nFemale\n79.0\n1\n0\nYes\nSelf-employed\nRural\n174.12\n24.0\nnever smoked\n1"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#data-description",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#data-description",
    "title": "Classification",
    "section": "Data description",
    "text": "Data description\n\n\n\nid: unique identifier\ngender: “Male”, “Female” or “Other”\nage: age of the patient\nhypertension: 0 or 1 if the patient has hypertension\nheart_disease: 0 or 1 if the patient has any heart disease\never_married: “No” or “Yes”\nwork_type: “children”, “Govt_jov”, “Never_worked”, “Private” or “Self-employed”\n\n\n\nResidence_type: “Rural” or “Urban”\navg_glucose_level: average glucose level in blood\nbmi: body mass index\nsmoking_status: “formerly smoked”, “never smoked”, “smokes” or “Unknown”\nstroke: 0 or 1 if the patient had a stroke\n\n\n\n\nSource: Kaggle, Stroke Prediction Dataset."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#split-the-data",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#split-the-data",
    "title": "Classification",
    "section": "Split the data",
    "text": "Split the data\nFirst, look for missing values.\n\nnumber_missing = data.isna().sum()\nnumber_missing[number_missing &gt; 0]\n\nbmi    201\ndtype: int64\n\n\n\nfeatures = data.drop([\"id\", \"stroke\"], axis=1)\ntarget = data[\"stroke\"]\n\nX_main, X_test, y_main, y_test = train_test_split(\n    features, target, test_size=0.2, random_state=7)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_main, y_main, test_size=0.25, random_state=12)\n\nX_train.shape, X_val.shape, X_test.shape\n\n((3066, 10), (1022, 10), (1022, 10))"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#what-values-do-we-see-in-the-data",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#what-values-do-we-see-in-the-data",
    "title": "Classification",
    "section": "What values do we see in the data?",
    "text": "What values do we see in the data?\n\n\n\nX_train[\"gender\"].value_counts()\n\ngender\nFemale    1802\nMale      1264\nName: count, dtype: int64\n\n\n\nX_train[\"ever_married\"].value_counts()\n\never_married\nYes    2007\nNo     1059\nName: count, dtype: int64\n\n\n\nX_train[\"Residence_type\"].value_counts()\n\nResidence_type\nUrban    1536\nRural    1530\nName: count, dtype: int64\n\n\n\n\nX_train[\"work_type\"].value_counts()\n\nwork_type\nPrivate          1754\nSelf-employed     490\nchildren          419\nGovt_job          390\nNever_worked       13\nName: count, dtype: int64\n\n\n\nX_train[\"smoking_status\"].value_counts()\n\nsmoking_status\nnever smoked       1130\nUnknown             944\nformerly smoked     522\nsmokes              470\nName: count, dtype: int64"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#preprocess-columns-individually",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#preprocess-columns-individually",
    "title": "Classification",
    "section": "Preprocess columns individually",
    "text": "Preprocess columns individually\n\nTake categorical columns \\hookrightarrow one-hot vectors\nbinary columns \\hookrightarrow do nothing\ncontinuous columns \\hookrightarrow impute NaNs & standardise."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#scikit-learn-column-transformer",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#scikit-learn-column-transformer",
    "title": "Classification",
    "section": "Scikit-learn column transformer",
    "text": "Scikit-learn column transformer\n\nfrom sklearn.pipeline import make_pipeline\n\ncat_vars =  [\"gender\", \"ever_married\", \"Residence_type\",\n    \"work_type\", \"smoking_status\"]                  \n\nct = make_column_transformer(\n  (OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), cat_vars),\n  (\"passthrough\", [\"hypertension\", \"heart_disease\"]),\n  remainder=make_pipeline(SimpleImputer(), StandardScaler()),\n  verbose_feature_names_out=False\n)\n\nX_train_ct = ct.fit_transform(X_train)\nX_val_ct = ct.transform(X_val)\nX_test_ct = ct.transform(X_test)\n\nfor name, X in zip((\"train\", \"val\", \"test\"), (X_train_ct, X_val_ct, X_test_ct)):\n    num_na = X.isna().sum().sum()\n    print(f\"The {name} set has shape {X_train_ct.shape} & with {num_na} NAs.\")\n\nThe train set has shape (3066, 20) & with 0 NAs.\nThe val set has shape (3066, 20) & with 0 NAs.\nThe test set has shape (3066, 20) & with 0 NAs."
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#handling-unseen-categories",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#handling-unseen-categories",
    "title": "Classification",
    "section": "Handling unseen categories",
    "text": "Handling unseen categories\n\n\n\nX_train[\"gender\"].value_counts()\n\ngender\nFemale    1802\nMale      1264\nName: count, dtype: int64\n\n\n\n\nX_val[\"gender\"].value_counts()\n\ngender\nFemale    615\nMale      406\nOther       1\nName: count, dtype: int64\n\n\n\n\n\n\n\nind = np.argmax(X_val[\"gender\"] == \"Other\")\nX_val.iloc[ind-1:ind+3][[\"gender\"]]\n\n\n\n\n\n\n\n\ngender\n\n\n\n\n4970\nMale\n\n\n3116\nOther\n\n\n4140\nMale\n\n\n2505\nFemale\n\n\n\n\n\n\n\n\n\ngender_cols = X_val_ct[[\"gender_Female\", \"gender_Male\"]]\ngender_cols.iloc[ind-1:ind+3]\n\n\n\n\n\n\n\n\ngender_Female\ngender_Male\n\n\n\n\n4970\n0.0\n1.0\n\n\n3116\n0.0\n0.0\n\n\n4140\n0.0\n1.0\n\n\n2505\n1.0\n0.0"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#setup-a-binary-classification-model",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#setup-a-binary-classification-model",
    "title": "Classification",
    "section": "Setup a binary classification model",
    "text": "Setup a binary classification model\n\ndef create_model(seed=42):\n    random.seed(seed)\n    model = Sequential()\n    model.add(Input(X_train_ct.shape[1:]))\n    model.add(Dense(32, \"leaky_relu\"))\n    model.add(Dense(16, \"leaky_relu\"))\n    model.add(Dense(1, \"sigmoid\"))\n    return model\n\n\nmodel = create_model()\nmodel.summary()\n\nModel: \"sequential_5\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ dense_10 (Dense)                │ (None, 32)                │        672 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_11 (Dense)                │ (None, 16)                │        528 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_12 (Dense)                │ (None, 1)                 │         17 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 1,217 (4.75 KB)\n\n\n\n Trainable params: 1,217 (4.75 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#add-metrics-compile-and-fit",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#add-metrics-compile-and-fit",
    "title": "Classification",
    "section": "Add metrics, compile, and fit",
    "text": "Add metrics, compile, and fit\n\nmodel = create_model()\n\npr_auc = keras.metrics.AUC(curve=\"PR\", name=\"pr_auc\")\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",\n    metrics=[pr_auc, \"accuracy\", \"auc\"])                                \n\nes = EarlyStopping(patience=50, restore_best_weights=True,\n    monitor=\"val_pr_auc\", verbose=1)\nmodel.fit(X_train_ct, y_train, callbacks=[es], epochs=1_000, verbose=0,\n  validation_data=(X_val_ct, y_val));\n\nEpoch 69: early stopping\nRestoring model weights from the end of the best epoch: 19.\n\n\n\n\n\nmodel.evaluate(X_val_ct, y_val, verbose=0)\n\n[0.1452300250530243,\n 0.9589040875434875,\n 0.8276846408843994,\n 0.13280197978019714]"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#overweight-the-minority-class",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#overweight-the-minority-class",
    "title": "Classification",
    "section": "Overweight the minority class",
    "text": "Overweight the minority class\n\nmodel = create_model()\n\npr_auc = keras.metrics.AUC(curve=\"PR\", name=\"pr_auc\")\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",\n    metrics=[pr_auc, \"accuracy\", \"auc\"])\n\nes = EarlyStopping(patience=50, restore_best_weights=True,\n    monitor=\"val_pr_auc\", verbose=1)\nmodel.fit(X_train_ct, y_train, callbacks=[es], epochs=1_000, verbose=0,\n  validation_data=(X_val_ct, y_val), class_weight={0: 1, 1: 10});\n\nEpoch 56: early stopping\nRestoring model weights from the end of the best epoch: 6.\n\n\n\n\n\nmodel.evaluate(X_val_ct, y_val, verbose=0)\n\n[0.3797358572483063, 0.767123281955719, 0.8222789168357849, 0.1360630989074707]\n\n\n\n\n\nmodel.evaluate(X_test_ct, y_test, verbose=0)\n\n[0.3906365931034088,\n 0.7837573289871216,\n 0.8110082149505615,\n 0.15662002563476562]"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.slides.html#classification-metrics",
    "href": "Lecture-3-Tabular-Data/classification.slides.html#classification-metrics",
    "title": "Classification",
    "section": "Classification Metrics",
    "text": "Classification Metrics\n\nfrom sklearn.metrics import confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay\ny_pred = model.predict(X_test_ct, verbose=0)\n\n\n\n\nRocCurveDisplay.from_predictions(y_test, y_pred, name=\"\");\n\n\n\n\n\n\n\n\n\n\nPrecisionRecallDisplay.from_predictions(y_test, y_pred, name=\"\"); plt.legend(loc=\"upper right\");\n\n\n\n\n\n\n\n\n\n\n\n\n\ny_pred_stroke = y_pred &gt; 0.5\nconfusion_matrix(y_test, y_pred_stroke)\n\narray([[762, 210],\n       [ 11,  39]])\n\n\n\n\ny_pred_stroke = y_pred &gt; 0.3\nconfusion_matrix(y_test, y_pred_stroke)\n\narray([[629, 343],\n       [  6,  44]])"
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html",
    "href": "Lecture-3-Tabular-Data/classification.html",
    "title": "Classification",
    "section": "",
    "text": "import random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input\nfrom keras.callbacks import EarlyStopping\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn import set_config\n\nset_config(transform_output=\"pandas\")\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.0\nIPython version      : 8.20.0\n\nsklearn   : 1.4.0\nkeras     : 3.0.4\ntorch     : 2.2.0\ntensorflow: 2.15.0.post1",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#load-packages",
    "href": "Lecture-3-Tabular-Data/classification.html#load-packages",
    "title": "Classification",
    "section": "",
    "text": "import random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input\nfrom keras.callbacks import EarlyStopping\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn import set_config\n\nset_config(transform_output=\"pandas\")\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.0\nIPython version      : 8.20.0\n\nsklearn   : 1.4.0\nkeras     : 3.0.4\ntorch     : 2.2.0\ntensorflow: 2.15.0.post1",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#iris-dataset",
    "href": "Lecture-3-Tabular-Data/classification.html#iris-dataset",
    "title": "Classification",
    "section": "Iris dataset",
    "text": "Iris dataset\n\nfrom sklearn.datasets import load_iris\niris = load_iris()\nnames = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]\nfeatures = pd.DataFrame(iris.data, columns = names)\nfeatures\n\n\n\n\n\n\n\n\nSepalLength\nSepalWidth\nPetalLength\nPetalWidth\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\n\n\n1\n4.9\n3.0\n1.4\n0.2\n\n\n...\n...\n...\n...\n...\n\n\n148\n6.2\n3.4\n5.4\n2.3\n\n\n149\n5.9\n3.0\n5.1\n1.8\n\n\n\n\n150 rows × 4 columns",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#target-variable",
    "href": "Lecture-3-Tabular-Data/classification.html#target-variable",
    "title": "Classification",
    "section": "Target variable",
    "text": "Target variable\n\n\n\niris.target_names\n\narray(['setosa', 'versicolor', 'virginica'], dtype='&lt;U10')\n\n\n\niris.target[:8]\n\narray([0, 0, 0, 0, 0, 0, 0, 0])\n\n\n\ntarget = iris.target\ntarget = target.reshape(-1, 1)\ntarget[:8]\n\narray([[0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0]])\n\n\n\n\nclasses, counts = np.unique(\n        target,\n        return_counts=True\n)\nprint(classes)\nprint(counts)\n\n[0 1 2]\n[50 50 50]\n\n\n\niris.target_names[\n  target[[0, 30, 60]]\n]\n\narray([['setosa'],\n       ['setosa'],\n       ['versicolor']], dtype='&lt;U10')",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#split-the-data-into-train-and-test",
    "href": "Lecture-3-Tabular-Data/classification.html#split-the-data-into-train-and-test",
    "title": "Classification",
    "section": "Split the data into train and test",
    "text": "Split the data into train and test\n\nX_train, X_test, y_train, y_test = train_test_split(features, target, random_state=24)\nX_train\n\n\n\n\n\n\n\n\nSepalLength\nSepalWidth\nPetalLength\nPetalWidth\n\n\n\n\n53\n5.5\n2.3\n4.0\n1.3\n\n\n58\n6.6\n2.9\n4.6\n1.3\n\n\n95\n5.7\n3.0\n4.2\n1.2\n\n\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\n\n\n87\n6.3\n2.3\n4.4\n1.3\n\n\n131\n7.9\n3.8\n6.4\n2.0\n\n\n\n\n112 rows × 4 columns\n\n\n\n\nX_test.shape, y_test.shape\n\n((38, 4), (38, 1))",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#a-basic-classifier-network",
    "href": "Lecture-3-Tabular-Data/classification.html#a-basic-classifier-network",
    "title": "Classification",
    "section": "A basic classifier network",
    "text": "A basic classifier network\n\n\n\nA basic network for classifying into three categories.\n\n\n\nSource: Marcus Lautier (2022).\n\nSince the task is a classification problem, we use softmax activation function. The softmax function takes in the input and returns a probability vector, which tells us about the probability of a data point belonging to a certain class.",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#create-a-classifier-model",
    "href": "Lecture-3-Tabular-Data/classification.html#create-a-classifier-model",
    "title": "Classification",
    "section": "Create a classifier model",
    "text": "Create a classifier model\n\nNUM_FEATURES = len(features.columns)\nNUM_CATS = len(np.unique(target))\n\nprint(\"Number of features:\", NUM_FEATURES)\nprint(\"Number of categories:\", NUM_CATS)\n\nNumber of features: 4\nNumber of categories: 3\n\n\nMake a function to return a Keras model:\n\ndef build_model(seed=42):\n    random.seed(seed)\n    return Sequential([\n        Dense(30, activation=\"relu\"),\n        Dense(NUM_CATS, activation=\"softmax\")\n    ])",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#fit-the-model",
    "href": "Lecture-3-Tabular-Data/classification.html#fit-the-model",
    "title": "Classification",
    "section": "Fit the model",
    "text": "Fit the model\n\nmodel = build_model()\nmodel.compile(\"adam\", \"sparse_categorical_crossentropy\")\n\nmodel.fit(X_train, y_train, epochs=5, verbose=2);\n\nEpoch 1/5\n4/4 - 0s - 2ms/step - loss: 1.3886\nEpoch 2/5\n4/4 - 0s - 2ms/step - loss: 1.2849\nEpoch 3/5\n4/4 - 0s - 2ms/step - loss: 1.2266\nEpoch 4/5\n4/4 - 0s - 2ms/step - loss: 1.1645\nEpoch 5/5\n4/4 - 0s - 2ms/step - loss: 1.0954\n\n\nSince the problem at hand is a classification problem, we define the optimizer and loss function accordingly. Optimizer is adam and the loss function is sparse_categorical_crossentropy. If the response variable represents the category directly using an integer (i.e. if the response variable is not one-hot encoded), we must use sparse_categorical_crossentropy. If the response variable (y label) is already one-hot encoded we can use categorical_crossentropy.",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#track-accuracy-as-the-model-trains",
    "href": "Lecture-3-Tabular-Data/classification.html#track-accuracy-as-the-model-trains",
    "title": "Classification",
    "section": "Track accuracy as the model trains",
    "text": "Track accuracy as the model trains\n\nmodel = build_model()\nmodel.compile(\"adam\", \"sparse_categorical_crossentropy\", \\\n        metrics=[\"accuracy\"])\nmodel.fit(X_train, y_train, epochs=5, verbose=2);\n\nEpoch 1/5\n4/4 - 0s - 2ms/step - accuracy: 0.2857 - loss: 1.3655\nEpoch 2/5\n4/4 - 0s - 2ms/step - accuracy: 0.2857 - loss: 1.2959\nEpoch 3/5\n4/4 - 0s - 2ms/step - accuracy: 0.2857 - loss: 1.2011\nEpoch 4/5\n4/4 - 0s - 2ms/step - accuracy: 0.3036 - loss: 1.1415\nEpoch 5/5\n4/4 - 0s - 2ms/step - accuracy: 0.4286 - loss: 1.1115\n\n\nWe can also specify which loss metric to monitor in assessing the performance during the training. The metric that is usually used in classification tasks is accuracy, which tracks the fraction of all predictions which identified the class accurately. The metrics are not used for optimizing. They are only used to keep track of how well the model is performing during the optimization. By setting verbose=2, we are printing the progress during training, and we can see how the loss is reducing and accuracy is improving.",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#run-a-long-fit",
    "href": "Lecture-3-Tabular-Data/classification.html#run-a-long-fit",
    "title": "Classification",
    "section": "Run a long fit",
    "text": "Run a long fit\nRun the model training for 500 epochs.\n\nmodel = build_model()\nmodel.compile(\"adam\", \"sparse_categorical_crossentropy\", \\\n        metrics=[\"accuracy\"])\n%time hist = model.fit(X_train, y_train, epochs=500, \\\n        validation_split=0.25, verbose=False)\n\nCPU times: user 3.42 s, sys: 4.44 ms, total: 3.42 s\nWall time: 3.42 s\n\n\nEvaluation now returns both loss and accuracy.\n\nmodel.evaluate(X_test, y_test, verbose=False)\n\n[0.1766415387392044, 0.9736841917037964]",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#add-early-stopping",
    "href": "Lecture-3-Tabular-Data/classification.html#add-early-stopping",
    "title": "Classification",
    "section": "Add early stopping",
    "text": "Add early stopping\n\nmodel = build_model()\nmodel.compile(\"adam\", \"sparse_categorical_crossentropy\", \\\n        metrics=[\"accuracy\"])\n\nes = EarlyStopping(restore_best_weights=True, patience=50,\n        monitor=\"val_accuracy\")                                         \n%time hist_es = model.fit(X_train, y_train, epochs=500, \\\n        validation_split=0.25, callbacks=[es], verbose=False);\n\nprint(f\"Stopped after {len(hist_es.history['loss'])} epochs.\")\n\nCPU times: user 478 ms, sys: 0 ns, total: 478 ms\nWall time: 477 ms\nStopped after 68 epochs.\n\n\n\nDefines a new model with the same architecture as model_build which is already constructed\nCompiles the model with optimizer, loss function and metric\nDefines the early stopping object as usual, with one slight change. The code is specified to activate the early stopping by monitoring the validation accuracy (val_accuracy), not the loss.\nFits the model\n\nEvaluation on test set:\n\nmodel.evaluate(X_test, y_test, verbose=False)\n\n[0.8394696712493896, 0.9473684430122375]",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#fitting-metrics",
    "href": "Lecture-3-Tabular-Data/classification.html#fitting-metrics",
    "title": "Classification",
    "section": "Fitting metrics",
    "text": "Fitting metrics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeft hand side plots show how loss behaved without and with early stopping. Right hand side plots show how accuracy performed without and with early stopping.",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#what-is-the-softmax-activation",
    "href": "Lecture-3-Tabular-Data/classification.html#what-is-the-softmax-activation",
    "title": "Classification",
    "section": "What is the softmax activation?",
    "text": "What is the softmax activation?\nIt creates a “probability” vector: \\text{Softmax}(\\boldsymbol{x}) = \\frac{\\mathrm{e}^x_i}{\\sum_j \\mathrm{e}^x_j} \\,.\nIn NumPy:\n\nout = np.array([5, -1, 6])\n(np.exp(out) / np.exp(out).sum()).round(3)\n\narray([0.269, 0.001, 0.731])\n\n\nIn Keras:\n\nout = keras.ops.convert_to_tensor([[5.0, -1.0, 6.0]])\nkeras.ops.round(keras.ops.softmax(out), 3)\n\ntensor([[0.2690, 0.0010, 0.7310]])",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#prediction-using-classifiers",
    "href": "Lecture-3-Tabular-Data/classification.html#prediction-using-classifiers",
    "title": "Classification",
    "section": "Prediction using classifiers",
    "text": "Prediction using classifiers\n\ny_test[:4]\n\narray([[2],\n       [2],\n       [1],\n       [1]])\n\n\nThe response variable y is an array of numeric integers, each representing a class to which the data belongs. However, the model.predict() function returns an array with probabilities not an array with integers. The array displays the probabilities of belonging to each category.\n\ny_pred = model.predict(X_test.head(4), verbose=0)\ny_pred\n\narray([[0.1651735 , 0.41306472, 0.4217618 ],\n       [0.1688867 , 0.30969042, 0.52142286],\n       [0.27956602, 0.41347983, 0.30695412],\n       [0.24625233, 0.38838378, 0.36536384]], dtype=float32)\n\n\nUsing np.argmax() which returns index of the maximum value in an array, we can obtain the predicted class.\n\n# Add 'keepdims=True' to get a column vector.\nnp.argmax(y_pred, axis=1)\n\narray([2, 2, 1, 1])\n\n\n\niris.target_names[np.argmax(y_pred, axis=1)]\n\narray(['virginica', 'virginica', 'versicolor', 'versicolor'], dtype='&lt;U10')",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#cross-entropy-loss-eli5",
    "href": "Lecture-3-Tabular-Data/classification.html#cross-entropy-loss-eli5",
    "title": "Classification",
    "section": "Cross-entropy loss: ELI5",
    "text": "Cross-entropy loss: ELI5",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#why-use-cross-entropy-loss",
    "href": "Lecture-3-Tabular-Data/classification.html#why-use-cross-entropy-loss",
    "title": "Classification",
    "section": "Why use cross-entropy loss?",
    "text": "Why use cross-entropy loss?\n\np = np.linspace(0, 1, 100)\nplt.plot(p, (1-p)**2)\nplt.plot(p, -np.log(p))\nplt.legend([\"MSE\", \"Cross-entropy\"]);\n\n/tmp/ipykernel_252802/2228567616.py:3: RuntimeWarning: divide by zero encountered in log\n  plt.plot(p, -np.log(p))\n\n\n\n\n\n\n\n\n\nThe above plot shows how MSE and cross-entropy penalize wrong predictions. The x-axis indicates the severity of misclassification. Suppose the neural network predicted that there is near-zero probability of an observation being in class “1” when the actual class is “1”. This represents a strong misclassification. The above graph shows how MSE does not impose heavy penalties for the misclassifications near zero. It displays a linear increment across the severity of misclassification. On the other hand, cross-entropy penalises bad predictions strongly. Also, the misclassification penalty grows exponentially. This makes cross entropy more suitable.",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#one-hot-encoding",
    "href": "Lecture-3-Tabular-Data/classification.html#one-hot-encoding",
    "title": "Classification",
    "section": "One-hot encoding",
    "text": "One-hot encoding\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nenc = OneHotEncoder(sparse_output=False)\n\ny_train_oh = enc.fit_transform(y_train)\ny_test_oh = enc.transform(y_test)\n\n\n\n\ny_train[:5]\n\narray([[1],\n       [1],\n       [1],\n       [0],\n       [0]])\n\n\n\n\ny_train_oh[:5]\n\n\n\n\n\n\n\n\nx0_0\nx0_1\nx0_2\n\n\n\n\n0\n0.0\n1.0\n0.0\n\n\n1\n0.0\n1.0\n0.0\n\n\n2\n0.0\n1.0\n0.0\n\n\n3\n1.0\n0.0\n0.0\n\n\n4\n1.0\n0.0\n0.0",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#classifier-given-one-hot-outputs",
    "href": "Lecture-3-Tabular-Data/classification.html#classifier-given-one-hot-outputs",
    "title": "Classification",
    "section": "Classifier given one-hot outputs",
    "text": "Classifier given one-hot outputs\nCreate the model (new loss function):\n\nmodel = build_model()\nmodel.compile(\"adam\", \"categorical_crossentropy\", \\\n    metrics=[\"accuracy\"])\n\nFit the model (new target variables):\n\nmodel.fit(X_train, y_train_oh, epochs=100, verbose=False);\n\nEvaluate the model (new target variables):\n\nmodel.evaluate(X_test, y_test_oh, verbose=False)\n\n[0.3633193075656891, 0.9473684430122375]",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#the-data",
    "href": "Lecture-3-Tabular-Data/classification.html#the-data",
    "title": "Classification",
    "section": "The data",
    "text": "The data\nDataset source: Kaggle Stroke Prediction Dataset.\n\ndata = pd.read_csv(\"stroke.csv\")\ndata.head()\n\n\n\n\n\n\n\n\nid\ngender\nage\nhypertension\nheart_disease\never_married\nwork_type\nResidence_type\navg_glucose_level\nbmi\nsmoking_status\nstroke\n\n\n\n\n0\n9046\nMale\n67.0\n0\n1\nYes\nPrivate\nUrban\n228.69\n36.6\nformerly smoked\n1\n\n\n1\n51676\nFemale\n61.0\n0\n0\nYes\nSelf-employed\nRural\n202.21\nNaN\nnever smoked\n1\n\n\n2\n31112\nMale\n80.0\n0\n1\nYes\nPrivate\nRural\n105.92\n32.5\nnever smoked\n1\n\n\n3\n60182\nFemale\n49.0\n0\n0\nYes\nPrivate\nUrban\n171.23\n34.4\nsmokes\n1\n\n\n4\n1665\nFemale\n79.0\n1\n0\nYes\nSelf-employed\nRural\n174.12\n24.0\nnever smoked\n1",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#data-description",
    "href": "Lecture-3-Tabular-Data/classification.html#data-description",
    "title": "Classification",
    "section": "Data description",
    "text": "Data description\n\n\n\nid: unique identifier\ngender: “Male”, “Female” or “Other”\nage: age of the patient\nhypertension: 0 or 1 if the patient has hypertension\nheart_disease: 0 or 1 if the patient has any heart disease\never_married: “No” or “Yes”\nwork_type: “children”, “Govt_jov”, “Never_worked”, “Private” or “Self-employed”\n\n\n\nResidence_type: “Rural” or “Urban”\navg_glucose_level: average glucose level in blood\nbmi: body mass index\nsmoking_status: “formerly smoked”, “never smoked”, “smokes” or “Unknown”\nstroke: 0 or 1 if the patient had a stroke\n\n\n\n\nSource: Kaggle, Stroke Prediction Dataset.",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#split-the-data",
    "href": "Lecture-3-Tabular-Data/classification.html#split-the-data",
    "title": "Classification",
    "section": "Split the data",
    "text": "Split the data\nFirst, look for missing values.\n\nnumber_missing = data.isna().sum()\nnumber_missing[number_missing &gt; 0]\n\nbmi    201\ndtype: int64\n\n\n\nfeatures = data.drop([\"id\", \"stroke\"], axis=1)\ntarget = data[\"stroke\"]\n\nX_main, X_test, y_main, y_test = train_test_split(\n    features, target, test_size=0.2, random_state=7)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_main, y_main, test_size=0.25, random_state=12)\n\nX_train.shape, X_val.shape, X_test.shape\n\n((3066, 10), (1022, 10), (1022, 10))",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#what-values-do-we-see-in-the-data",
    "href": "Lecture-3-Tabular-Data/classification.html#what-values-do-we-see-in-the-data",
    "title": "Classification",
    "section": "What values do we see in the data?",
    "text": "What values do we see in the data?\n\n\n\nX_train[\"gender\"].value_counts()\n\ngender\nFemale    1802\nMale      1264\nName: count, dtype: int64\n\n\n\nX_train[\"ever_married\"].value_counts()\n\never_married\nYes    2007\nNo     1059\nName: count, dtype: int64\n\n\n\nX_train[\"Residence_type\"].value_counts()\n\nResidence_type\nUrban    1536\nRural    1530\nName: count, dtype: int64\n\n\n\n\nX_train[\"work_type\"].value_counts()\n\nwork_type\nPrivate          1754\nSelf-employed     490\nchildren          419\nGovt_job          390\nNever_worked       13\nName: count, dtype: int64\n\n\n\nX_train[\"smoking_status\"].value_counts()\n\nsmoking_status\nnever smoked       1130\nUnknown             944\nformerly smoked     522\nsmokes              470\nName: count, dtype: int64",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#preprocess-columns-individually",
    "href": "Lecture-3-Tabular-Data/classification.html#preprocess-columns-individually",
    "title": "Classification",
    "section": "Preprocess columns individually",
    "text": "Preprocess columns individually\n\nTake categorical columns \\hookrightarrow one-hot vectors\nbinary columns \\hookrightarrow do nothing\ncontinuous columns \\hookrightarrow impute NaNs & standardise.",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#scikit-learn-column-transformer",
    "href": "Lecture-3-Tabular-Data/classification.html#scikit-learn-column-transformer",
    "title": "Classification",
    "section": "Scikit-learn column transformer",
    "text": "Scikit-learn column transformer\n\nfrom sklearn.pipeline import make_pipeline\n\ncat_vars =  [\"gender\", \"ever_married\", \"Residence_type\",\n    \"work_type\", \"smoking_status\"]                  \n\nct = make_column_transformer(\n  (OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), cat_vars),\n  (\"passthrough\", [\"hypertension\", \"heart_disease\"]),\n  remainder=make_pipeline(SimpleImputer(), StandardScaler()),\n  verbose_feature_names_out=False\n)\n\nX_train_ct = ct.fit_transform(X_train)\nX_val_ct = ct.transform(X_val)\nX_test_ct = ct.transform(X_test)\n\nfor name, X in zip((\"train\", \"val\", \"test\"), (X_train_ct, X_val_ct, X_test_ct)):\n    num_na = X.isna().sum().sum()\n    print(f\"The {name} set has shape {X_train_ct.shape} & with {num_na} NAs.\")\n\nThe train set has shape (3066, 20) & with 0 NAs.\nThe val set has shape (3066, 20) & with 0 NAs.\nThe test set has shape (3066, 20) & with 0 NAs.\n\n\n\nImports make_pipeline class from sklearn.pipeline library. make_pipeline is used to streamline the data pre processing. In the above example, make_pipeline is used to first treat for missing values and then scale numerical values\nStores categorical variables in cat_vars\nSpecifies the one-hot encoding for all categorical variables. We set the sparse_output=False, to return a dense array rather than a sparse matrix. handle_unknown specifies how the neural network should handle unseen categories. By setting handle_unknown=\"ignore\", we instruct the neural network to ignore categories that were not seen during training. If we did not do this, it will interrupt the model’s operation after deployment\nPasses through hypertension and heart_disease without any pre processing\nMakes a pipeline that first applies SimpleImputer() to replace missing values with the mean and then applies StandardScaler() to scale the numerical values\nPrints out the missing values to ensure the SimpleImputer() has worked",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#handling-unseen-categories",
    "href": "Lecture-3-Tabular-Data/classification.html#handling-unseen-categories",
    "title": "Classification",
    "section": "Handling unseen categories",
    "text": "Handling unseen categories\n\n\n\nX_train[\"gender\"].value_counts()\n\ngender\nFemale    1802\nMale      1264\nName: count, dtype: int64\n\n\n\n\nX_val[\"gender\"].value_counts()\n\ngender\nFemale    615\nMale      406\nOther       1\nName: count, dtype: int64\n\n\n\n\nBecause the way train and test was split, one-hot encoder could not pick up on the third category. This could interrupt the model performance. To avoid such confusions, we could either give instructions manually on how to tackle unseen categories. An example is given below.\n\n\n\nind = np.argmax(X_val[\"gender\"] == \"Other\")\nX_val.iloc[ind-1:ind+3][[\"gender\"]]\n\n\n\n\n\n\n\n\ngender\n\n\n\n\n4970\nMale\n\n\n3116\nOther\n\n\n4140\nMale\n\n\n2505\nFemale\n\n\n\n\n\n\n\n\n\ngender_cols = X_val_ct[[\"gender_Female\", \"gender_Male\"]]\ngender_cols.iloc[ind-1:ind+3]\n\n\n\n\n\n\n\n\ngender_Female\ngender_Male\n\n\n\n\n4970\n0.0\n1.0\n\n\n3116\n0.0\n0.0\n\n\n4140\n0.0\n1.0\n\n\n2505\n1.0\n0.0\n\n\n\n\n\n\n\n\n\nHowever, to give such instructions on handling unseen categories, we would first have to know what those possible categories could be. We should also have specific knowledge on what value to assign in case they come up during model performance. One easy way to tackle it would be to use handle_unknown=\"ignore\" during encoding, as mentioned before.",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#setup-a-binary-classification-model",
    "href": "Lecture-3-Tabular-Data/classification.html#setup-a-binary-classification-model",
    "title": "Classification",
    "section": "Setup a binary classification model",
    "text": "Setup a binary classification model\n\ndef create_model(seed=42):\n    random.seed(seed)\n    model = Sequential()\n    model.add(Input(X_train_ct.shape[1:]))\n    model.add(Dense(32, \"leaky_relu\"))\n    model.add(Dense(16, \"leaky_relu\"))\n    model.add(Dense(1, \"sigmoid\"))\n    return model\n\nSince this is a binary classification problem, we use the sigmoid activation function.\n\nmodel = create_model()\nmodel.summary()\n\nModel: \"sequential_5\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ dense_10 (Dense)                │ (None, 32)                │        672 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_11 (Dense)                │ (None, 16)                │        528 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_12 (Dense)                │ (None, 1)                 │         17 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 1,217 (4.75 KB)\n\n\n\n Trainable params: 1,217 (4.75 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\nmodel.summary() returns the summary of the constructed neural network.",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#add-metrics-compile-and-fit",
    "href": "Lecture-3-Tabular-Data/classification.html#add-metrics-compile-and-fit",
    "title": "Classification",
    "section": "Add metrics, compile, and fit",
    "text": "Add metrics, compile, and fit\n\nmodel = create_model()\n\npr_auc = keras.metrics.AUC(curve=\"PR\", name=\"pr_auc\")\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",\n    metrics=[pr_auc, \"accuracy\", \"auc\"])                                \n\nes = EarlyStopping(patience=50, restore_best_weights=True,\n    monitor=\"val_pr_auc\", verbose=1)\nmodel.fit(X_train_ct, y_train, callbacks=[es], epochs=1_000, verbose=0,\n  validation_data=(X_val_ct, y_val));\n\nEpoch 69: early stopping\nRestoring model weights from the end of the best epoch: 19.\n\n\n\nBrings in the created model\nCreates an instance pr_auc to store the AUC (Area Under Curve) metric for the PR (Precision-Recall) curve\nCompiles the model with an appropriate loss function, optimizer and relevant metrics. Since the above problem is a binary classification, we would optimize the binary_crossentropy, chose to monitor both accuracy and AUC and pr_auc.\n\nTracking AUC and pr_auc on top of the accuracy is important, particularly in the cases where there is a class imbalance. Suppose a data has 95% True class and only 5% False class, then, even a random classifier that predicts True 95% of the time will have a high accuracy. To avoid such issues, it is advisable to monitor both accuracy and AUC.\n\n\n\nmodel.evaluate(X_val_ct, y_val, verbose=0)\n\n[0.1452300250530243,\n 0.9589040875434875,\n 0.8276846408843994,\n 0.13280197978019714]",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#overweight-the-minority-class",
    "href": "Lecture-3-Tabular-Data/classification.html#overweight-the-minority-class",
    "title": "Classification",
    "section": "Overweight the minority class",
    "text": "Overweight the minority class\n\nmodel = create_model()\n\npr_auc = keras.metrics.AUC(curve=\"PR\", name=\"pr_auc\")\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",\n    metrics=[pr_auc, \"accuracy\", \"auc\"])\n\nes = EarlyStopping(patience=50, restore_best_weights=True,\n    monitor=\"val_pr_auc\", verbose=1)\nmodel.fit(X_train_ct, y_train, callbacks=[es], epochs=1_000, verbose=0,\n  validation_data=(X_val_ct, y_val), class_weight={0: 1, 1: 10});\n\nEpoch 56: early stopping\nRestoring model weights from the end of the best epoch: 6.\n\n\nAnother way to treat class imbalance would be to assign a higher weight to the minority class during model fitting. 1. Fits the model by assigning a higher weight to the misclassification in the minor class. This above class weight assignment says that misclassifying an observation from class 1 will be penalized 10 times more than misclassifying an observation from class 0. The weights can be assigned in relation to the level of data imbalance.\n\n\n\nmodel.evaluate(X_val_ct, y_val, verbose=0)\n\n[0.3797358572483063, 0.767123281955719, 0.8222789168357849, 0.1360630989074707]\n\n\n\n\n\nmodel.evaluate(X_test_ct, y_test, verbose=0)\n\n[0.3906365931034088,\n 0.7837573289871216,\n 0.8110082149505615,\n 0.15662002563476562]",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-3-Tabular-Data/classification.html#classification-metrics",
    "href": "Lecture-3-Tabular-Data/classification.html#classification-metrics",
    "title": "Classification",
    "section": "Classification Metrics",
    "text": "Classification Metrics\n\nfrom sklearn.metrics import confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay\ny_pred = model.predict(X_test_ct, verbose=0)\n\n\n\n\nRocCurveDisplay.from_predictions(y_test, y_pred, name=\"\");\n\n\n\n\n\n\n\n\n\n\nPrecisionRecallDisplay.from_predictions(y_test, y_pred, name=\"\"); plt.legend(loc=\"upper right\");\n\n\n\n\n\n\n\n\n\n\n\n\n\ny_pred_stroke = y_pred &gt; 0.5\nconfusion_matrix(y_test, y_pred_stroke)\n\narray([[762, 210],\n       [ 11,  39]])\n\n\n\n\ny_pred_stroke = y_pred &gt; 0.3\nconfusion_matrix(y_test, y_pred_stroke)\n\narray([[629, 343],\n       [  6,  44]])",
    "crumbs": [
      "Module 3",
      "Classification"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#load-packages",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#load-packages",
    "title": "Natural Language Processing",
    "section": "Load packages",
    "text": "Load packages\n\nimport random\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport numpy.random as rnd\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras import layers\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dense, Input\nfrom keras.metrics import SparseTopKCategoricalAccuracy\nfrom keras.models import Sequential\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.0\nIPython version      : 8.20.0\n\nsklearn   : 1.4.0\nkeras     : 3.0.4\ntorch     : 2.2.0\ntensorflow: 2.15.0.post1"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#what-is-nlp",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#what-is-nlp",
    "title": "Natural Language Processing",
    "section": "What is NLP?",
    "text": "What is NLP?\nA field of research at the intersection of computer science, linguistics, and artificial intelligence that takes the naturally spoken or written language of humans and processes it with machines to automate or help in certain tasks"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#how-the-computer-sees-text",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#how-the-computer-sees-text",
    "title": "Natural Language Processing",
    "section": "How the computer sees text",
    "text": "How the computer sees text\nSpot the odd one out:\n\n\n[112, 97, 116, 114, 105, 99, 107, 32, 108, 97, 117, 98]\n\n\n\n\n[80, 65, 84, 82, 73, 67, 75, 32, 76, 65, 85, 66]\n\n\n\n\n[76, 101, 118, 105, 32, 65, 99, 107, 101, 114, 109, 97, 110]\n\n\n\nGenerated by:\n\nprint([ord(x) for x in \"patrick laub\"])\nprint([ord(x) for x in \"PATRICK LAUB\"])\nprint([ord(x) for x in \"Levi Ackerman\"])\n\nThe ord built-in turns characters into their ASCII form.\n\n\n\n\n\n\nQuestion\n\n\nThe largest value for a character is 127, can you guess why?"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#ascii",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#ascii",
    "title": "Natural Language Processing",
    "section": "ASCII",
    "text": "ASCII\n\nAmerican Standard Code for Information InterchangeUnicode is the new standard.\n\nSource: Wikipedia"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#random-strings",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#random-strings",
    "title": "Natural Language Processing",
    "section": "Random strings",
    "text": "Random strings\nThe built-in chr function turns numbers into characters.\n\nrnd.seed(1)\n\n\nchars = [chr(rnd.randint(32, 127)) for _ in range(10)]\nchars\n\n['E', ',', 'h', ')', 'k', '%', 'o', '`', '0', '!']\n\n\n\n\" \".join(chars)\n\n'E , h ) k % o ` 0 !'\n\n\n\n\"\".join([chr(rnd.randint(32, 127)) for _ in range(50)])\n\n\"lg&9R42t+&lt;=.Rdww~v-)'_]6Y! \\\\q(x-Oh&gt;g#f5QY#d8Kl:TpI\"\n\n\n\n\"\".join([chr(rnd.randint(0, 128)) for _ in range(50)])\n\n'R\\x0f@D\\x19obW\\x07\\x1a\\x19h\\x16\\tCg~\\x17}d\\x1b%9S&\\x08 \"\\n\\x17\\x0foW\\x19Gs\\\\J&gt;. X\\x177AqM\\x03\\x00x'"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#escape-characters",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#escape-characters",
    "title": "Natural Language Processing",
    "section": "Escape characters",
    "text": "Escape characters\n\n\n\nprint(\"Hello,\\tworld!\")\n\nHello,  world!\n\n\n\nprint(\"Line 1\\nLine 2\")\n\nLine 1\nLine 2\n\n\n\nprint(\"Patrick\\rLaub\")\n\n\n\nLaubick\n\n\n\n\nprint(\"C:\\tom\\new folder\")\n\nC:  om\new folder\n\n\nEscape the backslash:\n\nprint(\"C:\\\\tom\\\\new folder\")\n\nC:\\tom\\new folder\n\n\n\nrepr(\"Hello,\\rworld!\")\n\n\"'Hello,\\\\rworld!'\""
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#non-natural-language-processing-i",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#non-natural-language-processing-i",
    "title": "Natural Language Processing",
    "section": "Non-natural language processing I",
    "text": "Non-natural language processing I\nHow would you evaluate\n\n10 + 2 * -3\n\n\nAll that Python sees is a string of characters.\n\n[ord(c) for c in \"10 + 2 * -3\"]\n\n[49, 48, 32, 43, 32, 50, 32, 42, 32, 45, 51]\n\n\n\n\n\n10 + 2 * -3\n\n4"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#non-natural-language-processing-ii",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#non-natural-language-processing-ii",
    "title": "Natural Language Processing",
    "section": "Non-natural language processing II",
    "text": "Non-natural language processing II\nPython first tokenizes the string:\n\nimport tokenize\nimport io\n\ncode = \"10 + 2 * -3\"\ntokens = tokenize.tokenize(io.BytesIO(code.encode(\"utf-8\")).readline)\nfor token in tokens:\n    print(token)\n\nTokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line='')\nTokenInfo(type=2 (NUMBER), string='10', start=(1, 0), end=(1, 2), line='10 + 2 * -3')\nTokenInfo(type=54 (OP), string='+', start=(1, 3), end=(1, 4), line='10 + 2 * -3')\nTokenInfo(type=2 (NUMBER), string='2', start=(1, 5), end=(1, 6), line='10 + 2 * -3')\nTokenInfo(type=54 (OP), string='*', start=(1, 7), end=(1, 8), line='10 + 2 * -3')\nTokenInfo(type=54 (OP), string='-', start=(1, 9), end=(1, 10), line='10 + 2 * -3')\nTokenInfo(type=2 (NUMBER), string='3', start=(1, 10), end=(1, 11), line='10 + 2 * -3')\nTokenInfo(type=4 (NEWLINE), string='', start=(1, 11), end=(1, 12), line='')\nTokenInfo(type=0 (ENDMARKER), string='', start=(2, 0), end=(2, 0), line='')"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#non-natural-language-processing-iii",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#non-natural-language-processing-iii",
    "title": "Natural Language Processing",
    "section": "Non-natural language processing III",
    "text": "Non-natural language processing III\nPython needs to parse the tokens into an abstract syntax tree.\n\n\n\nimport ast\n\nprint(ast.dump(ast.parse(\"10 + 2 * -3\"), indent=\"  \"))\n\nModule(\n  body=[\n    Expr(\n      value=BinOp(\n        left=Constant(value=10),\n        op=Add(),\n        right=BinOp(\n          left=Constant(value=2),\n          op=Mult(),\n          right=UnaryOp(\n            op=USub(),\n            operand=Constant(value=3)))))],\n  type_ignores=[])\n\n\n\n\n\n\n\n\ngraph TD;\n    Expr --&gt; C[Add]\n    C --&gt; D[10]\n    C --&gt; E[Mult]\n    E --&gt; F[2]\n    E --&gt; G[USub]\n    G --&gt; H[3]"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#non-natural-language-processing-iv",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#non-natural-language-processing-iv",
    "title": "Natural Language Processing",
    "section": "Non-natural language processing IV",
    "text": "Non-natural language processing IV\nThe abstract syntax tree is then compiled into bytecode.\n\n\n\nimport dis\n\ndef expression(a, b, c):\n    return a + b * -c\n\ndis.dis(expression)\n\n  3           0 RESUME                   0\n\n  4           2 LOAD_FAST                0 (a)\n              4 LOAD_FAST                1 (b)\n              6 LOAD_FAST                2 (c)\n              8 UNARY_NEGATIVE\n             10 BINARY_OP                5 (*)\n             14 BINARY_OP                0 (+)\n             18 RETURN_VALUE\n\n\n\n\n\n\nRunning the bytecode"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#applications-of-nlp-in-industry",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#applications-of-nlp-in-industry",
    "title": "Natural Language Processing",
    "section": "Applications of NLP in Industry",
    "text": "Applications of NLP in Industry\n1) Classifying documents: Using the language within a body of text to classify it into a particular category, e.g.:\n\nGrouping emails into high and low urgency\nMovie reviews into positive and negative sentiment (i.e. sentiment analysis)\nCompany news into bullish (positive) and bearish (negative) statements\n\n2) Machine translation: Assisting language translators with machine-generated suggestions from a source language (e.g. English) to a target language"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#applications-of-nlp-in-industry-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#applications-of-nlp-in-industry-1",
    "title": "Natural Language Processing",
    "section": "Applications of NLP in Industry",
    "text": "Applications of NLP in Industry\n3) Search engine functions, including:\n\nAutocomplete\nPredicting what information or website user is seeking\n\n4) Speech recognition: Interpreting voice commands to provide information or take action. Used in virtual assistants such as Alexa, Siri, and Cortana"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#deep-learning-nlp",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#deep-learning-nlp",
    "title": "Natural Language Processing",
    "section": "Deep learning & NLP?",
    "text": "Deep learning & NLP?\nSimple NLP applications such as spell checkers and synonym suggesters do not require deep learning and can be solved with deterministic, rules-based code with a dictionary/thesaurus.\nMore complex NLP applications such as classifying documents, search engine word prediction, and chatbots are complex enough to be solved using deep learning methods."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#nlp-in-1966-1973-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#nlp-in-1966-1973-1",
    "title": "Natural Language Processing",
    "section": "NLP in 1966-1973 #1",
    "text": "NLP in 1966-1973 #1\n\nA typical story occurred in early machine translation efforts, which were generously funded by the U.S. National Research Council in an attempt to speed up the translation of Russian scientific papers in the wake of the Sputnik launch in 1957. It was thought initially that simple syntactic transformations, based on the grammars of Russian and English, and word replacement from an electronic dictionary, would suffice to preserve the exact meanings of sentences.\n\n\nSource: Russell and Norvig (2016), Artificial Intelligence: A Modern Approach, Third Edition, p. 21."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#nlp-in-1966-1973-2",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#nlp-in-1966-1973-2",
    "title": "Natural Language Processing",
    "section": "NLP in 1966-1973 #2",
    "text": "NLP in 1966-1973 #2\n\nThe fact is that accurate translation requires background knowledge in order to resolve ambiguity and establish the content of the sentence. The famous retranslation of “the spirit is willing but the flesh is weak” as “the vodka is good but the meat is rotten” illustrates the difficulties encountered. In 1966, a report by an advisory committee found that “there has been no machine translation of general scientific text, and none is in immediate prospect.” All U.S. government funding for academic translation projects was canceled.\n\n\nSource: Russell and Norvig (2016), Artificial Intelligence: A Modern Approach, Third Edition, p. 21."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#high-level-history-of-deep-learning",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#high-level-history-of-deep-learning",
    "title": "Natural Language Processing",
    "section": "High-level history of deep learning",
    "text": "High-level history of deep learning\n\n\n\n\nA brief history of deep learning.\n\n\nSource: Krohn (2019), Deep Learning Illustrated, Figure 2-3."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#downloading-the-dataset",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#downloading-the-dataset",
    "title": "Natural Language Processing",
    "section": "Downloading the dataset",
    "text": "Downloading the dataset\nLook at the (U.S.) National Highway Traffic Safety Administration’s (NHTSA) National Motor Vehicle Crash Causation Survey (NMVCCS) dataset.\n\nfrom pathlib import Path\n\nif not Path(\"NHTSA_NMVCCS_extract.parquet.gzip\").exists():\n    print(\"Downloading dataset\")                                    \n    !wget https://github.com/JSchelldorfer/ActuarialDataScience/raw/master/12%20-%20NLP%20Using%20Transformers/NHTSA_NMVCCS_extract.parquet.gzip\n\ndf = pd.read_parquet(\"NHTSA_NMVCCS_extract.parquet.gzip\")\nprint(f\"shape of DataFrame: {df.shape}\")\n\nshape of DataFrame: (6949, 16)"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#features",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#features",
    "title": "Natural Language Processing",
    "section": "Features",
    "text": "Features\n\nlevel_0, index, SCASEID: all useless row numbers\nSUMMARY_EN and SUMMARY_GE: summaries of the accident\nNUMTOTV: total number of vehicles involved in the accident\nWEATHER1 to WEATHER8:\n\nWEATHER1: cloudy\nWEATHER2: snow\nWEATHER3: fog, smog, smoke\nWEATHER4: rain\nWEATHER5: sleet, hail (freezing drizzle or rain)\nWEATHER6: blowing snow\nWEATHER7: severe crosswinds\nWEATHER8: other\n\nINJSEVA and INJSEVB: injury severity & (binary) presence of bodily injury\n\n\nSource: JSchelldorfer’s GitHub."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#crash-summaries",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#crash-summaries",
    "title": "Natural Language Processing",
    "section": "Crash summaries",
    "text": "Crash summaries\n\ndf[\"SUMMARY_EN\"]\n\n0       V1, a 2000 Pontiac Montana minivan, made a lef...\n1       The crash occurred in the eastbound lane of a ...\n2       This crash occurred just after the noon time h...\n                              ...                        \n6946    The crash occurred in the eastbound lanes of a...\n6947    This single-vehicle crash occurred in a rural ...\n6948    This two vehicle daytime collision occurred mi...\nName: SUMMARY_EN, Length: 6949, dtype: object\n\n\n\ndf[\"SUMMARY_EN\"].map(lambda summary: len(summary)).hist(grid=False);"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#a-crash-summary",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#a-crash-summary",
    "title": "Natural Language Processing",
    "section": "A crash summary",
    "text": "A crash summary\n\ndf[\"SUMMARY_EN\"].iloc[1]\n\n\"The crash occurred in the eastbound lane of a two-lane, two-way asphalt roadway on level grade.  The conditions were daylight and wet with cloudy skies in the early afternoon on a weekday.\\t\\r \\r V1, a 1995 Chevrolet Lumina was traveling eastbound.  V2, a 2004 Chevrolet Trailblazer was also traveling eastbound on the same roadway.  V2, was attempting to make a left-hand turn into a private drive on the North side of the roadway.  While turning V1 attempted to pass V2 on the left-hand side contacting it's front to the left side of V2.  Both vehicles came to final rest on the roadway at impact.\\r \\r The driver of V1 fled the scene and was not identified, so no further information could be obtained from him.  The Driver of V2 stated that the driver was a male and had hit his head and was bleeding.  She did not pursue the driver because she thought she saw a gun. The officer said that the car had been reported stolen.\\r \\r The Critical Precrash Event for the driver of V1 was this vehicle traveling over left lane line on the left side of travel.  The Critical Reason for the Critical Event was coded as unknown reason for the critical event because the driver was not available. \\r \\r The driver of V2 was a 41-year old female who had reported that she had stopped prior to turning to make sure she was at the right house.  She was going to show a house for a client.  She had no health related problems.  She had taken amoxicillin.  She does not wear corrective lenses and felt rested.  She was not injured in the crash.\\r \\r The Critical Precrash Event for the driver of V2 was other vehicle encroachment from adjacent lane over left lane line.  The Critical Reason for the Critical Event was not coded for this vehicle and the driver of V2 was not thought to have contributed to the crash.\""
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#carriage-returns",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#carriage-returns",
    "title": "Natural Language Processing",
    "section": "Carriage returns",
    "text": "Carriage returns\n\nprint(df[\"SUMMARY_EN\"].iloc[1])\n\n\n\nThe Critical Precrash Event for the driver of V2 was other vehicle encroachment from adjacent lane over left lane line.  The Critical Reason for the Critical Event was not coded for this vehicle and the driver of V2 was not thought to have contributed to the crash.r corrective lenses and felt rested.  She was not injured in the crash. of V2.  Both vehicles came to final rest on the roadway at impact.\n\n\n\n# Replace every \\r with \\n\ndef replace_carriage_return(summary):\n    return summary.replace(\"\\r\", \"\\n\")\n\ndf[\"SUMMARY_EN\"] = df[\"SUMMARY_EN\"].map(replace_carriage_return)\nprint(df[\"SUMMARY_EN\"].iloc[1][:500])\n\nThe crash occurred in the eastbound lane of a two-lane, two-way asphalt roadway on level grade.  The conditions were daylight and wet with cloudy skies in the early afternoon on a weekday.    \n \n V1, a 1995 Chevrolet Lumina was traveling eastbound.  V2, a 2004 Chevrolet Trailblazer was also traveling eastbound on the same roadway.  V2, was attempting to make a left-hand turn into a private drive on the North side of the roadway.  While turning V1 attempted to pass V2 on the left-hand side contactin"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#target",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#target",
    "title": "Natural Language Processing",
    "section": "Target",
    "text": "Target\n\n\nPredict number of vehicles in the crash.\n\ndf[\"NUMTOTV\"].value_counts()\\\n    .sort_index()\n\nNUMTOTV\n1    1822\n2    4151\n3     783\n4     150\n5      34\n6       5\n7       2\n8       1\n9       1\nName: count, dtype: int64\n\n\n\nnp.sum(df[\"NUMTOTV\"] &gt; 3)\n\n193\n\n\n\nSimplify the target to just:\n\n1 vehicle\n2 vehicles\n3+ vehicles\n\n\ndf[\"NUM_VEHICLES\"] = \\\n  df[\"NUMTOTV\"].map(lambda x: \\\n    str(x) if x &lt;= 2 else \"3+\")\ndf[\"NUM_VEHICLES\"].value_counts()\\\n  .sort_index()\n\nNUM_VEHICLES\n1     1822\n2     4151\n3+     976\nName: count, dtype: int64"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#just-ignore-this-for-now",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#just-ignore-this-for-now",
    "title": "Natural Language Processing",
    "section": "Just ignore this for now…",
    "text": "Just ignore this for now…\n\nrnd.seed(123)\n\nfor i, summary in enumerate(df[\"SUMMARY_EN\"]):\n    word_numbers = [\"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\"]\n    num_cars = 10\n    new_car_nums = [f\"V{rnd.randint(100, 10000)}\" for _ in range(num_cars)]\n    num_spaces = 4\n\n    for car in range(1, num_cars+1):\n        new_num = new_car_nums[car-1]\n        summary = summary.replace(f\"V-{car}\", new_num)\n        summary = summary.replace(f\"Vehicle {word_numbers[car-1]}\", new_num).replace(f\"vehicle {word_numbers[car-1]}\", new_num)\n        summary = summary.replace(f\"Vehicle #{word_numbers[car-1]}\", new_num).replace(f\"vehicle #{word_numbers[car-1]}\", new_num)\n        summary = summary.replace(f\"Vehicle {car}\", new_num).replace(f\"vehicle {car}\", new_num)\n        summary = summary.replace(f\"Vehicle #{car}\", new_num).replace(f\"vehicle #{car}\", new_num)\n        summary = summary.replace(f\"Vehicle # {car}\", new_num).replace(f\"vehicle # {car}\", new_num)\n\n        for j in range(num_spaces+1):\n            summary = summary.replace(f\"V{' '*j}{car}\", new_num).replace(f\"V{' '*j}#{car}\", new_num).replace(f\"V{' '*j}# {car}\", new_num)\n            summary = summary.replace(f\"v{' '*j}{car}\", new_num).replace(f\"v{' '*j}#{car}\", new_num).replace(f\"v{' '*j}# {car}\", new_num)\n         \n    df.loc[i, \"SUMMARY_EN\"] = summary"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#convert-y-to-integers-split-the-data",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#convert-y-to-integers-split-the-data",
    "title": "Natural Language Processing",
    "section": "Convert y to integers & split the data",
    "text": "Convert y to integers & split the data\n\nfrom sklearn.preprocessing import LabelEncoder\ntarget_labels = df[\"NUM_VEHICLES\"]\ntarget = LabelEncoder().fit_transform(target_labels)\ntarget\n\narray([1, 1, 1, ..., 2, 0, 1])\n\n\n\nweather_cols = [f\"WEATHER{i}\" for i in range(1, 9)]\nfeatures = df[[\"SUMMARY_EN\"] + weather_cols]\n\nX_main, X_test, y_main, y_test = \\\n    train_test_split(features, target, test_size=0.2, random_state=1)\n\n# As 0.25 x 0.8 = 0.2\nX_train, X_val, y_train, y_val = \\\n    train_test_split(X_main, y_main, test_size=0.25, random_state=1)\n\nX_train.shape, X_val.shape, X_test.shape\n\n((4169, 9), (1390, 9), (1390, 9))\n\n\n\nprint([np.mean(y_train == y) for y in [0, 1, 2]])\n\n[0.25833533221396016, 0.6032621731830176, 0.1384024946030223]"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#grab-the-start-of-a-few-summaries",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#grab-the-start-of-a-few-summaries",
    "title": "Natural Language Processing",
    "section": "Grab the start of a few summaries",
    "text": "Grab the start of a few summaries\n\nfirst_summaries = X_train[\"SUMMARY_EN\"].iloc[:3]\nfirst_summaries\n\n2532    This crash occurred in the early afternoon of ...\n6209    This two-vehicle crash occurred in a four-legg...\n2561    The crash occurred in the eastbound direction ...\nName: SUMMARY_EN, dtype: object\n\n\n\nfirst_words = first_summaries.map(lambda txt: txt.split(\" \")[:7])\nfirst_words\n\n2532    [This, crash, occurred, in, the, early, aftern...\n6209    [This, two-vehicle, crash, occurred, in, a, fo...\n2561    [The, crash, occurred, in, the, eastbound, dir...\nName: SUMMARY_EN, dtype: object\n\n\n\nstart_of_summaries = first_words.map(lambda txt: \" \".join(txt))\nstart_of_summaries\n\n2532          This crash occurred in the early afternoon\n6209    This two-vehicle crash occurred in a four-legged\n2561       The crash occurred in the eastbound direction\nName: SUMMARY_EN, dtype: object"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#count-words-in-the-first-summaries",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#count-words-in-the-first-summaries",
    "title": "Natural Language Processing",
    "section": "Count words in the first summaries",
    "text": "Count words in the first summaries\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvect = CountVectorizer()\ncounts = vect.fit_transform(start_of_summaries)\nvocab = vect.get_feature_names_out()\nprint(len(vocab), vocab)\n\n13 ['afternoon' 'crash' 'direction' 'early' 'eastbound' 'four' 'in' 'legged'\n 'occurred' 'the' 'this' 'two' 'vehicle']\n\n\n\ncounts\n\n&lt;3x13 sparse matrix of type '&lt;class 'numpy.int64'&gt;'\n    with 21 stored elements in Compressed Sparse Row format&gt;\n\n\n\ncounts.toarray()\n\narray([[1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0],\n       [0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1],\n       [0, 1, 1, 0, 1, 0, 1, 0, 1, 2, 0, 0, 0]])"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#encode-new-sentences-to-bow",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#encode-new-sentences-to-bow",
    "title": "Natural Language Processing",
    "section": "Encode new sentences to BoW",
    "text": "Encode new sentences to BoW\n\nvect.transform([\n    \"first car hit second car in a crash\",\n    \"ipad os 16 beta released\",\n])\n\n&lt;2x13 sparse matrix of type '&lt;class 'numpy.int64'&gt;'\n    with 2 stored elements in Compressed Sparse Row format&gt;\n\n\n\nvect.transform([\n    \"first car hit second car in a crash\",\n    \"ipad os 16 beta released\",\n]).toarray()\n\narray([[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n\n\n\nprint(vocab)\n\n['afternoon' 'crash' 'direction' 'early' 'eastbound' 'four' 'in' 'legged'\n 'occurred' 'the' 'this' 'two' 'vehicle']"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#bag-of-n-grams",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#bag-of-n-grams",
    "title": "Natural Language Processing",
    "section": "Bag of n-grams",
    "text": "Bag of n-grams\n\nvect = CountVectorizer(ngram_range=(1, 2))\ncounts = vect.fit_transform(start_of_summaries)\nvocab = vect.get_feature_names_out()\nprint(len(vocab), vocab)\n\n27 ['afternoon' 'crash' 'crash occurred' 'direction' 'early'\n 'early afternoon' 'eastbound' 'eastbound direction' 'four' 'four legged'\n 'in' 'in four' 'in the' 'legged' 'occurred' 'occurred in' 'the'\n 'the crash' 'the early' 'the eastbound' 'this' 'this crash' 'this two'\n 'two' 'two vehicle' 'vehicle' 'vehicle crash']\n\n\n\ncounts.toarray()\n\narray([[1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n        0, 0, 0, 0, 0],\n       [0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n        1, 1, 1, 1, 1],\n       [0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 2, 1, 0, 1, 0, 0,\n        0, 0, 0, 0, 0]])\n\n\nSee: Google Books Ngram Viewer"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#tf-idf",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#tf-idf",
    "title": "Natural Language Processing",
    "section": "TF-IDF",
    "text": "TF-IDF\nStands for term frequency-inverse document frequency.\n\nInfographic explaining TF-IDF\nSource: FiloTechnologia (2014), A simple Java class for TF-IDF scoring, Blog post."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#count-words-in-all-the-summaries",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#count-words-in-all-the-summaries",
    "title": "Natural Language Processing",
    "section": "Count words in all the summaries",
    "text": "Count words in all the summaries\n\nvect = CountVectorizer()\nvect.fit(X_train[\"SUMMARY_EN\"])\nvocab = list(vect.get_feature_names_out())\nlen(vocab)\n\n18866\n\n\n\nvocab[:5], vocab[len(vocab)//2:(len(vocab)//2 + 5)], vocab[-5:]\n\n(['00', '000', '000lbs', '003', '005'],\n ['swinger', 'swinging', 'swipe', 'swiped', 'swiping'],\n ['zorcor', 'zotril', 'zx2', 'zx5', 'zyrtec'])"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#create-the-x-matrices",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#create-the-x-matrices",
    "title": "Natural Language Processing",
    "section": "Create the X matrices",
    "text": "Create the X matrices\n\ndef vectorise_dataset(X, vect, txt_col=\"SUMMARY_EN\", dataframe=False):\n    X_vects = vect.transform(X[txt_col]).toarray()\n    X_other = X.drop(txt_col, axis=1)\n\n    if not dataframe:\n        return np.concatenate([X_vects, X_other], axis=1)                           \n    else:\n        # Add column names and indices to the combined dataframe.\n        vocab = list(vect.get_feature_names_out())\n        X_vects_df = pd.DataFrame(X_vects, columns=vocab, index=X.index)\n        return pd.concat([X_vects_df, X_other], axis=1)\n\n\nX_train_ct = vectorise_dataset(X_train, vect)\nX_val_ct = vectorise_dataset(X_val, vect)\nX_test_ct = vectorise_dataset(X_test, vect)"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#check-the-input-matrix",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#check-the-input-matrix",
    "title": "Natural Language Processing",
    "section": "Check the input matrix",
    "text": "Check the input matrix\n\nvectorise_dataset(X_train, vect, dataframe=True)\n\n\n\n\n\n\n\n\n00\n000\n000lbs\n003\n005\n007\n00am\n00pm\n00tydo2\n01\n...\nzx5\nzyrtec\nWEATHER1\nWEATHER2\nWEATHER3\nWEATHER4\nWEATHER5\nWEATHER6\nWEATHER7\nWEATHER8\n\n\n\n\n2532\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6209\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2561\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n6882\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n206\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6356\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n4169 rows × 18874 columns"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#make-a-simple-dense-model",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#make-a-simple-dense-model",
    "title": "Natural Language Processing",
    "section": "Make a simple dense model",
    "text": "Make a simple dense model\n\nnum_features = X_train_ct.shape[1]\nnum_cats = 3 # 1, 2, 3+ vehicles\n\ndef build_model(num_features, num_cats):\n    random.seed(42)\n    \n    model = Sequential([\n        Input((num_features,)),\n        Dense(100, activation=\"relu\"),\n        Dense(num_cats, activation=\"softmax\")\n    ])\n    \n    topk = SparseTopKCategoricalAccuracy(k=2, name=\"topk\")\n    model.compile(\"adam\", \"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\", topk])\n    \n    return model\n\n\nmodel = build_model(num_features, num_cats)\nmodel.summary()\n\nModel: \"sequential\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ dense (Dense)                   │ (None, 100)               │  1,887,500 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_1 (Dense)                 │ (None, 3)                 │        303 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 1,887,803 (7.20 MB)\n\n\n\n Trainable params: 1,887,803 (7.20 MB)\n\n\n\n Non-trainable params: 0 (0.00 B)"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#fit-evaluate-the-model",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#fit-evaluate-the-model",
    "title": "Natural Language Processing",
    "section": "Fit & evaluate the model",
    "text": "Fit & evaluate the model\n\nes = EarlyStopping(patience=1, restore_best_weights=True,\n    monitor=\"val_accuracy\", verbose=2)\n%time hist = model.fit(X_train_ct, y_train, epochs=10, \\\n    callbacks=[es], validation_data=(X_val_ct, y_val), verbose=0);\n\nEpoch 3: early stopping\nRestoring model weights from the end of the best epoch: 2.\nCPU times: user 6.14 s, sys: 16.3 ms, total: 6.15 s\nWall time: 6.15 s\n\n\n\nmodel.evaluate(X_train_ct, y_train, verbose=0)\n\n[0.015500374138355255, 1.0, 1.0]\n\n\n\nmodel.evaluate(X_val_ct, y_val, verbose=0)\n\n[0.165849968791008, 0.9525179862976074, 0.9956834316253662]\n\n\n\nmodel.evaluate(X_test_ct, y_test, verbose=0)\n\n[0.17626968026161194, 0.9417266249656677, 0.9978417158126831]"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#the-max_features-value",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#the-max_features-value",
    "title": "Natural Language Processing",
    "section": "The max_features value",
    "text": "The max_features value\n\nvect = CountVectorizer(max_features=10)\nvect.fit(X_train[\"SUMMARY_EN\"])\nvocab = vect.get_feature_names_out()\nlen(vocab)\n\n10\n\n\n\nprint(vocab)\n\n['and' 'driver' 'for' 'in' 'lane' 'of' 'the' 'to' 'vehicle' 'was']"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#remove-stop-words",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#remove-stop-words",
    "title": "Natural Language Processing",
    "section": "Remove stop words",
    "text": "Remove stop words\n\nvect = CountVectorizer(max_features=10, stop_words=\"english\")\nvect.fit(X_train[\"SUMMARY_EN\"])\nvocab = vect.get_feature_names_out()\nlen(vocab)\n\n10\n\n\n\nprint(vocab)\n\n['coded' 'crash' 'critical' 'driver' 'event' 'intersection' 'lane' 'left'\n 'roadway' 'vehicle']"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#keep-1000-most-frequent-words",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#keep-1000-most-frequent-words",
    "title": "Natural Language Processing",
    "section": "Keep 1,000 most frequent words",
    "text": "Keep 1,000 most frequent words\n\nvect = CountVectorizer(max_features=1_000, stop_words=\"english\")\nvect.fit(X_train[\"SUMMARY_EN\"])\nvocab = vect.get_feature_names_out()\nlen(vocab)\n\n1000\n\n\n\nprint(vocab[:5], vocab[len(vocab)//2:(len(vocab)//2 + 5)], vocab[-5:])\n\n['10' '105' '113' '12' '15'] ['interruption' 'intersected' 'intersecting' 'intersection' 'interstate'] ['year' 'years' 'yellow' 'yield' 'zone']\n\n\nCreate the X matrices:\n\nX_train_ct = vectorise_dataset(X_train, vect)\nX_val_ct = vectorise_dataset(X_val, vect)\nX_test_ct = vectorise_dataset(X_test, vect)"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#check-the-input-matrix-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#check-the-input-matrix-1",
    "title": "Natural Language Processing",
    "section": "Check the input matrix",
    "text": "Check the input matrix\n\nvectorise_dataset(X_train, vect, dataframe=True)\n\n\n\n\n\n\n\n\n10\n105\n113\n12\n15\n150\n16\n17\n18\n180\n...\nyield\nzone\nWEATHER1\nWEATHER2\nWEATHER3\nWEATHER4\nWEATHER5\nWEATHER6\nWEATHER7\nWEATHER8\n\n\n\n\n2532\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6209\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2561\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n6882\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n206\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6356\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n4169 rows × 1008 columns"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#make-inspect-the-model",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#make-inspect-the-model",
    "title": "Natural Language Processing",
    "section": "Make & inspect the model",
    "text": "Make & inspect the model\n\nnum_features = X_train_ct.shape[1]\nmodel = build_model(num_features, num_cats)\nmodel.summary()\n\nModel: \"sequential_1\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ dense_2 (Dense)                 │ (None, 100)               │    100,900 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_3 (Dense)                 │ (None, 3)                 │        303 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 101,203 (395.32 KB)\n\n\n\n Trainable params: 101,203 (395.32 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#fit-evaluate-the-model-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#fit-evaluate-the-model-1",
    "title": "Natural Language Processing",
    "section": "Fit & evaluate the model",
    "text": "Fit & evaluate the model\n\nes = EarlyStopping(patience=1, restore_best_weights=True,\n    monitor=\"val_accuracy\", verbose=2)\n%time hist = model.fit(X_train_ct, y_train, epochs=10, \\\n    callbacks=[es], validation_data=(X_val_ct, y_val), verbose=0);\n\nEpoch 2: early stopping\nRestoring model weights from the end of the best epoch: 1.\nCPU times: user 767 ms, sys: 0 ns, total: 767 ms\nWall time: 766 ms\n\n\n\nmodel.evaluate(X_train_ct, y_train, verbose=0)\n\n[0.1617761105298996, 0.9573038816452026, 0.9988006949424744]\n\n\n\nmodel.evaluate(X_val_ct, y_val, verbose=0)\n\n[0.23044553399085999, 0.9258992671966553, 0.9942445755004883]"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#keep-1000-most-frequent-words-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#keep-1000-most-frequent-words-1",
    "title": "Natural Language Processing",
    "section": "Keep 1,000 most frequent words",
    "text": "Keep 1,000 most frequent words\n\nvect = CountVectorizer(max_features=1_000, stop_words=\"english\")\nvect.fit(X_train[\"SUMMARY_EN\"])\nvocab = vect.get_feature_names_out()\nlen(vocab)\n\n1000\n\n\n\nprint(vocab[:5], vocab[len(vocab)//2:(len(vocab)//2 + 5)], vocab[-5:])\n\n['10' '105' '113' '12' '15'] ['interruption' 'intersected' 'intersecting' 'intersection' 'interstate'] ['year' 'years' 'yellow' 'yield' 'zone']"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#install-spacy",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#install-spacy",
    "title": "Natural Language Processing",
    "section": "Install spacy",
    "text": "Install spacy\n\n!pip install spacy\n!python -m spacy download en_core_web_sm\n\n\nimport spacy\n\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\nfor token in doc:\n    print(token.text, token.pos_, token.dep_)\n\nApple PROPN nsubj\nis AUX aux\nlooking VERB ROOT\nat ADP prep\nbuying VERB pcomp\nU.K. PROPN dobj\nstartup NOUN dobj\nfor ADP prep\n$ SYM quantmod\n1 NUM compound\nbillion NUM pobj"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#lemmatize-the-text",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#lemmatize-the-text",
    "title": "Natural Language Processing",
    "section": "Lemmatize the text",
    "text": "Lemmatize the text\n\ndef lemmatize(txt):\n    doc = nlp(txt)\n    good_tokens = [token.lemma_.lower() for token in doc \\\n        if not token.like_num and \\\n           not token.is_punct and \\\n           not token.is_space and \\\n           not token.is_currency and \\\n           not token.is_stop]\n    return \" \".join(good_tokens)\n\n\ntest_str = \"Incident at 100kph and '10 incidents -13.3%' are incidental?\\t $5\"\nlemmatize(test_str)\n\n'incident 100kph incident incidental'\n\n\n\ntest_str = \"I interviewed 5-years ago, 150 interviews every year at 10:30 are..\"\nlemmatize(test_str)\n\n'interview year ago interview year 10:30'"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#apply-to-the-whole-dataset",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#apply-to-the-whole-dataset",
    "title": "Natural Language Processing",
    "section": "Apply to the whole dataset",
    "text": "Apply to the whole dataset\n\ndf[\"SUMMARY_EN_LEMMA\"] = df[\"SUMMARY_EN\"].map(lemmatize)\n\n\nweather_cols = [f\"WEATHER{i}\" for i in range(1, 9)]\nfeatures = df[[\"SUMMARY_EN_LEMMA\"] + weather_cols]\n\nX_main, X_test, y_main, y_test = \\\n    train_test_split(features, target, test_size=0.2, random_state=1)\n\n# As 0.25 x 0.8 = 0.2\nX_train, X_val, y_train, y_val = \\\n    train_test_split(X_main, y_main, test_size=0.25, random_state=1)\n\nX_train.shape, X_val.shape, X_test.shape\n\n((4169, 9), (1390, 9), (1390, 9))"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#keep-1000-most-frequent-lemmas",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#keep-1000-most-frequent-lemmas",
    "title": "Natural Language Processing",
    "section": "Keep 1,000 most frequent lemmas",
    "text": "Keep 1,000 most frequent lemmas\n\nvect = CountVectorizer(max_features=1_000, stop_words=\"english\")\nvect.fit(X_train[\"SUMMARY_EN_LEMMA\"])\nvocab = vect.get_feature_names_out()\nlen(vocab)\n\n1000\n\n\n\nprint(vocab[:5], vocab[len(vocab)//2:(len(vocab)//2 + 5)], vocab[-5:])\n\n['10' '150' '48kmph' '4x4' '56kmph'] ['let' 'level' 'lexus' 'license' 'light'] ['yaw' 'year' 'yellow' 'yield' 'zone']\n\n\nCreate the X matrices:\n\nX_train_ct = vectorise_dataset(X_train, vect, \"SUMMARY_EN_LEMMA\")\nX_val_ct = vectorise_dataset(X_val, vect, \"SUMMARY_EN_LEMMA\")\nX_test_ct = vectorise_dataset(X_test, vect, \"SUMMARY_EN_LEMMA\")"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#check-the-input-matrix-2",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#check-the-input-matrix-2",
    "title": "Natural Language Processing",
    "section": "Check the input matrix",
    "text": "Check the input matrix\n\nvectorise_dataset(X_train, vect, \"SUMMARY_EN_LEMMA\", dataframe=True)\n\n\n\n\n\n\n\n\n10\n150\n48kmph\n4x4\n56kmph\n64kmph\n72kmph\nability\nable\naccelerate\n...\nyield\nzone\nWEATHER1\nWEATHER2\nWEATHER3\nWEATHER4\nWEATHER5\nWEATHER6\nWEATHER7\nWEATHER8\n\n\n\n\n2532\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6209\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2561\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n6882\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n206\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6356\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n4169 rows × 1008 columns"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#make-inspect-the-model-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#make-inspect-the-model-1",
    "title": "Natural Language Processing",
    "section": "Make & inspect the model",
    "text": "Make & inspect the model\n\nnum_features = X_train_ct.shape[1]\nmodel = build_model(num_features, num_cats)\nmodel.summary()\n\nModel: \"sequential_2\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ dense_4 (Dense)                 │ (None, 100)               │    100,900 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_5 (Dense)                 │ (None, 3)                 │        303 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 101,203 (395.32 KB)\n\n\n\n Trainable params: 101,203 (395.32 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#fit-evaluate-the-model-2",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#fit-evaluate-the-model-2",
    "title": "Natural Language Processing",
    "section": "Fit & evaluate the model",
    "text": "Fit & evaluate the model\n\nes = EarlyStopping(patience=1, restore_best_weights=True,\n    monitor=\"val_accuracy\", verbose=2)\n%time hist = model.fit(X_train_ct, y_train, epochs=10, \\\n    callbacks=[es], validation_data=(X_val_ct, y_val), verbose=0);\n\nEpoch 2: early stopping\nRestoring model weights from the end of the best epoch: 1.\nCPU times: user 772 ms, sys: 55 µs, total: 773 ms\nWall time: 772 ms\n\n\n\nmodel.evaluate(X_train_ct, y_train, verbose=0)\n\n[0.1704728752374649, 0.9573038816452026, 0.9988006949424744]\n\n\n\nmodel.evaluate(X_val_ct, y_val, verbose=0)\n\n[0.2595383822917938, 0.9136690497398376, 0.9942445755004883]"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#permutation-importance-algorithm",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#permutation-importance-algorithm",
    "title": "Natural Language Processing",
    "section": "Permutation importance algorithm",
    "text": "Permutation importance algorithm\nTaken directly from scikit-learn documentation:\n\nInputs: fitted predictive model m, tabular dataset (training or validation) D.\nCompute the reference score s of the model m on data D (for instance the accuracy for a classifier or the R^2 for a regressor).\nFor each feature j (column of D):\n\nFor each repetition k in {1, \\dots, K}:\n\nRandomly shuffle column j of dataset D to generate a corrupted version of the data named \\tilde{D}_{k,j}.\nCompute the score s_{k,j} of model m on corrupted data \\tilde{D}_{k,j}.\n\nCompute importance i_j for feature f_j defined as:\n i_j = s - \\frac{1}{K} \\sum_{k=1}^{K} s_{k,j} \n\n\n\nSource: scikit-learn documentation, permutation_importance function."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#find-important-inputs",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#find-important-inputs",
    "title": "Natural Language Processing",
    "section": "Find important inputs",
    "text": "Find important inputs\n\ndef permutation_test(model, X, y, num_reps=1, seed=42):\n    \"\"\"\n    Run the permutation test for variable importance.\n    Returns matrix of shape (X.shape[1], len(model.evaluate(X, y))).\n    \"\"\"\n    rnd.seed(seed)\n    scores = []    \n\n    for j in range(X.shape[1]):\n        original_column = np.copy(X[:, j])\n        col_scores = []\n\n        for r in range(num_reps):\n            rnd.shuffle(X[:,j])\n            col_scores.append(model.evaluate(X, y, verbose=0))\n\n        scores.append(np.mean(col_scores, axis=0))\n        X[:,j] = original_column\n    \n    return np.array(scores)"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#run-the-permutation-test",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#run-the-permutation-test",
    "title": "Natural Language Processing",
    "section": "Run the permutation test",
    "text": "Run the permutation test\n\nperm_scores = permutation_test(model, X_val_ct, y_val)[:,1]\nplt.plot(perm_scores);\nplt.xlabel(\"Input index\"); plt.ylabel(\"Accuracy when shuffled\");"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#find-the-most-significant-inputs",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#find-the-most-significant-inputs",
    "title": "Natural Language Processing",
    "section": "Find the most significant inputs",
    "text": "Find the most significant inputs\n\nvocab = vect.get_feature_names_out()\ninput_cols = list(vocab) + weather_cols\n\nbest_input_inds = np.argsort(perm_scores)[:100]\nbest_inputs = [input_cols[idx] for idx in best_input_inds]\n\nprint(best_inputs)\n\n['harmful', 'involve', 'event', 'lane', 'rear', 'code', 'single', 'year', 'park', 'edge', 'traffic', 'medication', 'north', 'dry', 'cross', 'impact', 'asphalt', 'male', 'barrier', 'motor', 'intersection', 'critical', 'tree', 'try', 'drive', 'turn', 'afternoon', 'direction', 'familiar', 'female', 'pickup', 'line', 'WEATHER4', 'light', 'WEATHER2', 'reason', 'assign', 'undivided', 'look', 'car', 'southbound', 'legally', 'control', 'kmph', 'occur', 'overcompensation', 'curb', 'rush', 'strike', 'quarter', 'WEATHER8', 'weekday', 'WEATHER5', 'complete', 'counterclockwise', 'forward', 'street', 'recognition', 'transport', 'bind', 'driver', 'kph', 'wall', 'old', 'bmw', 'action', 'change', 'pedestrian', 'distraction', 'grassy', 'sideswipe', 'directional', 'ground', 'shoulder', 'past', 'help', 'route', 'decelerate', 'hear', 'stop', 'realize', 'weekly', 'encroachment', 'contact', 'pre', 'WEATHER7', 'ford', 'lexus', 'continue', 'lot', 'push', 'exist', 'contribute', 'cloudy', 'close', 'force', 'failure', 'poor', 'shopping', 'northeast']"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#how-about-a-simple-decision-tree",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#how-about-a-simple-decision-tree",
    "title": "Natural Language Processing",
    "section": "How about a simple decision tree?",
    "text": "How about a simple decision tree?\n\nfrom sklearn import tree\nclf = tree.DecisionTreeClassifier(random_state=0, max_leaf_nodes=3)\nclf.fit(X_train_ct[:, best_input_inds], y_train);\n\n\nprint(clf.score(X_train_ct[:, best_input_inds], y_train))\nprint(clf.score(X_val_ct[:, best_input_inds], y_val))\n\n0.920844327176781\n0.9330935251798561"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#decision-tree",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#decision-tree",
    "title": "Natural Language Processing",
    "section": "Decision tree",
    "text": "Decision tree\n\ntree.plot_tree(clf, feature_names=best_inputs, filled=True);\n\n\n\nprint(np.where(clf.feature_importances_ &gt; 0)[0])\n[best_inputs[ind] for ind in np.where(clf.feature_importances_ &gt; 0)[0]]\n\n[ 0 35]\n\n\n['harmful', 'reason']"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#using-the-original-dataset",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#using-the-original-dataset",
    "title": "Natural Language Processing",
    "section": "Using the original dataset",
    "text": "Using the original dataset\n\nperm_scores = permutation_test(model, X_val_ct, y_val)[:,1]\nplt.plot(perm_scores);\nplt.xlabel(\"Input index\"); plt.ylabel(\"Accuracy when shuffled\");"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#find-the-most-significant-inputs-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#find-the-most-significant-inputs-1",
    "title": "Natural Language Processing",
    "section": "Find the most significant inputs",
    "text": "Find the most significant inputs\n\nvocab = vect.get_feature_names_out()\ninput_cols = list(vocab) + weather_cols\n\nbest_input_inds = np.argsort(perm_scores)[:100]\nbest_inputs = [input_cols[idx] for idx in best_input_inds]\n\nprint(best_inputs)\n\n['v3', 'v2', 'involved', 'road', 'coded', 'impact', 'harmful', 'parked', 'WEATHER3', 'event', 'edge', 'v4', 'single', 'year', 'bituminous', 'WEATHER8', 'conditions', 'pushed', 'legally', 'came', 'vehicle', 'line', 'WEATHER5', 'WEATHER4', 'crash', 'WEATHER1', 'towed', 'cm', 'downhill', 'generally', 'highway', 'slope', 'higher', 'straight', 'brake', 'stopped', 'direction', 'occurred', 'critical', 'turning', 'WEATHER7', 'looked', 'way', 'trailer', 'let', 'driven', 'wet', 'precrash', 'location', 'went', 'light', 'continued', 'sign', 'motor', 'controlled', 'barrier', '30', 'illegal', 'events', 'steer', 'police', 'exit', 'steering', 'curve', 'daily', 'damage', 'failed', 'headed', 'route', 'northbound', 'poor', 'blazer', 'avoid', 'near', 'facing', 'posted', 'belted', 'cadillac', 'non', '1998', 'nissan', 'began', 'suffered', 'hearing', 'curb', 'right', 'picked', 'sedan', 'outside', 'fast', 'conversation', 'skidded', 'free', 'ford', 'setting', 'comprised', 'seven', 'condition', 'flow', 'passengers']"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#how-about-a-simple-decision-tree-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#how-about-a-simple-decision-tree-1",
    "title": "Natural Language Processing",
    "section": "How about a simple decision tree?",
    "text": "How about a simple decision tree?\n\nclf = tree.DecisionTreeClassifier(random_state=0, max_leaf_nodes=3)\nclf.fit(X_train_ct[:, best_input_inds], y_train);\n\n\nprint(clf.score(X_train_ct[:, best_input_inds], y_train))\nprint(clf.score(X_val_ct[:, best_input_inds], y_val))\n\n0.9275605660829935\n0.939568345323741"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#decision-tree-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#decision-tree-1",
    "title": "Natural Language Processing",
    "section": "Decision tree",
    "text": "Decision tree\n\ntree.plot_tree(clf, feature_names=best_inputs, filled=True);\n\n\n\nprint(np.where(clf.feature_importances_ &gt; 0)[0])\n[best_inputs[ind] for ind in np.where(clf.feature_importances_ &gt; 0)[0]]\n\n[ 0 38]\n\n\n['v3', 'critical']"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#overview",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#overview",
    "title": "Natural Language Processing",
    "section": "Overview",
    "text": "Overview\n\nIn order for deep learning models to process language, we need to supply that language to the model in a way it can digest, i.e. a quantitative representation such as a 2-D matrix of numerical values.\n\n\n\nPopular methods for converting text into numbers include:\n\nOne-hot encoding\nBag of words\nTF-IDF\nWord vectors (transfer learning)\n\n\n\n\n\nAssigning Numbers\n\n\n\n\n\nSource: Randall Munroe (2022), xkcd #2610: Assigning Numbers."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#word-vectors",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#word-vectors",
    "title": "Natural Language Processing",
    "section": "Word Vectors",
    "text": "Word Vectors\n\nOne-hot representations capture word ‘existence’ only, whereas word vectors capture information about word meaning as well as location.\nThis enables deep learning NLP models to automatically learn linguistic features.\nWord2Vec & GloVe are popular algorithms for generating word embeddings (i.e. word vectors)."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#word-vectors-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#word-vectors-1",
    "title": "Natural Language Processing",
    "section": "Word Vectors",
    "text": "Word Vectors\n\nIllustrative word vectors.\n\nOverarching concept is to assign each word within a corpus to a particular, meaningful location within a multidimensional space called the vector space.\nInitially each word is assigned to a random location.\nBUT by considering the words that tend to be used around a given word within the corpus, the locations of the words shift.\n\n\n\nSource: Krohn (2019), Deep Learning Illustrated, Figure 2-6."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#remember-this-diagram",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#remember-this-diagram",
    "title": "Natural Language Processing",
    "section": "Remember this diagram?",
    "text": "Remember this diagram?\n\nEmbeddings will gradually improve during training.\nSource: Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Figure 13-4."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#word2vec",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#word2vec",
    "title": "Natural Language Processing",
    "section": "Word2Vec",
    "text": "Word2Vec\nKey idea: You’re known by the company you keep.\nTwo algorithms are used to calculate embeddings:\n\nContinuous bag of words: uses the context words to predict the target word\nSkip-gram: uses the target word to predict the context words\n\nPredictions are made using a neural network with one hidden layer. Through backpropagation, we update a set of “weights” which become the word vectors.\n\nPaper: Mikolov et al. (2013), Efficient estimation of word representations in vector space, arXiv:1301.3781."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#word2vec-training-methods",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#word2vec-training-methods",
    "title": "Natural Language Processing",
    "section": "Word2Vec training methods",
    "text": "Word2Vec training methods\n\n\n\nContinuous bag of words is a center word prediction task\n\n\n\n\n\nSkip-gram is a neighbour word prediction task\n\n\n\n\n\n\n\n\nSuggested viewing\n\n\nComputerphile (2019), Vectoring Words (Word Embeddings), YouTube (16 mins).\n\n\n\n\nSource: Amit Chaudhary (2020), Self Supervised Representation Learning in NLP."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#the-skip-gram-network",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#the-skip-gram-network",
    "title": "Natural Language Processing",
    "section": "The skip-gram network",
    "text": "The skip-gram network\n\nThe skip-gram model. Both the input vector \\boldsymbol{x} and the output \\boldsymbol{y} are one-hot encoded word representations. The hidden layer is the word embedding of size N.\nSource: Lilian Weng (2017), Learning Word Embedding, Blog post, Figure 1."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#word-vector-arithmetic",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#word-vector-arithmetic",
    "title": "Natural Language Processing",
    "section": "Word Vector Arithmetic",
    "text": "Word Vector Arithmetic\n\n\nRelationships between words becomes vector math.\n\n\n\nYou remember vectors, right?\n\n\n\n\nE.g., if we calculate the direction and distance between the coordinates of the words Paris and France, and trace this direction and distance from London, we should be close to the word England.\n\n\n\n\n\n\nIllustrative word vector arithmetic\n\n\n\n\n\nScreenshot from Word2viz\n\n\n\n\n\nSources: PressBooks, College Physics: OpenStax, Chapter 17 Figure 9, and Krohn (2019), Deep Learning Illustrated, Figures 2-7 & 2-8."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#pretrained-word-embeddings",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#pretrained-word-embeddings",
    "title": "Natural Language Processing",
    "section": "Pretrained word embeddings",
    "text": "Pretrained word embeddings\n\n!pip install gensim\n\nLoad word2vec embeddings trained on Google News:\n\nimport gensim.downloader as api\nwv = api.load('word2vec-google-news-300')\n\nWhen run for the first time, that downloads a huge file:\n\ngensim_dir = Path(\"~/gensim-data/\").expanduser()\n[str(p) for p in gensim_dir.iterdir()]\n\n['/home/plaub/gensim-data/information.json',\n '/home/plaub/gensim-data/word2vec-google-news-300']\n\n\n\nnext(gensim_dir.glob(\"*/*.gz\")).stat().st_size / 1024**3\n\n1.6238203644752502\n\n\n\nf\"The size of the vocabulary is {len(wv)}\"\n\n'The size of the vocabulary is 3000000'"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#treat-wv-like-a-dictionary",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#treat-wv-like-a-dictionary",
    "title": "Natural Language Processing",
    "section": "Treat wv like a dictionary",
    "text": "Treat wv like a dictionary\n\nwv[\"pizza\"]\n\narray([-1.26e-01,  2.54e-02,  1.67e-01,  5.51e-01, -7.67e-02,  1.29e-01,\n        1.03e-01, -3.95e-04,  1.22e-01,  4.32e-02,  1.73e-01, -6.84e-02,\n        3.42e-01,  8.40e-02,  6.69e-02,  2.68e-01, -3.71e-02, -5.57e-02,\n        1.81e-01,  1.90e-02, -5.08e-02,  9.03e-03,  1.77e-01,  6.49e-02,\n       -6.25e-02, -9.42e-02, -9.72e-02,  4.00e-01,  1.15e-01,  1.03e-01,\n       -1.87e-02, -2.70e-01,  1.81e-01,  1.25e-01, -3.17e-02, -5.49e-02,\n        3.46e-01, -1.57e-02,  1.82e-05,  2.07e-01, -1.26e-01, -2.83e-01,\n        2.00e-01,  8.35e-02, -4.74e-02, -3.11e-02, -2.62e-01,  1.70e-01,\n       -2.03e-02,  1.53e-01, -1.21e-01,  3.75e-01, -5.69e-02, -4.76e-03,\n       -1.95e-01, -2.03e-01,  3.01e-01, -1.01e-01, -3.18e-01, -9.03e-02,\n       -1.19e-01,  1.95e-01, -8.79e-02,  1.58e-01,  1.52e-02, -1.60e-01,\n       -3.30e-01, -4.67e-01,  1.69e-01,  2.23e-02,  1.55e-01,  1.08e-01,\n       -3.56e-02,  9.13e-02, -8.69e-02, -1.20e-01, -3.09e-01, -2.61e-02,\n       -7.23e-02, -4.80e-01,  3.78e-02, -1.36e-01, -1.03e-01, -2.91e-01,\n       -1.93e-01, -4.22e-01, -1.06e-01,  3.55e-01,  1.67e-01, -3.63e-03,\n       -7.42e-02, -3.22e-01, -7.52e-02, -8.25e-02, -2.91e-01, -1.26e-01,\n        1.68e-02,  5.00e-02,  1.28e-01, -7.42e-02, -1.31e-01, -2.46e-01,\n        6.49e-02,  1.53e-01,  2.60e-01, -1.05e-01,  3.57e-01, -4.30e-02,\n       -1.58e-01,  8.20e-02, -5.98e-02, -2.34e-01, -3.22e-01, -1.26e-01,\n        5.40e-02, -1.88e-01,  1.36e-01, -6.59e-02,  8.36e-03, -1.85e-01,\n       -2.97e-01, -1.85e-01, -4.74e-02, -1.06e-01, -6.93e-02,  3.83e-02,\n       -3.20e-02,  3.64e-02, -1.20e-01,  1.77e-01, -1.16e-01,  1.99e-02,\n        8.64e-02,  6.08e-02, -1.41e-01,  3.30e-01,  1.94e-01, -1.56e-01,\n        3.93e-01,  1.81e-03,  7.28e-02, -2.54e-01, -3.54e-02,  2.87e-03,\n       -1.73e-01,  9.77e-03, -1.56e-02,  3.23e-03, -1.70e-01,  1.55e-01,\n        7.18e-02,  4.10e-01, -2.11e-01,  1.32e-01,  7.63e-03,  4.79e-02,\n       -4.54e-02,  7.32e-02, -4.06e-01, -2.06e-02, -4.04e-01, -1.01e-01,\n       -2.03e-01,  1.55e-01, -1.89e-01,  6.59e-02,  6.54e-02, -2.05e-01,\n        5.47e-02, -3.06e-02, -1.54e-01, -2.62e-01,  3.81e-03, -8.20e-02,\n       -3.20e-01,  2.84e-02,  2.70e-01,  1.74e-01, -1.67e-01,  2.23e-01,\n        6.35e-02, -1.96e-01,  1.46e-01, -1.56e-02,  2.60e-02, -6.30e-02,\n        2.94e-02,  3.28e-01, -4.69e-02, -1.52e-01,  6.98e-02,  3.18e-01,\n       -1.08e-01,  3.66e-02, -1.99e-01,  1.64e-03,  6.41e-03, -1.47e-01,\n       -6.25e-02, -4.36e-03, -2.75e-01,  8.54e-02, -5.00e-02, -3.12e-01,\n       -1.34e-01, -1.99e-01,  5.18e-02, -9.28e-02, -2.40e-01, -7.86e-02,\n       -1.54e-01, -6.64e-02, -1.97e-01,  1.77e-01, -1.57e-01, -1.63e-01,\n        6.01e-02, -5.86e-02, -2.23e-01, -6.59e-02, -9.38e-02, -4.14e-01,\n        2.56e-01, -1.77e-01,  2.52e-01,  1.48e-01, -1.04e-01, -8.61e-03,\n       -1.23e-01, -9.23e-02,  4.42e-02, -1.71e-01, -1.98e-01,  1.92e-01,\n        2.85e-01, -4.35e-02,  1.08e-01, -5.37e-02, -2.10e-02,  1.46e-01,\n        3.83e-01,  2.32e-02, -8.84e-02,  7.32e-02, -1.01e-01, -1.06e-01,\n        4.12e-01,  2.11e-01,  2.79e-01, -2.09e-02,  2.07e-01,  9.81e-02,\n        2.39e-01,  7.67e-02,  2.02e-01, -6.08e-02, -2.64e-03, -1.84e-01,\n       -1.57e-02, -3.20e-01,  9.03e-02,  1.02e-01, -4.96e-01, -9.72e-02,\n       -8.11e-02, -1.81e-01, -1.46e-01,  8.64e-02, -2.04e-01, -2.02e-01,\n       -5.47e-02,  2.54e-01,  2.09e-02, -1.16e-01,  2.02e-01, -8.06e-02,\n       -1.05e-01, -7.96e-02,  1.97e-02, -2.49e-01,  1.31e-01,  2.89e-01,\n       -2.26e-01,  4.55e-01, -2.73e-01, -2.58e-01, -3.15e-02,  4.04e-01,\n       -2.68e-01,  2.89e-01, -1.84e-01, -1.48e-01, -1.07e-01,  1.28e-01,\n        5.47e-01, -8.69e-02, -1.48e-02,  6.98e-02, -8.50e-02, -1.55e-01],\n      dtype=float32)\n\n\n\nlen(wv[\"pizza\"])\n\n300"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#find-nearby-word-vectors",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#find-nearby-word-vectors",
    "title": "Natural Language Processing",
    "section": "Find nearby word vectors",
    "text": "Find nearby word vectors\n\nwv.most_similar(\"Python\")\n\n[('Jython', 0.6152505874633789),\n ('Perl_Python', 0.5710949897766113),\n ('IronPython', 0.5704679489135742),\n ('scripting_languages', 0.5695090889930725),\n ('PHP_Perl', 0.5687724947929382),\n ('Java_Python', 0.5681070685386658),\n ('PHP', 0.5660915970802307),\n ('Python_Ruby', 0.5632461905479431),\n ('Visual_Basic', 0.5603480339050293),\n ('Perl', 0.5530891418457031)]\n\n\n\nwv.similarity(\"Python\", \"Java\")\n\n0.46189708\n\n\n\nwv.similarity(\"Python\", \"sport\")\n\n0.08406468\n\n\n\nwv.similarity(\"Python\", \"R\")\n\n0.066954285\n\n\n\nFun fact: Gensim’s most_similar uses Spotify’s annoy library (“Approximate Nearest Neighbors Oh Yeah”)"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#what-does-similarity-mean",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#what-does-similarity-mean",
    "title": "Natural Language Processing",
    "section": "What does ‘similarity’ mean?",
    "text": "What does ‘similarity’ mean?\nThe ‘similarity’ scores\n\nwv.similarity(\"Sydney\", \"Melbourne\")\n\n0.8613987\n\n\nare normally based on cosine distance.\n\nx = wv[\"Sydney\"]\ny = wv[\"Melbourne\"]\nx.dot(y) / (np.linalg.norm(x) * np.linalg.norm(y))\n\n0.86139864\n\n\n\nwv.similarity(\"Sydney\", \"Aarhus\")\n\n0.19079602"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#wengs-got-word2vec",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#wengs-got-word2vec",
    "title": "Natural Language Processing",
    "section": "Weng’s GoT Word2Vec",
    "text": "Weng’s GoT Word2Vec\nIn the GoT word embedding space, the top similar words to “king” and “queen” are:\n\n\nmodel.most_similar('king')\n('kings', 0.897245) \n('baratheon', 0.809675) \n('son', 0.763614)\n('robert', 0.708522)\n('lords', 0.698684)\n('joffrey', 0.696455)\n('prince', 0.695699)\n('brother', 0.685239)\n('aerys', 0.684527)\n('stannis', 0.682932)\n\nmodel.most_similar('queen')\n('cersei', 0.942618)\n('joffrey', 0.933756)\n('margaery', 0.931099)\n('sister', 0.928902)\n('prince', 0.927364)\n('uncle', 0.922507)\n('varys', 0.918421)\n('ned', 0.917492)\n('melisandre', 0.915403)\n('robb', 0.915272)\n\n\n\nSource: Lilian Weng (2017), Learning Word Embedding, Blog post."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#combining-word-vectors",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#combining-word-vectors",
    "title": "Natural Language Processing",
    "section": "Combining word vectors",
    "text": "Combining word vectors\nYou can summarise a sentence by averaging the individual word vectors.\n\nsv = (wv[\"Melbourne\"] + wv[\"has\"] + wv[\"better\"] + wv[\"coffee\"]) / 4\nlen(sv), sv[:5]\n\n(300, array([-0.08, -0.11, -0.16,  0.24,  0.06], dtype=float32))\n\n\n\nAs it turns out, averaging word embeddings is a surprisingly effective way to create word embeddings. It’s not perfect (as you’ll see), but it does a strong job of capturing what you might perceive to be complex relationships between words.\n\n\nSource: Trask (2019), Grokking Deep Learning, Chapter 12."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#recipe-recommender",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#recipe-recommender",
    "title": "Natural Language Processing",
    "section": "Recipe recommender",
    "text": "Recipe recommender\n\n\n\n\n\nRecipes are the average of the word vectors of the ingredients.\n\n\n\n\n\n\nNearest neighbours used to classify new recipes as potentially delicious.\n\n\n\n\n\nSource: Duarte O.Carmo (2022), A recipe recommendation system, Blog post."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#analogies-with-word-vectors",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#analogies-with-word-vectors",
    "title": "Natural Language Processing",
    "section": "Analogies with word vectors",
    "text": "Analogies with word vectors\nObama is to America as ___ is to Australia.\n\n \\text{Obama} - \\text{America} + \\text{Australia} = ? \n\n\n\nwv.most_similar(positive=[\"Obama\", \"Australia\"], negative=[\"America\"])\n\n[('Mr_Rudd', 0.6151423454284668),\n ('Prime_Minister_Julia_Gillard', 0.6045385003089905),\n ('Prime_Minister_Kevin_Rudd', 0.5982581973075867),\n ('Kevin_Rudd', 0.5627648830413818),\n ('Ms_Gillard', 0.5517690777778625),\n ('Opposition_Leader_Kevin_Rudd', 0.5298037528991699),\n ('Mr_Beazley', 0.5259249210357666),\n ('Gillard', 0.5250653624534607),\n ('NARDA_GILMORE', 0.5203536748886108),\n ('Mr_Downer', 0.5150347948074341)]"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#testing-more-associations",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#testing-more-associations",
    "title": "Natural Language Processing",
    "section": "Testing more associations",
    "text": "Testing more associations\n\nwv.most_similar(positive=[\"France\", \"London\"], negative=[\"Paris\"])\n\n[('Britain', 0.7368935346603394),\n ('UK', 0.6637030839920044),\n ('England', 0.6119861602783203),\n ('United_Kingdom', 0.6067784428596497),\n ('Great_Britain', 0.5870823860168457),\n ('Britian', 0.5852951407432556),\n ('Scotland', 0.5410018563270569),\n ('British', 0.5318332314491272),\n ('Europe', 0.5307435989379883),\n ('East_Midlands', 0.5230222344398499)]"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#quickly-get-to-bad-associations",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#quickly-get-to-bad-associations",
    "title": "Natural Language Processing",
    "section": "Quickly get to bad associations",
    "text": "Quickly get to bad associations\n\nwv.most_similar(positive=[\"King\", \"woman\"], negative=[\"man\"])\n\n[('Queen', 0.5515626668930054),\n ('Oprah_BFF_Gayle', 0.47597548365592957),\n ('Geoffrey_Rush_Exit', 0.46460166573524475),\n ('Princess', 0.4533674716949463),\n ('Yvonne_Stickney', 0.4507041573524475),\n ('L._Bonauto', 0.4422135353088379),\n ('gal_pal_Gayle', 0.4408389925956726),\n ('Alveda_C.', 0.4402790665626526),\n ('Tupou_V.', 0.4373864233493805),\n ('K._Letourneau', 0.4351031482219696)]\n\n\n\nwv.most_similar(positive=[\"computer_programmer\", \"woman\"], negative=[\"man\"])\n\n[('homemaker', 0.5627118945121765),\n ('housewife', 0.5105047225952148),\n ('graphic_designer', 0.505180299282074),\n ('schoolteacher', 0.497949481010437),\n ('businesswoman', 0.493489146232605),\n ('paralegal', 0.49255111813545227),\n ('registered_nurse', 0.4907974898815155),\n ('saleswoman', 0.4881627559661865),\n ('electrical_engineer', 0.4797725975513458),\n ('mechanical_engineer', 0.4755399227142334)]"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#bias-in-nlp-models",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#bias-in-nlp-models",
    "title": "Natural Language Processing",
    "section": "Bias in NLP models",
    "text": "Bias in NLP models\n\n\n\nThe Verge (2016), Twitter taught Microsoft’s AI chatbot to be a racist a****** in less than a day.\n\n\n… there are serious questions to answer, like how are we going to teach AI using public data without incorporating the worst traits of humanity? If we create bots that mirror their users, do we care if their users are human trash? There are plenty of examples of technology embodying — either accidentally or on purpose — the prejudices of society, and Tay’s adventures on Twitter show that even big corporations like Microsoft forget to take any preventative measures against these problems."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#the-library-cheats-a-little-bit",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#the-library-cheats-a-little-bit",
    "title": "Natural Language Processing",
    "section": "The library cheats a little bit",
    "text": "The library cheats a little bit\n\nwv.similar_by_vector(wv[\"computer_programmer\"]-wv[\"man\"]+wv[\"woman\"])\n\n[('computer_programmer', 0.910581111907959),\n ('homemaker', 0.5771316289901733),\n ('schoolteacher', 0.5500192046165466),\n ('graphic_designer', 0.5464698672294617),\n ('mechanical_engineer', 0.539836585521698),\n ('electrical_engineer', 0.5337055325508118),\n ('housewife', 0.5274525284767151),\n ('programmer', 0.5096209049224854),\n ('businesswoman', 0.5029540657997131),\n ('keypunch_operator', 0.4974639415740967)]\n\n\nTo get the ‘nice’ analogies, the .most_similar ignores the input words as possible answers.\n\n# ignore (don't return) keys from the input\nresult = [\n    (self.index_to_key[sim + clip_start], float(dists[sim]))\n    for sim in best if (sim + clip_start) not in all_keys\n]\n\n\nSource: gensim, gensim/models/keyedvectors.py, lines 853-857."
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#predict-injury-severity",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#predict-injury-severity",
    "title": "Natural Language Processing",
    "section": "Predict injury severity",
    "text": "Predict injury severity\n\nfeatures = df[\"SUMMARY_EN\"]\ntarget = LabelEncoder().fit_transform(df[\"INJSEVB\"])\n\nX_main, X_test, y_main, y_test = \\\n    train_test_split(features, target, test_size=0.2, random_state=1)\nX_train, X_val, y_train, y_val = \\\n    train_test_split(X_main, y_main, test_size=0.25, random_state=1)\nX_train.shape, X_val.shape, X_test.shape\n\n((4169,), (1390,), (1390,))"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#using-keras-textvectorization",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#using-keras-textvectorization",
    "title": "Natural Language Processing",
    "section": "Using Keras TextVectorization",
    "text": "Using Keras TextVectorization\n\nmax_tokens = 1_000\nvect = layers.TextVectorization(\n    max_tokens=max_tokens,\n    output_mode=\"tf_idf\",\n    standardize=\"lower_and_strip_punctuation\",\n)\n\nvect.adapt(X_train)\nvocab = vect.get_vocabulary()\n\nX_train_txt = vect(X_train)\nX_val_txt = vect(X_val)\nX_test_txt = vect(X_test)\n\nprint(vocab[:50])\n\n['[UNK]', 'the', 'was', 'a', 'to', 'of', 'and', 'in', 'driver', 'for', 'this', 'vehicle', 'critical', 'lane', 'he', 'on', 'with', 'that', 'left', 'roadway', 'coded', 'she', 'event', 'crash', 'not', 'at', 'intersection', 'traveling', 'right', 'precrash', 'as', 'from', 'were', 'by', 'had', 'reason', 'his', 'side', 'is', 'front', 'her', 'traffic', 'an', 'it', 'two', 'speed', 'stated', 'one', 'occurred', 'no']"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#the-tf-idf-vectors",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#the-tf-idf-vectors",
    "title": "Natural Language Processing",
    "section": "The TF-IDF vectors",
    "text": "The TF-IDF vectors\n\npd.DataFrame(X_train_txt, columns=vocab, index=X_train.index)\n\n\n\n\n\n\n\n\n[UNK]\nthe\nwas\na\nto\nof\nand\nin\ndriver\nfor\n...\nencroaching\nclosely\nordinarily\nlocked\nhistory\nfourleg\ndetermined\nbox\naltima\nabove\n\n\n\n\n2532\n121.857979\n42.274662\n10.395409\n10.395409\n11.785541\n8.323526\n8.323526\n9.775118\n3.489896\n4.168983\n...\n0.0\n0.0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n6209\n72.596237\n17.325682\n10.395409\n5.544218\n4.159603\n5.549018\n7.629900\n4.887559\n4.187876\n6.253474\n...\n0.0\n0.0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n2561\n124.450699\n30.493198\n15.246599\n11.088436\n9.012472\n7.629900\n8.323526\n2.792891\n3.489896\n5.558644\n...\n0.0\n0.0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n6882\n75.188965\n20.790817\n4.851191\n7.623300\n9.012472\n4.855391\n4.161763\n2.094668\n5.583834\n2.084491\n...\n0.0\n0.0\n3.61771\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n206\n147.785202\n27.028063\n13.167518\n6.237246\n8.319205\n4.855391\n6.242645\n2.094668\n3.489896\n9.032796\n...\n0.0\n0.0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n6356\n75.188965\n15.246599\n9.702381\n8.316327\n7.625938\n5.549018\n7.629900\n8.378673\n2.791917\n5.558644\n...\n0.0\n0.0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n4169 rows × 1000 columns"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#feed-tf-idf-into-an-ann",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#feed-tf-idf-into-an-ann",
    "title": "Natural Language Processing",
    "section": "Feed TF-IDF into an ANN",
    "text": "Feed TF-IDF into an ANN\n\nrandom.seed(42)\ntfidf_model = keras.models.Sequential([\n    layers.Input((X_train_txt.shape[1],)),\n    layers.Dense(250, \"relu\"),\n    layers.Dense(1, \"sigmoid\")\n])\n\ntfidf_model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\ntfidf_model.summary()\n\nModel: \"sequential_4\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ dense_8 (Dense)                 │ (None, 250)               │    250,250 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_9 (Dense)                 │ (None, 1)                 │        251 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 250,501 (978.52 KB)\n\n\n\n Trainable params: 250,501 (978.52 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#fit-evaluate",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#fit-evaluate",
    "title": "Natural Language Processing",
    "section": "Fit & evaluate",
    "text": "Fit & evaluate\n\nes = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True,\n    monitor=\"val_accuracy\", verbose=2)\n\nif not Path(\"tfidf-model.keras\").exists():\n    tfidf_model.fit(X_train_txt, y_train, epochs=1_000, callbacks=es,\n        validation_data=(X_val_txt, y_val), verbose=0)\n    tfidf_model.save(\"tfidf-model.keras\")\nelse:\n    tfidf_model = keras.models.load_model(\"tfidf-model.keras\")\n\n\ntfidf_model.evaluate(X_train_txt, y_train, verbose=0, batch_size=1_000)\n\n[0.0677284300327301, 0.9824662208557129]\n\n\n\ntfidf_model.evaluate(X_val_txt, y_val, verbose=0, batch_size=1_000)\n\n[0.34314268827438354, 0.8787692785263062]"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#keep-text-as-sequence-of-tokens",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#keep-text-as-sequence-of-tokens",
    "title": "Natural Language Processing",
    "section": "Keep text as sequence of tokens",
    "text": "Keep text as sequence of tokens\n\nmax_length = 500\nmax_tokens = 1_000\nvect = layers.TextVectorization(\n    max_tokens=max_tokens,\n    output_sequence_length=max_length,\n    standardize=\"lower_and_strip_punctuation\",\n)\n\nvect.adapt(X_train)\nvocab = vect.get_vocabulary()\n\nX_train_txt = vect(X_train)\nX_val_txt = vect(X_val)\nX_test_txt = vect(X_test)\n\nprint(vocab[:50])\n\n['', '[UNK]', 'the', 'was', 'a', 'to', 'of', 'and', 'in', 'driver', 'for', 'this', 'vehicle', 'critical', 'lane', 'he', 'on', 'with', 'that', 'left', 'roadway', 'coded', 'she', 'event', 'crash', 'not', 'at', 'intersection', 'traveling', 'right', 'precrash', 'as', 'from', 'were', 'by', 'had', 'reason', 'his', 'side', 'is', 'front', 'her', 'traffic', 'an', 'it', 'two', 'speed', 'stated', 'one', 'occurred']"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#a-sequence-of-integers",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#a-sequence-of-integers",
    "title": "Natural Language Processing",
    "section": "A sequence of integers",
    "text": "A sequence of integers\n\nX_train_txt[0]\n\ntensor([ 11,  24,  49,   8,   2, 253, 219,   6,   4, 165,   8,   2, 410,   6,\n          4, 564, 971,  27,   2,  27, 568,   6,   4, 192,   1,  45,  51, 208,\n         65, 235,  54,  14,  20, 867,  34,  43, 183,   1,  45,  51, 208,  65,\n        235,  54,  14,  20, 178,  34,   4, 676,   1,  42, 237,   2, 153, 192,\n         20,   3, 107,   7,  75,  17,   4, 612, 441, 549,   2,  88,  46,   3,\n        207,  63, 185,  55,   2,  42, 243,   3, 400,   7,  58,  33,  50, 172,\n        251,  84,  26,   2,  60,   6,   2,  24,   1,   4, 402, 970,   1,   1,\n          3,  68,  26,   2,  27,  94, 118,   8,  14, 101, 311,  10,   2, 237,\n          5, 422, 269,  44, 154,  54,  19,   1,   4, 308, 342,   1,   3,  79,\n          8,  14,  45, 159,   2, 121,  27, 190,  44, 598,   5, 325,  75,  70,\n          2, 105, 189, 231,   1, 241,  81,  19,  31,   1, 193,   2,  54,  81,\n          9, 134,   4, 174,  12,  17,   1, 390,   1, 159,   2,  27,  32,   2,\n        119,   1,  68,   8,   2, 410,   6,   2,  27,   8,   1,   5,   2, 159,\n        174,  12,   1, 168,   2,  27,   7,  69,   2,  40,   6,   1,  17,  81,\n         40,  19, 246,  73,  83,  64,   5, 129,  56,   8,   2,  27,   7,  33,\n         73,  71,  57,   5,  82,   2,   9,   6,   1,   4,   1,  59, 382,   5,\n        113,   8, 276, 258,   1, 317, 928, 284,  10, 784, 294, 462, 483,   7,\n          1,  15,   3,  16,  37, 112,   5, 677, 144,   1,  26,   2,  60,   6,\n          2,  24,  15,  47,  18,  70,   2, 105, 429,  15,  35, 448,   1,   5,\n        493,  37,  54,  62,  68,  25,   1,  33,   5, 325,  70,  15, 134,   2,\n        174, 232, 406,  15, 341, 134,   1, 691,   2,  27,   7,  15,   1,  10,\n         93,  15,   3,  25, 216,   8,   2,  24,   2,  13,  30,  23,  10,   1,\n          3,  21,  11,  12,  28,  76,   2,  14, 130,  19,  38,   6, 106,  14,\n          2,  13,  36,   3,  21,  31,   4,   9,  91, 180,   1, 137,   1,   2,\n         87,  97,  21,   5,   1, 285,  43,   1, 511, 569,  15, 775, 140,   1,\n          2,  27,   7,  25,  68,  31, 184,  31,   2, 159, 174,  12,   1,   2,\n         42,   1,   2,   9,   6,   1,   4,   1,  59,   8, 276, 258,   3, 489,\n         37, 753, 544,  10,   4, 975, 313,  26,   2,  60,   6,   2,  24,  15,\n          3,  16,  37, 112, 110,  32, 151,  70,   2,  24,  49,  15,  47,  15,\n          3,  79,   8,  14, 191,  31,   2,  42, 105, 189, 231,  15, 647,   2,\n         12,   8,   2,  19,  94, 118,  35,   1,   5,  54,  19,   7, 141,   2,\n         27,  15,   1,  31,   2,  12, 347,  81,  54,   7,  90,   8,   2, 410,\n          6,   2,  27,  15, 503,  62, 154,  25, 143,   1,  15, 157, 134,   2,\n        174,  12,  17,  81, 390,   7,   1,  16, 111,  15, 168,   2,  27,  15,\n        588, 329, 117,   7,   3, 163,   5, 113, 947, 175,  26,   4, 643,   1,\n          2,  13,  30,  23,  10,   1,   3,  21,  52,  12])"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#feed-lstm-a-sequence-of-one-hots",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#feed-lstm-a-sequence-of-one-hots",
    "title": "Natural Language Processing",
    "section": "Feed LSTM a sequence of one-hots",
    "text": "Feed LSTM a sequence of one-hots\n\nrandom.seed(42)\ninputs = keras.Input(shape=(max_length,), dtype=\"int64\")\nonehot = keras.ops.one_hot(inputs, max_tokens)\nx = layers.Bidirectional(layers.LSTM(24))(onehot)\nx = layers.Dropout(0.5)(x) \noutputs = layers.Dense(1, activation=\"sigmoid\")(x)    \none_hot_model = keras.Model(inputs, outputs)\none_hot_model.compile(optimizer=\"adam\",\n    loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\none_hot_model.summary()\n\nModel: \"functional_8\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ input_layer_5 (InputLayer)      │ (None, 500)               │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ one_hot (OneHot)                │ (None, 500, 1000)         │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ bidirectional (Bidirectional)   │ (None, 48)                │    196,800 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dropout (Dropout)               │ (None, 48)                │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_10 (Dense)                │ (None, 1)                 │         49 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 196,849 (768.94 KB)\n\n\n\n Trainable params: 196,849 (768.94 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#fit-evaluate-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#fit-evaluate-1",
    "title": "Natural Language Processing",
    "section": "Fit & evaluate",
    "text": "Fit & evaluate\n\nes = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True,\n    monitor=\"val_accuracy\", verbose=2)\n\n# if not Path(\"one-hot-model.keras\").exists():\none_hot_model.fit(X_train_txt, y_train, epochs=1_000, callbacks=es,\n    validation_data=(X_val_txt, y_val), verbose=0);\none_hot_model.save(\"one-hot-model.keras\")\n# else:\n#     one_hot_model = keras.models.load_model(\"one-hot-model.keras\")\n\nEpoch 9: early stopping\nRestoring model weights from the end of the best epoch: 6.\n\n\n\none_hot_model.evaluate(X_train_txt, y_train, verbose=0, batch_size=1_000)\n\n[0.5114213824272156, 0.755796492099762]\n\n\n\none_hot_model.evaluate(X_val_txt, y_val, verbose=0, batch_size=1_000)\n\n[0.552155613899231, 0.7065256834030151]"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#custom-embeddings",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#custom-embeddings",
    "title": "Natural Language Processing",
    "section": "Custom embeddings",
    "text": "Custom embeddings\n\ninputs = keras.Input(shape=(max_length,), dtype=\"int64\")\nembedded = layers.Embedding(input_dim=max_tokens, output_dim=32,\n        mask_zero=True)(inputs)\nx = layers.Bidirectional(layers.LSTM(24))(embedded)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(1, activation=\"sigmoid\")(x)\nembed_lstm = keras.Model(inputs, outputs)\nembed_lstm.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\nembed_lstm.summary()\n\nModel: \"functional_10\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)        ┃ Output Shape      ┃ Param # ┃ Connected to         ┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_6       │ (None, 500)       │       0 │ -                    │\n│ (InputLayer)        │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ embedding           │ (None, 500, 32)   │  32,000 │ input_layer_6[0][0]  │\n│ (Embedding)         │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ not_equal           │ (None, 500)       │       0 │ input_layer_6[0][0]  │\n│ (NotEqual)          │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ bidirectional_1     │ (None, 48)        │  10,944 │ embedding[0][0],     │\n│ (Bidirectional)     │                   │         │ not_equal[0][0]      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_1 (Dropout) │ (None, 48)        │       0 │ bidirectional_1[0][… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_11 (Dense)    │ (None, 1)         │      49 │ dropout_1[0][0]      │\n└─────────────────────┴───────────────────┴─────────┴──────────────────────┘\n\n\n\n Total params: 42,993 (167.94 KB)\n\n\n\n Trainable params: 42,993 (167.94 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#fit-evaluate-2",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.slides.html#fit-evaluate-2",
    "title": "Natural Language Processing",
    "section": "Fit & evaluate",
    "text": "Fit & evaluate\n\nes = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True,\n    monitor=\"val_accuracy\", verbose=2)\n\n# if not Path(\"embed-lstm.keras\").exists():\nembed_lstm.fit(X_train_txt, y_train, epochs=1_000, callbacks=es,\n    validation_data=(X_val_txt, y_val), verbose=0);\nembed_lstm.save(\"embed-lstm.keras\")\n# else:\n#     embed_lstm = keras.models.load_model(\"embed-lstm.keras\")\n\nEpoch 7: early stopping\nRestoring model weights from the end of the best epoch: 4.\n\n\n\nembed_lstm.evaluate(X_train_txt, y_train, verbose=0, batch_size=1_000)\n\n[0.5268873572349548, 0.7479952573776245]\n\n\n\nembed_lstm.evaluate(X_val_txt, y_val, verbose=0, batch_size=1_000)\n\n[0.5730966925621033, 0.720064103603363]\n\n\n\nembed_lstm.evaluate(X_test_txt, y_test, verbose=0, batch_size=1_000)\n\n[0.5498431324958801, 0.742551326751709]"
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html",
    "title": "Natural Language Processing",
    "section": "",
    "text": "import random\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport numpy.random as rnd\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras import layers\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dense, Input\nfrom keras.metrics import SparseTopKCategoricalAccuracy\nfrom keras.models import Sequential\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.0\nIPython version      : 8.20.0\n\nsklearn   : 1.4.0\nkeras     : 3.0.4\ntorch     : 2.2.0\ntensorflow: 2.15.0.post1",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#load-packages",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#load-packages",
    "title": "Natural Language Processing",
    "section": "",
    "text": "import random\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport numpy.random as rnd\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras import layers\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dense, Input\nfrom keras.metrics import SparseTopKCategoricalAccuracy\nfrom keras.models import Sequential\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.0\nIPython version      : 8.20.0\n\nsklearn   : 1.4.0\nkeras     : 3.0.4\ntorch     : 2.2.0\ntensorflow: 2.15.0.post1",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#what-is-nlp",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#what-is-nlp",
    "title": "Natural Language Processing",
    "section": "What is NLP?",
    "text": "What is NLP?\nA field of research at the intersection of computer science, linguistics, and artificial intelligence that takes the naturally spoken or written language of humans and processes it with machines to automate or help in certain tasks",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#how-the-computer-sees-text",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#how-the-computer-sees-text",
    "title": "Natural Language Processing",
    "section": "How the computer sees text",
    "text": "How the computer sees text\nSpot the odd one out:\n\n\n[112, 97, 116, 114, 105, 99, 107, 32, 108, 97, 117, 98]\n\n\n\n\n[80, 65, 84, 82, 73, 67, 75, 32, 76, 65, 85, 66]\n\n\n\n\n[76, 101, 118, 105, 32, 65, 99, 107, 101, 114, 109, 97, 110]\n\n\n\nGenerated by:\n\nprint([ord(x) for x in \"patrick laub\"])\nprint([ord(x) for x in \"PATRICK LAUB\"])\nprint([ord(x) for x in \"Levi Ackerman\"])\n\nThe ord built-in turns characters into their ASCII form.\n\n\n\n\n\n\nQuestion\n\n\n\nThe largest value for a character is 127, can you guess why?",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#ascii",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#ascii",
    "title": "Natural Language Processing",
    "section": "ASCII",
    "text": "ASCII\n\n\n\nAmerican Standard Code for Information Interchange\n\n\nUnicode is the new standard.\n\nSource: Wikipedia",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#random-strings",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#random-strings",
    "title": "Natural Language Processing",
    "section": "Random strings",
    "text": "Random strings\nThe built-in chr function turns numbers into characters.\n\nrnd.seed(1)\n\n\nchars = [chr(rnd.randint(32, 127)) for _ in range(10)]\nchars\n\n['E', ',', 'h', ')', 'k', '%', 'o', '`', '0', '!']\n\n\n\n\" \".join(chars)\n\n'E , h ) k % o ` 0 !'\n\n\n\n\"\".join([chr(rnd.randint(32, 127)) for _ in range(50)])\n\n\"lg&9R42t+&lt;=.Rdww~v-)'_]6Y! \\\\q(x-Oh&gt;g#f5QY#d8Kl:TpI\"\n\n\n\n\"\".join([chr(rnd.randint(0, 128)) for _ in range(50)])\n\n'R\\x0f@D\\x19obW\\x07\\x1a\\x19h\\x16\\tCg~\\x17}d\\x1b%9S&\\x08 \"\\n\\x17\\x0foW\\x19Gs\\\\J&gt;. X\\x177AqM\\x03\\x00x'",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#escape-characters",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#escape-characters",
    "title": "Natural Language Processing",
    "section": "Escape characters",
    "text": "Escape characters\n\n\n\nprint(\"Hello,\\tworld!\")\n\nHello,  world!\n\n\n\nprint(\"Line 1\\nLine 2\")\n\nLine 1\nLine 2\n\n\n\nprint(\"Patrick\\rLaub\")\n\n\n\nLaubick\n\n\n\n\nprint(\"C:\\tom\\new folder\")\n\nC:  om\new folder\n\n\nEscape the backslash:\n\nprint(\"C:\\\\tom\\\\new folder\")\n\nC:\\tom\\new folder\n\n\n\nrepr(\"Hello,\\rworld!\")\n\n\"'Hello,\\\\rworld!'\"",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#non-natural-language-processing-i",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#non-natural-language-processing-i",
    "title": "Natural Language Processing",
    "section": "Non-natural language processing I",
    "text": "Non-natural language processing I\nHow would you evaluate\n\n10 + 2 * -3\n\n\nAll that Python sees is a string of characters.\n\n[ord(c) for c in \"10 + 2 * -3\"]\n\n[49, 48, 32, 43, 32, 50, 32, 42, 32, 45, 51]\n\n\n\n\n\n10 + 2 * -3\n\n4",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#non-natural-language-processing-ii",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#non-natural-language-processing-ii",
    "title": "Natural Language Processing",
    "section": "Non-natural language processing II",
    "text": "Non-natural language processing II\nPython first tokenizes the string:\n\nimport tokenize\nimport io\n\ncode = \"10 + 2 * -3\"\ntokens = tokenize.tokenize(io.BytesIO(code.encode(\"utf-8\")).readline)\nfor token in tokens:\n    print(token)\n\nTokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line='')\nTokenInfo(type=2 (NUMBER), string='10', start=(1, 0), end=(1, 2), line='10 + 2 * -3')\nTokenInfo(type=54 (OP), string='+', start=(1, 3), end=(1, 4), line='10 + 2 * -3')\nTokenInfo(type=2 (NUMBER), string='2', start=(1, 5), end=(1, 6), line='10 + 2 * -3')\nTokenInfo(type=54 (OP), string='*', start=(1, 7), end=(1, 8), line='10 + 2 * -3')\nTokenInfo(type=54 (OP), string='-', start=(1, 9), end=(1, 10), line='10 + 2 * -3')\nTokenInfo(type=2 (NUMBER), string='3', start=(1, 10), end=(1, 11), line='10 + 2 * -3')\nTokenInfo(type=4 (NEWLINE), string='', start=(1, 11), end=(1, 12), line='')\nTokenInfo(type=0 (ENDMARKER), string='', start=(2, 0), end=(2, 0), line='')",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#non-natural-language-processing-iii",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#non-natural-language-processing-iii",
    "title": "Natural Language Processing",
    "section": "Non-natural language processing III",
    "text": "Non-natural language processing III\nPython needs to parse the tokens into an abstract syntax tree.\n\n\n\nimport ast\n\nprint(ast.dump(ast.parse(\"10 + 2 * -3\"), indent=\"  \"))\n\nModule(\n  body=[\n    Expr(\n      value=BinOp(\n        left=Constant(value=10),\n        op=Add(),\n        right=BinOp(\n          left=Constant(value=2),\n          op=Mult(),\n          right=UnaryOp(\n            op=USub(),\n            operand=Constant(value=3)))))],\n  type_ignores=[])\n\n\n\n\n\n\n\n\ngraph TD;\n    Expr --&gt; C[Add]\n    C --&gt; D[10]\n    C --&gt; E[Mult]\n    E --&gt; F[2]\n    E --&gt; G[USub]\n    G --&gt; H[3]",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#non-natural-language-processing-iv",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#non-natural-language-processing-iv",
    "title": "Natural Language Processing",
    "section": "Non-natural language processing IV",
    "text": "Non-natural language processing IV\nThe abstract syntax tree is then compiled into bytecode.\n\n\n\nimport dis\n\ndef expression(a, b, c):\n    return a + b * -c\n\ndis.dis(expression)\n\n  3           0 RESUME                   0\n\n  4           2 LOAD_FAST                0 (a)\n              4 LOAD_FAST                1 (b)\n              6 LOAD_FAST                2 (c)\n              8 UNARY_NEGATIVE\n             10 BINARY_OP                5 (*)\n             14 BINARY_OP                0 (+)\n             18 RETURN_VALUE\n\n\n\n\n\n\nRunning the bytecode",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#applications-of-nlp-in-industry",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#applications-of-nlp-in-industry",
    "title": "Natural Language Processing",
    "section": "Applications of NLP in Industry",
    "text": "Applications of NLP in Industry\n1) Classifying documents: Using the language within a body of text to classify it into a particular category, e.g.:\n\nGrouping emails into high and low urgency\nMovie reviews into positive and negative sentiment (i.e. sentiment analysis)\nCompany news into bullish (positive) and bearish (negative) statements\n\n2) Machine translation: Assisting language translators with machine-generated suggestions from a source language (e.g. English) to a target language",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#applications-of-nlp-in-industry-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#applications-of-nlp-in-industry-1",
    "title": "Natural Language Processing",
    "section": "Applications of NLP in Industry",
    "text": "Applications of NLP in Industry\n3) Search engine functions, including:\n\nAutocomplete\nPredicting what information or website user is seeking\n\n4) Speech recognition: Interpreting voice commands to provide information or take action. Used in virtual assistants such as Alexa, Siri, and Cortana",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#deep-learning-nlp",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#deep-learning-nlp",
    "title": "Natural Language Processing",
    "section": "Deep learning & NLP?",
    "text": "Deep learning & NLP?\nSimple NLP applications such as spell checkers and synonym suggesters do not require deep learning and can be solved with deterministic, rules-based code with a dictionary/thesaurus.\nMore complex NLP applications such as classifying documents, search engine word prediction, and chatbots are complex enough to be solved using deep learning methods.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#nlp-in-1966-1973-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#nlp-in-1966-1973-1",
    "title": "Natural Language Processing",
    "section": "NLP in 1966-1973 #1",
    "text": "NLP in 1966-1973 #1\n\nA typical story occurred in early machine translation efforts, which were generously funded by the U.S. National Research Council in an attempt to speed up the translation of Russian scientific papers in the wake of the Sputnik launch in 1957. It was thought initially that simple syntactic transformations, based on the grammars of Russian and English, and word replacement from an electronic dictionary, would suffice to preserve the exact meanings of sentences.\n\n\nSource: Russell and Norvig (2016), Artificial Intelligence: A Modern Approach, Third Edition, p. 21.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#nlp-in-1966-1973-2",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#nlp-in-1966-1973-2",
    "title": "Natural Language Processing",
    "section": "NLP in 1966-1973 #2",
    "text": "NLP in 1966-1973 #2\n\nThe fact is that accurate translation requires background knowledge in order to resolve ambiguity and establish the content of the sentence. The famous retranslation of “the spirit is willing but the flesh is weak” as “the vodka is good but the meat is rotten” illustrates the difficulties encountered. In 1966, a report by an advisory committee found that “there has been no machine translation of general scientific text, and none is in immediate prospect.” All U.S. government funding for academic translation projects was canceled.\n\n\nSource: Russell and Norvig (2016), Artificial Intelligence: A Modern Approach, Third Edition, p. 21.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#high-level-history-of-deep-learning",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#high-level-history-of-deep-learning",
    "title": "Natural Language Processing",
    "section": "High-level history of deep learning",
    "text": "High-level history of deep learning\n\n\n\n\nA brief history of deep learning.\n\n\nSource: Krohn (2019), Deep Learning Illustrated, Figure 2-3.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#downloading-the-dataset",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#downloading-the-dataset",
    "title": "Natural Language Processing",
    "section": "Downloading the dataset",
    "text": "Downloading the dataset\nLook at the (U.S.) National Highway Traffic Safety Administration’s (NHTSA) National Motor Vehicle Crash Causation Survey (NMVCCS) dataset.\n\n1from pathlib import Path\n\n2if not Path(\"NHTSA_NMVCCS_extract.parquet.gzip\").exists():\n    print(\"Downloading dataset\")                                    \n    !wget https://github.com/JSchelldorfer/ActuarialDataScience/raw/master/12%20-%20NLP%20Using%20Transformers/NHTSA_NMVCCS_extract.parquet.gzip\n3\n4df = pd.read_parquet(\"NHTSA_NMVCCS_extract.parquet.gzip\")\n5print(f\"shape of DataFrame: {df.shape}\")\n\n\n1\n\nImports Path class from pathlib library\n\n2\n\nChecks whether the zip folder already exists\n\n3\n\nIf it doesn’t, gets the folder from the given location\n\n4\n\nReads the zipped parquet file and stores it as a data frame. parquet is an efficient data storage format, similar to .csv\n\n5\n\nPrints the shape of the data frame\n\n\n\n\nshape of DataFrame: (6949, 16)",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#features",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#features",
    "title": "Natural Language Processing",
    "section": "Features",
    "text": "Features\n\nlevel_0, index, SCASEID: all useless row numbers\nSUMMARY_EN and SUMMARY_GE: summaries of the accident\nNUMTOTV: total number of vehicles involved in the accident\nWEATHER1 to WEATHER8:\n\nWEATHER1: cloudy\nWEATHER2: snow\nWEATHER3: fog, smog, smoke\nWEATHER4: rain\nWEATHER5: sleet, hail (freezing drizzle or rain)\nWEATHER6: blowing snow\nWEATHER7: severe crosswinds\nWEATHER8: other\n\nINJSEVA and INJSEVB: injury severity & (binary) presence of bodily injury\n\n\nSource: JSchelldorfer’s GitHub.\n\nThe analysis will ignore variables level_0, index, SCASEID, SUMMARY_GE and INJSEVA.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#crash-summaries",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#crash-summaries",
    "title": "Natural Language Processing",
    "section": "Crash summaries",
    "text": "Crash summaries\n\ndf[\"SUMMARY_EN\"]\n\n0       V1, a 2000 Pontiac Montana minivan, made a lef...\n1       The crash occurred in the eastbound lane of a ...\n2       This crash occurred just after the noon time h...\n                              ...                        \n6946    The crash occurred in the eastbound lanes of a...\n6947    This single-vehicle crash occurred in a rural ...\n6948    This two vehicle daytime collision occurred mi...\nName: SUMMARY_EN, Length: 6949, dtype: object\n\n\nThe SUMMARY_EN column contains summary of the accidents. There are 6949 rows corresponding to 6949 accidents. The data type is object, therefore, it will perform string (not mathematical) operations on the data. The following code shows how to generate a histogram for the length of the string. It looks at each entry of the column SUMMARY_EN, computes the length of the string (number of letters in the string), and create a histogram. The histogram shows that summaries are 2000 characters long on average.\n\ndf[\"SUMMARY_EN\"].map(lambda summary: len(summary)).hist(grid=False);",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#a-crash-summary",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#a-crash-summary",
    "title": "Natural Language Processing",
    "section": "A crash summary",
    "text": "A crash summary\nThe following code looks at the data entry for integer location 1 from the SUMMARY_EN data column in the dataframe df.\n\ndf[\"SUMMARY_EN\"].iloc[1]\n\n\"The crash occurred in the eastbound lane of a two-lane, two-way asphalt roadway on level grade.  The conditions were daylight and wet with cloudy skies in the early afternoon on a weekday.\\t\\r \\r V1, a 1995 Chevrolet Lumina was traveling eastbound.  V2, a 2004 Chevrolet Trailblazer was also traveling eastbound on the same roadway.  V2, was attempting to make a left-hand turn into a private drive on the North side of the roadway.  While turning V1 attempted to pass V2 on the left-hand side contacting it's front to the left side of V2.  Both vehicles came to final rest on the roadway at impact.\\r \\r The driver of V1 fled the scene and was not identified, so no further information could be obtained from him.  The Driver of V2 stated that the driver was a male and had hit his head and was bleeding.  She did not pursue the driver because she thought she saw a gun. The officer said that the car had been reported stolen.\\r \\r The Critical Precrash Event for the driver of V1 was this vehicle traveling over left lane line on the left side of travel.  The Critical Reason for the Critical Event was coded as unknown reason for the critical event because the driver was not available. \\r \\r The driver of V2 was a 41-year old female who had reported that she had stopped prior to turning to make sure she was at the right house.  She was going to show a house for a client.  She had no health related problems.  She had taken amoxicillin.  She does not wear corrective lenses and felt rested.  She was not injured in the crash.\\r \\r The Critical Precrash Event for the driver of V2 was other vehicle encroachment from adjacent lane over left lane line.  The Critical Reason for the Critical Event was not coded for this vehicle and the driver of V2 was not thought to have contributed to the crash.\"\n\n\nNote that the output is with in double quotations. Further, we can see characters like \\r \\t in the output. This allows us to copy the entire output, and insert it in any python code for running codes. It is different from printing the output.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#carriage-returns",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#carriage-returns",
    "title": "Natural Language Processing",
    "section": "Carriage returns",
    "text": "Carriage returns\n\nprint(df[\"SUMMARY_EN\"].iloc[1])\n\nPassing the print command for df[\"SUMMARY_EN\"].iloc[1] returns an output without the double quotations. Furthermore, the characters like \\r \\t are now activated in to ‘carriage return’ and ‘tab’ controls respectively. If ‘carriage return’ characters are activated (without newline character \\n following it), then it can write next text over the previous lines and create confusion in the text processing.\n\n\nThe Critical Precrash Event for the driver of V2 was other vehicle encroachment from adjacent lane over left lane line.  The Critical Reason for the Critical Event was not coded for this vehicle and the driver of V2 was not thought to have contributed to the crash.r corrective lenses and felt rested.  She was not injured in the crash. of V2.  Both vehicles came to final rest on the roadway at impact.\n\n\nTo avoid such confusions in text processing, we can write a function to replace \\r character with \\n in the following manner, and apply the function to the entire SUMMARY_EN column using the map function.\n\n# Replace every \\r with \\n\ndef replace_carriage_return(summary):\n    return summary.replace(\"\\r\", \"\\n\")\n\ndf[\"SUMMARY_EN\"] = df[\"SUMMARY_EN\"].map(replace_carriage_return)\nprint(df[\"SUMMARY_EN\"].iloc[1][:500])\n\nThe crash occurred in the eastbound lane of a two-lane, two-way asphalt roadway on level grade.  The conditions were daylight and wet with cloudy skies in the early afternoon on a weekday.    \n \n V1, a 1995 Chevrolet Lumina was traveling eastbound.  V2, a 2004 Chevrolet Trailblazer was also traveling eastbound on the same roadway.  V2, was attempting to make a left-hand turn into a private drive on the North side of the roadway.  While turning V1 attempted to pass V2 on the left-hand side contactin",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#target",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#target",
    "title": "Natural Language Processing",
    "section": "Target",
    "text": "Target\n\n\nPredict number of vehicles in the crash.\n\ndf[\"NUMTOTV\"].value_counts()\\\n1    .sort_index()\n\n\n1\n\nThe code selects the column with total number of vehicles NUMTOTV, obtain the value counts for each categories, returns the sorted vector.\n\n\n\n\nNUMTOTV\n1    1822\n2    4151\n3     783\n4     150\n5      34\n6       5\n7       2\n8       1\n9       1\nName: count, dtype: int64\n\n\n\nnp.sum(df[\"NUMTOTV\"] &gt; 3)\n\n193\n\n\n\nSimplify the target to just:\n\n1 vehicle\n2 vehicles\n3+ vehicles\n\n\ndf[\"NUM_VEHICLES\"] = \\\n  df[\"NUMTOTV\"].map(lambda x: \\\n1    str(x) if x &lt;= 2 else \"3+\")\ndf[\"NUM_VEHICLES\"].value_counts()\\\n  .sort_index()\n\n\n1\n\nWrites a function to reduce categories to 3, by combining all categories with 3 or more vehicles into one category\n\n\n\n\nNUM_VEHICLES\n1     1822\n2     4151\n3+     976\nName: count, dtype: int64",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#just-ignore-this-for-now",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#just-ignore-this-for-now",
    "title": "Natural Language Processing",
    "section": "Just ignore this for now…",
    "text": "Just ignore this for now…\n\nrnd.seed(123)\n\nfor i, summary in enumerate(df[\"SUMMARY_EN\"]):\n    word_numbers = [\"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\"]\n    num_cars = 10\n    new_car_nums = [f\"V{rnd.randint(100, 10000)}\" for _ in range(num_cars)]\n    num_spaces = 4\n\n    for car in range(1, num_cars+1):\n        new_num = new_car_nums[car-1]\n        summary = summary.replace(f\"V-{car}\", new_num)\n        summary = summary.replace(f\"Vehicle {word_numbers[car-1]}\", new_num).replace(f\"vehicle {word_numbers[car-1]}\", new_num)\n        summary = summary.replace(f\"Vehicle #{word_numbers[car-1]}\", new_num).replace(f\"vehicle #{word_numbers[car-1]}\", new_num)\n        summary = summary.replace(f\"Vehicle {car}\", new_num).replace(f\"vehicle {car}\", new_num)\n        summary = summary.replace(f\"Vehicle #{car}\", new_num).replace(f\"vehicle #{car}\", new_num)\n        summary = summary.replace(f\"Vehicle # {car}\", new_num).replace(f\"vehicle # {car}\", new_num)\n\n        for j in range(num_spaces+1):\n            summary = summary.replace(f\"V{' '*j}{car}\", new_num).replace(f\"V{' '*j}#{car}\", new_num).replace(f\"V{' '*j}# {car}\", new_num)\n            summary = summary.replace(f\"v{' '*j}{car}\", new_num).replace(f\"v{' '*j}#{car}\", new_num).replace(f\"v{' '*j}# {car}\", new_num)\n         \n    df.loc[i, \"SUMMARY_EN\"] = summary",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#convert-y-to-integers-split-the-data",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#convert-y-to-integers-split-the-data",
    "title": "Natural Language Processing",
    "section": "Convert y to integers & split the data",
    "text": "Convert y to integers & split the data\n\n1from sklearn.preprocessing import LabelEncoder\n2target_labels = df[\"NUM_VEHICLES\"]\n3target = LabelEncoder().fit_transform(target_labels)\ntarget\n\n\n1\n\nImports the LabelEncoder from sklearn.preprocessing library\n\n2\n\nDefines the target variable\n\n3\n\nFit and transform the target variable using LabelEncoder\n\n\n\n\narray([1, 1, 1, ..., 2, 0, 1])\n\n\n\n1weather_cols = [f\"WEATHER{i}\" for i in range(1, 9)]\n2features = df[[\"SUMMARY_EN\"] + weather_cols]\n\nX_main, X_test, y_main, y_test = \\\n3    train_test_split(features, target, test_size=0.2, random_state=1)\n\n# As 0.25 x 0.8 = 0.2\nX_train, X_val, y_train, y_val = \\\n4    train_test_split(X_main, y_main, test_size=0.25, random_state=1)\n\n5X_train.shape, X_val.shape, X_test.shape\n\n\n1\n\nCreates a list that returns column names of weather conditions, i.e. ['WEATHER1', 'WEATHER2', 'WEATHER3', 'WEATHER4', 'WEATHER5', 'WEATHER6', 'WEATHER7', 'WEATHER8']\n\n2\n\nDefines the feature vector by selecting relevant columns from the data frame df\n\n3\n\nSplits the data into train and validation sets\n\n4\n\nFurther divides the validation set into validation set and test set\n\n5\n\nPrints the dimensions of the data frames\n\n\n\n\n((4169, 9), (1390, 9), (1390, 9))\n\n\n\nprint([np.mean(y_train == y) for y in [0, 1, 2]])\n\n[0.25833533221396016, 0.6032621731830176, 0.1384024946030223]",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#grab-the-start-of-a-few-summaries",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#grab-the-start-of-a-few-summaries",
    "title": "Natural Language Processing",
    "section": "Grab the start of a few summaries",
    "text": "Grab the start of a few summaries\n\nfirst_summaries = X_train[\"SUMMARY_EN\"].iloc[:3]\nfirst_summaries\n\n2532    This crash occurred in the early afternoon of ...\n6209    This two-vehicle crash occurred in a four-legg...\n2561    The crash occurred in the eastbound direction ...\nName: SUMMARY_EN, dtype: object\n\n\n\n1first_words = first_summaries.map(lambda txt: txt.split(\" \")[:7])\nfirst_words\n\n\n1\n\nTakes the first_summaries, converts the string of words in to a list of words by breaking the string at spaces and returns the first 7 words\n\n\n\n\n2532    [This, crash, occurred, in, the, early, aftern...\n6209    [This, two-vehicle, crash, occurred, in, a, fo...\n2561    [The, crash, occurred, in, the, eastbound, dir...\nName: SUMMARY_EN, dtype: object\n\n\n\n1start_of_summaries = first_words.map(lambda txt: \" \".join(txt))\nstart_of_summaries\n\n\n1\n\nJoint the words in the list with a space in between to return a string\n\n\n\n\n2532          This crash occurred in the early afternoon\n6209    This two-vehicle crash occurred in a four-legged\n2561       The crash occurred in the eastbound direction\nName: SUMMARY_EN, dtype: object",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#count-words-in-the-first-summaries",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#count-words-in-the-first-summaries",
    "title": "Natural Language Processing",
    "section": "Count words in the first summaries",
    "text": "Count words in the first summaries\n\n1from sklearn.feature_extraction.text import CountVectorizer\n\n2vect = CountVectorizer()\n3counts = vect.fit_transform(start_of_summaries)\n4vocab = vect.get_feature_names_out()\nprint(len(vocab), vocab)\n\n\n1\n\nImports the CountVectorizer class from the sklearn.feature_extraction.text library. CountVectorizer goes through a text document, identifies distinct words in it, and returns a sparse matrix.\n\n2\n\nApplies fit_transform function to the start_of_summaries\n\n3\n\nStores the distinct words in the vector vocab\n\n4\n\nReturns the number of distinct words, and the words themselves\n\n\n\n\n13 ['afternoon' 'crash' 'direction' 'early' 'eastbound' 'four' 'in' 'legged'\n 'occurred' 'the' 'this' 'two' 'vehicle']\n\n\n\ncounts\n\n&lt;3x13 sparse matrix of type '&lt;class 'numpy.int64'&gt;'\n    with 21 stored elements in Compressed Sparse Row format&gt;\n\n\nGiving the command to return counts does not return the matrix in full form. Since python saves the matrix in a Therefore, we use the following code.\n\ncounts.toarray()\n\narray([[1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0],\n       [0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1],\n       [0, 1, 1, 0, 1, 0, 1, 0, 1, 2, 0, 0, 0]])\n\n\nIn the above matrix, rows correspond to the data entries (strings), columns correspond to distinct words, and cell entries correspond to the frequencies of distinct words in each row",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#encode-new-sentences-to-bow",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#encode-new-sentences-to-bow",
    "title": "Natural Language Processing",
    "section": "Encode new sentences to BoW",
    "text": "Encode new sentences to BoW\n\nvect.transform([\n    \"first car hit second car in a crash\",\n    \"ipad os 16 beta released\",\n1])\n\n\n1\n\nApplies transform to two new lines of data. vect.transform applies the already fitted transformation to the new data. It goes through the new data entries, identifies words that were seen during fit_transform stage, and returns a matrix containing the counts of distinct words (identified during fitting stage).\n\n\n\n\n&lt;2x13 sparse matrix of type '&lt;class 'numpy.int64'&gt;'\n    with 2 stored elements in Compressed Sparse Row format&gt;\n\n\nNote that the matrix is stored in a special format in python, hence, we must pass the command to convert it to an array using the following code.\n\nvect.transform([\n    \"first car hit second car in a crash\",\n    \"ipad os 16 beta released\",\n]).toarray()\n\narray([[0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n\n\nThere are couple issues with the output. Since the transform function, will identify only the words trained during the fit_transform stage, it will not recognize the new words. The returned matrix can only say whether new data contains words seen during the fitting stage or not. We can see how the matrix returns an entire row of zero values for the second line.\n\nprint(vocab)\n\n['afternoon' 'crash' 'direction' 'early' 'eastbound' 'four' 'in' 'legged'\n 'occurred' 'the' 'this' 'two' 'vehicle']",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#bag-of-n-grams",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#bag-of-n-grams",
    "title": "Natural Language Processing",
    "section": "Bag of n-grams",
    "text": "Bag of n-grams\nThe same CountVectorizer class can be customized to look at 2 words too. This is useful in some situations. For example, the word ‘new’ and ‘york’ separately might not be meaningful, but together, it can. This motivates the n-grams option. The following code CountVectorizer(ngram_range=(1, 2)) is an example of giving instructions to look for phrases with one word and two words.\n\nvect = CountVectorizer(ngram_range=(1, 2))\ncounts = vect.fit_transform(start_of_summaries)\nvocab = vect.get_feature_names_out()\nprint(len(vocab), vocab)\n\n27 ['afternoon' 'crash' 'crash occurred' 'direction' 'early'\n 'early afternoon' 'eastbound' 'eastbound direction' 'four' 'four legged'\n 'in' 'in four' 'in the' 'legged' 'occurred' 'occurred in' 'the'\n 'the crash' 'the early' 'the eastbound' 'this' 'this crash' 'this two'\n 'two' 'two vehicle' 'vehicle' 'vehicle crash']\n\n\n\ncounts.toarray()\n\narray([[1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n        0, 0, 0, 0, 0],\n       [0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n        1, 1, 1, 1, 1],\n       [0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 2, 1, 0, 1, 0, 0,\n        0, 0, 0, 0, 0]])\n\n\nSee: Google Books Ngram Viewer",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#tf-idf",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#tf-idf",
    "title": "Natural Language Processing",
    "section": "TF-IDF",
    "text": "TF-IDF\nStands for term frequency-inverse document frequency.\n\n\n\nInfographic explaining TF-IDF\n\n\n\nSource: FiloTechnologia (2014), A simple Java class for TF-IDF scoring, Blog post.\n\nterm frequency-inverse document frequency measures the importance of a word across documents. It first computes the frequency of term x in the document y and weights it by a measure of how common it is. The intuition here is that, the more the word x appears across documents, the less important it becomes.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#count-words-in-all-the-summaries",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#count-words-in-all-the-summaries",
    "title": "Natural Language Processing",
    "section": "Count words in all the summaries",
    "text": "Count words in all the summaries\n\n1vect = CountVectorizer()\n2vect.fit(X_train[\"SUMMARY_EN\"])\n3vocab = list(vect.get_feature_names_out())\n4len(vocab)\n\n\n1\n\nDefines the class CountVectorizer() as vect\n\n2\n\nFits the vectorizer to the entire column of SUMMARY_EN\n\n3\n\nStores the distinct words as a list\n\n4\n\nReturns the number of unique words\n\n\n\n\n18866\n\n\nThe above code returns 18866 number of unique words.\n\n1vocab[:5], vocab[len(vocab)//2:(len(vocab)//2 + 5)], vocab[-5:]\n\n\n1\n\nReturns (i) the first five elements, (ii) the middle five elements and (iii) the last five elements of the array.\n\n\n\n\n(['00', '000', '000lbs', '003', '005'],\n ['swinger', 'swinging', 'swipe', 'swiped', 'swiping'],\n ['zorcor', 'zotril', 'zx2', 'zx5', 'zyrtec'])",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#create-the-x-matrices",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#create-the-x-matrices",
    "title": "Natural Language Processing",
    "section": "Create the X matrices",
    "text": "Create the X matrices\nThe following function is designed to select and vectorize the text column of a given dataset, and then combine it with the other non-textual columns of the same dataset.\n\n1def vectorise_dataset(X, vect, txt_col=\"SUMMARY_EN\", dataframe=False):\n2    X_vects = vect.transform(X[txt_col]).toarray()\n3    X_other = X.drop(txt_col, axis=1)\n\n4    if not dataframe:\n        return np.concatenate([X_vects, X_other], axis=1)                           \n    else:\n        # Add column names and indices to the combined dataframe.\n5        vocab = list(vect.get_feature_names_out())\n6        X_vects_df = pd.DataFrame(X_vects, columns=vocab, index=X.index)\n7        return pd.concat([X_vects_df, X_other], axis=1)\n\n\n1\n\nDefines the function vectorise_dataset which takes in the dataframe X, vectorizer class, the name of the text column, a boolean function defining whether we want the output in dataframe format or numpy array format\n\n2\n\nTransforms the text column based on a already fitted vectorizer function\n\n3\n\nDrops the column containing text data from the dataframe\n\n4\n\nIf dataframe=False, then returns a numpy array by concatenating non-textual data and vectorized text data\n\n5\n\nOtherwise, extracts the unique words as a list\n\n6\n\nGenerates a dataframe, with columns names vocab, while preserving the index from the original dataset X\n\n7\n\nConcatenates X_vects_df with the remaining non-textual data and returns the output as a dataframe\n\n\n\n\n\nX_train_ct = vectorise_dataset(X_train, vect)\nX_val_ct = vectorise_dataset(X_val, vect)\nX_test_ct = vectorise_dataset(X_test, vect)",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#check-the-input-matrix",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#check-the-input-matrix",
    "title": "Natural Language Processing",
    "section": "Check the input matrix",
    "text": "Check the input matrix\n\nvectorise_dataset(X_train, vect, dataframe=True)\n\n\n\n\n\n\n\n\n00\n000\n000lbs\n003\n005\n007\n00am\n00pm\n00tydo2\n01\n...\nzx5\nzyrtec\nWEATHER1\nWEATHER2\nWEATHER3\nWEATHER4\nWEATHER5\nWEATHER6\nWEATHER7\nWEATHER8\n\n\n\n\n2532\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6209\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2561\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n6882\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n206\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6356\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n4169 rows × 18874 columns\n\n\n\nThe above code returns the output matrix and it contains 4169 rows with 18874 columns. Next, we build a simple neural network on the data, to predict the probabilities of number of vehicles involved in the accident.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#make-a-simple-dense-model",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#make-a-simple-dense-model",
    "title": "Natural Language Processing",
    "section": "Make a simple dense model",
    "text": "Make a simple dense model\n\n1num_features = X_train_ct.shape[1]\n2num_cats = 3 # 1, 2, 3+ vehicles\n\n3def build_model(num_features, num_cats):\n4    random.seed(42)\n    \n    model = Sequential([\n        Input((num_features,)),\n        Dense(100, activation=\"relu\"),\n        Dense(num_cats, activation=\"softmax\")\n5    ])\n    \n6    topk = SparseTopKCategoricalAccuracy(k=2, name=\"topk\")\n    model.compile(\"adam\", \"sparse_categorical_crossentropy\",\n7        metrics=[\"accuracy\", topk])\n    \n    return model\n\n\n1\n\nStores the number of input features in num_features\n\n2\n\nStores the number of output features in num_cats\n\n3\n\nStarts building the model by giving number of input and output features as parameters\n\n4\n\nSets the random seed for reproducibility\n\n5\n\nConstructs the neural network with 2 dense layers. Since the output must be a vector of probabilities, we choose softmax activation in the output layer\n\n6\n\nDefines the a customized metric to keep track of during the training. The metric will compute the accuracy by looking at top 2 classes(the 2 classes with highest predicted probability) and checking if either of them contains the true class\n\n7\n\nCompiles the model with the adam optimizer, loss function and metrics to monitor. Here we ask the model to optimize sparse_categorical_crossentropy loss while keeping track of sparse_categorical_crossentropy for the top 2 classes ## Inspect the model\n\n\n\n\n\nmodel = build_model(num_features, num_cats)\nmodel.summary()\n\nModel: \"sequential\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ dense (Dense)                   │ (None, 100)               │  1,887,500 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_1 (Dense)                 │ (None, 3)                 │        303 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 1,887,803 (7.20 MB)\n\n\n\n Trainable params: 1,887,803 (7.20 MB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\nThe model summary shows that there are 1,887,803 parameters to learn. This is because we have 188500 (18874*100 weights + 100 biases) parameters to train in the first layer.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#fit-evaluate-the-model",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#fit-evaluate-the-model",
    "title": "Natural Language Processing",
    "section": "Fit & evaluate the model",
    "text": "Fit & evaluate the model\n\nes = EarlyStopping(patience=1, restore_best_weights=True,\n    monitor=\"val_accuracy\", verbose=2)\n%time hist = model.fit(X_train_ct, y_train, epochs=10, \\\n    callbacks=[es], validation_data=(X_val_ct, y_val), verbose=0);\n\nEpoch 3: early stopping\nRestoring model weights from the end of the best epoch: 2.\nCPU times: user 6.14 s, sys: 16.3 ms, total: 6.15 s\nWall time: 6.15 s\n\n\nResults from training the neural network shows that the model performs almost perfectly for the in sample data, and with very high accuracies for both validation and test data.\n\nmodel.evaluate(X_train_ct, y_train, verbose=0)\n\n[0.015500374138355255, 1.0, 1.0]\n\n\n\nmodel.evaluate(X_val_ct, y_val, verbose=0)\n\n[0.165849968791008, 0.9525179862976074, 0.9956834316253662]\n\n\n\nmodel.evaluate(X_test_ct, y_test, verbose=0)\n\n[0.17626968026161194, 0.9417266249656677, 0.9978417158126831]",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#the-max_features-value",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#the-max_features-value",
    "title": "Natural Language Processing",
    "section": "The max_features value",
    "text": "The max_features value\nOne way would be to select the most frequent words. The following code shows how we can choose max_features option to select the 10 words that occur most. This simplifies the problem, however, we might miss out on important words that might add value to the task. For example, and, for and of are among the selected words, but they are less meaningful.\n\nvect = CountVectorizer(max_features=10)\nvect.fit(X_train[\"SUMMARY_EN\"])\nvocab = vect.get_feature_names_out()\nlen(vocab)\n\n10\n\n\n\nprint(vocab)\n\n['and' 'driver' 'for' 'in' 'lane' 'of' 'the' 'to' 'vehicle' 'was']",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#remove-stop-words",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#remove-stop-words",
    "title": "Natural Language Processing",
    "section": "Remove stop words",
    "text": "Remove stop words\nOne way to overcome selecting less meaningful words would be to use the option 'stop_words=\"english' option. This option checks if the set of selected words contain common words, and ignore them when selecting the most frequent words.\n\nvect = CountVectorizer(max_features=10, stop_words=\"english\")\nvect.fit(X_train[\"SUMMARY_EN\"])\nvocab = vect.get_feature_names_out()\nlen(vocab)\n\n10\n\n\n\nprint(vocab)\n\n['coded' 'crash' 'critical' 'driver' 'event' 'intersection' 'lane' 'left'\n 'roadway' 'vehicle']",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#keep-1000-most-frequent-words",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#keep-1000-most-frequent-words",
    "title": "Natural Language Processing",
    "section": "Keep 1,000 most frequent words",
    "text": "Keep 1,000 most frequent words\n\nvect = CountVectorizer(max_features=1_000, stop_words=\"english\")\nvect.fit(X_train[\"SUMMARY_EN\"])\nvocab = vect.get_feature_names_out()\nlen(vocab)\n\n1000\n\n\n\nprint(vocab[:5], vocab[len(vocab)//2:(len(vocab)//2 + 5)], vocab[-5:])\n\n['10' '105' '113' '12' '15'] ['interruption' 'intersected' 'intersecting' 'intersection' 'interstate'] ['year' 'years' 'yellow' 'yield' 'zone']\n\n\nThe above output shows, how selecting just 1000 words would still contain less meaningful phrases. Also, we can see how the same word(but slightly differently spelled) are appearing together. This redundancy does not add value either. For example year and years.\nCreate the X matrices:\n\nX_train_ct = vectorise_dataset(X_train, vect)\nX_val_ct = vectorise_dataset(X_val, vect)\nX_test_ct = vectorise_dataset(X_test, vect)",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#check-the-input-matrix-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#check-the-input-matrix-1",
    "title": "Natural Language Processing",
    "section": "Check the input matrix",
    "text": "Check the input matrix\n\nvectorise_dataset(X_train, vect, dataframe=True)\n\n\n\n\n\n\n\n\n10\n105\n113\n12\n15\n150\n16\n17\n18\n180\n...\nyield\nzone\nWEATHER1\nWEATHER2\nWEATHER3\nWEATHER4\nWEATHER5\nWEATHER6\nWEATHER7\nWEATHER8\n\n\n\n\n2532\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6209\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2561\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n6882\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n206\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6356\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n4169 rows × 1008 columns",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#make-inspect-the-model",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#make-inspect-the-model",
    "title": "Natural Language Processing",
    "section": "Make & inspect the model",
    "text": "Make & inspect the model\n\nnum_features = X_train_ct.shape[1]\nmodel = build_model(num_features, num_cats)\nmodel.summary()\n\nModel: \"sequential_1\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ dense_2 (Dense)                 │ (None, 100)               │    100,900 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_3 (Dense)                 │ (None, 3)                 │        303 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 101,203 (395.32 KB)\n\n\n\n Trainable params: 101,203 (395.32 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\nFrom the above summary, we can see how we have brought down the number of parameters to be trained down to 101,203. That is done by reducing the number of covariates, not by reducing the number of neurons.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#fit-evaluate-the-model-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#fit-evaluate-the-model-1",
    "title": "Natural Language Processing",
    "section": "Fit & evaluate the model",
    "text": "Fit & evaluate the model\n\nes = EarlyStopping(patience=1, restore_best_weights=True,\n    monitor=\"val_accuracy\", verbose=2)\n%time hist = model.fit(X_train_ct, y_train, epochs=10, \\\n    callbacks=[es], validation_data=(X_val_ct, y_val), verbose=0);\n\nEpoch 2: early stopping\nRestoring model weights from the end of the best epoch: 1.\nCPU times: user 767 ms, sys: 0 ns, total: 767 ms\nWall time: 766 ms\n\n\nThe following results show how despite dropping so many covariates, the trained model is still able to achieve a performance similar to the previous case.\n\nmodel.evaluate(X_train_ct, y_train, verbose=0)\n\n[0.1617761105298996, 0.9573038816452026, 0.9988006949424744]\n\n\n\nmodel.evaluate(X_val_ct, y_val, verbose=0)\n\n[0.23044553399085999, 0.9258992671966553, 0.9942445755004883]",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#keep-1000-most-frequent-words-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#keep-1000-most-frequent-words-1",
    "title": "Natural Language Processing",
    "section": "Keep 1,000 most frequent words",
    "text": "Keep 1,000 most frequent words\n\nvect = CountVectorizer(max_features=1_000, stop_words=\"english\")\nvect.fit(X_train[\"SUMMARY_EN\"])\nvocab = vect.get_feature_names_out()\nlen(vocab)\n\n1000\n\n\n\nprint(vocab[:5], vocab[len(vocab)//2:(len(vocab)//2 + 5)], vocab[-5:])\n\n['10' '105' '113' '12' '15'] ['interruption' 'intersected' 'intersecting' 'intersection' 'interstate'] ['year' 'years' 'yellow' 'yield' 'zone']\n\n\nSpacy is a popular open-source library that is used to analyse data and carry out prediction tasks related to natural language processing.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#install-spacy",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#install-spacy",
    "title": "Natural Language Processing",
    "section": "Install spacy",
    "text": "Install spacy\n\n1!pip install spacy\n2!python -m spacy download en_core_web_sm\n\n\n1\n\nInstalls the library spacy\n\n2\n\nDownloads the trained model en_core_web_sm which a small, efficient English language model trained using text data. It can be used for tasks like lemmatization, tokenization etc.\n\n\n\n\n\n1import spacy\n\n2nlp = spacy.load(\"en_core_web_sm\")\n3doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\nfor token in doc:\n4    print(token.text, token.pos_, token.dep_)\n\n\n1\n\nImports the library\n\n2\n\nLoads the model and stores it as nlp\n\n3\n\nApplies nlp model to the given string for processing. Processing involves tokenization, part-of-speech application, dependency application etc.\n\n4\n\nReturns information about each token(word) in the line. token.text returns each word in the string, token.pos_ returns the part-of-speech; the grammatical category of the word, and token.dep_ which provides information about the syntactic relationship of the word to the rest of the words in the string.\n\n\n\n\nApple PROPN nsubj\nis AUX aux\nlooking VERB ROOT\nat ADP prep\nbuying VERB pcomp\nU.K. PROPN dobj\nstartup NOUN dobj\nfor ADP prep\n$ SYM quantmod\n1 NUM compound\nbillion NUM pobj",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#lemmatize-the-text",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#lemmatize-the-text",
    "title": "Natural Language Processing",
    "section": "Lemmatize the text",
    "text": "Lemmatize the text\nLemmatization refers to the act of reducing the words in to its base form. For example; reduced form of looking would be look. The following code shows how we can lemmatize the a text, by first processing it with nlp.\n\n1def lemmatize(txt):\n2    doc = nlp(txt)\n    good_tokens = [token.lemma_.lower() for token in doc \\\n        if not token.like_num and \\\n           not token.is_punct and \\\n           not token.is_space and \\\n           not token.is_currency and \\\n3           not token.is_stop]\n4    return \" \".join(good_tokens)\n\n\n1\n\nStarts defining the function which taken in a string of text as input\n\n2\n\nSends the text through nlp model\n\n3\n\nFor each token(word) in the document, first it takes the lemma of the token, converts it to lower case and then applies several filters on the lemmatized token to select only the good tokens. The filtering process filters out numbers, punctuation marks, white spaces, currency signs and stop words like the and and\n\n4\n\nJoins the good tokens and returns it as a string\n\n\n\n\n\ntest_str = \"Incident at 100kph and '10 incidents -13.3%' are incidental?\\t $5\"\nlemmatize(test_str)\n\n'incident 100kph incident incidental'\n\n\n\ntest_str = \"I interviewed 5-years ago, 150 interviews every year at 10:30 are..\"\nlemmatize(test_str)\n\n'interview year ago interview year 10:30'\n\n\nThe output above shows how stop words, numbers and punctuation marks are removed. We can also see how incident and incidental are treated as separate words.\nLemmatizing data in the above manner, giving each string at a time is quite inefficient. We can use map(lemmatize) function to map the function to the entire column at once.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#apply-to-the-whole-dataset",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#apply-to-the-whole-dataset",
    "title": "Natural Language Processing",
    "section": "Apply to the whole dataset",
    "text": "Apply to the whole dataset\n\ndf[\"SUMMARY_EN_LEMMA\"] = df[\"SUMMARY_EN\"].map(lemmatize)\n\nLemmatized version of the column is now stored in SUMMARY_EN_LEMM. Next we merge the non-textual columns of the dataset df with the lemmatized column and create the final dataset. This dataset will be split in to train, val and test sets for training the neural network.\n\n1weather_cols = [f\"WEATHER{i}\" for i in range(1, 9)]\n2features = df[[\"SUMMARY_EN_LEMMA\"] + weather_cols]\n\nX_main, X_test, y_main, y_test = \\\n3    train_test_split(features, target, test_size=0.2, random_state=1)\n\n# As 0.25 x 0.8 = 0.2\nX_train, X_val, y_train, y_val = \\\n4    train_test_split(X_main, y_main, test_size=0.25, random_state=1)\n\n5X_train.shape, X_val.shape, X_test.shape\n\n\n1\n\nDefines the names of the columns that will be used for creating the final dataset\n\n2\n\nSelects the relevant input feature columns and stores it in features column\n\n3\n\nSplits the data in to main and test sets\n\n4\n\nFurther splits the main set in to train and val sets\n\n5\n\nReturns the dimensions of the datasets\n\n\n\n\n((4169, 9), (1390, 9), (1390, 9))",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#keep-1000-most-frequent-lemmas",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#keep-1000-most-frequent-lemmas",
    "title": "Natural Language Processing",
    "section": "Keep 1,000 most frequent lemmas",
    "text": "Keep 1,000 most frequent lemmas\n\nvect = CountVectorizer(max_features=1_000, stop_words=\"english\")\nvect.fit(X_train[\"SUMMARY_EN_LEMMA\"])\nvocab = vect.get_feature_names_out()\nlen(vocab)\n\n1000\n\n\nThe output after lemmatization, when compared with the previous output (with 1000 words) does not contain similar words.\n\nprint(vocab[:5], vocab[len(vocab)//2:(len(vocab)//2 + 5)], vocab[-5:])\n\n['10' '150' '48kmph' '4x4' '56kmph'] ['let' 'level' 'lexus' 'license' 'light'] ['yaw' 'year' 'yellow' 'yield' 'zone']\n\n\nThe following code demonstrates the steps for training a neural network using lemmatized datasets:\n\nWe start by using the vectorise_dataset function to convert the text data into numerical vectors.\nNext, we train the neural network model using the vectorized dataset.\nFinally, we assess the model’s performance\n\nCreate the X matrices:\n\nX_train_ct = vectorise_dataset(X_train, vect, \"SUMMARY_EN_LEMMA\")\nX_val_ct = vectorise_dataset(X_val, vect, \"SUMMARY_EN_LEMMA\")\nX_test_ct = vectorise_dataset(X_test, vect, \"SUMMARY_EN_LEMMA\")",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#check-the-input-matrix-2",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#check-the-input-matrix-2",
    "title": "Natural Language Processing",
    "section": "Check the input matrix",
    "text": "Check the input matrix\n\nvectorise_dataset(X_train, vect, \"SUMMARY_EN_LEMMA\", dataframe=True)\n\n\n\n\n\n\n\n\n10\n150\n48kmph\n4x4\n56kmph\n64kmph\n72kmph\nability\nable\naccelerate\n...\nyield\nzone\nWEATHER1\nWEATHER2\nWEATHER3\nWEATHER4\nWEATHER5\nWEATHER6\nWEATHER7\nWEATHER8\n\n\n\n\n2532\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6209\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2561\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n6882\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n206\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6356\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n4169 rows × 1008 columns",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#make-inspect-the-model-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#make-inspect-the-model-1",
    "title": "Natural Language Processing",
    "section": "Make & inspect the model",
    "text": "Make & inspect the model\n\nnum_features = X_train_ct.shape[1]\nmodel = build_model(num_features, num_cats)\nmodel.summary()\n\nModel: \"sequential_2\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ dense_4 (Dense)                 │ (None, 100)               │    100,900 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_5 (Dense)                 │ (None, 3)                 │        303 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 101,203 (395.32 KB)\n\n\n\n Trainable params: 101,203 (395.32 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#fit-evaluate-the-model-2",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#fit-evaluate-the-model-2",
    "title": "Natural Language Processing",
    "section": "Fit & evaluate the model",
    "text": "Fit & evaluate the model\n\nes = EarlyStopping(patience=1, restore_best_weights=True,\n    monitor=\"val_accuracy\", verbose=2)\n%time hist = model.fit(X_train_ct, y_train, epochs=10, \\\n    callbacks=[es], validation_data=(X_val_ct, y_val), verbose=0);\n\nEpoch 2: early stopping\nRestoring model weights from the end of the best epoch: 1.\nCPU times: user 772 ms, sys: 55 µs, total: 773 ms\nWall time: 772 ms\n\n\n\nmodel.evaluate(X_train_ct, y_train, verbose=0)\n\n[0.1704728752374649, 0.9573038816452026, 0.9988006949424744]\n\n\n\nmodel.evaluate(X_val_ct, y_val, verbose=0)\n\n[0.2595383822917938, 0.9136690497398376, 0.9942445755004883]",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#permutation-importance-algorithm",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#permutation-importance-algorithm",
    "title": "Natural Language Processing",
    "section": "Permutation importance algorithm",
    "text": "Permutation importance algorithm\nTaken directly from scikit-learn documentation:\n\nInputs: fitted predictive model m, tabular dataset (training or validation) D.\nCompute the reference score s of the model m on data D (for instance the accuracy for a classifier or the R^2 for a regressor).\nFor each feature j (column of D):\n\nFor each repetition k in {1, \\dots, K}:\n\nRandomly shuffle column j of dataset D to generate a corrupted version of the data named \\tilde{D}_{k,j}.\nCompute the score s_{k,j} of model m on corrupted data \\tilde{D}_{k,j}.\n\nCompute importance i_j for feature f_j defined as:\n i_j = s - \\frac{1}{K} \\sum_{k=1}^{K} s_{k,j} \n\n\n\nSource: scikit-learn documentation, permutation_importance function.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#find-important-inputs",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#find-important-inputs",
    "title": "Natural Language Processing",
    "section": "Find important inputs",
    "text": "Find important inputs\n\ndef permutation_test(model, X, y, num_reps=1, seed=42):\n    \"\"\"\n    Run the permutation test for variable importance.\n    Returns matrix of shape (X.shape[1], len(model.evaluate(X, y))).\n    \"\"\"\n    rnd.seed(seed)\n    scores = []    \n\n    for j in range(X.shape[1]):\n        original_column = np.copy(X[:, j])\n        col_scores = []\n\n        for r in range(num_reps):\n            rnd.shuffle(X[:,j])\n            col_scores.append(model.evaluate(X, y, verbose=0))\n\n        scores.append(np.mean(col_scores, axis=0))\n        X[:,j] = original_column\n    \n    return np.array(scores)",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#run-the-permutation-test",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#run-the-permutation-test",
    "title": "Natural Language Processing",
    "section": "Run the permutation test",
    "text": "Run the permutation test\n\n1perm_scores = permutation_test(model, X_val_ct, y_val)[:,1]\n2plt.plot(perm_scores);\n3plt.xlabel(\"Input index\"); plt.ylabel(\"Accuracy when shuffled\");\n\n\n1\n\nThe permutation_test, aims to evaluate the model’s performance on different sets of unseen data. The idea here is to shuffle the order of the val set, and compare the model performance. [:,1] part will extract the accuracy of the output from the model evaluation and store is as a vector.\n\n2\n\nPlots the permutation scores\n\n3\n\nLabels x and y axes\n\n\n\n\n\n\n\n\n\n\n\nThe above method on a high-level says that, if we corrupt the information contained in a feature by changing the order of the data in that feature column, then we are able to see how much information the variable brings in. If a certain variable is not contributing to the prediction accuracy, then changing the order of the variable will not result in a notable drop in accuracy. However, if a certain variable is highly important, then changing the order of data will result in a larger drop. This is an indication of variable importance. The plot above shows how model’s accuracy fluctuates across variables, and we can see how certain variables result in larger drops of accuracies.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#find-the-most-significant-inputs",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#find-the-most-significant-inputs",
    "title": "Natural Language Processing",
    "section": "Find the most significant inputs",
    "text": "Find the most significant inputs\n\n1vocab = vect.get_feature_names_out()\n2input_cols = list(vocab) + weather_cols\n\n3best_input_inds = np.argsort(perm_scores)[:100]\n4best_inputs = [input_cols[idx] for idx in best_input_inds]\n\n5print(best_inputs)\n\n\n1\n\nExtracts the names of the features in a vectorizer object\n\n2\n\nCombines the list of names in the vectorizer object with the weather columns\n\n3\n\nSorts the perm_scores in the ascending order and select the 100 observation which had the most impact on model’s accuracy\n\n4\n\nFind the names of the input features by mapping the index\n\n5\n\nPrints the output\n\n\n\n\n['harmful', 'involve', 'event', 'lane', 'rear', 'code', 'single', 'year', 'park', 'edge', 'traffic', 'medication', 'north', 'dry', 'cross', 'impact', 'asphalt', 'male', 'barrier', 'motor', 'intersection', 'critical', 'tree', 'try', 'drive', 'turn', 'afternoon', 'direction', 'familiar', 'female', 'pickup', 'line', 'WEATHER4', 'light', 'WEATHER2', 'reason', 'assign', 'undivided', 'look', 'car', 'southbound', 'legally', 'control', 'kmph', 'occur', 'overcompensation', 'curb', 'rush', 'strike', 'quarter', 'WEATHER8', 'weekday', 'WEATHER5', 'complete', 'counterclockwise', 'forward', 'street', 'recognition', 'transport', 'bind', 'driver', 'kph', 'wall', 'old', 'bmw', 'action', 'change', 'pedestrian', 'distraction', 'grassy', 'sideswipe', 'directional', 'ground', 'shoulder', 'past', 'help', 'route', 'decelerate', 'hear', 'stop', 'realize', 'weekly', 'encroachment', 'contact', 'pre', 'WEATHER7', 'ford', 'lexus', 'continue', 'lot', 'push', 'exist', 'contribute', 'cloudy', 'close', 'force', 'failure', 'poor', 'shopping', 'northeast']",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#how-about-a-simple-decision-tree",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#how-about-a-simple-decision-tree",
    "title": "Natural Language Processing",
    "section": "How about a simple decision tree?",
    "text": "How about a simple decision tree?\nWe can try building a simpler model using only the most important features. Here, we chose a classification decision tree.\n\n1from sklearn import tree\n2clf = tree.DecisionTreeClassifier(random_state=0, max_leaf_nodes=3)\n3clf.fit(X_train_ct[:, best_input_inds], y_train);\n\n\n1\n\nImports tree class from sklearn\n\n2\n\nSpecifies a decision tree with 3 leaf nodes. max_leaf_nodes=3 ensures that the fitted tree will have at most 3 leaf nodes\n\n3\n\nFits the decision tree on the selected dataset. Here we only select the best_input_inds columns from the train set\n\n\n\n\n\nprint(clf.score(X_train_ct[:, best_input_inds], y_train))\nprint(clf.score(X_val_ct[:, best_input_inds], y_val))\n\n0.920844327176781\n0.9330935251798561\n\n\nThe decision tree ends up giving pretty good results.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#decision-tree",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#decision-tree",
    "title": "Natural Language Processing",
    "section": "Decision tree",
    "text": "Decision tree\n\ntree.plot_tree(clf, feature_names=best_inputs, filled=True);\n\n\n\n\n\n\n\n\n\n\n\nprint(np.where(clf.feature_importances_ &gt; 0)[0])\n[best_inputs[ind] for ind in np.where(clf.feature_importances_ &gt; 0)[0]]\n\n[ 0 35]\n\n\n['harmful', 'reason']",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#using-the-original-dataset",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#using-the-original-dataset",
    "title": "Natural Language Processing",
    "section": "Using the original dataset",
    "text": "Using the original dataset\n\nperm_scores = permutation_test(model, X_val_ct, y_val)[:,1]\nplt.plot(perm_scores);\nplt.xlabel(\"Input index\"); plt.ylabel(\"Accuracy when shuffled\");",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#find-the-most-significant-inputs-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#find-the-most-significant-inputs-1",
    "title": "Natural Language Processing",
    "section": "Find the most significant inputs",
    "text": "Find the most significant inputs\n\nvocab = vect.get_feature_names_out()\ninput_cols = list(vocab) + weather_cols\n\nbest_input_inds = np.argsort(perm_scores)[:100]\nbest_inputs = [input_cols[idx] for idx in best_input_inds]\n\nprint(best_inputs)\n\n['v3', 'v2', 'involved', 'road', 'coded', 'impact', 'harmful', 'parked', 'WEATHER3', 'event', 'edge', 'v4', 'single', 'year', 'bituminous', 'WEATHER8', 'conditions', 'pushed', 'legally', 'came', 'vehicle', 'line', 'WEATHER5', 'WEATHER4', 'crash', 'WEATHER1', 'towed', 'cm', 'downhill', 'generally', 'highway', 'slope', 'higher', 'straight', 'brake', 'stopped', 'direction', 'occurred', 'critical', 'turning', 'WEATHER7', 'looked', 'way', 'trailer', 'let', 'driven', 'wet', 'precrash', 'location', 'went', 'light', 'continued', 'sign', 'motor', 'controlled', 'barrier', '30', 'illegal', 'events', 'steer', 'police', 'exit', 'steering', 'curve', 'daily', 'damage', 'failed', 'headed', 'route', 'northbound', 'poor', 'blazer', 'avoid', 'near', 'facing', 'posted', 'belted', 'cadillac', 'non', '1998', 'nissan', 'began', 'suffered', 'hearing', 'curb', 'right', 'picked', 'sedan', 'outside', 'fast', 'conversation', 'skidded', 'free', 'ford', 'setting', 'comprised', 'seven', 'condition', 'flow', 'passengers']",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#how-about-a-simple-decision-tree-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#how-about-a-simple-decision-tree-1",
    "title": "Natural Language Processing",
    "section": "How about a simple decision tree?",
    "text": "How about a simple decision tree?\n\nclf = tree.DecisionTreeClassifier(random_state=0, max_leaf_nodes=3)\nclf.fit(X_train_ct[:, best_input_inds], y_train);\n\n\nprint(clf.score(X_train_ct[:, best_input_inds], y_train))\nprint(clf.score(X_val_ct[:, best_input_inds], y_val))\n\n0.9275605660829935\n0.939568345323741",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#decision-tree-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#decision-tree-1",
    "title": "Natural Language Processing",
    "section": "Decision tree",
    "text": "Decision tree\n\ntree.plot_tree(clf, feature_names=best_inputs, filled=True);\n\nThe tree shows how, the model would check for the word v3, and decides the prediction as 3+. This is not very meaningful, because having v3 in the input is a direct indication of the number of vehicles.\n\n\n\n\n\n\n\n\n\n\nprint(np.where(clf.feature_importances_ &gt; 0)[0])\n[best_inputs[ind] for ind in np.where(clf.feature_importances_ &gt; 0)[0]]\n\n[ 0 38]\n\n\n['v3', 'critical']",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#overview",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#overview",
    "title": "Natural Language Processing",
    "section": "Overview",
    "text": "Overview\n\nIn order for deep learning models to process language, we need to supply that language to the model in a way it can digest, i.e. a quantitative representation such as a 2-D matrix of numerical values.\n\n\n\nPopular methods for converting text into numbers include:\n\nOne-hot encoding\nBag of words\nTF-IDF\nWord vectors (transfer learning)\n\n\n\n\n\nAssigning Numbers\n\n\n\n\n\nSource: Randall Munroe (2022), xkcd #2610: Assigning Numbers.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#word-vectors",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#word-vectors",
    "title": "Natural Language Processing",
    "section": "Word Vectors",
    "text": "Word Vectors\n\nOne-hot representations capture word ‘existence’ only, whereas word vectors capture information about word meaning as well as location.\nThis enables deep learning NLP models to automatically learn linguistic features.\nWord2Vec & GloVe are popular algorithms for generating word embeddings (i.e. word vectors).",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#word-vectors-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#word-vectors-1",
    "title": "Natural Language Processing",
    "section": "Word Vectors",
    "text": "Word Vectors\n\n\n\nIllustrative word vectors.\n\n\nWord vectors are a type of word embedding which can return numerical representations of words in a continuous vector space. There representations capture semantic knowledge of the words. For example, we can see how days are positioned closer to each other in a n-dimensional space.\n\n\nOverarching concept is to assign each word within a corpus to a particular, meaningful location within a multidimensional space called the vector space.\nInitially each word is assigned to a random location.\nBUT by considering the words that tend to be used around a given word within the corpus, the locations of the words shift.\n\n\n\nSource: Krohn (2019), Deep Learning Illustrated, Figure 2-6.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#remember-this-diagram",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#remember-this-diagram",
    "title": "Natural Language Processing",
    "section": "Remember this diagram?",
    "text": "Remember this diagram?\n\n\n\nEmbeddings will gradually improve during training.\n\n\nEmbeddings are numerical representations of categorical data that were learned during the supervised learning process. However, numerical representations like Word2Vec & GloVe are popular algorithms for generating word embeddings that were trained by others, i.e. they are pretrained.\n\nSource: Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Figure 13-4.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#word2vec",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#word2vec",
    "title": "Natural Language Processing",
    "section": "Word2Vec",
    "text": "Word2Vec\nKey idea: You’re known by the company you keep.\nTwo algorithms are used to calculate embeddings:\n\nContinuous bag of words: uses the context words to predict the target word\nSkip-gram: uses the target word to predict the context words\n\nPredictions are made using a neural network with one hidden layer. Through backpropagation, we update a set of “weights” which become the word vectors.\n\nPaper: Mikolov et al. (2013), Efficient estimation of word representations in vector space, arXiv:1301.3781.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#word2vec-training-methods",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#word2vec-training-methods",
    "title": "Natural Language Processing",
    "section": "Word2Vec training methods",
    "text": "Word2Vec training methods\n\n\n\nContinuous bag of words is a center word prediction task\n\n\n\n\n\nSkip-gram is a neighbour word prediction task\n\n\n\n\n\n\n\n\nSuggested viewing\n\n\n\nComputerphile (2019), Vectoring Words (Word Embeddings), YouTube (16 mins).\n\n\n\nSource: Amit Chaudhary (2020), Self Supervised Representation Learning in NLP.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#the-skip-gram-network",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#the-skip-gram-network",
    "title": "Natural Language Processing",
    "section": "The skip-gram network",
    "text": "The skip-gram network\n\n\n\nThe skip-gram model. Both the input vector \\boldsymbol{x} and the output \\boldsymbol{y} are one-hot encoded word representations. The hidden layer is the word embedding of size N.\n\n\n\nSource: Lilian Weng (2017), Learning Word Embedding, Blog post, Figure 1.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#word-vector-arithmetic",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#word-vector-arithmetic",
    "title": "Natural Language Processing",
    "section": "Word Vector Arithmetic",
    "text": "Word Vector Arithmetic\n\n\nRelationships between words becomes vector math.\n\n\n\nYou remember vectors, right?\n\n\n\n\nE.g., if we calculate the direction and distance between the coordinates of the words Paris and France, and trace this direction and distance from London, we should be close to the word England.\n\n\n\n\n\n\nIllustrative word vector arithmetic\n\n\n\n\n\nScreenshot from Word2viz\n\n\n\n\n\nSources: PressBooks, College Physics: OpenStax, Chapter 17 Figure 9, and Krohn (2019), Deep Learning Illustrated, Figures 2-7 & 2-8.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#pretrained-word-embeddings",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#pretrained-word-embeddings",
    "title": "Natural Language Processing",
    "section": "Pretrained word embeddings",
    "text": "Pretrained word embeddings\n\n1!pip install gensim\n\n\n1\n\nImports the gensim library. This is a popular library for document analysis\n\n\n\n\nLoad word2vec embeddings trained on Google News:\n\n1import gensim.downloader as api\n2wv = api.load('word2vec-google-news-300')\n\n\n1\n\nImports the gensim.downloader module from the gensim library and stores is as api. This module contains pretrained models including Word2Vec and GloVe that can be used for NLP tasks\n\n2\n\nLoads the Word2Vec from the word2vec-google-news-300 dataset and stores is as wv\n\n\n\n\nWhen run for the first time, that downloads a huge file:\n\ngensim_dir = Path(\"~/gensim-data/\").expanduser()\n[str(p) for p in gensim_dir.iterdir()]\n\n['/home/plaub/gensim-data/information.json',\n '/home/plaub/gensim-data/word2vec-google-news-300']\n\n\n\nnext(gensim_dir.glob(\"*/*.gz\")).stat().st_size / 1024**3\n\n1.6238203644752502\n\n\n\nf\"The size of the vocabulary is {len(wv)}\"\n\n'The size of the vocabulary is 3000000'",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#treat-wv-like-a-dictionary",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#treat-wv-like-a-dictionary",
    "title": "Natural Language Processing",
    "section": "Treat wv like a dictionary",
    "text": "Treat wv like a dictionary\n\nwv[\"pizza\"]\n\narray([-1.26e-01,  2.54e-02,  1.67e-01,  5.51e-01, -7.67e-02,  1.29e-01,\n        1.03e-01, -3.95e-04,  1.22e-01,  4.32e-02,  1.73e-01, -6.84e-02,\n        3.42e-01,  8.40e-02,  6.69e-02,  2.68e-01, -3.71e-02, -5.57e-02,\n        1.81e-01,  1.90e-02, -5.08e-02,  9.03e-03,  1.77e-01,  6.49e-02,\n       -6.25e-02, -9.42e-02, -9.72e-02,  4.00e-01,  1.15e-01,  1.03e-01,\n       -1.87e-02, -2.70e-01,  1.81e-01,  1.25e-01, -3.17e-02, -5.49e-02,\n        3.46e-01, -1.57e-02,  1.82e-05,  2.07e-01, -1.26e-01, -2.83e-01,\n        2.00e-01,  8.35e-02, -4.74e-02, -3.11e-02, -2.62e-01,  1.70e-01,\n       -2.03e-02,  1.53e-01, -1.21e-01,  3.75e-01, -5.69e-02, -4.76e-03,\n       -1.95e-01, -2.03e-01,  3.01e-01, -1.01e-01, -3.18e-01, -9.03e-02,\n       -1.19e-01,  1.95e-01, -8.79e-02,  1.58e-01,  1.52e-02, -1.60e-01,\n       -3.30e-01, -4.67e-01,  1.69e-01,  2.23e-02,  1.55e-01,  1.08e-01,\n       -3.56e-02,  9.13e-02, -8.69e-02, -1.20e-01, -3.09e-01, -2.61e-02,\n       -7.23e-02, -4.80e-01,  3.78e-02, -1.36e-01, -1.03e-01, -2.91e-01,\n       -1.93e-01, -4.22e-01, -1.06e-01,  3.55e-01,  1.67e-01, -3.63e-03,\n       -7.42e-02, -3.22e-01, -7.52e-02, -8.25e-02, -2.91e-01, -1.26e-01,\n        1.68e-02,  5.00e-02,  1.28e-01, -7.42e-02, -1.31e-01, -2.46e-01,\n        6.49e-02,  1.53e-01,  2.60e-01, -1.05e-01,  3.57e-01, -4.30e-02,\n       -1.58e-01,  8.20e-02, -5.98e-02, -2.34e-01, -3.22e-01, -1.26e-01,\n        5.40e-02, -1.88e-01,  1.36e-01, -6.59e-02,  8.36e-03, -1.85e-01,\n       -2.97e-01, -1.85e-01, -4.74e-02, -1.06e-01, -6.93e-02,  3.83e-02,\n       -3.20e-02,  3.64e-02, -1.20e-01,  1.77e-01, -1.16e-01,  1.99e-02,\n        8.64e-02,  6.08e-02, -1.41e-01,  3.30e-01,  1.94e-01, -1.56e-01,\n        3.93e-01,  1.81e-03,  7.28e-02, -2.54e-01, -3.54e-02,  2.87e-03,\n       -1.73e-01,  9.77e-03, -1.56e-02,  3.23e-03, -1.70e-01,  1.55e-01,\n        7.18e-02,  4.10e-01, -2.11e-01,  1.32e-01,  7.63e-03,  4.79e-02,\n       -4.54e-02,  7.32e-02, -4.06e-01, -2.06e-02, -4.04e-01, -1.01e-01,\n       -2.03e-01,  1.55e-01, -1.89e-01,  6.59e-02,  6.54e-02, -2.05e-01,\n        5.47e-02, -3.06e-02, -1.54e-01, -2.62e-01,  3.81e-03, -8.20e-02,\n       -3.20e-01,  2.84e-02,  2.70e-01,  1.74e-01, -1.67e-01,  2.23e-01,\n        6.35e-02, -1.96e-01,  1.46e-01, -1.56e-02,  2.60e-02, -6.30e-02,\n        2.94e-02,  3.28e-01, -4.69e-02, -1.52e-01,  6.98e-02,  3.18e-01,\n       -1.08e-01,  3.66e-02, -1.99e-01,  1.64e-03,  6.41e-03, -1.47e-01,\n       -6.25e-02, -4.36e-03, -2.75e-01,  8.54e-02, -5.00e-02, -3.12e-01,\n       -1.34e-01, -1.99e-01,  5.18e-02, -9.28e-02, -2.40e-01, -7.86e-02,\n       -1.54e-01, -6.64e-02, -1.97e-01,  1.77e-01, -1.57e-01, -1.63e-01,\n        6.01e-02, -5.86e-02, -2.23e-01, -6.59e-02, -9.38e-02, -4.14e-01,\n        2.56e-01, -1.77e-01,  2.52e-01,  1.48e-01, -1.04e-01, -8.61e-03,\n       -1.23e-01, -9.23e-02,  4.42e-02, -1.71e-01, -1.98e-01,  1.92e-01,\n        2.85e-01, -4.35e-02,  1.08e-01, -5.37e-02, -2.10e-02,  1.46e-01,\n        3.83e-01,  2.32e-02, -8.84e-02,  7.32e-02, -1.01e-01, -1.06e-01,\n        4.12e-01,  2.11e-01,  2.79e-01, -2.09e-02,  2.07e-01,  9.81e-02,\n        2.39e-01,  7.67e-02,  2.02e-01, -6.08e-02, -2.64e-03, -1.84e-01,\n       -1.57e-02, -3.20e-01,  9.03e-02,  1.02e-01, -4.96e-01, -9.72e-02,\n       -8.11e-02, -1.81e-01, -1.46e-01,  8.64e-02, -2.04e-01, -2.02e-01,\n       -5.47e-02,  2.54e-01,  2.09e-02, -1.16e-01,  2.02e-01, -8.06e-02,\n       -1.05e-01, -7.96e-02,  1.97e-02, -2.49e-01,  1.31e-01,  2.89e-01,\n       -2.26e-01,  4.55e-01, -2.73e-01, -2.58e-01, -3.15e-02,  4.04e-01,\n       -2.68e-01,  2.89e-01, -1.84e-01, -1.48e-01, -1.07e-01,  1.28e-01,\n        5.47e-01, -8.69e-02, -1.48e-02,  6.98e-02, -8.50e-02, -1.55e-01],\n      dtype=float32)\n\n\n\nlen(wv[\"pizza\"])\n\n300",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#find-nearby-word-vectors",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#find-nearby-word-vectors",
    "title": "Natural Language Processing",
    "section": "Find nearby word vectors",
    "text": "Find nearby word vectors\nWith wv, we can find words similar for a given word, or compute the similarity between two words.\n\nwv.most_similar(\"Python\")\n\n[('Jython', 0.6152505874633789),\n ('Perl_Python', 0.5710949897766113),\n ('IronPython', 0.5704679489135742),\n ('scripting_languages', 0.5695090889930725),\n ('PHP_Perl', 0.5687724947929382),\n ('Java_Python', 0.5681070685386658),\n ('PHP', 0.5660915970802307),\n ('Python_Ruby', 0.5632461905479431),\n ('Visual_Basic', 0.5603480339050293),\n ('Perl', 0.5530891418457031)]\n\n\n\nwv.similarity(\"Python\", \"Java\")\n\n0.46189708\n\n\n\nwv.similarity(\"Python\", \"sport\")\n\n0.08406468\n\n\n\nwv.similarity(\"Python\", \"R\")\n\n0.066954285\n\n\n\nFun fact: Gensim’s most_similar uses Spotify’s annoy library (“Approximate Nearest Neighbors Oh Yeah”)",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#what-does-similarity-mean",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#what-does-similarity-mean",
    "title": "Natural Language Processing",
    "section": "What does ‘similarity’ mean?",
    "text": "What does ‘similarity’ mean?\nThe ‘similarity’ scores\n\nwv.similarity(\"Sydney\", \"Melbourne\")\n\n0.8613987\n\n\nare normally based on cosine distance.\n\nx = wv[\"Sydney\"]\ny = wv[\"Melbourne\"]\nx.dot(y) / (np.linalg.norm(x) * np.linalg.norm(y))\n\n0.86139864\n\n\n\nwv.similarity(\"Sydney\", \"Aarhus\")\n\n0.19079602",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#wengs-got-word2vec",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#wengs-got-word2vec",
    "title": "Natural Language Processing",
    "section": "Weng’s GoT Word2Vec",
    "text": "Weng’s GoT Word2Vec\nIn the GoT word embedding space, the top similar words to “king” and “queen” are:\n\n\nmodel.most_similar('king')\n('kings', 0.897245) \n('baratheon', 0.809675) \n('son', 0.763614)\n('robert', 0.708522)\n('lords', 0.698684)\n('joffrey', 0.696455)\n('prince', 0.695699)\n('brother', 0.685239)\n('aerys', 0.684527)\n('stannis', 0.682932)\n\nmodel.most_similar('queen')\n('cersei', 0.942618)\n('joffrey', 0.933756)\n('margaery', 0.931099)\n('sister', 0.928902)\n('prince', 0.927364)\n('uncle', 0.922507)\n('varys', 0.918421)\n('ned', 0.917492)\n('melisandre', 0.915403)\n('robb', 0.915272)\n\n\n\nSource: Lilian Weng (2017), Learning Word Embedding, Blog post.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#combining-word-vectors",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#combining-word-vectors",
    "title": "Natural Language Processing",
    "section": "Combining word vectors",
    "text": "Combining word vectors\nYou can summarise a sentence by averaging the individual word vectors.\n\nsv = (wv[\"Melbourne\"] + wv[\"has\"] + wv[\"better\"] + wv[\"coffee\"]) / 4\nlen(sv), sv[:5]\n\n(300, array([-0.08, -0.11, -0.16,  0.24,  0.06], dtype=float32))\n\n\n\nAs it turns out, averaging word embeddings is a surprisingly effective way to create word embeddings. It’s not perfect (as you’ll see), but it does a strong job of capturing what you might perceive to be complex relationships between words.\n\n\nSource: Trask (2019), Grokking Deep Learning, Chapter 12.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#recipe-recommender",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#recipe-recommender",
    "title": "Natural Language Processing",
    "section": "Recipe recommender",
    "text": "Recipe recommender\n\n\n\n\n\nRecipes are the average of the word vectors of the ingredients.\n\n\n\n\n\n\nNearest neighbours used to classify new recipes as potentially delicious.\n\n\n\n\n\nSource: Duarte O.Carmo (2022), A recipe recommendation system, Blog post.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#analogies-with-word-vectors",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#analogies-with-word-vectors",
    "title": "Natural Language Processing",
    "section": "Analogies with word vectors",
    "text": "Analogies with word vectors\nObama is to America as ___ is to Australia.\n\n \\text{Obama} - \\text{America} + \\text{Australia} = ? \n\n\n\nwv.most_similar(positive=[\"Obama\", \"Australia\"], negative=[\"America\"])\n\n[('Mr_Rudd', 0.6151423454284668),\n ('Prime_Minister_Julia_Gillard', 0.6045385003089905),\n ('Prime_Minister_Kevin_Rudd', 0.5982581973075867),\n ('Kevin_Rudd', 0.5627648830413818),\n ('Ms_Gillard', 0.5517690777778625),\n ('Opposition_Leader_Kevin_Rudd', 0.5298037528991699),\n ('Mr_Beazley', 0.5259249210357666),\n ('Gillard', 0.5250653624534607),\n ('NARDA_GILMORE', 0.5203536748886108),\n ('Mr_Downer', 0.5150347948074341)]",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#testing-more-associations",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#testing-more-associations",
    "title": "Natural Language Processing",
    "section": "Testing more associations",
    "text": "Testing more associations\n\nwv.most_similar(positive=[\"France\", \"London\"], negative=[\"Paris\"])\n\n[('Britain', 0.7368935346603394),\n ('UK', 0.6637030839920044),\n ('England', 0.6119861602783203),\n ('United_Kingdom', 0.6067784428596497),\n ('Great_Britain', 0.5870823860168457),\n ('Britian', 0.5852951407432556),\n ('Scotland', 0.5410018563270569),\n ('British', 0.5318332314491272),\n ('Europe', 0.5307435989379883),\n ('East_Midlands', 0.5230222344398499)]",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#quickly-get-to-bad-associations",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#quickly-get-to-bad-associations",
    "title": "Natural Language Processing",
    "section": "Quickly get to bad associations",
    "text": "Quickly get to bad associations\n\nwv.most_similar(positive=[\"King\", \"woman\"], negative=[\"man\"])\n\n[('Queen', 0.5515626668930054),\n ('Oprah_BFF_Gayle', 0.47597548365592957),\n ('Geoffrey_Rush_Exit', 0.46460166573524475),\n ('Princess', 0.4533674716949463),\n ('Yvonne_Stickney', 0.4507041573524475),\n ('L._Bonauto', 0.4422135353088379),\n ('gal_pal_Gayle', 0.4408389925956726),\n ('Alveda_C.', 0.4402790665626526),\n ('Tupou_V.', 0.4373864233493805),\n ('K._Letourneau', 0.4351031482219696)]\n\n\n\nwv.most_similar(positive=[\"computer_programmer\", \"woman\"], negative=[\"man\"])\n\n[('homemaker', 0.5627118945121765),\n ('housewife', 0.5105047225952148),\n ('graphic_designer', 0.505180299282074),\n ('schoolteacher', 0.497949481010437),\n ('businesswoman', 0.493489146232605),\n ('paralegal', 0.49255111813545227),\n ('registered_nurse', 0.4907974898815155),\n ('saleswoman', 0.4881627559661865),\n ('electrical_engineer', 0.4797725975513458),\n ('mechanical_engineer', 0.4755399227142334)]",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#bias-in-nlp-models",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#bias-in-nlp-models",
    "title": "Natural Language Processing",
    "section": "Bias in NLP models",
    "text": "Bias in NLP models\n\n\n\nThe Verge (2016), Twitter taught Microsoft’s AI chatbot to be a racist a****** in less than a day.\n\n\n… there are serious questions to answer, like how are we going to teach AI using public data without incorporating the worst traits of humanity? If we create bots that mirror their users, do we care if their users are human trash? There are plenty of examples of technology embodying — either accidentally or on purpose — the prejudices of society, and Tay’s adventures on Twitter show that even big corporations like Microsoft forget to take any preventative measures against these problems.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#the-library-cheats-a-little-bit",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#the-library-cheats-a-little-bit",
    "title": "Natural Language Processing",
    "section": "The library cheats a little bit",
    "text": "The library cheats a little bit\n\nwv.similar_by_vector(wv[\"computer_programmer\"]-wv[\"man\"]+wv[\"woman\"])\n\n[('computer_programmer', 0.910581111907959),\n ('homemaker', 0.5771316289901733),\n ('schoolteacher', 0.5500192046165466),\n ('graphic_designer', 0.5464698672294617),\n ('mechanical_engineer', 0.539836585521698),\n ('electrical_engineer', 0.5337055325508118),\n ('housewife', 0.5274525284767151),\n ('programmer', 0.5096209049224854),\n ('businesswoman', 0.5029540657997131),\n ('keypunch_operator', 0.4974639415740967)]\n\n\nTo get the ‘nice’ analogies, the .most_similar ignores the input words as possible answers.\n\n# ignore (don't return) keys from the input\nresult = [\n    (self.index_to_key[sim + clip_start], float(dists[sim]))\n    for sim in best if (sim + clip_start) not in all_keys\n]\n\n\nSource: gensim, gensim/models/keyedvectors.py, lines 853-857.",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#predict-injury-severity",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#predict-injury-severity",
    "title": "Natural Language Processing",
    "section": "Predict injury severity",
    "text": "Predict injury severity\n\nfeatures = df[\"SUMMARY_EN\"]\ntarget = LabelEncoder().fit_transform(df[\"INJSEVB\"])\n\nX_main, X_test, y_main, y_test = \\\n    train_test_split(features, target, test_size=0.2, random_state=1)\nX_train, X_val, y_train, y_val = \\\n    train_test_split(X_main, y_main, test_size=0.25, random_state=1)\nX_train.shape, X_val.shape, X_test.shape\n\n((4169,), (1390,), (1390,))",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#using-keras-textvectorization",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#using-keras-textvectorization",
    "title": "Natural Language Processing",
    "section": "Using Keras TextVectorization",
    "text": "Using Keras TextVectorization\n\nmax_tokens = 1_000\nvect = layers.TextVectorization(\n    max_tokens=max_tokens,\n    output_mode=\"tf_idf\",\n    standardize=\"lower_and_strip_punctuation\",\n)\n\nvect.adapt(X_train)\nvocab = vect.get_vocabulary()\n\nX_train_txt = vect(X_train)\nX_val_txt = vect(X_val)\nX_test_txt = vect(X_test)\n\nprint(vocab[:50])\n\n['[UNK]', 'the', 'was', 'a', 'to', 'of', 'and', 'in', 'driver', 'for', 'this', 'vehicle', 'critical', 'lane', 'he', 'on', 'with', 'that', 'left', 'roadway', 'coded', 'she', 'event', 'crash', 'not', 'at', 'intersection', 'traveling', 'right', 'precrash', 'as', 'from', 'were', 'by', 'had', 'reason', 'his', 'side', 'is', 'front', 'her', 'traffic', 'an', 'it', 'two', 'speed', 'stated', 'one', 'occurred', 'no']",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#the-tf-idf-vectors",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#the-tf-idf-vectors",
    "title": "Natural Language Processing",
    "section": "The TF-IDF vectors",
    "text": "The TF-IDF vectors\n\npd.DataFrame(X_train_txt, columns=vocab, index=X_train.index)\n\n\n\n\n\n\n\n\n[UNK]\nthe\nwas\na\nto\nof\nand\nin\ndriver\nfor\n...\nencroaching\nclosely\nordinarily\nlocked\nhistory\nfourleg\ndetermined\nbox\naltima\nabove\n\n\n\n\n2532\n121.857979\n42.274662\n10.395409\n10.395409\n11.785541\n8.323526\n8.323526\n9.775118\n3.489896\n4.168983\n...\n0.0\n0.0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n6209\n72.596237\n17.325682\n10.395409\n5.544218\n4.159603\n5.549018\n7.629900\n4.887559\n4.187876\n6.253474\n...\n0.0\n0.0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n2561\n124.450699\n30.493198\n15.246599\n11.088436\n9.012472\n7.629900\n8.323526\n2.792891\n3.489896\n5.558644\n...\n0.0\n0.0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n6882\n75.188965\n20.790817\n4.851191\n7.623300\n9.012472\n4.855391\n4.161763\n2.094668\n5.583834\n2.084491\n...\n0.0\n0.0\n3.61771\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n206\n147.785202\n27.028063\n13.167518\n6.237246\n8.319205\n4.855391\n6.242645\n2.094668\n3.489896\n9.032796\n...\n0.0\n0.0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n6356\n75.188965\n15.246599\n9.702381\n8.316327\n7.625938\n5.549018\n7.629900\n8.378673\n2.791917\n5.558644\n...\n0.0\n0.0\n0.00000\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n4169 rows × 1000 columns",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#feed-tf-idf-into-an-ann",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#feed-tf-idf-into-an-ann",
    "title": "Natural Language Processing",
    "section": "Feed TF-IDF into an ANN",
    "text": "Feed TF-IDF into an ANN\n\nrandom.seed(42)\ntfidf_model = keras.models.Sequential([\n    layers.Input((X_train_txt.shape[1],)),\n    layers.Dense(250, \"relu\"),\n    layers.Dense(1, \"sigmoid\")\n])\n\ntfidf_model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\ntfidf_model.summary()\n\nModel: \"sequential_4\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ dense_8 (Dense)                 │ (None, 250)               │    250,250 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_9 (Dense)                 │ (None, 1)                 │        251 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 250,501 (978.52 KB)\n\n\n\n Trainable params: 250,501 (978.52 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#fit-evaluate",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#fit-evaluate",
    "title": "Natural Language Processing",
    "section": "Fit & evaluate",
    "text": "Fit & evaluate\n\nes = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True,\n    monitor=\"val_accuracy\", verbose=2)\n\nif not Path(\"tfidf-model.keras\").exists():\n    tfidf_model.fit(X_train_txt, y_train, epochs=1_000, callbacks=es,\n        validation_data=(X_val_txt, y_val), verbose=0)\n    tfidf_model.save(\"tfidf-model.keras\")\nelse:\n    tfidf_model = keras.models.load_model(\"tfidf-model.keras\")\n\n\ntfidf_model.evaluate(X_train_txt, y_train, verbose=0, batch_size=1_000)\n\n[0.0677284300327301, 0.9824662208557129]\n\n\n\ntfidf_model.evaluate(X_val_txt, y_val, verbose=0, batch_size=1_000)\n\n[0.34314268827438354, 0.8787692785263062]",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#keep-text-as-sequence-of-tokens",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#keep-text-as-sequence-of-tokens",
    "title": "Natural Language Processing",
    "section": "Keep text as sequence of tokens",
    "text": "Keep text as sequence of tokens\n\nmax_length = 500\nmax_tokens = 1_000\nvect = layers.TextVectorization(\n    max_tokens=max_tokens,\n    output_sequence_length=max_length,\n    standardize=\"lower_and_strip_punctuation\",\n)\n\nvect.adapt(X_train)\nvocab = vect.get_vocabulary()\n\nX_train_txt = vect(X_train)\nX_val_txt = vect(X_val)\nX_test_txt = vect(X_test)\n\nprint(vocab[:50])\n\n['', '[UNK]', 'the', 'was', 'a', 'to', 'of', 'and', 'in', 'driver', 'for', 'this', 'vehicle', 'critical', 'lane', 'he', 'on', 'with', 'that', 'left', 'roadway', 'coded', 'she', 'event', 'crash', 'not', 'at', 'intersection', 'traveling', 'right', 'precrash', 'as', 'from', 'were', 'by', 'had', 'reason', 'his', 'side', 'is', 'front', 'her', 'traffic', 'an', 'it', 'two', 'speed', 'stated', 'one', 'occurred']",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#a-sequence-of-integers",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#a-sequence-of-integers",
    "title": "Natural Language Processing",
    "section": "A sequence of integers",
    "text": "A sequence of integers\n\nX_train_txt[0]\n\ntensor([ 11,  24,  49,   8,   2, 253, 219,   6,   4, 165,   8,   2, 410,   6,\n          4, 564, 971,  27,   2,  27, 568,   6,   4, 192,   1,  45,  51, 208,\n         65, 235,  54,  14,  20, 867,  34,  43, 183,   1,  45,  51, 208,  65,\n        235,  54,  14,  20, 178,  34,   4, 676,   1,  42, 237,   2, 153, 192,\n         20,   3, 107,   7,  75,  17,   4, 612, 441, 549,   2,  88,  46,   3,\n        207,  63, 185,  55,   2,  42, 243,   3, 400,   7,  58,  33,  50, 172,\n        251,  84,  26,   2,  60,   6,   2,  24,   1,   4, 402, 970,   1,   1,\n          3,  68,  26,   2,  27,  94, 118,   8,  14, 101, 311,  10,   2, 237,\n          5, 422, 269,  44, 154,  54,  19,   1,   4, 308, 342,   1,   3,  79,\n          8,  14,  45, 159,   2, 121,  27, 190,  44, 598,   5, 325,  75,  70,\n          2, 105, 189, 231,   1, 241,  81,  19,  31,   1, 193,   2,  54,  81,\n          9, 134,   4, 174,  12,  17,   1, 390,   1, 159,   2,  27,  32,   2,\n        119,   1,  68,   8,   2, 410,   6,   2,  27,   8,   1,   5,   2, 159,\n        174,  12,   1, 168,   2,  27,   7,  69,   2,  40,   6,   1,  17,  81,\n         40,  19, 246,  73,  83,  64,   5, 129,  56,   8,   2,  27,   7,  33,\n         73,  71,  57,   5,  82,   2,   9,   6,   1,   4,   1,  59, 382,   5,\n        113,   8, 276, 258,   1, 317, 928, 284,  10, 784, 294, 462, 483,   7,\n          1,  15,   3,  16,  37, 112,   5, 677, 144,   1,  26,   2,  60,   6,\n          2,  24,  15,  47,  18,  70,   2, 105, 429,  15,  35, 448,   1,   5,\n        493,  37,  54,  62,  68,  25,   1,  33,   5, 325,  70,  15, 134,   2,\n        174, 232, 406,  15, 341, 134,   1, 691,   2,  27,   7,  15,   1,  10,\n         93,  15,   3,  25, 216,   8,   2,  24,   2,  13,  30,  23,  10,   1,\n          3,  21,  11,  12,  28,  76,   2,  14, 130,  19,  38,   6, 106,  14,\n          2,  13,  36,   3,  21,  31,   4,   9,  91, 180,   1, 137,   1,   2,\n         87,  97,  21,   5,   1, 285,  43,   1, 511, 569,  15, 775, 140,   1,\n          2,  27,   7,  25,  68,  31, 184,  31,   2, 159, 174,  12,   1,   2,\n         42,   1,   2,   9,   6,   1,   4,   1,  59,   8, 276, 258,   3, 489,\n         37, 753, 544,  10,   4, 975, 313,  26,   2,  60,   6,   2,  24,  15,\n          3,  16,  37, 112, 110,  32, 151,  70,   2,  24,  49,  15,  47,  15,\n          3,  79,   8,  14, 191,  31,   2,  42, 105, 189, 231,  15, 647,   2,\n         12,   8,   2,  19,  94, 118,  35,   1,   5,  54,  19,   7, 141,   2,\n         27,  15,   1,  31,   2,  12, 347,  81,  54,   7,  90,   8,   2, 410,\n          6,   2,  27,  15, 503,  62, 154,  25, 143,   1,  15, 157, 134,   2,\n        174,  12,  17,  81, 390,   7,   1,  16, 111,  15, 168,   2,  27,  15,\n        588, 329, 117,   7,   3, 163,   5, 113, 947, 175,  26,   4, 643,   1,\n          2,  13,  30,  23,  10,   1,   3,  21,  52,  12])",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#feed-lstm-a-sequence-of-one-hots",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#feed-lstm-a-sequence-of-one-hots",
    "title": "Natural Language Processing",
    "section": "Feed LSTM a sequence of one-hots",
    "text": "Feed LSTM a sequence of one-hots\n\nrandom.seed(42)\ninputs = keras.Input(shape=(max_length,), dtype=\"int64\")\nonehot = keras.ops.one_hot(inputs, max_tokens)\nx = layers.Bidirectional(layers.LSTM(24))(onehot)\nx = layers.Dropout(0.5)(x) \noutputs = layers.Dense(1, activation=\"sigmoid\")(x)    \none_hot_model = keras.Model(inputs, outputs)\none_hot_model.compile(optimizer=\"adam\",\n    loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\none_hot_model.summary()\n\nModel: \"functional_8\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape              ┃    Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n│ input_layer_5 (InputLayer)      │ (None, 500)               │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ one_hot (OneHot)                │ (None, 500, 1000)         │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ bidirectional (Bidirectional)   │ (None, 48)                │    196,800 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dropout (Dropout)               │ (None, 48)                │          0 │\n├─────────────────────────────────┼───────────────────────────┼────────────┤\n│ dense_10 (Dense)                │ (None, 1)                 │         49 │\n└─────────────────────────────────┴───────────────────────────┴────────────┘\n\n\n\n Total params: 196,849 (768.94 KB)\n\n\n\n Trainable params: 196,849 (768.94 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#fit-evaluate-1",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#fit-evaluate-1",
    "title": "Natural Language Processing",
    "section": "Fit & evaluate",
    "text": "Fit & evaluate\n\nes = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True,\n    monitor=\"val_accuracy\", verbose=2)\n\n# if not Path(\"one-hot-model.keras\").exists():\none_hot_model.fit(X_train_txt, y_train, epochs=1_000, callbacks=es,\n    validation_data=(X_val_txt, y_val), verbose=0);\none_hot_model.save(\"one-hot-model.keras\")\n# else:\n#     one_hot_model = keras.models.load_model(\"one-hot-model.keras\")\n\nEpoch 9: early stopping\nRestoring model weights from the end of the best epoch: 6.\n\n\n\none_hot_model.evaluate(X_train_txt, y_train, verbose=0, batch_size=1_000)\n\n[0.5114213824272156, 0.755796492099762]\n\n\n\none_hot_model.evaluate(X_val_txt, y_val, verbose=0, batch_size=1_000)\n\n[0.552155613899231, 0.7065256834030151]",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#custom-embeddings",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#custom-embeddings",
    "title": "Natural Language Processing",
    "section": "Custom embeddings",
    "text": "Custom embeddings\n\ninputs = keras.Input(shape=(max_length,), dtype=\"int64\")\nembedded = layers.Embedding(input_dim=max_tokens, output_dim=32,\n        mask_zero=True)(inputs)\nx = layers.Bidirectional(layers.LSTM(24))(embedded)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(1, activation=\"sigmoid\")(x)\nembed_lstm = keras.Model(inputs, outputs)\nembed_lstm.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\nembed_lstm.summary()\n\nModel: \"functional_10\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)        ┃ Output Shape      ┃ Param # ┃ Connected to         ┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_6       │ (None, 500)       │       0 │ -                    │\n│ (InputLayer)        │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ embedding           │ (None, 500, 32)   │  32,000 │ input_layer_6[0][0]  │\n│ (Embedding)         │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ not_equal           │ (None, 500)       │       0 │ input_layer_6[0][0]  │\n│ (NotEqual)          │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ bidirectional_1     │ (None, 48)        │  10,944 │ embedding[0][0],     │\n│ (Bidirectional)     │                   │         │ not_equal[0][0]      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_1 (Dropout) │ (None, 48)        │       0 │ bidirectional_1[0][… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_11 (Dense)    │ (None, 1)         │      49 │ dropout_1[0][0]      │\n└─────────────────────┴───────────────────┴─────────┴──────────────────────┘\n\n\n\n Total params: 42,993 (167.94 KB)\n\n\n\n Trainable params: 42,993 (167.94 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#fit-evaluate-2",
    "href": "Lecture-5-Natural-Language-Processing/natural-language-processing.html#fit-evaluate-2",
    "title": "Natural Language Processing",
    "section": "Fit & evaluate",
    "text": "Fit & evaluate\n\nes = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True,\n    monitor=\"val_accuracy\", verbose=2)\n\n# if not Path(\"embed-lstm.keras\").exists():\nembed_lstm.fit(X_train_txt, y_train, epochs=1_000, callbacks=es,\n    validation_data=(X_val_txt, y_val), verbose=0);\nembed_lstm.save(\"embed-lstm.keras\")\n# else:\n#     embed_lstm = keras.models.load_model(\"embed-lstm.keras\")\n\nEpoch 7: early stopping\nRestoring model weights from the end of the best epoch: 4.\n\n\n\nembed_lstm.evaluate(X_train_txt, y_train, verbose=0, batch_size=1_000)\n\n[0.5268873572349548, 0.7479952573776245]\n\n\n\nembed_lstm.evaluate(X_val_txt, y_val, verbose=0, batch_size=1_000)\n\n[0.5730966925621033, 0.720064103603363]\n\n\n\nembed_lstm.evaluate(X_test_txt, y_test, verbose=0, batch_size=1_000)\n\n[0.5498431324958801, 0.742551326751709]",
    "crumbs": [
      "Module 5",
      "Natural Language Processing"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#load-packages",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#load-packages",
    "title": "Recurrent Neural Networks",
    "section": "Load packages",
    "text": "Load packages\n\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input\nfrom keras.callbacks import EarlyStopping\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.0\nIPython version      : 8.20.0\n\nsklearn   : 1.4.0\nkeras     : 3.0.4\ntorch     : 2.2.0\ntensorflow: 2.15.0.post1"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#shapes-of-data",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#shapes-of-data",
    "title": "Recurrent Neural Networks",
    "section": "Shapes of data",
    "text": "Shapes of data\n\nIllustration of tensors of different rank.\nSource: Paras Patidar (2019), Tensors — Representation of Data In Neural Networks, Medium article."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#the-axis-argument-in-numpy",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#the-axis-argument-in-numpy",
    "title": "Recurrent Neural Networks",
    "section": "The axis argument in numpy",
    "text": "The axis argument in numpy\nStarting with a (3, 4)-shaped matrix:\n\nX = np.arange(12).reshape(3,4)\nX\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\n\n\n\n\naxis=0: (3, 4) \\leadsto (4,).\n\nX.sum(axis=0)\n\narray([12, 15, 18, 21])\n\n\n\naxis=1: (3, 4) \\leadsto (3,).\n\nX.prod(axis=1)\n\narray([   0,  840, 7920])\n\n\n\n\nThe return value’s rank is one less than the input’s rank.\n\n\n\n\n\n\nImportant\n\n\nThe axis parameter tells us which dimension is removed."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#using-axis-keepdims",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#using-axis-keepdims",
    "title": "Recurrent Neural Networks",
    "section": "Using axis & keepdims",
    "text": "Using axis & keepdims\nWith keepdims=True, the rank doesn’t change.\n\nX = np.arange(12).reshape(3,4)\nX\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\n\n\n\n\naxis=0: (3, 4) \\leadsto (1, 4).\n\nX.sum(axis=0, keepdims=True)\n\narray([[12, 15, 18, 21]])\n\n\n\naxis=1: (3, 4) \\leadsto (3, 1).\n\nX.prod(axis=1, keepdims=True)\n\narray([[   0],\n       [ 840],\n       [7920]])\n\n\n\n\n\n\n\nX / X.sum(axis=1)\n\nValueError: operands could not be broadcast together with shapes (3,4) (3,) \n\n\n\n\nX / X.sum(axis=1, keepdims=True)\n\narray([[0.  , 0.17, 0.33, 0.5 ],\n       [0.18, 0.23, 0.27, 0.32],\n       [0.21, 0.24, 0.26, 0.29]])"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#the-rank-of-a-time-series",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#the-rank-of-a-time-series",
    "title": "Recurrent Neural Networks",
    "section": "The rank of a time series",
    "text": "The rank of a time series\nSay we had n observations of a time series x_1, x_2, \\dots, x_n.\nThis \\mathbf{x} = (x_1, \\dots, x_n) would have shape (n,) & rank 1.\nIf instead we had a batch of b time series’\n\n\\mathbf{X} = \\begin{pmatrix}\nx_7 & x_8 & \\dots & x_{7+n-1} \\\\\nx_2 & x_3 & \\dots & x_{2+n-1} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_3 & x_4 & \\dots & x_{3+n-1} \\\\\n\\end{pmatrix}  \\,,\n\nthe batch \\mathbf{X} would have shape (b, n) & rank 2."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#multivariate-time-series",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#multivariate-time-series",
    "title": "Recurrent Neural Networks",
    "section": "Multivariate time series",
    "text": "Multivariate time series\n\n\n\n\n\n\n\n\nt\nx\ny\n\n\n\n\n0\nx_0\ny_0\n\n\n1\nx_1\ny_1\n\n\n2\nx_2\ny_2\n\n\n3\nx_3\ny_3\n\n\n\n\n\n\n\nSay n observations of the m time series, would be a shape (n, m) matrix of rank 2.\nIn Keras, a batch of b of these time series has shape (b, n, m) and has rank 3.\n\n\n\n\n\n\n\n\nNote\n\n\nUse \\mathbf{x}_t \\in \\mathbb{R}^{1 \\times m} to denote the vector of all time series at time t. Here, \\mathbf{x}_t = (x_t, y_t)."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#recurrence-relation",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#recurrence-relation",
    "title": "Recurrent Neural Networks",
    "section": "Recurrence relation",
    "text": "Recurrence relation\n\nA recurrence relation is an equation that expresses each element of a sequence as a function of the preceding ones. More precisely, in the case where only the immediately preceding element is involved, a recurrence relation has the form\n u_n = \\psi(n, u_{n-1}) \\quad \\text{ for } \\quad n &gt; 0.\n\nExample: Factorial n! = n (n-1)! for n &gt; 0 given 0! = 1.\n\nSource: Wikipedia, Recurrence relation."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#diagram-of-an-rnn-cell",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#diagram-of-an-rnn-cell",
    "title": "Recurrent Neural Networks",
    "section": "Diagram of an RNN cell",
    "text": "Diagram of an RNN cell\nThe RNN processes each data in the sequence one by one, while keeping memory of what came before.\n\nSchematic of a simple recurrent neural network. E.g. SimpleRNN, LSTM, or GRU.\nSource: James et al (2022), An Introduction to Statistical Learning, 2nd edition, Figure 10.12."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-simplernn-cell.",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-simplernn-cell.",
    "title": "Recurrent Neural Networks",
    "section": "A SimpleRNN cell.",
    "text": "A SimpleRNN cell.\n\nDiagram of a SimpleRNN cell.All the outputs before the final one are often discarded.\n\nSource: Christopher Olah (2015), Understanding LSTM Networks, Colah’s Blog."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#simplernn",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#simplernn",
    "title": "Recurrent Neural Networks",
    "section": "SimpleRNN",
    "text": "SimpleRNN\nSay each prediction is a vector of size d, so \\mathbf{y}_t \\in \\mathbb{R}^{1 \\times d}.\nThen the main equation of a SimpleRNN, given \\mathbf{y}_0 = \\mathbf{0}, is\n \\mathbf{y}_t = \\psi\\bigl( \\mathbf{x}_t \\mathbf{W}_x + \\mathbf{y}_{t-1} \\mathbf{W}_y + \\mathbf{b} \\bigr) . \nHere, \n\\begin{aligned}\n&\\mathbf{x}_t \\in \\mathbb{R}^{1 \\times m}, \\mathbf{W}_x \\in \\mathbb{R}^{m \\times d}, \\\\\n&\\mathbf{y}_{t-1} \\in \\mathbb{R}^{1 \\times d}, \\mathbf{W}_y \\in \\mathbb{R}^{d \\times d}, \\text{ and } \\mathbf{b} \\in \\mathbb{R}^{d}.\n\\end{aligned}"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#simplernn-in-batches",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#simplernn-in-batches",
    "title": "Recurrent Neural Networks",
    "section": "SimpleRNN (in batches)",
    "text": "SimpleRNN (in batches)\nSay we operate on batches of size b, then \\mathbf{Y}_t \\in \\mathbb{R}^{b \\times d}.\nThe main equation of a SimpleRNN, given \\mathbf{Y}_0 = \\mathbf{0}, is  \\mathbf{Y}_t = \\psi\\bigl( \\mathbf{X}_t \\mathbf{W}_x + \\mathbf{Y}_{t-1} \\mathbf{W}_y + \\mathbf{b} \\bigr) .  Here, \n\\begin{aligned}\n&\\mathbf{X}_t \\in \\mathbb{R}^{b \\times m}, \\mathbf{W}_x \\in \\mathbb{R}^{m \\times d}, \\\\\n&\\mathbf{Y}_{t-1} \\in \\mathbb{R}^{b \\times d}, \\mathbf{W}_y \\in \\mathbb{R}^{d \\times d}, \\text{ and } \\mathbf{b} \\in \\mathbb{R}^{d}.\n\\end{aligned}\n\n\nRemember, \\mathbf{X} \\in \\mathbb{R}^{b \\times n \\times m}, \\mathbf{Y} \\in \\mathbb{R}^{b \\times d}, and \\mathbf{X}_t is equivalent to X[:, t, :]."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#simple-keras-demo",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#simple-keras-demo",
    "title": "Recurrent Neural Networks",
    "section": "Simple Keras demo",
    "text": "Simple Keras demo\n\nnum_obs = 4\nnum_time_steps = 3\nnum_time_series = 2\n\nX = np.arange(num_obs*num_time_steps*num_time_series).astype(np.float32) \\\n        .reshape([num_obs, num_time_steps, num_time_series])\n\noutput_size = 1                                                                 \ny = np.array([0, 0, 1, 1])\n\n\n\n\nX[:2]\n\narray([[[ 0.,  1.],\n        [ 2.,  3.],\n        [ 4.,  5.]],\n\n       [[ 6.,  7.],\n        [ 8.,  9.],\n        [10., 11.]]], dtype=float32)\n\n\n\n\nX[2:]\n\narray([[[12., 13.],\n        [14., 15.],\n        [16., 17.]],\n\n       [[18., 19.],\n        [20., 21.],\n        [22., 23.]]], dtype=float32)"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#keras-simplernn",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#keras-simplernn",
    "title": "Recurrent Neural Networks",
    "section": "Keras’ SimpleRNN",
    "text": "Keras’ SimpleRNN\nAs usual, the SimpleRNN is just a layer in Keras.\n\nfrom keras.layers import SimpleRNN\n\nrandom.seed(1234)\nmodel = Sequential([\n  SimpleRNN(output_size, activation=\"sigmoid\")\n])\nmodel.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n\nhist = model.fit(X, y, epochs=500, verbose=False)\nmodel.evaluate(X, y, verbose=False)\n\n[8.05906867980957, 0.5]\n\n\nThe predicted probabilities on the training set are:\n\nmodel.predict(X, verbose=0)\n\narray([[8.56e-05],\n       [2.25e-10],\n       [5.98e-16],\n       [1.59e-21]], dtype=float32)"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#simplernn-weights",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#simplernn-weights",
    "title": "Recurrent Neural Networks",
    "section": "SimpleRNN weights",
    "text": "SimpleRNN weights\n\nmodel.get_weights()\n\n[array([[-1.47],\n        [-0.67]], dtype=float32),\n array([[0.99]], dtype=float32),\n array([-0.14], dtype=float32)]\n\n\n\ndef sigmoid(x):\n  return 1 / (1 + np.exp(-x))\n\nW_x, W_y, b = model.get_weights()\n\nY = np.zeros((num_obs, output_size), dtype=np.float32)\nfor t in range(num_time_steps):\n    X_t = X[:, t, :]\n    z = X_t @ W_x + Y @ W_y + b\n    Y = sigmoid(z)\n\nY\n\narray([[8.56e-05],\n       [2.25e-10],\n       [5.98e-16],\n       [1.59e-21]], dtype=float32)"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#lstm-internals",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#lstm-internals",
    "title": "Recurrent Neural Networks",
    "section": "LSTM internals",
    "text": "LSTM internals\n \n\nSource: Christopher Olah (2015), Understanding LSTM Networks, Colah’s Blog."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#gru-internals",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#gru-internals",
    "title": "Recurrent Neural Networks",
    "section": "GRU internals",
    "text": "GRU internals\n\nDiagram of a GRU cell.\nSource: Christopher Olah (2015), Understanding LSTM Networks, Colah’s Blog."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#basic-facts-of-rnns",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#basic-facts-of-rnns",
    "title": "Recurrent Neural Networks",
    "section": "Basic facts of RNNs",
    "text": "Basic facts of RNNs\n\nA recurrent neural network is a type of neural network that is designed to process sequences of data (e.g. time series, sentences).\nA recurrent neural network is any network that contains a recurrent layer.\nA recurrent layer is a layer that processes data in a sequence.\nAn RNN can have one or more recurrent layers.\nWeights are shared over time; this allows the model to be used on arbitrary-length sequences."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#applications",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#applications",
    "title": "Recurrent Neural Networks",
    "section": "Applications",
    "text": "Applications\n\nForecasting: revenue forecast, weather forecast, predict disease rate from medical history, etc.\nClassification: given a time series of the activities of a visitor on a website, classify whether the visitor is a bot or a human.\nEvent detection: given a continuous data stream, identify the occurrence of a specific event. Example: Detect utterances like “Hey Alexa” from an audio stream.\nAnomaly detection: given a continuous data stream, detect anything unusual happening. Example: Detect unusual activity on the corporate network."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#input-and-output-sequences",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#input-and-output-sequences",
    "title": "Recurrent Neural Networks",
    "section": "Input and output sequences",
    "text": "Input and output sequences\n\nCategories of recurrent neural networks: sequence to sequence, sequence to vector, vector to sequence, encoder-decoder network.\nSource: Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Chapter 15."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#input-and-output-sequences-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#input-and-output-sequences-1",
    "title": "Recurrent Neural Networks",
    "section": "Input and output sequences",
    "text": "Input and output sequences\n\nSequence to sequence: Useful for predicting time series such as using prices over the last N days to output the prices shifted one day into the future (i.e. from N-1 days ago to tomorrow.)\nSequence to vector: ignore all outputs in the previous time steps except for the last one. Example: give a sentiment score to a sequence of words corresponding to a movie review."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#input-and-output-sequences-2",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#input-and-output-sequences-2",
    "title": "Recurrent Neural Networks",
    "section": "Input and output sequences",
    "text": "Input and output sequences\n\nVector to sequence: feed the network the same input vector over and over at each time step and let it output a sequence. Example: given that the input is an image, find a caption for it. The image is treated as an input vector (pixels in an image do not follow a sequence). The caption is a sequence of textual description of the image. A dataset containing images and their descriptions is the input of the RNN.\nThe Encoder-Decoder: The encoder is a sequence-to-vector network. The decoder is a vector-to-sequence network. Example: Feed the network a sequence in one language. Use the encoder to convert the sentence into a single vector representation. The decoder decodes this vector into the translation of the sentence in another language."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#recurrent-layers-can-be-stacked.",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#recurrent-layers-can-be-stacked.",
    "title": "Recurrent Neural Networks",
    "section": "Recurrent layers can be stacked.",
    "text": "Recurrent layers can be stacked.\n\nDeep RNN unrolled through time.\nSource: Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Chapter 15."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#australian-house-price-indices",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#australian-house-price-indices",
    "title": "Recurrent Neural Networks",
    "section": "Australian House Price Indices",
    "text": "Australian House Price Indices"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#percentage-changes",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#percentage-changes",
    "title": "Recurrent Neural Networks",
    "section": "Percentage changes",
    "text": "Percentage changes\n\nchanges = house_prices.pct_change().dropna()\nchanges.round(2)\n\n\n\n\n\n\n\n\nBrisbane\nEast_Bris\nNorth_Bris\nWest_Bris\nMelbourne\nNorth_Syd\nSydney\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n1990-02-28\n0.03\n-0.01\n0.01\n0.01\n0.00\n-0.00\n-0.02\n\n\n1990-03-31\n0.01\n0.03\n0.01\n0.01\n0.02\n-0.00\n0.03\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2021-04-30\n0.03\n0.01\n0.01\n-0.00\n0.01\n0.02\n0.02\n\n\n2021-05-31\n0.03\n0.03\n0.03\n0.03\n0.03\n0.02\n0.04\n\n\n\n\n376 rows × 7 columns"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#percentage-changes-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#percentage-changes-1",
    "title": "Recurrent Neural Networks",
    "section": "Percentage changes",
    "text": "Percentage changes\n\nchanges.plot();"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#the-size-of-the-changes",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#the-size-of-the-changes",
    "title": "Recurrent Neural Networks",
    "section": "The size of the changes",
    "text": "The size of the changes\n\n\n\nchanges.mean()\n\nBrisbane      0.005496\nEast_Bris     0.005416\nNorth_Bris    0.005024\nWest_Bris     0.004842\nMelbourne     0.005677\nNorth_Syd     0.004819\nSydney        0.005526\ndtype: float64\n\n\n\nchanges *= 100\n\n\nchanges.mean()\n\nBrisbane      0.549605\nEast_Bris     0.541562\nNorth_Bris    0.502390\nWest_Bris     0.484204\nMelbourne     0.567700\nNorth_Syd     0.481863\nSydney        0.552641\ndtype: float64\n\n\n\n\nchanges.plot(legend=False);"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#split-without-shuffling",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#split-without-shuffling",
    "title": "Recurrent Neural Networks",
    "section": "Split without shuffling",
    "text": "Split without shuffling\n\nnum_train = int(0.6 * len(changes))\nnum_val = int(0.2 * len(changes))\nnum_test = len(changes) - num_train - num_val\nprint(f\"# Train: {num_train}, # Val: {num_val}, # Test: {num_test}\")\n\n# Train: 225, # Val: 75, # Test: 76"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#subsequences-of-a-time-series",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#subsequences-of-a-time-series",
    "title": "Recurrent Neural Networks",
    "section": "Subsequences of a time series",
    "text": "Subsequences of a time series\nKeras has a built-in method for converting a time series into subsequences/chunks.\n\nfrom keras.utils import timeseries_dataset_from_array\n\nintegers = range(10)                                \ndummy_dataset = timeseries_dataset_from_array(\n    data=integers[:-3],                                 \n    targets=integers[3:],                               \n    sequence_length=3,                                      \n    batch_size=2,                                           \n)\n\nfor inputs, targets in dummy_dataset:\n    for i in range(inputs.shape[0]):\n        print([int(x) for x in inputs[i]], int(targets[i]))\n\n[0, 1, 2] 3\n[1, 2, 3] 4\n[2, 3, 4] 5\n[3, 4, 5] 6\n[4, 5, 6] 7\n\n\n\nSource: Code snippet in Chapter 10 of Chollet."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#on-time-series-splits",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#on-time-series-splits",
    "title": "Recurrent Neural Networks",
    "section": "On time series splits",
    "text": "On time series splits\nIf you have a lot of time series data, then use:\n\nfrom keras.utils import timeseries_dataset_from_array\ndata = range(20); seq = 3; ts = data[:-seq]; target = data[seq:]\nnTrain = int(0.5 * len(ts)); nVal = int(0.25 * len(ts))\nnTest = len(ts) - nTrain - nVal\nprint(f\"# Train: {nTrain}, # Val: {nVal}, # Test: {nTest}\")\n\n# Train: 8, # Val: 4, # Test: 5\n\n\n\n\n\ntrainDS = \\\n  timeseries_dataset_from_array(\n    ts, target, seq,\n    end_index=nTrain)\n\n\n\nvalDS = \\\n  timeseries_dataset_from_array(\n    ts, target, seq,\n    start_index=nTrain,\n    end_index=nTrain+nVal)\n\n\n\ntestDS = \\\n  timeseries_dataset_from_array(\n    ts, target, seq,\n    start_index=nTrain+nVal)\n\n\n\n\n\n\n\nTraining dataset\n[0, 1, 2] 3\n[1, 2, 3] 4\n[2, 3, 4] 5\n[3, 4, 5] 6\n[4, 5, 6] 7\n[5, 6, 7] 8\n\n\n\n\n\nValidation dataset\n[8, 9, 10] 11\n[9, 10, 11] 12\n\n\n\n\n\nTest dataset\n[12, 13, 14] 15\n[13, 14, 15] 16\n[14, 15, 16] 17\n\n\n\n\n\nAdapted from: François Chollet (2021), Deep Learning with Python, Second Edition, Listing 10.7."
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#on-time-series-splits-ii",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#on-time-series-splits-ii",
    "title": "Recurrent Neural Networks",
    "section": "On time series splits II",
    "text": "On time series splits II\nIf you don’t have a lot of time series data, consider:\n\nX = []; y = []\nfor i in range(len(data)-seq):\n    X.append(data[i:i+seq])\n    y.append(data[i+seq])\nX = np.array(X); y = np.array(y);\n\n\n\n\nnTrain = int(0.5 * X.shape[0])\nX_train = X[:nTrain]\ny_train = y[:nTrain]\n\n\n\nnVal = int(np.ceil(0.25 * X.shape[0]))\nX_val = X[nTrain:nTrain+nVal]\ny_val = y[nTrain:nTrain+nVal]\n\n\n\nnTest = X.shape[0] - nTrain - nVal\nX_test = X[nTrain+nVal:]\ny_test = y[nTrain+nVal:]\n\n\n\n\n\n\n\nTraining dataset\n[0, 1, 2] 3\n[1, 2, 3] 4\n[2, 3, 4] 5\n[3, 4, 5] 6\n[4, 5, 6] 7\n[5, 6, 7] 8\n[6, 7, 8] 9\n[7, 8, 9] 10\n\n\n\n\n\nValidation dataset\n[8, 9, 10] 11\n[9, 10, 11] 12\n[10, 11, 12] 13\n[11, 12, 13] 14\n[12, 13, 14] 15\n\n\n\n\n\nTest dataset\n[13, 14, 15] 16\n[14, 15, 16] 17\n[15, 16, 17] 18\n[16, 17, 18] 19"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#creating-dataset-objects",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#creating-dataset-objects",
    "title": "Recurrent Neural Networks",
    "section": "Creating dataset objects",
    "text": "Creating dataset objects\n\n\n\n# Num. of input time series.\nnum_ts = changes.shape[1]\n\n# How many prev. months to use.\nseq_length = 6\n\n# Predict the next month ahead.\nahead = 1\n\n# The index of the first target.\ndelay = (seq_length+ahead-1)\n\n\n\n# Which suburb to predict.\ntarget_suburb = changes[\"Sydney\"]\n\ntrain_ds = \\\n  timeseries_dataset_from_array(\n    changes[:-delay],\n    targets=target_suburb[delay:],\n    sequence_length=seq_length,\n    end_index=num_train)\n\n\n\n\n\n\nval_ds = \\\n  timeseries_dataset_from_array(\n    changes[:-delay],\n    targets=target_suburb[delay:],\n    sequence_length=seq_length,\n    start_index=num_train,\n    end_index=num_train+num_val)\n\n\n\ntest_ds = \\\n  timeseries_dataset_from_array(\n    changes[:-delay],\n    targets=target_suburb[delay:],\n    sequence_length=seq_length,\n    start_index=num_train+num_val)"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#converting-dataset-to-numpy",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#converting-dataset-to-numpy",
    "title": "Recurrent Neural Networks",
    "section": "Converting Dataset to numpy",
    "text": "Converting Dataset to numpy\nThe Dataset object can be handed to Keras directly, but if we really need a numpy array, we can run:\n\nX_train = np.concatenate(list(train_ds.map(lambda x, y: x)))\ny_train = np.concatenate(list(train_ds.map(lambda x, y: y)))\n\nThe shape of our training set is now:\n\nX_train.shape\n\n(220, 6, 7)\n\n\n\ny_train.shape\n\n(220,)\n\n\nLater, we need the targets as numpy arrays:\n\ny_train = np.concatenate(list(train_ds.map(lambda x, y: y)))\ny_val = np.concatenate(list(val_ds.map(lambda x, y: y)))\ny_test = np.concatenate(list(test_ds.map(lambda x, y: y)))"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-dense-network",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-dense-network",
    "title": "Recurrent Neural Networks",
    "section": "A dense network",
    "text": "A dense network\n\nfrom keras.layers import Input, Flatten\nrandom.seed(1)\nmodel_dense = Sequential([\n    Input((seq_length, num_ts)),\n    Flatten(),\n    Dense(50, activation=\"leaky_relu\"),\n    Dense(20, activation=\"leaky_relu\"),\n    Dense(1, activation=\"linear\")\n])\nmodel_dense.compile(loss=\"mse\", optimizer=\"adam\")\nprint(f\"This model has {model_dense.count_params()} parameters.\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n%time hist = model_dense.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0);\n\nThis model has 3191 parameters.\nEpoch 126: early stopping\nRestoring model weights from the end of the best epoch: 76.\nCPU times: user 8.54 s, sys: 1.45 s, total: 9.99 s\nWall time: 4.87 s"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plot-the-model",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plot-the-model",
    "title": "Recurrent Neural Networks",
    "section": "Plot the model",
    "text": "Plot the model\n\nfrom keras.utils import plot_model\nplot_model(model_dense, show_shapes=True)"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\nmodel_dense.evaluate(val_ds, verbose=0)\n\n1.3521653413772583"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-simplernn-layer",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-simplernn-layer",
    "title": "Recurrent Neural Networks",
    "section": "A SimpleRNN layer",
    "text": "A SimpleRNN layer\n\nrandom.seed(1)\n\nmodel_simple = Sequential([\n    Input((seq_length, num_ts)),\n    SimpleRNN(50),\n    Dense(1, activation=\"linear\")\n])\nmodel_simple.compile(loss=\"mse\", optimizer=\"adam\")\nprint(f\"This model has {model_simple.count_params()} parameters.\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n%time hist = model_simple.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0);\n\nThis model has 2951 parameters.\nEpoch 57: early stopping\nRestoring model weights from the end of the best epoch: 7.\nCPU times: user 4.21 s, sys: 676 ms, total: 4.89 s\nWall time: 2.43 s"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-1",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\nmodel_simple.evaluate(val_ds, verbose=0)\n\n0.869707465171814"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plot-the-model-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plot-the-model-1",
    "title": "Recurrent Neural Networks",
    "section": "Plot the model",
    "text": "Plot the model\n\nplot_model(model_simple, show_shapes=True)"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-1",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-lstm-layer",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-lstm-layer",
    "title": "Recurrent Neural Networks",
    "section": "A LSTM layer",
    "text": "A LSTM layer\n\nfrom keras.layers import LSTM\n\nrandom.seed(1)\n\nmodel_lstm = Sequential([\n    Input((seq_length, num_ts)),\n    LSTM(50),\n    Dense(1, activation=\"linear\")\n])\n\nmodel_lstm.compile(loss=\"mse\", optimizer=\"adam\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n\n%time hist = model_lstm.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0);\n\nEpoch 72: early stopping\nRestoring model weights from the end of the best epoch: 22.\nCPU times: user 5.08 s, sys: 853 ms, total: 5.93 s\nWall time: 3.1 s"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-2",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-2",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\nmodel_lstm.evaluate(val_ds, verbose=0)\n\n0.8331282734870911"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-2",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-2",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-gru-layer",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-gru-layer",
    "title": "Recurrent Neural Networks",
    "section": "A GRU layer",
    "text": "A GRU layer\n\nfrom keras.layers import GRU\n\nrandom.seed(1)\n\nmodel_gru = Sequential([\n    Input((seq_length, num_ts)),\n    GRU(50),\n    Dense(1, activation=\"linear\")\n])\n\nmodel_gru.compile(loss=\"mse\", optimizer=\"adam\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n\n%time hist = model_gru.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0)\n\nEpoch 66: early stopping\nRestoring model weights from the end of the best epoch: 16.\nCPU times: user 4.8 s, sys: 777 ms, total: 5.58 s\nWall time: 2.94 s"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-3",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-3",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\nmodel_gru.evaluate(val_ds, verbose=0)\n\n0.8188608884811401"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-3",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-3",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#two-gru-layers",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#two-gru-layers",
    "title": "Recurrent Neural Networks",
    "section": "Two GRU layers",
    "text": "Two GRU layers\n\nrandom.seed(1)\n\nmodel_two_grus = Sequential([\n    Input((seq_length, num_ts)),\n    GRU(50, return_sequences=True),\n    GRU(50),\n    Dense(1, activation=\"linear\")\n])\n\nmodel_two_grus.compile(loss=\"mse\", optimizer=\"adam\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n\n%time hist = model_two_grus.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0)\n\nEpoch 69: early stopping\nRestoring model weights from the end of the best epoch: 19.\nCPU times: user 5.78 s, sys: 767 ms, total: 6.55 s\nWall time: 3.76 s"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-4",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-4",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\nmodel_two_grus.evaluate(val_ds, verbose=0)\n\n0.777770459651947"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-4",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-4",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#compare-the-models",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#compare-the-models",
    "title": "Recurrent Neural Networks",
    "section": "Compare the models",
    "text": "Compare the models\n\n\n\n\n\n\n\n\n\nModel\nMSE\n\n\n\n\n0\nDense\n1.352165\n\n\n1\nSimpleRNN\n0.869707\n\n\n2\nLSTM\n0.833128\n\n\n3\nGRU\n0.818861\n\n\n4\n2 GRUs\n0.777770\n\n\n\n\n\n\n\nThe network with two GRU layers is the best.\n\nmodel_two_grus.evaluate(test_ds, verbose=0)\n\n1.9774343967437744"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#test-set",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#test-set",
    "title": "Recurrent Neural Networks",
    "section": "Test set",
    "text": "Test set"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#creating-dataset-objects-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#creating-dataset-objects-1",
    "title": "Recurrent Neural Networks",
    "section": "Creating dataset objects",
    "text": "Creating dataset objects\n\n\nChange the targets argument to include all the suburbs.\n\n\ntrain_ds = \\\n  timeseries_dataset_from_array(\n    changes[:-delay],\n    targets=changes[delay:],\n    sequence_length=seq_length,\n    end_index=num_train)\n\n\n\n\n\n\nval_ds = \\\n  timeseries_dataset_from_array(\n    changes[:-delay],\n    targets=changes[delay:],\n    sequence_length=seq_length,\n    start_index=num_train,\n    end_index=num_train+num_val)\n\n\n\ntest_ds = \\\n  timeseries_dataset_from_array(\n    changes[:-delay],\n    targets=changes[delay:],\n    sequence_length=seq_length,\n    start_index=num_train+num_val)"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#converting-dataset-to-numpy-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#converting-dataset-to-numpy-1",
    "title": "Recurrent Neural Networks",
    "section": "Converting Dataset to numpy",
    "text": "Converting Dataset to numpy\nThe shape of our training set is now:\n\nX_train = np.concatenate(list(train_ds.map(lambda x, y: x)))\nX_train.shape\n\n(220, 6, 7)\n\n\n\nY_train = np.concatenate(list(train_ds.map(lambda x, y: y)))\nY_train.shape\n\n(220, 7)\n\n\nLater, we need the targets as numpy arrays:\n\nY_train = np.concatenate(list(train_ds.map(lambda x, y: y)))\nY_val = np.concatenate(list(val_ds.map(lambda x, y: y)))\nY_test = np.concatenate(list(test_ds.map(lambda x, y: y)))"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-dense-network-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-dense-network-1",
    "title": "Recurrent Neural Networks",
    "section": "A dense network",
    "text": "A dense network\n\nrandom.seed(1)\nmodel_dense = Sequential([\n    Input((seq_length, num_ts)),\n    Flatten(),\n    Dense(50, activation=\"leaky_relu\"),\n    Dense(20, activation=\"leaky_relu\"),\n    Dense(num_ts, activation=\"linear\")\n])\nmodel_dense.compile(loss=\"mse\", optimizer=\"adam\")\nprint(f\"This model has {model_dense.count_params()} parameters.\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n%time hist = model_dense.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0);\n\nThis model has 3317 parameters.\nEpoch 96: early stopping\nRestoring model weights from the end of the best epoch: 46.\nCPU times: user 6.39 s, sys: 931 ms, total: 7.32 s\nWall time: 3.43 s"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plot-the-model-2",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plot-the-model-2",
    "title": "Recurrent Neural Networks",
    "section": "Plot the model",
    "text": "Plot the model\n\nplot_model(model_dense, show_shapes=True)"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-5",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-5",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\nmodel_dense.evaluate(val_ds, verbose=0)\n\n1.445832371711731"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-5",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-5",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-simplernn-layer-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-simplernn-layer-1",
    "title": "Recurrent Neural Networks",
    "section": "A SimpleRNN layer",
    "text": "A SimpleRNN layer\n\nrandom.seed(1)\n\nmodel_simple = Sequential([\n    Input((seq_length, num_ts)),\n    SimpleRNN(50),\n    Dense(num_ts, activation=\"linear\")\n])\nmodel_simple.compile(loss=\"mse\", optimizer=\"adam\")\nprint(f\"This model has {model_simple.count_params()} parameters.\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n%time hist = model_simple.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0);\n\nThis model has 3257 parameters.\nEpoch 93: early stopping\nRestoring model weights from the end of the best epoch: 43.\nCPU times: user 6.48 s, sys: 1.15 s, total: 7.62 s\nWall time: 3.87 s"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-6",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-6",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\nmodel_simple.evaluate(val_ds, verbose=0)\n\n1.6287589073181152"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plot-the-model-3",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plot-the-model-3",
    "title": "Recurrent Neural Networks",
    "section": "Plot the model",
    "text": "Plot the model\n\nplot_model(model_simple, show_shapes=True)"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-6",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-6",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-lstm-layer-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-lstm-layer-1",
    "title": "Recurrent Neural Networks",
    "section": "A LSTM layer",
    "text": "A LSTM layer\n\nrandom.seed(1)\n\nmodel_lstm = Sequential([\n    Input((seq_length, num_ts)),\n    LSTM(50),\n    Dense(num_ts, activation=\"linear\")\n])\n\nmodel_lstm.compile(loss=\"mse\", optimizer=\"adam\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n\n%time hist = model_lstm.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0);\n\nEpoch 106: early stopping\nRestoring model weights from the end of the best epoch: 56.\nCPU times: user 7.75 s, sys: 1.3 s, total: 9.05 s\nWall time: 4.69 s"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-7",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-7",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\nmodel_lstm.evaluate(val_ds, verbose=0)\n\n1.3439934253692627"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-7",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-7",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-gru-layer-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#a-gru-layer-1",
    "title": "Recurrent Neural Networks",
    "section": "A GRU layer",
    "text": "A GRU layer\n\nrandom.seed(1)\n\nmodel_gru = Sequential([\n    Input((seq_length, num_ts)),\n    GRU(50),\n    Dense(num_ts, activation=\"linear\")\n])\n\nmodel_gru.compile(loss=\"mse\", optimizer=\"adam\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n\n%time hist = model_gru.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0)\n\nEpoch 114: early stopping\nRestoring model weights from the end of the best epoch: 64.\nCPU times: user 8.14 s, sys: 1.44 s, total: 9.58 s\nWall time: 4.94 s"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-8",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-8",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\nmodel_gru.evaluate(val_ds, verbose=0)\n\n1.3462404012680054"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-8",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-8",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#two-gru-layers-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#two-gru-layers-1",
    "title": "Recurrent Neural Networks",
    "section": "Two GRU layers",
    "text": "Two GRU layers\n\nrandom.seed(1)\n\nmodel_two_grus = Sequential([\n    Input((seq_length, num_ts)),\n    GRU(50, return_sequences=True),\n    GRU(50),\n    Dense(num_ts, activation=\"linear\")\n])\n\nmodel_two_grus.compile(loss=\"mse\", optimizer=\"adam\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n\n%time hist = model_two_grus.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0)\n\nEpoch 93: early stopping\nRestoring model weights from the end of the best epoch: 43.\nCPU times: user 7.59 s, sys: 1.04 s, total: 8.62 s\nWall time: 4.96 s"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-9",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#assess-the-fits-9",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\nmodel_two_grus.evaluate(val_ds, verbose=0)\n\n1.361182451248169"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-9",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#plotting-the-predictions-9",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#compare-the-models-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#compare-the-models-1",
    "title": "Recurrent Neural Networks",
    "section": "Compare the models",
    "text": "Compare the models\n\n\n\n\n\n\n\n\n\nModel\nMSE\n\n\n\n\n1\nSimpleRNN\n1.628759\n\n\n0\nDense\n1.445832\n\n\n4\n2 GRUs\n1.361182\n\n\n3\nGRU\n1.346240\n\n\n2\nLSTM\n1.343993\n\n\n\n\n\n\n\nThe network with an LSTM layer is the best.\n\nmodel_lstm.evaluate(test_ds, verbose=0)\n\n1.879453420639038"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#test-set-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.slides.html#test-set-1",
    "title": "Recurrent Neural Networks",
    "section": "Test set",
    "text": "Test set"
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html",
    "title": "Recurrent Neural Networks",
    "section": "",
    "text": "import random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input\nfrom keras.callbacks import EarlyStopping\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.0\nIPython version      : 8.20.0\n\nsklearn   : 1.4.0\nkeras     : 3.0.4\ntorch     : 2.2.0\ntensorflow: 2.15.0.post1",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#load-packages",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#load-packages",
    "title": "Recurrent Neural Networks",
    "section": "",
    "text": "import random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input\nfrom keras.callbacks import EarlyStopping\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.0\nIPython version      : 8.20.0\n\nsklearn   : 1.4.0\nkeras     : 3.0.4\ntorch     : 2.2.0\ntensorflow: 2.15.0.post1",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#shapes-of-data",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#shapes-of-data",
    "title": "Recurrent Neural Networks",
    "section": "Shapes of data",
    "text": "Shapes of data\n\n\n\nIllustration of tensors of different rank.\n\n\n\nSource: Paras Patidar (2019), Tensors — Representation of Data In Neural Networks, Medium article.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#the-axis-argument-in-numpy",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#the-axis-argument-in-numpy",
    "title": "Recurrent Neural Networks",
    "section": "The axis argument in numpy",
    "text": "The axis argument in numpy\nStarting with a (3, 4)-shaped matrix:\n\nX = np.arange(12).reshape(3,4)\nX\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\n\n\nThe above code creates an array with values from 0 to 11 and converts that array into a matrix with 3 rows and 4 columns.\n\n\naxis=0: (3, 4) \\leadsto (4,).\n\nX.sum(axis=0)\n\narray([12, 15, 18, 21])\n\n\nThe above code returns the column sum. This changes the shape of the matrix from (3,4) to (4,). Similarly, X.sum(axis=1) returns row sums and will change the shape of the matrix from (3,4) to (3,).\n\naxis=1: (3, 4) \\leadsto (3,).\n\nX.prod(axis=1)\n\narray([   0,  840, 7920])\n\n\n\n\nThe return value’s rank is one less than the input’s rank.\n\n\n\n\n\n\nImportant\n\n\n\nThe axis parameter tells us which dimension is removed.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#using-axis-keepdims",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#using-axis-keepdims",
    "title": "Recurrent Neural Networks",
    "section": "Using axis & keepdims",
    "text": "Using axis & keepdims\nWith keepdims=True, the rank doesn’t change.\n\nX = np.arange(12).reshape(3,4)\nX\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\n\n\n\n\naxis=0: (3, 4) \\leadsto (1, 4).\n\nX.sum(axis=0, keepdims=True)\n\narray([[12, 15, 18, 21]])\n\n\n\naxis=1: (3, 4) \\leadsto (3, 1).\n\nX.prod(axis=1, keepdims=True)\n\narray([[   0],\n       [ 840],\n       [7920]])\n\n\n\n\n\n\n\nX / X.sum(axis=1)\n\nValueError: operands could not be broadcast together with shapes (3,4) (3,) \n\n\n\n\nX / X.sum(axis=1, keepdims=True)\n\narray([[0.  , 0.17, 0.33, 0.5 ],\n       [0.18, 0.23, 0.27, 0.32],\n       [0.21, 0.24, 0.26, 0.29]])",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#the-rank-of-a-time-series",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#the-rank-of-a-time-series",
    "title": "Recurrent Neural Networks",
    "section": "The rank of a time series",
    "text": "The rank of a time series\nSay we had n observations of a time series x_1, x_2, \\dots, x_n.\nThis \\mathbf{x} = (x_1, \\dots, x_n) would have shape (n,) & rank 1.\nIf instead we had a batch of b time series’\n\n\\mathbf{X} = \\begin{pmatrix}\nx_7 & x_8 & \\dots & x_{7+n-1} \\\\\nx_2 & x_3 & \\dots & x_{2+n-1} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_3 & x_4 & \\dots & x_{3+n-1} \\\\\n\\end{pmatrix}  \\,,\n\nthe batch \\mathbf{X} would have shape (b, n) & rank 2.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#multivariate-time-series",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#multivariate-time-series",
    "title": "Recurrent Neural Networks",
    "section": "Multivariate time series",
    "text": "Multivariate time series\nMultivariate time series consists of more than 1 variable observation at a given time point. Following example has two variables x and y.\n\n\n\n\n\n\n\n\nt\nx\ny\n\n\n\n\n0\nx_0\ny_0\n\n\n1\nx_1\ny_1\n\n\n2\nx_2\ny_2\n\n\n3\nx_3\ny_3\n\n\n\n\n\n\n\nSay n observations of the m time series, would be a shape (n, m) matrix of rank 2.\nIn Keras, a batch of b of these time series has shape (b, n, m) and has rank 3.\n\n\n\n\n\n\n\n\nNote\n\n\n\nUse \\mathbf{x}_t \\in \\mathbb{R}^{1 \\times m} to denote the vector of all time series at time t. Here, \\mathbf{x}_t = (x_t, y_t).",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#recurrence-relation",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#recurrence-relation",
    "title": "Recurrent Neural Networks",
    "section": "Recurrence relation",
    "text": "Recurrence relation\n\nA recurrence relation is an equation that expresses each element of a sequence as a function of the preceding ones. More precisely, in the case where only the immediately preceding element is involved, a recurrence relation has the form\n u_n = \\psi(n, u_{n-1}) \\quad \\text{ for } \\quad n &gt; 0.\n\nExample: Factorial n! = n (n-1)! for n &gt; 0 given 0! = 1.\n\nSource: Wikipedia, Recurrence relation.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#diagram-of-an-rnn-cell",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#diagram-of-an-rnn-cell",
    "title": "Recurrent Neural Networks",
    "section": "Diagram of an RNN cell",
    "text": "Diagram of an RNN cell\nThe RNN processes each data in the sequence one by one, while keeping memory of what came before.\nThe following figure shows how the recurrent neural network combines an input X_l with a preprocessed state of the process A_l to produce the output O_l. RNNs have a cyclic information processing structure that enables them to pass information sequentially from previous inputs. RNNs can capture dependencies and patterns in sequential data, making them useful for analysing time series data.\n\n\n\nSchematic of a simple recurrent neural network. E.g. SimpleRNN, LSTM, or GRU.\n\n\n\nSource: James et al (2022), An Introduction to Statistical Learning, 2nd edition, Figure 10.12.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-simplernn-cell.",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-simplernn-cell.",
    "title": "Recurrent Neural Networks",
    "section": "A SimpleRNN cell.",
    "text": "A SimpleRNN cell.\n\n\n\nDiagram of a SimpleRNN cell.\n\n\nAll the outputs before the final one are often discarded.\n\nSource: Christopher Olah (2015), Understanding LSTM Networks, Colah’s Blog.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#simplernn",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#simplernn",
    "title": "Recurrent Neural Networks",
    "section": "SimpleRNN",
    "text": "SimpleRNN\nSay each prediction is a vector of size d, so \\mathbf{y}_t \\in \\mathbb{R}^{1 \\times d}.\nThen the main equation of a SimpleRNN, given \\mathbf{y}_0 = \\mathbf{0}, is\n \\mathbf{y}_t = \\psi\\bigl( \\mathbf{x}_t \\mathbf{W}_x + \\mathbf{y}_{t-1} \\mathbf{W}_y + \\mathbf{b} \\bigr) . \nHere, \n\\begin{aligned}\n&\\mathbf{x}_t \\in \\mathbb{R}^{1 \\times m}, \\mathbf{W}_x \\in \\mathbb{R}^{m \\times d}, \\\\\n&\\mathbf{y}_{t-1} \\in \\mathbb{R}^{1 \\times d}, \\mathbf{W}_y \\in \\mathbb{R}^{d \\times d}, \\text{ and } \\mathbf{b} \\in \\mathbb{R}^{d}.\n\\end{aligned}\n\nAt each time step, a simple Recurrent Neural Network (RNN) takes an input vector x_t, incorporate it with the information from the previous hidden state {y}_{t-1} and produces an output vector at each time step y_t. The hidden state helps the network remember the context of the previous words, enabling it to make informed predictions about what comes next in the sequence. In a simple RNN, the output at time (t-1) is the same as the hidden state at time t.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#simplernn-in-batches",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#simplernn-in-batches",
    "title": "Recurrent Neural Networks",
    "section": "SimpleRNN (in batches)",
    "text": "SimpleRNN (in batches)\nThe difference between RNN and RNNs with batch processing lies in the way how the neural network handles sequences of input data. With batch processing, the model processes multiple (b) input sequences simultaneously. The training data is grouped into batches, and the weights are updated based on the average error across the entire batch. Batch processing often results in more stable weight updates, as the model learns from a diverse set of examples in each batch, reducing the impact of noise in individual sequences.\nSay we operate on batches of size b, then \\mathbf{Y}_t \\in \\mathbb{R}^{b \\times d}.\nThe main equation of a SimpleRNN, given \\mathbf{Y}_0 = \\mathbf{0}, is  \\mathbf{Y}_t = \\psi\\bigl( \\mathbf{X}_t \\mathbf{W}_x + \\mathbf{Y}_{t-1} \\mathbf{W}_y + \\mathbf{b} \\bigr) .  Here, \n\\begin{aligned}\n&\\mathbf{X}_t \\in \\mathbb{R}^{b \\times m}, \\mathbf{W}_x \\in \\mathbb{R}^{m \\times d}, \\\\\n&\\mathbf{Y}_{t-1} \\in \\mathbb{R}^{b \\times d}, \\mathbf{W}_y \\in \\mathbb{R}^{d \\times d}, \\text{ and } \\mathbf{b} \\in \\mathbb{R}^{d}.\n\\end{aligned}\n\n\nRemember, \\mathbf{X} \\in \\mathbb{R}^{b \\times n \\times m}, \\mathbf{Y} \\in \\mathbb{R}^{b \\times d}, and \\mathbf{X}_t is equivalent to X[:, t, :].",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#simple-keras-demo",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#simple-keras-demo",
    "title": "Recurrent Neural Networks",
    "section": "Simple Keras demo",
    "text": "Simple Keras demo\n\n1num_obs = 4\n2num_time_steps = 3\n3num_time_series = 2\n\nX = np.arange(num_obs*num_time_steps*num_time_series).astype(np.float32) \\\n4        .reshape([num_obs, num_time_steps, num_time_series])\n\noutput_size = 1                                                                 \ny = np.array([0, 0, 1, 1])\n\n\n1\n\nDefines the number of observations\n\n2\n\nDefines the number of time steps\n\n3\n\nDefines the number of time series\n\n4\n\nReshapes the array to a range 3 tensor (4,3,2)\n\n\n\n\n\n\n\n1X[:2]\n\n\n1\n\nSelects the first two slices along the first dimension. Since the tensor of dimensions (4,3,2), X[:2] selects the first two slices (0 and 1) along the first dimension, and returns a sub-tensor of shape (2,3,2).\n\n\n\n\narray([[[ 0.,  1.],\n        [ 2.,  3.],\n        [ 4.,  5.]],\n\n       [[ 6.,  7.],\n        [ 8.,  9.],\n        [10., 11.]]], dtype=float32)\n\n\n\n\n1X[2:]\n\n\n1\n\nSelects the last two slices along the first dimension. The first dimension (axis=0) has size 4. Therefore, X[2:] selects the last two slices (2 and 3) along the first dimension, and returns a sub-tensor of shape (2,3,2).\n\n\n\n\narray([[[12., 13.],\n        [14., 15.],\n        [16., 17.]],\n\n       [[18., 19.],\n        [20., 21.],\n        [22., 23.]]], dtype=float32)",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#keras-simplernn",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#keras-simplernn",
    "title": "Recurrent Neural Networks",
    "section": "Keras’ SimpleRNN",
    "text": "Keras’ SimpleRNN\nAs usual, the SimpleRNN is just a layer in Keras.\n\n1from keras.layers import SimpleRNN\n\n2random.seed(1234)\nmodel = Sequential([\n3  SimpleRNN(output_size, activation=\"sigmoid\")\n])\n4model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n\n5hist = model.fit(X, y, epochs=500, verbose=False)\n6model.evaluate(X, y, verbose=False)\n\n\n1\n\nImports the SimpleRNN layer from the Keras library\n\n2\n\nSets the seed for the random number generator to ensure reproducibility\n\n3\n\nDefines a simple RNN with one output node and sigmoid activation function\n\n4\n\nSpecifies binary crossentropy as the loss function (usually used in classification problems), and specifies “accuracy” as the metric to be monitored during training\n\n5\n\nTrains the model for 500 epochs and saves output as hist\n\n6\n\nEvaluates the model to obtain a value for the loss and accuracy\n\n\n\n\n[8.05906867980957, 0.5]\n\n\nThe predicted probabilities on the training set are:\n\nmodel.predict(X, verbose=0)\n\narray([[8.56e-05],\n       [2.25e-10],\n       [5.98e-16],\n       [1.59e-21]], dtype=float32)",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#simplernn-weights",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#simplernn-weights",
    "title": "Recurrent Neural Networks",
    "section": "SimpleRNN weights",
    "text": "SimpleRNN weights\nTo verify the results of predicted probabilities, we can obtain the weights of the fitted model and calculate the outcome manually as follows.\n\nmodel.get_weights()\n\n[array([[-1.47],\n        [-0.67]], dtype=float32),\n array([[0.99]], dtype=float32),\n array([-0.14], dtype=float32)]\n\n\n\ndef sigmoid(x):\n  return 1 / (1 + np.exp(-x))\n\nW_x, W_y, b = model.get_weights()\n\nY = np.zeros((num_obs, output_size), dtype=np.float32)\nfor t in range(num_time_steps):\n    X_t = X[:, t, :]\n    z = X_t @ W_x + Y @ W_y + b\n    Y = sigmoid(z)\n\nY\n\narray([[8.56e-05],\n       [2.25e-10],\n       [5.98e-16],\n       [1.59e-21]], dtype=float32)",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#lstm-internals",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#lstm-internals",
    "title": "Recurrent Neural Networks",
    "section": "LSTM internals",
    "text": "LSTM internals\nSimple RNN structures encounter vanishing gradient problems, hence, struggle with learning long term dependencies. LSTM are designed to overcome this problem. LSTMs have a more complex network structure (contains more memory cells and gating mechanisms) and can better regulate the information flow.\n \n\nSource: Christopher Olah (2015), Understanding LSTM Networks, Colah’s Blog.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#gru-internals",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#gru-internals",
    "title": "Recurrent Neural Networks",
    "section": "GRU internals",
    "text": "GRU internals\nGRUs are simpler compared to LSTM, hence, computationally more efficient than LSTMs.\n\n\n\nDiagram of a GRU cell.\n\n\n\nSource: Christopher Olah (2015), Understanding LSTM Networks, Colah’s Blog.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#basic-facts-of-rnns",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#basic-facts-of-rnns",
    "title": "Recurrent Neural Networks",
    "section": "Basic facts of RNNs",
    "text": "Basic facts of RNNs\n\nA recurrent neural network is a type of neural network that is designed to process sequences of data (e.g. time series, sentences).\nA recurrent neural network is any network that contains a recurrent layer.\nA recurrent layer is a layer that processes data in a sequence.\nAn RNN can have one or more recurrent layers.\nWeights are shared over time; this allows the model to be used on arbitrary-length sequences.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#applications",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#applications",
    "title": "Recurrent Neural Networks",
    "section": "Applications",
    "text": "Applications\n\nForecasting: revenue forecast, weather forecast, predict disease rate from medical history, etc.\nClassification: given a time series of the activities of a visitor on a website, classify whether the visitor is a bot or a human.\nEvent detection: given a continuous data stream, identify the occurrence of a specific event. Example: Detect utterances like “Hey Alexa” from an audio stream.\nAnomaly detection: given a continuous data stream, detect anything unusual happening. Example: Detect unusual activity on the corporate network.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#input-and-output-sequences",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#input-and-output-sequences",
    "title": "Recurrent Neural Networks",
    "section": "Input and output sequences",
    "text": "Input and output sequences\n\n\n\nCategories of recurrent neural networks: sequence to sequence, sequence to vector, vector to sequence, encoder-decoder network.\n\n\n\nSource: Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Chapter 15.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#input-and-output-sequences-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#input-and-output-sequences-1",
    "title": "Recurrent Neural Networks",
    "section": "Input and output sequences",
    "text": "Input and output sequences\n\nSequence to sequence: Useful for predicting time series such as using prices over the last N days to output the prices shifted one day into the future (i.e. from N-1 days ago to tomorrow.)\nSequence to vector: ignore all outputs in the previous time steps except for the last one. Example: give a sentiment score to a sequence of words corresponding to a movie review.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#input-and-output-sequences-2",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#input-and-output-sequences-2",
    "title": "Recurrent Neural Networks",
    "section": "Input and output sequences",
    "text": "Input and output sequences\n\nVector to sequence: feed the network the same input vector over and over at each time step and let it output a sequence. Example: given that the input is an image, find a caption for it. The image is treated as an input vector (pixels in an image do not follow a sequence). The caption is a sequence of textual description of the image. A dataset containing images and their descriptions is the input of the RNN.\nThe Encoder-Decoder: The encoder is a sequence-to-vector network. The decoder is a vector-to-sequence network. Example: Feed the network a sequence in one language. Use the encoder to convert the sentence into a single vector representation. The decoder decodes this vector into the translation of the sentence in another language.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#recurrent-layers-can-be-stacked.",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#recurrent-layers-can-be-stacked.",
    "title": "Recurrent Neural Networks",
    "section": "Recurrent layers can be stacked.",
    "text": "Recurrent layers can be stacked.\n\n\n\nDeep RNN unrolled through time.\n\n\n\nSource: Aurélien Géron (2019), Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, Chapter 15.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#australian-house-price-indices",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#australian-house-price-indices",
    "title": "Recurrent Neural Networks",
    "section": "Australian House Price Indices",
    "text": "Australian House Price Indices",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#percentage-changes",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#percentage-changes",
    "title": "Recurrent Neural Networks",
    "section": "Percentage changes",
    "text": "Percentage changes\n\nchanges = house_prices.pct_change().dropna()\nchanges.round(2)\n\n\n\n\n\n\n\n\nBrisbane\nEast_Bris\nNorth_Bris\nWest_Bris\nMelbourne\nNorth_Syd\nSydney\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n1990-02-28\n0.03\n-0.01\n0.01\n0.01\n0.00\n-0.00\n-0.02\n\n\n1990-03-31\n0.01\n0.03\n0.01\n0.01\n0.02\n-0.00\n0.03\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2021-04-30\n0.03\n0.01\n0.01\n-0.00\n0.01\n0.02\n0.02\n\n\n2021-05-31\n0.03\n0.03\n0.03\n0.03\n0.03\n0.02\n0.04\n\n\n\n\n376 rows × 7 columns",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#percentage-changes-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#percentage-changes-1",
    "title": "Recurrent Neural Networks",
    "section": "Percentage changes",
    "text": "Percentage changes\n\nchanges.plot();",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#the-size-of-the-changes",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#the-size-of-the-changes",
    "title": "Recurrent Neural Networks",
    "section": "The size of the changes",
    "text": "The size of the changes\n\n\n\nchanges.mean()\n\nBrisbane      0.005496\nEast_Bris     0.005416\nNorth_Bris    0.005024\nWest_Bris     0.004842\nMelbourne     0.005677\nNorth_Syd     0.004819\nSydney        0.005526\ndtype: float64\n\n\n\nchanges *= 100\n\n\nchanges.mean()\n\nBrisbane      0.549605\nEast_Bris     0.541562\nNorth_Bris    0.502390\nWest_Bris     0.484204\nMelbourne     0.567700\nNorth_Syd     0.481863\nSydney        0.552641\ndtype: float64\n\n\n\n\nchanges.plot(legend=False);",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#split-without-shuffling",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#split-without-shuffling",
    "title": "Recurrent Neural Networks",
    "section": "Split without shuffling",
    "text": "Split without shuffling\n\nnum_train = int(0.6 * len(changes))\nnum_val = int(0.2 * len(changes))\nnum_test = len(changes) - num_train - num_val\nprint(f\"# Train: {num_train}, # Val: {num_val}, # Test: {num_test}\")\n\n# Train: 225, # Val: 75, # Test: 76",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#subsequences-of-a-time-series",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#subsequences-of-a-time-series",
    "title": "Recurrent Neural Networks",
    "section": "Subsequences of a time series",
    "text": "Subsequences of a time series\nKeras has a built-in method for converting a time series into subsequences/chunks.\n\nfrom keras.utils import timeseries_dataset_from_array\n\nintegers = range(10)                                \ndummy_dataset = timeseries_dataset_from_array(\n    data=integers[:-3],                                 \n    targets=integers[3:],                               \n    sequence_length=3,                                      \n    batch_size=2,                                           \n)\n\nfor inputs, targets in dummy_dataset:\n    for i in range(inputs.shape[0]):\n        print([int(x) for x in inputs[i]], int(targets[i]))\n\n[0, 1, 2] 3\n[1, 2, 3] 4\n[2, 3, 4] 5\n[3, 4, 5] 6\n[4, 5, 6] 7\n\n\n\nSource: Code snippet in Chapter 10 of Chollet.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#on-time-series-splits",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#on-time-series-splits",
    "title": "Recurrent Neural Networks",
    "section": "On time series splits",
    "text": "On time series splits\nIf you have a lot of time series data, then use:\n\nfrom keras.utils import timeseries_dataset_from_array\ndata = range(20); seq = 3; ts = data[:-seq]; target = data[seq:]\nnTrain = int(0.5 * len(ts)); nVal = int(0.25 * len(ts))\nnTest = len(ts) - nTrain - nVal\nprint(f\"# Train: {nTrain}, # Val: {nVal}, # Test: {nTest}\")\n\n# Train: 8, # Val: 4, # Test: 5\n\n\n\n\n\ntrainDS = \\\n  timeseries_dataset_from_array(\n    ts, target, seq,\n    end_index=nTrain)\n\n\n\nvalDS = \\\n  timeseries_dataset_from_array(\n    ts, target, seq,\n    start_index=nTrain,\n    end_index=nTrain+nVal)\n\n\n\ntestDS = \\\n  timeseries_dataset_from_array(\n    ts, target, seq,\n    start_index=nTrain+nVal)\n\n\n\n\n\n\n\nTraining dataset\n[0, 1, 2] 3\n[1, 2, 3] 4\n[2, 3, 4] 5\n[3, 4, 5] 6\n[4, 5, 6] 7\n[5, 6, 7] 8\n\n\n\n\n\nValidation dataset\n[8, 9, 10] 11\n[9, 10, 11] 12\n\n\n\n\n\nTest dataset\n[12, 13, 14] 15\n[13, 14, 15] 16\n[14, 15, 16] 17\n\n\n\n\n\nAdapted from: François Chollet (2021), Deep Learning with Python, Second Edition, Listing 10.7.",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#on-time-series-splits-ii",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#on-time-series-splits-ii",
    "title": "Recurrent Neural Networks",
    "section": "On time series splits II",
    "text": "On time series splits II\nIf you don’t have a lot of time series data, consider:\n\nX = []; y = []\nfor i in range(len(data)-seq):\n    X.append(data[i:i+seq])\n    y.append(data[i+seq])\nX = np.array(X); y = np.array(y);\n\n\n\n\nnTrain = int(0.5 * X.shape[0])\nX_train = X[:nTrain]\ny_train = y[:nTrain]\n\n\n\nnVal = int(np.ceil(0.25 * X.shape[0]))\nX_val = X[nTrain:nTrain+nVal]\ny_val = y[nTrain:nTrain+nVal]\n\n\n\nnTest = X.shape[0] - nTrain - nVal\nX_test = X[nTrain+nVal:]\ny_test = y[nTrain+nVal:]\n\n\n\n\n\n\n\nTraining dataset\n[0, 1, 2] 3\n[1, 2, 3] 4\n[2, 3, 4] 5\n[3, 4, 5] 6\n[4, 5, 6] 7\n[5, 6, 7] 8\n[6, 7, 8] 9\n[7, 8, 9] 10\n\n\n\n\n\nValidation dataset\n[8, 9, 10] 11\n[9, 10, 11] 12\n[10, 11, 12] 13\n[11, 12, 13] 14\n[12, 13, 14] 15\n\n\n\n\n\nTest dataset\n[13, 14, 15] 16\n[14, 15, 16] 17\n[15, 16, 17] 18\n[16, 17, 18] 19",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#creating-dataset-objects",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#creating-dataset-objects",
    "title": "Recurrent Neural Networks",
    "section": "Creating dataset objects",
    "text": "Creating dataset objects\n\n\n\n# Num. of input time series.\nnum_ts = changes.shape[1]\n\n# How many prev. months to use.\nseq_length = 6\n\n# Predict the next month ahead.\nahead = 1\n\n# The index of the first target.\ndelay = (seq_length+ahead-1)\n\n\n\n# Which suburb to predict.\ntarget_suburb = changes[\"Sydney\"]\n\ntrain_ds = \\\n  timeseries_dataset_from_array(\n    changes[:-delay],\n    targets=target_suburb[delay:],\n    sequence_length=seq_length,\n    end_index=num_train)\n\n\n\n\n\n\nval_ds = \\\n  timeseries_dataset_from_array(\n    changes[:-delay],\n    targets=target_suburb[delay:],\n    sequence_length=seq_length,\n    start_index=num_train,\n    end_index=num_train+num_val)\n\n\n\ntest_ds = \\\n  timeseries_dataset_from_array(\n    changes[:-delay],\n    targets=target_suburb[delay:],\n    sequence_length=seq_length,\n    start_index=num_train+num_val)",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#converting-dataset-to-numpy",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#converting-dataset-to-numpy",
    "title": "Recurrent Neural Networks",
    "section": "Converting Dataset to numpy",
    "text": "Converting Dataset to numpy\nThe Dataset object can be handed to Keras directly, but if we really need a numpy array, we can run:\n\nX_train = np.concatenate(list(train_ds.map(lambda x, y: x)))\ny_train = np.concatenate(list(train_ds.map(lambda x, y: y)))\n\nThe shape of our training set is now:\n\nX_train.shape\n\n(220, 6, 7)\n\n\n\ny_train.shape\n\n(220,)\n\n\nLater, we need the targets as numpy arrays:\n\ny_train = np.concatenate(list(train_ds.map(lambda x, y: y)))\ny_val = np.concatenate(list(val_ds.map(lambda x, y: y)))\ny_test = np.concatenate(list(test_ds.map(lambda x, y: y)))",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-dense-network",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-dense-network",
    "title": "Recurrent Neural Networks",
    "section": "A dense network",
    "text": "A dense network\n\nfrom keras.layers import Input, Flatten\nrandom.seed(1)\nmodel_dense = Sequential([\n    Input((seq_length, num_ts)),\n    Flatten(),\n    Dense(50, activation=\"leaky_relu\"),\n    Dense(20, activation=\"leaky_relu\"),\n    Dense(1, activation=\"linear\")\n])\nmodel_dense.compile(loss=\"mse\", optimizer=\"adam\")\nprint(f\"This model has {model_dense.count_params()} parameters.\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n%time hist = model_dense.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0);\n\nThis model has 3191 parameters.\nEpoch 126: early stopping\nRestoring model weights from the end of the best epoch: 76.\nCPU times: user 8.29 s, sys: 1.33 s, total: 9.62 s\nWall time: 4.67 s",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plot-the-model",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plot-the-model",
    "title": "Recurrent Neural Networks",
    "section": "Plot the model",
    "text": "Plot the model\n\nfrom keras.utils import plot_model\nplot_model(model_dense, show_shapes=True)",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\n\n\n\n\n\n\n\n\nmodel_dense.evaluate(val_ds, verbose=0)\n\n1.3521653413772583",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-simplernn-layer",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-simplernn-layer",
    "title": "Recurrent Neural Networks",
    "section": "A SimpleRNN layer",
    "text": "A SimpleRNN layer\n\nrandom.seed(1)\n\nmodel_simple = Sequential([\n    Input((seq_length, num_ts)),\n    SimpleRNN(50),\n    Dense(1, activation=\"linear\")\n])\nmodel_simple.compile(loss=\"mse\", optimizer=\"adam\")\nprint(f\"This model has {model_simple.count_params()} parameters.\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n%time hist = model_simple.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0);\n\nThis model has 2951 parameters.\nEpoch 57: early stopping\nRestoring model weights from the end of the best epoch: 7.\nCPU times: user 3.98 s, sys: 618 ms, total: 4.6 s\nWall time: 2.33 s",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-1",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\n\n\n\n\n\n\n\n\nmodel_simple.evaluate(val_ds, verbose=0)\n\n0.869707465171814",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plot-the-model-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plot-the-model-1",
    "title": "Recurrent Neural Networks",
    "section": "Plot the model",
    "text": "Plot the model\n\nplot_model(model_simple, show_shapes=True)",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-1",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-lstm-layer",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-lstm-layer",
    "title": "Recurrent Neural Networks",
    "section": "A LSTM layer",
    "text": "A LSTM layer\n\nfrom keras.layers import LSTM\n\nrandom.seed(1)\n\nmodel_lstm = Sequential([\n    Input((seq_length, num_ts)),\n    LSTM(50),\n    Dense(1, activation=\"linear\")\n])\n\nmodel_lstm.compile(loss=\"mse\", optimizer=\"adam\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n\n%time hist = model_lstm.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0);\n\nEpoch 72: early stopping\nRestoring model weights from the end of the best epoch: 22.\nCPU times: user 5.01 s, sys: 870 ms, total: 5.88 s\nWall time: 3.09 s",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-2",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-2",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\n\n\n\n\n\n\n\n\nmodel_lstm.evaluate(val_ds, verbose=0)\n\n0.8331282734870911",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-2",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-2",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-gru-layer",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-gru-layer",
    "title": "Recurrent Neural Networks",
    "section": "A GRU layer",
    "text": "A GRU layer\n\nfrom keras.layers import GRU\n\nrandom.seed(1)\n\nmodel_gru = Sequential([\n    Input((seq_length, num_ts)),\n    GRU(50),\n    Dense(1, activation=\"linear\")\n])\n\nmodel_gru.compile(loss=\"mse\", optimizer=\"adam\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n\n%time hist = model_gru.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0)\n\nEpoch 66: early stopping\nRestoring model weights from the end of the best epoch: 16.\nCPU times: user 4.94 s, sys: 780 ms, total: 5.72 s\nWall time: 3.04 s",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-3",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-3",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\n\n\n\n\n\n\n\n\nmodel_gru.evaluate(val_ds, verbose=0)\n\n0.8188608884811401",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-3",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-3",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#two-gru-layers",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#two-gru-layers",
    "title": "Recurrent Neural Networks",
    "section": "Two GRU layers",
    "text": "Two GRU layers\n\nrandom.seed(1)\n\nmodel_two_grus = Sequential([\n    Input((seq_length, num_ts)),\n    GRU(50, return_sequences=True),\n    GRU(50),\n    Dense(1, activation=\"linear\")\n])\n\nmodel_two_grus.compile(loss=\"mse\", optimizer=\"adam\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n\n%time hist = model_two_grus.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0)\n\nEpoch 69: early stopping\nRestoring model weights from the end of the best epoch: 19.\nCPU times: user 5.82 s, sys: 844 ms, total: 6.66 s\nWall time: 3.9 s",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-4",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-4",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\n\n\n\n\n\n\n\n\nmodel_two_grus.evaluate(val_ds, verbose=0)\n\n0.777770459651947",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-4",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-4",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#compare-the-models",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#compare-the-models",
    "title": "Recurrent Neural Networks",
    "section": "Compare the models",
    "text": "Compare the models\n\n\n\n\n\n\n\n\n\nModel\nMSE\n\n\n\n\n0\nDense\n1.352165\n\n\n1\nSimpleRNN\n0.869707\n\n\n2\nLSTM\n0.833128\n\n\n3\nGRU\n0.818861\n\n\n4\n2 GRUs\n0.777770\n\n\n\n\n\n\n\nThe network with two GRU layers is the best.\n\nmodel_two_grus.evaluate(test_ds, verbose=0)\n\n1.9774343967437744",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#test-set",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#test-set",
    "title": "Recurrent Neural Networks",
    "section": "Test set",
    "text": "Test set",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#creating-dataset-objects-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#creating-dataset-objects-1",
    "title": "Recurrent Neural Networks",
    "section": "Creating dataset objects",
    "text": "Creating dataset objects\n\n\nChange the targets argument to include all the suburbs.\n\n\ntrain_ds = \\\n  timeseries_dataset_from_array(\n    changes[:-delay],\n    targets=changes[delay:],\n    sequence_length=seq_length,\n    end_index=num_train)\n\n\n\n\n\n\nval_ds = \\\n  timeseries_dataset_from_array(\n    changes[:-delay],\n    targets=changes[delay:],\n    sequence_length=seq_length,\n    start_index=num_train,\n    end_index=num_train+num_val)\n\n\n\ntest_ds = \\\n  timeseries_dataset_from_array(\n    changes[:-delay],\n    targets=changes[delay:],\n    sequence_length=seq_length,\n    start_index=num_train+num_val)",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#converting-dataset-to-numpy-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#converting-dataset-to-numpy-1",
    "title": "Recurrent Neural Networks",
    "section": "Converting Dataset to numpy",
    "text": "Converting Dataset to numpy\nThe shape of our training set is now:\n\nX_train = np.concatenate(list(train_ds.map(lambda x, y: x)))\nX_train.shape\n\n(220, 6, 7)\n\n\n\nY_train = np.concatenate(list(train_ds.map(lambda x, y: y)))\nY_train.shape\n\n(220, 7)\n\n\nLater, we need the targets as numpy arrays:\n\nY_train = np.concatenate(list(train_ds.map(lambda x, y: y)))\nY_val = np.concatenate(list(val_ds.map(lambda x, y: y)))\nY_test = np.concatenate(list(test_ds.map(lambda x, y: y)))",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-dense-network-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-dense-network-1",
    "title": "Recurrent Neural Networks",
    "section": "A dense network",
    "text": "A dense network\n\nrandom.seed(1)\nmodel_dense = Sequential([\n    Input((seq_length, num_ts)),\n    Flatten(),\n    Dense(50, activation=\"leaky_relu\"),\n    Dense(20, activation=\"leaky_relu\"),\n    Dense(num_ts, activation=\"linear\")\n])\nmodel_dense.compile(loss=\"mse\", optimizer=\"adam\")\nprint(f\"This model has {model_dense.count_params()} parameters.\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n%time hist = model_dense.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0);\n\nThis model has 3317 parameters.\nEpoch 96: early stopping\nRestoring model weights from the end of the best epoch: 46.\nCPU times: user 6.37 s, sys: 1.21 s, total: 7.58 s\nWall time: 3.62 s",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plot-the-model-2",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plot-the-model-2",
    "title": "Recurrent Neural Networks",
    "section": "Plot the model",
    "text": "Plot the model\n\nplot_model(model_dense, show_shapes=True)",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-5",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-5",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\n\n\n\n\n\n\n\n\nmodel_dense.evaluate(val_ds, verbose=0)\n\n1.445832371711731",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-5",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-5",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-simplernn-layer-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-simplernn-layer-1",
    "title": "Recurrent Neural Networks",
    "section": "A SimpleRNN layer",
    "text": "A SimpleRNN layer\n\nrandom.seed(1)\n\nmodel_simple = Sequential([\n    Input((seq_length, num_ts)),\n    SimpleRNN(50),\n    Dense(num_ts, activation=\"linear\")\n])\nmodel_simple.compile(loss=\"mse\", optimizer=\"adam\")\nprint(f\"This model has {model_simple.count_params()} parameters.\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n%time hist = model_simple.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0);\n\nThis model has 3257 parameters.\nEpoch 93: early stopping\nRestoring model weights from the end of the best epoch: 43.\nCPU times: user 6.38 s, sys: 1.07 s, total: 7.45 s\nWall time: 3.79 s",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-6",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-6",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\n\n\n\n\n\n\n\n\nmodel_simple.evaluate(val_ds, verbose=0)\n\n1.6287589073181152",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plot-the-model-3",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plot-the-model-3",
    "title": "Recurrent Neural Networks",
    "section": "Plot the model",
    "text": "Plot the model\n\nplot_model(model_simple, show_shapes=True)",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-6",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-6",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-lstm-layer-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-lstm-layer-1",
    "title": "Recurrent Neural Networks",
    "section": "A LSTM layer",
    "text": "A LSTM layer\n\nrandom.seed(1)\n\nmodel_lstm = Sequential([\n    Input((seq_length, num_ts)),\n    LSTM(50),\n    Dense(num_ts, activation=\"linear\")\n])\n\nmodel_lstm.compile(loss=\"mse\", optimizer=\"adam\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n\n%time hist = model_lstm.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0);\n\nEpoch 106: early stopping\nRestoring model weights from the end of the best epoch: 56.\nCPU times: user 7.86 s, sys: 1.24 s, total: 9.1 s\nWall time: 4.81 s",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-7",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-7",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\n\n\n\n\n\n\n\n\nmodel_lstm.evaluate(val_ds, verbose=0)\n\n1.3439934253692627",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-7",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-7",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-gru-layer-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#a-gru-layer-1",
    "title": "Recurrent Neural Networks",
    "section": "A GRU layer",
    "text": "A GRU layer\n\nrandom.seed(1)\n\nmodel_gru = Sequential([\n    Input((seq_length, num_ts)),\n    GRU(50),\n    Dense(num_ts, activation=\"linear\")\n])\n\nmodel_gru.compile(loss=\"mse\", optimizer=\"adam\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n\n%time hist = model_gru.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0)\n\nEpoch 114: early stopping\nRestoring model weights from the end of the best epoch: 64.\nCPU times: user 8.28 s, sys: 1.26 s, total: 9.54 s\nWall time: 5.11 s",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-8",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-8",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\n\n\n\n\n\n\n\n\nmodel_gru.evaluate(val_ds, verbose=0)\n\n1.3462404012680054",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-8",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-8",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#two-gru-layers-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#two-gru-layers-1",
    "title": "Recurrent Neural Networks",
    "section": "Two GRU layers",
    "text": "Two GRU layers\n\nrandom.seed(1)\n\nmodel_two_grus = Sequential([\n    Input((seq_length, num_ts)),\n    GRU(50, return_sequences=True),\n    GRU(50),\n    Dense(num_ts, activation=\"linear\")\n])\n\nmodel_two_grus.compile(loss=\"mse\", optimizer=\"adam\")\n\nes = EarlyStopping(patience=50, restore_best_weights=True, verbose=1)\n\n%time hist = model_two_grus.fit(train_ds, epochs=1_000, \\\n  validation_data=val_ds, callbacks=[es], verbose=0)\n\nEpoch 93: early stopping\nRestoring model weights from the end of the best epoch: 43.\nCPU times: user 7.49 s, sys: 1.05 s, total: 8.54 s\nWall time: 4.93 s",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-9",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#assess-the-fits-9",
    "title": "Recurrent Neural Networks",
    "section": "Assess the fits",
    "text": "Assess the fits\n\n\n\n\n\n\n\n\n\n\nmodel_two_grus.evaluate(val_ds, verbose=0)\n\n1.361182451248169",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-9",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#plotting-the-predictions-9",
    "title": "Recurrent Neural Networks",
    "section": "Plotting the predictions",
    "text": "Plotting the predictions",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#compare-the-models-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#compare-the-models-1",
    "title": "Recurrent Neural Networks",
    "section": "Compare the models",
    "text": "Compare the models\n\n\n\n\n\n\n\n\n\nModel\nMSE\n\n\n\n\n1\nSimpleRNN\n1.628759\n\n\n0\nDense\n1.445832\n\n\n4\n2 GRUs\n1.361182\n\n\n3\nGRU\n1.346240\n\n\n2\nLSTM\n1.343993\n\n\n\n\n\n\n\nThe network with an LSTM layer is the best.\n\nmodel_lstm.evaluate(test_ds, verbose=0)\n\n1.879453420639038",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#test-set-1",
    "href": "Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html#test-set-1",
    "title": "Recurrent Neural Networks",
    "section": "Test set",
    "text": "Test set",
    "crumbs": [
      "Module 7",
      "Recurrent Neural Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#lecture-outline",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#lecture-outline",
    "title": "Generative Networks",
    "section": "Lecture Outline",
    "text": "Lecture Outline\n\nText Generation\nImage Generation\nAutoencoders\nGenerative adversarial networks"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#load-packages",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#load-packages",
    "title": "Generative Networks",
    "section": "Load packages",
    "text": "Load packages\n\nimport random\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport numpy.random as rnd\nimport pandas as pd\nimport keras\nfrom keras import layers\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.21.0\n\nsklearn   : 1.4.0\nkeras     : 2.15.0\ntorch     : 2.0.1\ntensorflow: 2.15.0.post1"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#generative-deep-learning",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#generative-deep-learning",
    "title": "Generative Networks",
    "section": "Generative deep learning",
    "text": "Generative deep learning\n\nUsing AI as augmented intelligence rather than artificial intelligence.\nUse of deep learning to augment creative activities such as writing, music and art, to generate new things.\nSome applications: text generation, deep dreaming, neural style transfer, variational autoencoders and generative adversarial networks."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#text-generation-1",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#text-generation-1",
    "title": "Generative Networks",
    "section": "Text generation",
    "text": "Text generation\n\nGenerating sequential data is the closest computers get to dreaming.\n\n\nGenerate sequence data: Train a model to predict the next token or next few tokens in a sentence, using previous tokens as input.\nA network that models the probability of the next tokens given the previous ones is called a language model.\n\n\nGPT-3 is a 175 billion parameter text-generation model trained by the startup OpenAI on a large text corpus of digitally available books, Wikipedia and web crawling. GPT-3 made headlines in 2020 due to its capability to generate plausible-sounding text paragraphs on virtually any topic.\n\n\nSource: Alex Graves (2013), Generating Sequences With Recurrent Neural Networks"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#word-level-language-model",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#word-level-language-model",
    "title": "Generative Networks",
    "section": "Word-level language model",
    "text": "Word-level language model\n\nDiagram of a word-level language model.\nSource: Marcus Lautier (2022)."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#character-level-language-model",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#character-level-language-model",
    "title": "Generative Networks",
    "section": "Character-level language model",
    "text": "Character-level language model\n\nDiagram of a character-level language model (Char-RNN)\nSource: Tensorflow tutorial, Text generation with an RNN."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#useful-for-speech-recognition",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#useful-for-speech-recognition",
    "title": "Generative Networks",
    "section": "Useful for speech recognition",
    "text": "Useful for speech recognition\n\n\n\n\n\n\n\n\n\n\nRNN output\nDecoded Transcription\n\n\n\n\nwhat is the weather like in bostin right now\nwhat is the weather like in boston right now\n\n\nprime miniter nerenr modi\nprime minister narendra modi\n\n\narther n tickets for the game\nare there any tickets for the game\n\n\n\n\n\nFigure 1: Examples of transcriptions directly from the RNN with errors that are fixed by addition of a language model.\n\n\n\n\nSource: Hannun et al. (2014), Deep Speech: Scaling up end-to-end speech recognition, arXiv:1412.5567, Table 1."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-shakespeare-i",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-shakespeare-i",
    "title": "Generative Networks",
    "section": "Generating Shakespeare I",
    "text": "Generating Shakespeare I\n\nROMEO:\nWhy, sir, what think you, sir?\n\nAUTOLYCUS:\nA dozen; shall I be deceased.\nThe enemy is parting with your general,\nAs bias should still combit them offend\nThat Montague is as devotions that did satisfied;\nBut not they are put your pleasure.\n\n\nSource: Tensorflow tutorial, Text generation with an RNN."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-shakespeare-ii",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-shakespeare-ii",
    "title": "Generative Networks",
    "section": "Generating Shakespeare II",
    "text": "Generating Shakespeare II\n\nDUKE OF YORK:\nPeace, sing! do you must be all the law;\nAnd overmuting Mercutio slain;\nAnd stand betide that blows which wretched shame;\nWhich, I, that have been complaints me older hours.\n\nLUCENTIO:\nWhat, marry, may shame, the forish priest-lay estimest you, sir,\nWhom I will purchase with green limits o’ the commons’ ears!\n\n\nSource: Tensorflow tutorial, Text generation with an RNN."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-shakespeare-iii",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-shakespeare-iii",
    "title": "Generative Networks",
    "section": "Generating Shakespeare III",
    "text": "Generating Shakespeare III\n\nANTIGONUS:\nTo be by oath enjoin’d to this. Farewell!\nThe day frowns more and more: thou’rt like to have\nA lullaby too rough: I never saw\nThe heavens so dim by day. A savage clamour!\n\n[Exit, pursued by a bear]"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#softmax-temperature",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#softmax-temperature",
    "title": "Generative Networks",
    "section": "Softmax temperature",
    "text": "Softmax temperature\n\nThe softmax temperature is a parameter that controls the randomness of the next token.\nThe formula is:  \\text{softmax}_\\text{temperature}(x) = \\frac{\\exp(x / \\text{temperature})}{\\sum_i \\exp(x_i / \\text{temperature})}"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#i-am-a",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#i-am-a",
    "title": "Generative Networks",
    "section": "“I am a” …",
    "text": "“I am a” …\n\n\nIdea inspired by Mehta (2023), The need for sampling temperature and differences between whisper, GPT-3, and probabilistic model’s temperature"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-laub-temp-0.01",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-laub-temp-0.01",
    "title": "Generative Networks",
    "section": "Generating Laub (temp = 0.01)",
    "text": "Generating Laub (temp = 0.01)\n\nIn today’s lecture we will be different situation. So, next one is what they rective that each commit to be able to learn some relationships from the course, and that is part of the image that it’s very clese and black problems that you’re trying to fit the neural network to do there instead of like a specific though shef series of layers mean about full of the chosen the baseline of car was in the right, but that’s an important facts and it’s a very small summary with very scrort by the beginning of the sentence."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-laub-temp-0.25",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-laub-temp-0.25",
    "title": "Generative Networks",
    "section": "Generating Laub (temp = 0.25)",
    "text": "Generating Laub (temp = 0.25)\n\nIn today’s lecture we will decreas before model that we that we have to think about it, this mightsks better, for chattely the same project, because you might use the test set because it’s to be picked up the things that I wanted to heard of things that I like that even real you and you’re using the same thing again now because we need to understand what it’s doing the same thing but instead of putting it in particular week, and we can say that’s a thing I mainly link it’s three columns."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-laub-temp-0.5",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-laub-temp-0.5",
    "title": "Generative Networks",
    "section": "Generating Laub (temp = 0.5)",
    "text": "Generating Laub (temp = 0.5)\n\nIn today’s lecture we will probably the adw n wait lots of ngobs teulagedation to calculate the gradient and then I’ll be less than one layer the next slide will br input over and over the threshow you ampaigey the one that we want to apply them quickly. So, here this is the screen here the main top kecw onct three thing to told them, and the output is a vertical variables and Marceparase of things that you’re moving the blurring and that just data set is to maybe kind of categorical variants here but there’s more efficiently not basically replace that with respect to the best and be the same thing."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-laub-temp-1",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-laub-temp-1",
    "title": "Generative Networks",
    "section": "Generating Laub (temp = 1)",
    "text": "Generating Laub (temp = 1)\n\nIn today’s lecture we will put it different shates to touch on last week, so I want to ask what are you object frod current. They don’t have any zero into it, things like that which mistakes. 10 claims that the average version was relden distever ditgs and Python for the whole term wo long right to really. The name of these two options. There are in that seems to be modified version. If you look at when you’re putting numbers into your, that that’s over. And I went backwards, up, if they’rina functional pricing working with."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-laub-temp-1.5",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#generating-laub-temp-1.5",
    "title": "Generative Networks",
    "section": "Generating Laub (temp = 1.5)",
    "text": "Generating Laub (temp = 1.5)\n\nIn today’s lecture we will put it could be bedinnth. Lowerstoriage nruron. So rochain the everything that I just sGiming. If there was a large. It’s gonua draltionation. Tow many, up, would that black and 53% that’s girter thankAty will get you jast typically stickK thing. But maybe. Anyway, I’m going to work on this libry two, past, at shit citcs jast pleming to memorize overcamples like pre pysing, why wareed to smart a one in this reportbryeccuriay."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#generate-the-most-likely-sequence",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#generate-the-most-likely-sequence",
    "title": "Generative Networks",
    "section": "Generate the most likely sequence",
    "text": "Generate the most likely sequence\n\nAn example sequence-to-sequence chatbot model.\nSource: Payne (2021), What is beam search, Width.ai blog."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#beam-search",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#beam-search",
    "title": "Generative Networks",
    "section": "Beam search",
    "text": "Beam search\n\nIllustration of a beam search.\nSource: Doshi (2021), Foundations of NLP Explained Visually: Beam Search, How It Works, towardsdatascience.com."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#transformer-architecture",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#transformer-architecture",
    "title": "Generative Networks",
    "section": "Transformer architecture",
    "text": "Transformer architecture\n\nGPT makes use of a mechanism known as attention, which removes the need for recurrent layers (e.g., LSTMs). It works like an information retrieval system, utilizing queries, keys, and values to decide how much information it wants to extract from each input token.\nAttention heads can be grouped together to form what is known as a multihead attention layer. These are then wrapped up inside a Transformer block, which includes layer normalization and skip connections around the attention layer. Transformer blocks can be stacked to create very deep neural networks.\n\n\nSource: David Foster (2023), Generative Deep Learning, 2nd Edition, O’Reilly Media, Chapter 9."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#transformer-architecture-reference",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#transformer-architecture-reference",
    "title": "Generative Networks",
    "section": "Transformer architecture reference",
    "text": "Transformer architecture reference"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#transformers-package",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#transformers-package",
    "title": "Generative Networks",
    "section": "🤗 Transformers package",
    "text": "🤗 Transformers package\n\nimport transformers\nfrom transformers import pipeline\ngenerator = pipeline(task=\"text-generation\", model=\"gpt2\", revision=\"6c0e608\")\n\n/home/plaub/miniconda3/envs/ai2023/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n\n\n\ntransformers.set_seed(1)\nprint(generator(\"It's the holidays so I'm going to enjoy\")[0][\"generated_text\"])\n\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n\n\nIt's the holidays so I'm going to enjoy playing in there.\"\n\nAdvertisement\n\nBut how many other holiday-goers would want to join his team?\n\n\n\"They wouldn't know if I would be there, not that I'm\n\n\n\ntransformers.set_seed(1337)\nprint(generator(\"It's the holidays so I'm going to enjoy\")[0][\"generated_text\"])\n\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n\n\nIt's the holidays so I'm going to enjoy myself. I don't want to be a full-grown man when I get to get pregnant (if I didn't, I would never take it). I want to learn and find my own ways"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#reading-the-course-profile",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#reading-the-course-profile",
    "title": "Generative Networks",
    "section": "Reading the course profile",
    "text": "Reading the course profile\n\ncontext = \"\"\"\nStoryWall Formative Discussions: An initial StoryWall, worth 2%, is due by noon on June 3. The following StoryWalls are worth 4% each (taking the best 7 of 9) and are due at noon on the following dates:\nThe project will be submitted in stages: draft due at noon on July 1 (10%), recorded presentation due at noon on July 22 (15%), final report due at noon on August 1 (15%).\n\nAs a student at UNSW you are expected to display academic integrity in your work and interactions. Where a student breaches the UNSW Student Code with respect to academic integrity, the University may take disciplinary action under the Student Misconduct Procedure. To assure academic integrity, you may be required to demonstrate reasoning, research and the process of constructing work submitted for assessment.\nTo assist you in understanding what academic integrity means, and how to ensure that you do comply with the UNSW Student Code, it is strongly recommended that you complete the Working with Academic Integrity module before submitting your first assessment task. It is a free, online self-paced Moodle module that should take about one hour to complete.\n\nStoryWall (30%)\n\nThe StoryWall format will be used for small weekly questions. Each week of questions will be released on a Monday, and most of them will be due the following Monday at midday (see assessment table for exact dates). Students will upload their responses to the question sets, and give comments on another student's submission. Each week will be worth 4%, and the grading is pass/fail, with the best 7 of 9 being counted. The first week's basic 'introduction' StoryWall post is counted separately and is worth 2%.\n\nProject (40%)\n\nOver the term, students will complete an individual project. There will be a selection of deep learning topics to choose from (this will be outlined during Week 1).\n\nThe deliverables for the project will include: a draft/progress report mid-way through the term, a presentation (recorded), a final report including a written summary of the project and the relevant Python code (Jupyter notebook).\n\nExam (30%)\n\nThe exam will test the concepts presented in the lectures. For example, students will be expected to: provide definitions for various deep learning terminology, suggest neural network designs to solve risk and actuarial problems, give advice to mock deep learning engineers whose projects have hit common roadblocks, find/explain common bugs in deep learning Python code.\n\"\"\""
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#question-answering",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#question-answering",
    "title": "Generative Networks",
    "section": "Question answering",
    "text": "Question answering\n\nqa = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", revision=\"626af31\")\n\n\nqa(question=\"What weight is the exam?\", context=context)\n\n{'score': 0.5019665956497192, 'start': 2092, 'end': 2095, 'answer': '30%'}\n\n\n\nqa(question=\"What topics are in the exam?\", context=context)\n\n{'score': 0.21276019513607025,\n 'start': 1778,\n 'end': 1791,\n 'answer': 'deep learning'}\n\n\n\nqa(question=\"When is the presentation due?\", context=context)\n\n{'score': 0.5296485424041748,\n 'start': 1319,\n 'end': 1335,\n 'answer': 'Monday at midday'}\n\n\n\nqa(question=\"How many StoryWall tasks are there?\", context=context)\n\n{'score': 0.2139102965593338, 'start': 1155, 'end': 1158, 'answer': '30%'}"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#chatgpt-is-transformer-rlhf",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#chatgpt-is-transformer-rlhf",
    "title": "Generative Networks",
    "section": "ChatGPT is Transformer + RLHF",
    "text": "ChatGPT is Transformer + RLHF\n\nAt the time of writing, there is no official paper that describes how ChatGPT works in detail, but from the official blog post we know that it uses a technique called reinforcement learning from human feedback (RLHF) to fine-tune the GPT-3.5 model.\n\n\nSource: David Foster (2023), Generative Deep Learning, 2nd Edition, O’Reilly Media, Chapter 9."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#chatgpt-internals",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#chatgpt-internals",
    "title": "Generative Networks",
    "section": "ChatGPT internals",
    "text": "ChatGPT internals\n\nIt uses a fair bit of human feedback\nSource: OpenAI blog."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#chatgpt",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#chatgpt",
    "title": "Generative Networks",
    "section": "ChatGPT",
    "text": "ChatGPT\n\nWhile ChatGPT still has many limitations (such as sometimes “hallucinating” factually incorrect information), it is a powerful example of how Transformers can be used to build generative models that can produce complex, long-ranging, and novel output that is often indistinguishable from human-generated text. The progress made thus far by models like ChatGPT serves as a testament to the potential of AI and its transformative impact on the world.\n\n\nSource: David Foster (2023), Generative Deep Learning, 2nd Edition, O’Reilly Media, Chapter 9."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#recommended-reading",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#recommended-reading",
    "title": "Generative Networks",
    "section": "Recommended reading",
    "text": "Recommended reading\n\nThe Verge (2022), The Great Fiction of AI: The strange world of high-speed semi-automated genre fiction\nVaswani et al. (2017), Attention Is All You Need, NeurIPS\nBommasani et al. (2021), On the Opportunities and Risks of Foundation Models\nGary Marcus (2022), Deep Learning Is Hitting a Wall, Nautilus article\nSDS 564, Clem Delangue on Hugging Face and Transformers\nSDS 559, GPT-3 for Natural Language Processing\nComputerphile (2019), AI Language Models & Transformers (20m)\nComputerphile (2020), GPT3: An Even Bigger Language Model (25m)\nNicholas Renotte (2021), AI Blog Post Summarization with Hugging Face Transformers… (33m)\nSeattle Applied Deep Learning (2019), LSTM is dead. Long Live Transformers! (28m)"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#reverse-engineering-a-cnn",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#reverse-engineering-a-cnn",
    "title": "Generative Networks",
    "section": "Reverse-engineering a CNN",
    "text": "Reverse-engineering a CNN\nA CNN is a function f_{\\boldsymbol{\\theta}}(\\mathbf{x}) that takes a vector (image) \\mathbf{x} and returns a vector (distribution) \\widehat{\\mathbf{y}}.\nNormally, we train it by modifying \\boldsymbol{\\theta} so that\n \\boldsymbol{\\theta}^*\\ =\\  \\underset{\\boldsymbol{\\theta}}{\\mathrm{argmin}} \\,\\, \\text{Loss} \\bigl( f_{\\boldsymbol{\\theta}}(\\mathbf{x}), \\mathbf{y} \\bigr). \nHowever, it is possible to not train the network but to modify \\mathbf{x}, like\n \\mathbf{x}^*\\ =\\  \\underset{\\mathbf{x}}{\\mathrm{argmin}} \\,\\, \\text{Loss} \\bigl( f_{\\boldsymbol{\\theta}}(\\mathbf{x}), \\mathbf{y} \\bigr). \nThis is very slow as we do gradient descent every single time."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#adversarial-examples",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#adversarial-examples",
    "title": "Generative Networks",
    "section": "Adversarial examples",
    "text": "Adversarial examples\n\nA demonstration of fast adversarial example generation applied to GoogLeNet on ImageNet. By adding an imperceptibly small vector whose elements are equal to the sign of the elements of the gradient of the cost function with respect to the input, we can change GoogLeNet’s classification of the image.\nSource: Goodfellow et al. (2015), Explaining and Harnessing Adversarial Examples, ICLR."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#adversarial-stickers",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#adversarial-stickers",
    "title": "Generative Networks",
    "section": "Adversarial stickers",
    "text": "Adversarial stickers\n\nAdversarial stickers.\nSource: The Verge (2018), These stickers make computer vision software hallucinate things that aren’t there."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#adversarial-text",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#adversarial-text",
    "title": "Generative Networks",
    "section": "Adversarial text",
    "text": "Adversarial text\n“TextAttack 🐙 is a Python framework for adversarial attacks, data augmentation, and model training in NLP”\n\nDemo"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#deep-dream",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#deep-dream",
    "title": "Generative Networks",
    "section": "Deep Dream",
    "text": "Deep Dream\n\nDeep Dream is an image-modification program released by Google in 2015.\nSource: Wikipedia, DeepDream page."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#deepdream",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#deepdream",
    "title": "Generative Networks",
    "section": "DeepDream",
    "text": "DeepDream\n\nEven though many deep learning models are black boxes, convnets are quite interpretable via visualization. Some visualization techniques are: visualizing convnet outputs shows how convnet layers transform the input, visualizing convnet filters shows what visual patterns or concept each filter is receptive to, etc.\nThe activations of the first few layers of the network carries more information about the visual contents, while deeper layers encode higher, more abstract concepts."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#deepdream-1",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#deepdream-1",
    "title": "Generative Networks",
    "section": "DeepDream",
    "text": "DeepDream\n\nEach filter is receptive to a visual pattern. To visualize a convnet filter, gradient ascent is used to maximize the response of the filter. Gradient ascent maximize a loss function and moves the image in a direction that activate the filter more strongly to enhance its reading of the visual pattern.\nDeepDream maximizes the activation of the entire convnet layer rather than that of a specific filter, thus mixing together many visual patterns all at once.\nDeepDream starts with an existing image, latches on to preexisting visual patterns, distorting elements of the image in a somewhat artistic fashion."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#original",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#original",
    "title": "Generative Networks",
    "section": "Original",
    "text": "Original\n\nA sunny day on the Mornington peninsula."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#transformed",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#transformed",
    "title": "Generative Networks",
    "section": "Transformed",
    "text": "Transformed\n\nDeep-dreaming version.\nGenerated by Keras’ Deep Dream tutorial."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#goal-of-nst",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#goal-of-nst",
    "title": "Generative Networks",
    "section": "Goal of NST",
    "text": "Goal of NST\nWhat the model does:\n\nPreserve content by maintaining similar deeper layer activations between the original image and the generated image. The convnet should “see” both the original image and the generated image as containing the same things.\nPreserve style by maintaining similar correlations within activations for both low level layers and high-level layers. Feature correlations within a layer capture textures: the generated image and the style-reference image should share the same textures at different spatial scales."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#a-wanderer-in-greenland",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#a-wanderer-in-greenland",
    "title": "Generative Networks",
    "section": "A wanderer in Greenland",
    "text": "A wanderer in Greenland\n\n\nContent\n\n\n\nSome striking young hiker in Greenland.\n\n\n\nStyle\n\n\n\nWanderer above the Sea of Fog by Caspar David Friedrich.\n\n\n\n\n\nSource: Laub (2018), On Neural Style Transfer, Blog post."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#a-wanderer-in-greenland-ii",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#a-wanderer-in-greenland-ii",
    "title": "Generative Networks",
    "section": "A wanderer in Greenland II",
    "text": "A wanderer in Greenland II\n\n\n\n\n\nAnimation of NST in progress.\n\n\n\n\n\n\nOne result of NST.\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\nHow would you make this faster for one specific style image?\n\n\n\n\nSource: Laub (2018), On Neural Style Transfer, Blog post."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#a-new-style-image",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#a-new-style-image",
    "title": "Generative Networks",
    "section": "A new style image",
    "text": "A new style image\n\nHokusai’s Great Wave off Kanagawa\nSource: Laub (2018), On Neural Style Transfer, Blog post."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#a-new-content-image",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#a-new-content-image",
    "title": "Generative Networks",
    "section": "A new content image",
    "text": "A new content image\n\nThe seascape in Qingdao\nSource: Laub (2018), On Neural Style Transfer, Blog post."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#another-neural-style-transfer",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#another-neural-style-transfer",
    "title": "Generative Networks",
    "section": "Another neural style transfer",
    "text": "Another neural style transfer\n\nThe seascape in Qingdao in the style of Hokusai’s Great Wave off Kanagawa\nSource: Laub (2018), On Neural Style Transfer, Blog post."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#why-is-this-important",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#why-is-this-important",
    "title": "Generative Networks",
    "section": "Why is this important?",
    "text": "Why is this important?\nTaking derivatives with respect to the input image can be a first step toward explainable AI for convolutional networks.\n\nSaliency maps\nGrad-CAM"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#autoencoder",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#autoencoder",
    "title": "Generative Networks",
    "section": "Autoencoder",
    "text": "Autoencoder\nAn autoencoder takes a data/image, maps it to a latent space via an encoder module, then decodes it back to an output with the same dimensions via a decoder module.\n\nSchematic of an autoencoder.\nSource: Marcus Lautier (2022)."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#autoencoder-ii",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#autoencoder-ii",
    "title": "Generative Networks",
    "section": "Autoencoder II",
    "text": "Autoencoder II\n\nAn autoencoder is trained by using the same image as both the input and the target, meaning an autoencoder learns to reconstruct the original inputs. Therefore it’s not supervised learning, but self-supervised learning.\nIf we impose constraints on the encoders to be low-dimensional and sparse, the input data will be compressed into fewer bits of information.\nLatent space is a place that stores low-dimensional representation of data. It can be used for data compression, where data is compressed to a point in a latent space.\nAn image can be compressed into a latent representation, which can then be reconstructed back to a slightly different image.\n\n\nFor image editing, an image can be projected onto a latent space and moved inside the latent space in a meaningful way (which means we modify its latent representation), before being mapped back to the image space. This will edit the image and allow us to generate images that have never been seen before."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#example-psam",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#example-psam",
    "title": "Generative Networks",
    "section": "Example: PSAM",
    "text": "Example: PSAM\nLoading the dataset off-screen (using Lecture 6 code).\n\n\n\nplt.imshow(X_train[0], cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nplt.imshow(X_train[42], cmap=\"gray\");"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#a-compression-game",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#a-compression-game",
    "title": "Generative Networks",
    "section": "A compression game",
    "text": "A compression game\n\n\n\nplt.imshow(X_train[42], cmap=\"gray\");\nprint(img_width * img_height)\n\n6400\n\n\n\n\n\n\n\n\n\n\n\nA 4 with a curly foot, a flat line goes across the middle of the 4, two feet come off the bottom.\n\n96 characters\n\nA Dōng character, rotated counterclockwise 15 degrees.\n\n54 characters"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#make-a-basic-autoencoder",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#make-a-basic-autoencoder",
    "title": "Generative Networks",
    "section": "Make a basic autoencoder",
    "text": "Make a basic autoencoder\n\nnum_hidden_layer = 400\nprint(f\"Compress from {img_height * img_width} pixels to {num_hidden_layer} latent variables.\")\n\nCompress from 6400 pixels to 400 latent variables.\n\n\n\nrandom.seed(123)\n\nmodel = keras.models.Sequential([\n    layers.Input((img_height, img_width, 1)),\n    layers.Rescaling(1./255),\n    layers.Flatten(),\n    layers.Dense(num_hidden_layer, \"relu\"),\n    layers.Dense(img_height*img_width, \"sigmoid\"),\n    layers.Reshape((img_height, img_width, 1)),\n    layers.Rescaling(255),\n])\n\nmodel.compile(\"adam\", \"mse\")\nepochs = 1_000\nes = keras.callbacks.EarlyStopping(\n    patience=5, restore_best_weights=True)\nmodel.fit(X_train, X_train, epochs=epochs, verbose=0,\n    validation_data=(X_val, X_val), callbacks=es);"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#the-model",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#the-model",
    "title": "Generative Networks",
    "section": "The model",
    "text": "The model\n\nmodel.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n rescaling (Rescaling)       (None, 80, 80, 1)         0         \n                                                                 \n flatten (Flatten)           (None, 6400)              0         \n                                                                 \n dense (Dense)               (None, 400)               2560400   \n                                                                 \n dense_1 (Dense)             (None, 6400)              2566400   \n                                                                 \n reshape (Reshape)           (None, 80, 80, 1)         0         \n                                                                 \n rescaling_1 (Rescaling)     (None, 80, 80, 1)         0         \n                                                                 \n=================================================================\nTotal params: 5126800 (19.56 MB)\nTrainable params: 5126800 (19.56 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\nmodel.evaluate(X_val, X_val, verbose=0)\n\n2263.939453125"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#some-recovered-image",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#some-recovered-image",
    "title": "Generative Networks",
    "section": "Some recovered image",
    "text": "Some recovered image\n\nX_val_rec = model.predict(X_val, verbose=0)\n\n\n\n\nplt.imshow(X_val[42], cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nplt.imshow(X_val_rec[42], cmap=\"gray\");"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#invert-the-images",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#invert-the-images",
    "title": "Generative Networks",
    "section": "Invert the images",
    "text": "Invert the images\n\n\n\nplt.imshow(255 - X_train[0], cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nplt.imshow(255 - X_train[42], cmap=\"gray\");"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#try-inverting-the-images",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#try-inverting-the-images",
    "title": "Generative Networks",
    "section": "Try inverting the images",
    "text": "Try inverting the images\n\nrandom.seed(123)\n\nmodel = keras.models.Sequential([\n    layers.Input((img_height, img_width, 1)),\n    layers.Rescaling(1./255),\n    layers.Lambda(lambda x: 1 - x),\n    layers.Flatten(),\n    layers.Dense(num_hidden_layer, \"relu\"),\n    layers.Dense(img_height*img_width, \"sigmoid\"),\n    layers.Lambda(lambda x: 1 - x),\n    layers.Reshape((img_height, img_width, 1)),\n    layers.Rescaling(255),\n])\n\nmodel.compile(\"adam\", \"mse\")\nmodel.fit(X_train, X_train, epochs=epochs, verbose=0,\n    validation_data=(X_val, X_val), callbacks=es);"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#the-model-1",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#the-model-1",
    "title": "Generative Networks",
    "section": "The model",
    "text": "The model\n\nmodel.summary()\n\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n rescaling_2 (Rescaling)     (None, 80, 80, 1)         0         \n                                                                 \n lambda (Lambda)             (None, 80, 80, 1)         0         \n                                                                 \n flatten_1 (Flatten)         (None, 6400)              0         \n                                                                 \n dense_2 (Dense)             (None, 400)               2560400   \n                                                                 \n dense_3 (Dense)             (None, 6400)              2566400   \n                                                                 \n lambda_1 (Lambda)           (None, 6400)              0         \n                                                                 \n reshape_1 (Reshape)         (None, 80, 80, 1)         0         \n                                                                 \n rescaling_3 (Rescaling)     (None, 80, 80, 1)         0         \n                                                                 \n=================================================================\nTotal params: 5126800 (19.56 MB)\nTrainable params: 5126800 (19.56 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\nmodel.evaluate(X_val, X_val, verbose=0)\n\n2382.336669921875"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#some-recovered-image-1",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#some-recovered-image-1",
    "title": "Generative Networks",
    "section": "Some recovered image",
    "text": "Some recovered image\n\nX_val_rec = model.predict(X_val, verbose=0)\n\n\n\n\nplt.imshow(X_val[42], cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nplt.imshow(X_val_rec[42], cmap=\"gray\");"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#cnn-enhanced-encoder",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#cnn-enhanced-encoder",
    "title": "Generative Networks",
    "section": "CNN-enhanced encoder",
    "text": "CNN-enhanced encoder\n\nrandom.seed(123)\n\nencoder = keras.models.Sequential([\n    layers.Input((img_height, img_width, 1)),\n    layers.Rescaling(1./255),\n    layers.Lambda(lambda x: 1 - x),\n    layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n    layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dense(num_hidden_layer, \"relu\")\n])\n\n\ndecoder = keras.models.Sequential([\n    keras.Input(shape=(num_hidden_layer,)),\n    layers.Dense(20*20),\n    layers.Reshape((20, 20, 1)),\n    layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n    layers.UpSampling2D(),\n    layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n    layers.UpSampling2D(),\n    layers.Conv2D(1, 1, padding=\"same\", activation=\"relu\"),\n    layers.Lambda(lambda x: 1 - x),\n    layers.Rescaling(255),\n])\n\nmodel = keras.models.Sequential([encoder, decoder])\nmodel.compile(\"adam\", \"mse\")\nmodel.fit(X_train, X_train, epochs=epochs, verbose=0,\n    validation_data=(X_val, X_val), callbacks=es);"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#encoder-summary",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#encoder-summary",
    "title": "Generative Networks",
    "section": "Encoder summary",
    "text": "Encoder summary\n\nencoder.summary()\n\nModel: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n rescaling_4 (Rescaling)     (None, 80, 80, 1)         0         \n                                                                 \n lambda_2 (Lambda)           (None, 80, 80, 1)         0         \n                                                                 \n conv2d (Conv2D)             (None, 80, 80, 16)        160       \n                                                                 \n max_pooling2d (MaxPooling2  (None, 40, 40, 16)        0         \n D)                                                              \n                                                                 \n conv2d_1 (Conv2D)           (None, 40, 40, 32)        4640      \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 20, 20, 32)        0         \n g2D)                                                            \n                                                                 \n conv2d_2 (Conv2D)           (None, 20, 20, 64)        18496     \n                                                                 \n max_pooling2d_2 (MaxPoolin  (None, 10, 10, 64)        0         \n g2D)                                                            \n                                                                 \n flatten_2 (Flatten)         (None, 6400)              0         \n                                                                 \n dense_4 (Dense)             (None, 400)               2560400   \n                                                                 \n=================================================================\nTotal params: 2583696 (9.86 MB)\nTrainable params: 2583696 (9.86 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#decoder-summary",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#decoder-summary",
    "title": "Generative Networks",
    "section": "Decoder summary",
    "text": "Decoder summary\n\ndecoder.summary()\n\nModel: \"sequential_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_5 (Dense)             (None, 400)               160400    \n                                                                 \n reshape_2 (Reshape)         (None, 20, 20, 1)         0         \n                                                                 \n conv2d_3 (Conv2D)           (None, 20, 20, 128)       1280      \n                                                                 \n up_sampling2d (UpSampling2  (None, 40, 40, 128)       0         \n D)                                                              \n                                                                 \n conv2d_4 (Conv2D)           (None, 40, 40, 64)        73792     \n                                                                 \n up_sampling2d_1 (UpSamplin  (None, 80, 80, 64)        0         \n g2D)                                                            \n                                                                 \n conv2d_5 (Conv2D)           (None, 80, 80, 1)         65        \n                                                                 \n lambda_3 (Lambda)           (None, 80, 80, 1)         0         \n                                                                 \n rescaling_5 (Rescaling)     (None, 80, 80, 1)         0         \n                                                                 \n=================================================================\nTotal params: 235537 (920.07 KB)\nTrainable params: 235537 (920.07 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\nmodel.evaluate(X_val, X_val, verbose=0)\n\n2022.39990234375"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#some-recovered-image-2",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#some-recovered-image-2",
    "title": "Generative Networks",
    "section": "Some recovered image",
    "text": "Some recovered image\n\nX_val_rec = model.predict(X_val, verbose=0)\n\n\n\n\nplt.imshow(X_val[42], cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nplt.imshow(X_val_rec[42], cmap=\"gray\");"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#latent-space-vs-word-embedding",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#latent-space-vs-word-embedding",
    "title": "Generative Networks",
    "section": "Latent space vs word embedding",
    "text": "Latent space vs word embedding\n\nWe revisit the concept of word embedding, where words in the vocabulary are mapped into vector representations. Words with similar meaning should lie close to one another in the word-embedding space.\nLatent space contains low-dimensional representation of data. Data/Images that are similar should lie close in the latent space.\nThere are pre-trained word-embedding spaces such as those for English-language movie review, German-language legal documents, etc. Semantic relationships between words differ for different tasks. Similarly, the structure of latent spaces for different data sets (humans faces, animals, etc) are different."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#latent-space-vs-word-embedding-1",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#latent-space-vs-word-embedding-1",
    "title": "Generative Networks",
    "section": "Latent space vs word embedding",
    "text": "Latent space vs word embedding\n\nGiven a latent space of representations, or an embedding space, certain directions in the space may encode interesting axes of variation in the original data.\nA concept vector is a direction of variation in the data. For example there may be a smile vector such that if z is the latent representation of a face, then z+s is the representation of the same face, smiling. We can generate an image of the person smiling from this latent representation."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#intentionally-add-noise-to-inputs",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#intentionally-add-noise-to-inputs",
    "title": "Generative Networks",
    "section": "Intentionally add noise to inputs",
    "text": "Intentionally add noise to inputs\n\n\n\nmask = rnd.random(size=X_train.shape[1:]) &lt; 0.5\nplt.imshow(mask * (255 - X_train[0]), cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nmask = rnd.random(size=X_train.shape[1:]) &lt; 0.5\nplt.imshow(mask * (255 - X_train[42]) * mask, cmap=\"gray\");"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#denoising-autoencoder",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#denoising-autoencoder",
    "title": "Generative Networks",
    "section": "Denoising autoencoder",
    "text": "Denoising autoencoder\nCan be used to do feature engineering for supervised learning problems\n\nIt is also possible to include input variables as outputs to infer missing values or just help the model “understand” the features – in fact the winning solution of a claims prediction Kaggle competition heavily used denoising autoencoders together with model stacking and ensembling – read more here.\n\nJacky Poon\n\nSource: Poon (2021), Multitasking Risk Pricing Using Deep Learning, Actuaries’ Analytical Cookbook."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#variational-autoencoder",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#variational-autoencoder",
    "title": "Generative Networks",
    "section": "Variational autoencoder",
    "text": "Variational autoencoder\n\nA slightly different sample from the distribution in the latent space will be decoded to a slightly different image. The stochasticity of this process improves robustness and forces the latent space to encode meaningful representation everywhere: every point in the latent space is decoded to a valid output. So the latent spaces of VAEs are continuous and highly-structured.\n\n\nSchematic of a variational autoencoder.\nSource: François Chollet (2021), Deep Learning with Python, Second Edition, Figure 12.17."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#vae-schematic-process",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#vae-schematic-process",
    "title": "Generative Networks",
    "section": "VAE schematic process",
    "text": "VAE schematic process\n\nKeras code for a VAE.\nSource: François Chollet (2021), Deep Learning with Python, Second Edition, Unnumbered listing in Chapter 12."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#focus-on-the-decoder",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#focus-on-the-decoder",
    "title": "Generative Networks",
    "section": "Focus on the decoder",
    "text": "Focus on the decoder\n\nSampling new artificial images from the latent space.\nSource: François Chollet (2021), Deep Learning with Python, Second Edition, Figure 12.13."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#exploring-the-mnist-latent-space",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#exploring-the-mnist-latent-space",
    "title": "Generative Networks",
    "section": "Exploring the MNIST latent space",
    "text": "Exploring the MNIST latent space\n\nExample of MNIST-like images generated from the latent space.\nSource: François Chollet (2021), Deep Learning with Python, Second Edition, Figure 12.18."
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#recommended-viewing",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#recommended-viewing",
    "title": "Generative Networks",
    "section": "Recommended Viewing",
    "text": "Recommended Viewing"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.slides.html#using-kerascv",
    "href": "Lecture-8-Generative-Networks/generative-networks.slides.html#using-kerascv",
    "title": "Generative Networks",
    "section": "Using KerasCV",
    "text": "Using KerasCV"
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html",
    "href": "Lecture-8-Generative-Networks/generative-networks.html",
    "title": "Generative Networks",
    "section": "",
    "text": "Text Generation\nImage Generation\nAutoencoders\nGenerative adversarial networks",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#lecture-outline",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#lecture-outline",
    "title": "Generative Networks",
    "section": "",
    "text": "Text Generation\nImage Generation\nAutoencoders\nGenerative adversarial networks",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#load-packages",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#load-packages",
    "title": "Generative Networks",
    "section": "Load packages",
    "text": "Load packages\n\nimport random\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport numpy.random as rnd\nimport pandas as pd\nimport keras\nfrom keras import layers\n\n\nfrom watermark import watermark\nprint(watermark(python=True, packages=\"sklearn,keras,torch,tensorflow\"))\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.21.0\n\nsklearn   : 1.4.0\nkeras     : 2.15.0\ntorch     : 2.0.1\ntensorflow: 2.15.0.post1",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#generative-deep-learning",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#generative-deep-learning",
    "title": "Generative Networks",
    "section": "Generative deep learning",
    "text": "Generative deep learning\n\nUsing AI as augmented intelligence rather than artificial intelligence.\nUse of deep learning to augment creative activities such as writing, music and art, to generate new things.\nSome applications: text generation, deep dreaming, neural style transfer, variational autoencoders and generative adversarial networks.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#text-generation-1",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#text-generation-1",
    "title": "Generative Networks",
    "section": "Text generation",
    "text": "Text generation\n\nGenerating sequential data is the closest computers get to dreaming.\n\n\nGenerate sequence data: Train a model to predict the next token or next few tokens in a sentence, using previous tokens as input.\nA network that models the probability of the next tokens given the previous ones is called a language model.\n\n\nGPT-3 is a 175 billion parameter text-generation model trained by the startup OpenAI on a large text corpus of digitally available books, Wikipedia and web crawling. GPT-3 made headlines in 2020 due to its capability to generate plausible-sounding text paragraphs on virtually any topic.\n\n\nSource: Alex Graves (2013), Generating Sequences With Recurrent Neural Networks",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#word-level-language-model",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#word-level-language-model",
    "title": "Generative Networks",
    "section": "Word-level language model",
    "text": "Word-level language model\n\n\n\nDiagram of a word-level language model.\n\n\n\nSource: Marcus Lautier (2022).\n\nThe way how word-level language models work is that, it first takes in the input text and then generates the probability distribution of the next word. This distribution tells us how likely a certain word is to be the next word. Thereafter, the model implements a appropriate sampling strategy to select the next word. Once the next word is predicted, it is appended to the input text and then passed in to the model again to predict the next word. The idea here is to predict the word after word.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#character-level-language-model",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#character-level-language-model",
    "title": "Generative Networks",
    "section": "Character-level language model",
    "text": "Character-level language model\n\n\n\nDiagram of a character-level language model (Char-RNN)\n\n\n\nSource: Tensorflow tutorial, Text generation with an RNN.\n\nCharacter-level language predtics the next character given a certain input character. They capture patterns at a much granular level and do not aim to capture semantics of words.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#useful-for-speech-recognition",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#useful-for-speech-recognition",
    "title": "Generative Networks",
    "section": "Useful for speech recognition",
    "text": "Useful for speech recognition\n\n\n\n\n\n\n\n\n\n\nRNN output\nDecoded Transcription\n\n\n\n\nwhat is the weather like in bostin right now\nwhat is the weather like in boston right now\n\n\nprime miniter nerenr modi\nprime minister narendra modi\n\n\narther n tickets for the game\nare there any tickets for the game\n\n\n\n\n\nFigure 1: Examples of transcriptions directly from the RNN with errors that are fixed by addition of a language model.\n\n\n\n\nSource: Hannun et al. (2014), Deep Speech: Scaling up end-to-end speech recognition, arXiv:1412.5567, Table 1.\n\nThe above example shows how RNN predictions (for sequential data processing) can be improved by fixing errors using a language model.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#generating-shakespeare-i",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#generating-shakespeare-i",
    "title": "Generative Networks",
    "section": "Generating Shakespeare I",
    "text": "Generating Shakespeare I\nThe following is an example how a language model trained on works of Shakespeare starts predicting words after we input a string. This is an example of a character-level prediction, where we aim to predict the most likely character, not the word.\n\nROMEO:\nWhy, sir, what think you, sir?\n\nAUTOLYCUS:\nA dozen; shall I be deceased.\nThe enemy is parting with your general,\nAs bias should still combit them offend\nThat Montague is as devotions that did satisfied;\nBut not they are put your pleasure.\n\n\nSource: Tensorflow tutorial, Text generation with an RNN.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#generating-shakespeare-ii",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#generating-shakespeare-ii",
    "title": "Generative Networks",
    "section": "Generating Shakespeare II",
    "text": "Generating Shakespeare II\n\nDUKE OF YORK:\nPeace, sing! do you must be all the law;\nAnd overmuting Mercutio slain;\nAnd stand betide that blows which wretched shame;\nWhich, I, that have been complaints me older hours.\n\nLUCENTIO:\nWhat, marry, may shame, the forish priest-lay estimest you, sir,\nWhom I will purchase with green limits o’ the commons’ ears!\n\n\nSource: Tensorflow tutorial, Text generation with an RNN.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#generating-shakespeare-iii",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#generating-shakespeare-iii",
    "title": "Generative Networks",
    "section": "Generating Shakespeare III",
    "text": "Generating Shakespeare III\n\nANTIGONUS:\nTo be by oath enjoin’d to this. Farewell!\nThe day frowns more and more: thou’rt like to have\nA lullaby too rough: I never saw\nThe heavens so dim by day. A savage clamour!\n\n[Exit, pursued by a bear]",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#softmax-temperature",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#softmax-temperature",
    "title": "Generative Networks",
    "section": "Softmax temperature",
    "text": "Softmax temperature\n\nThe softmax temperature is a parameter that controls the randomness of the next token.\nThe formula is:  \\text{softmax}_\\text{temperature}(x) = \\frac{\\exp(x / \\text{temperature})}{\\sum_i \\exp(x_i / \\text{temperature})}",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#i-am-a",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#i-am-a",
    "title": "Generative Networks",
    "section": "“I am a” …",
    "text": "“I am a” …\n\n\n\n\n\n\n\n\n\n\nIdea inspired by Mehta (2023), The need for sampling temperature and differences between whisper, GPT-3, and probabilistic model’s temperature\n\nThe graphical illustration above shows how the distribution of words change with different levels of Temp values. Higher levels of temperatures result in less predictable(more interesting) outcomes. If we continue to increase the Temp levels, after a certain point, outcomes will be picked completely at random. This predictions after this point might not be meaningful. Hence, attention to the trade-off between predictability and interestingness is important when deciding the Temp levels.\nThe following sections show how a neural network turned on the same dataset, and given the same starting input string In today’s lecture we will shall generate very different sequences of text as predictions. Temp=0.25 may give interesting outputs compared to Temp=0.01 and Temp=0.50 may give interesting outputs compared to Temp=0.25. However, when we keep on increasing Temp levels, the neural network starts giving out random(meaningless) outcomes.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#generating-laub-temp-0.01",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#generating-laub-temp-0.01",
    "title": "Generative Networks",
    "section": "Generating Laub (temp = 0.01)",
    "text": "Generating Laub (temp = 0.01)\n\nIn today’s lecture we will be different situation. So, next one is what they rective that each commit to be able to learn some relationships from the course, and that is part of the image that it’s very clese and black problems that you’re trying to fit the neural network to do there instead of like a specific though shef series of layers mean about full of the chosen the baseline of car was in the right, but that’s an important facts and it’s a very small summary with very scrort by the beginning of the sentence.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#generating-laub-temp-0.25",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#generating-laub-temp-0.25",
    "title": "Generative Networks",
    "section": "Generating Laub (temp = 0.25)",
    "text": "Generating Laub (temp = 0.25)\n\nIn today’s lecture we will decreas before model that we that we have to think about it, this mightsks better, for chattely the same project, because you might use the test set because it’s to be picked up the things that I wanted to heard of things that I like that even real you and you’re using the same thing again now because we need to understand what it’s doing the same thing but instead of putting it in particular week, and we can say that’s a thing I mainly link it’s three columns.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#generating-laub-temp-0.5",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#generating-laub-temp-0.5",
    "title": "Generative Networks",
    "section": "Generating Laub (temp = 0.5)",
    "text": "Generating Laub (temp = 0.5)\n\nIn today’s lecture we will probably the adw n wait lots of ngobs teulagedation to calculate the gradient and then I’ll be less than one layer the next slide will br input over and over the threshow you ampaigey the one that we want to apply them quickly. So, here this is the screen here the main top kecw onct three thing to told them, and the output is a vertical variables and Marceparase of things that you’re moving the blurring and that just data set is to maybe kind of categorical variants here but there’s more efficiently not basically replace that with respect to the best and be the same thing.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#generating-laub-temp-1",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#generating-laub-temp-1",
    "title": "Generative Networks",
    "section": "Generating Laub (temp = 1)",
    "text": "Generating Laub (temp = 1)\n\nIn today’s lecture we will put it different shates to touch on last week, so I want to ask what are you object frod current. They don’t have any zero into it, things like that which mistakes. 10 claims that the average version was relden distever ditgs and Python for the whole term wo long right to really. The name of these two options. There are in that seems to be modified version. If you look at when you’re putting numbers into your, that that’s over. And I went backwards, up, if they’rina functional pricing working with.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#generating-laub-temp-1.5",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#generating-laub-temp-1.5",
    "title": "Generative Networks",
    "section": "Generating Laub (temp = 1.5)",
    "text": "Generating Laub (temp = 1.5)\n\nIn today’s lecture we will put it could be bedinnth. Lowerstoriage nruron. So rochain the everything that I just sGiming. If there was a large. It’s gonua draltionation. Tow many, up, would that black and 53% that’s girter thankAty will get you jast typically stickK thing. But maybe. Anyway, I’m going to work on this libry two, past, at shit citcs jast pleming to memorize overcamples like pre pysing, why wareed to smart a one in this reportbryeccuriay.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#generate-the-most-likely-sequence",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#generate-the-most-likely-sequence",
    "title": "Generative Networks",
    "section": "Generate the most likely sequence",
    "text": "Generate the most likely sequence\nSimilar to other sequence generating tasks such as generating the next word or generating the next character, generating an entire sequence of words is also useful. The task involves generating the most likely sequence after observing model predictions.\n\n\n\nAn example sequence-to-sequence chatbot model.\n\n\n\nSource: Payne (2021), What is beam search, Width.ai blog.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#beam-search",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#beam-search",
    "title": "Generative Networks",
    "section": "Beam search",
    "text": "Beam search\nInstead of trying to carry forward only the highest probable prediction, beam search carries forward several high probable predictions, and then decide the highest probable combination of predictions. Beam search helps expand the exploration horizon for predictions which can contribute to more contextually relevant model predictions. However, this comes at a certain computational complexity.\n\n\n\nIllustration of a beam search.\n\n\n\nSource: Doshi (2021), Foundations of NLP Explained Visually: Beam Search, How It Works, towardsdatascience.com.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#transformer-architecture",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#transformer-architecture",
    "title": "Generative Networks",
    "section": "Transformer architecture",
    "text": "Transformer architecture\n\nGPT makes use of a mechanism known as attention, which removes the need for recurrent layers (e.g., LSTMs). It works like an information retrieval system, utilizing queries, keys, and values to decide how much information it wants to extract from each input token.\nAttention heads can be grouped together to form what is known as a multihead attention layer. These are then wrapped up inside a Transformer block, which includes layer normalization and skip connections around the attention layer. Transformer blocks can be stacked to create very deep neural networks.\n\n\nSource: David Foster (2023), Generative Deep Learning, 2nd Edition, O’Reilly Media, Chapter 9.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#transformer-architecture-reference",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#transformer-architecture-reference",
    "title": "Generative Networks",
    "section": "Transformer architecture reference",
    "text": "Transformer architecture reference",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#transformers-package",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#transformers-package",
    "title": "Generative Networks",
    "section": "🤗 Transformers package",
    "text": "🤗 Transformers package\nThe following code uses transformers library from Hugging Face to create a text generation pipeline using the GPT2 (Generative Pre-trained Transformer 2).\n\n1import transformers\n2from transformers import pipeline\n3generator = pipeline(task=\"text-generation\", model=\"gpt2\", revision=\"6c0e608\")\n\n\n1\n\nImports the transformers library\n\n2\n\nImports the class pipeline\n\n3\n\nCreates a pipeline object called the generator, whose task would be to generate text, using the pretrained model GPT2. revision=\"6c0e608\" specifies the specific revision of the model to refer\n\n\n\n\n/home/plaub/miniconda3/envs/ai2023/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n\n\n\n1transformers.set_seed(1)\n2print(generator(\"It's the holidays so I'm going to enjoy\")[0][\"generated_text\"])\n\n\n1\n\nSets the seed for reproducibility\n\n2\n\nApplies the generator object to generate a text based on the input It’s the holidays so I’m going to enjoy. The result from genrator would be a list of generated texts. To select the first output sequence hence, we pass the command [0][\"generated_text\"]\n\n\n\n\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n\n\nIt's the holidays so I'm going to enjoy playing in there.\"\n\nAdvertisement\n\nBut how many other holiday-goers would want to join his team?\n\n\n\"They wouldn't know if I would be there, not that I'm\n\n\nWe can try the same code with a different seed value, and it would give a very different output.\n\ntransformers.set_seed(1337)\nprint(generator(\"It's the holidays so I'm going to enjoy\")[0][\"generated_text\"])\n\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n\n\nIt's the holidays so I'm going to enjoy myself. I don't want to be a full-grown man when I get to get pregnant (if I didn't, I would never take it). I want to learn and find my own ways",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#reading-the-course-profile",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#reading-the-course-profile",
    "title": "Generative Networks",
    "section": "Reading the course profile",
    "text": "Reading the course profile\nAnother application of pipeline is the ability to generate texts in the answer format. The following is an example of how a pretrained model can be used to answer questions by relating it to a body of text information(context).\n\ncontext = \"\"\"\nStoryWall Formative Discussions: An initial StoryWall, worth 2%, is due by noon on June 3. The following StoryWalls are worth 4% each (taking the best 7 of 9) and are due at noon on the following dates:\nThe project will be submitted in stages: draft due at noon on July 1 (10%), recorded presentation due at noon on July 22 (15%), final report due at noon on August 1 (15%).\n\nAs a student at UNSW you are expected to display academic integrity in your work and interactions. Where a student breaches the UNSW Student Code with respect to academic integrity, the University may take disciplinary action under the Student Misconduct Procedure. To assure academic integrity, you may be required to demonstrate reasoning, research and the process of constructing work submitted for assessment.\nTo assist you in understanding what academic integrity means, and how to ensure that you do comply with the UNSW Student Code, it is strongly recommended that you complete the Working with Academic Integrity module before submitting your first assessment task. It is a free, online self-paced Moodle module that should take about one hour to complete.\n\nStoryWall (30%)\n\nThe StoryWall format will be used for small weekly questions. Each week of questions will be released on a Monday, and most of them will be due the following Monday at midday (see assessment table for exact dates). Students will upload their responses to the question sets, and give comments on another student's submission. Each week will be worth 4%, and the grading is pass/fail, with the best 7 of 9 being counted. The first week's basic 'introduction' StoryWall post is counted separately and is worth 2%.\n\nProject (40%)\n\nOver the term, students will complete an individual project. There will be a selection of deep learning topics to choose from (this will be outlined during Week 1).\n\nThe deliverables for the project will include: a draft/progress report mid-way through the term, a presentation (recorded), a final report including a written summary of the project and the relevant Python code (Jupyter notebook).\n\nExam (30%)\n\nThe exam will test the concepts presented in the lectures. For example, students will be expected to: provide definitions for various deep learning terminology, suggest neural network designs to solve risk and actuarial problems, give advice to mock deep learning engineers whose projects have hit common roadblocks, find/explain common bugs in deep learning Python code.\n\"\"\"",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#question-answering",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#question-answering",
    "title": "Generative Networks",
    "section": "Question answering",
    "text": "Question answering\n\n1qa = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", revision=\"626af31\")\n\n\n1\n\nCreates a question and answer style pipeline object by referring to the pretrained model pre-trained DistilBERT model (fine-tuned on the SQuAD: Stanford Question Answering Dataset) with revision 626af31\n\n\n\n\n\n1qa(question=\"What weight is the exam?\", context=context)\n\n\n1\n\nAnswers the questions What weight is the exam given the context specified\n\n\n\n\n{'score': 0.5019665956497192, 'start': 2092, 'end': 2095, 'answer': '30%'}\n\n\n\nqa(question=\"What topics are in the exam?\", context=context)\n\n{'score': 0.21276019513607025,\n 'start': 1778,\n 'end': 1791,\n 'answer': 'deep learning'}\n\n\n\nqa(question=\"When is the presentation due?\", context=context)\n\n{'score': 0.5296485424041748,\n 'start': 1319,\n 'end': 1335,\n 'answer': 'Monday at midday'}\n\n\n\nqa(question=\"How many StoryWall tasks are there?\", context=context)\n\n{'score': 0.2139102965593338, 'start': 1155, 'end': 1158, 'answer': '30%'}",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#chatgpt-is-transformer-rlhf",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#chatgpt-is-transformer-rlhf",
    "title": "Generative Networks",
    "section": "ChatGPT is Transformer + RLHF",
    "text": "ChatGPT is Transformer + RLHF\n\nAt the time of writing, there is no official paper that describes how ChatGPT works in detail, but from the official blog post we know that it uses a technique called reinforcement learning from human feedback (RLHF) to fine-tune the GPT-3.5 model.\n\n\nSource: David Foster (2023), Generative Deep Learning, 2nd Edition, O’Reilly Media, Chapter 9.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#chatgpt-internals",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#chatgpt-internals",
    "title": "Generative Networks",
    "section": "ChatGPT internals",
    "text": "ChatGPT internals\n\n\n\nIt uses a fair bit of human feedback\n\n\n\nSource: OpenAI blog.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#chatgpt",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#chatgpt",
    "title": "Generative Networks",
    "section": "ChatGPT",
    "text": "ChatGPT\n\nWhile ChatGPT still has many limitations (such as sometimes “hallucinating” factually incorrect information), it is a powerful example of how Transformers can be used to build generative models that can produce complex, long-ranging, and novel output that is often indistinguishable from human-generated text. The progress made thus far by models like ChatGPT serves as a testament to the potential of AI and its transformative impact on the world.\n\n\nSource: David Foster (2023), Generative Deep Learning, 2nd Edition, O’Reilly Media, Chapter 9.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#recommended-reading",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#recommended-reading",
    "title": "Generative Networks",
    "section": "Recommended reading",
    "text": "Recommended reading\n\nThe Verge (2022), The Great Fiction of AI: The strange world of high-speed semi-automated genre fiction\nVaswani et al. (2017), Attention Is All You Need, NeurIPS\nBommasani et al. (2021), On the Opportunities and Risks of Foundation Models\nGary Marcus (2022), Deep Learning Is Hitting a Wall, Nautilus article\nSDS 564, Clem Delangue on Hugging Face and Transformers\nSDS 559, GPT-3 for Natural Language Processing\nComputerphile (2019), AI Language Models & Transformers (20m)\nComputerphile (2020), GPT3: An Even Bigger Language Model (25m)\nNicholas Renotte (2021), AI Blog Post Summarization with Hugging Face Transformers… (33m)\nSeattle Applied Deep Learning (2019), LSTM is dead. Long Live Transformers! (28m)",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#reverse-engineering-a-cnn",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#reverse-engineering-a-cnn",
    "title": "Generative Networks",
    "section": "Reverse-engineering a CNN",
    "text": "Reverse-engineering a CNN\nReverse engineering is a process where we manipulate the inputs x while keeping the loss function and the model architecture the same. This is useful in understanding the inner workings of the model, especially when we do not have access to the model architecture or the original train dataset. The idea here is to tweak/distort the input feature data and observe how model predictions vary. This provides meaningful insights in to what patterns in the input data are most critical to making model predictions.\nThis task however requires computing the gradients of the model’s outputs with respect to all input features, hence, can be time consuming.\nA CNN is a function f_{\\boldsymbol{\\theta}}(\\mathbf{x}) that takes a vector (image) \\mathbf{x} and returns a vector (distribution) \\widehat{\\mathbf{y}}.\nNormally, we train it by modifying \\boldsymbol{\\theta} so that\n \\boldsymbol{\\theta}^*\\ =\\  \\underset{\\boldsymbol{\\theta}}{\\mathrm{argmin}} \\,\\, \\text{Loss} \\bigl( f_{\\boldsymbol{\\theta}}(\\mathbf{x}), \\mathbf{y} \\bigr). \nHowever, it is possible to not train the network but to modify \\mathbf{x}, like\n \\mathbf{x}^*\\ =\\  \\underset{\\mathbf{x}}{\\mathrm{argmin}} \\,\\, \\text{Loss} \\bigl( f_{\\boldsymbol{\\theta}}(\\mathbf{x}), \\mathbf{y} \\bigr). \nThis is very slow as we do gradient descent every single time.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#adversarial-examples",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#adversarial-examples",
    "title": "Generative Networks",
    "section": "Adversarial examples",
    "text": "Adversarial examples\nAn adversarial attack refers to a small carefully created modifications to the input data that aims to trick the model in to making wrong predictions while keeping the y_true same. The goal is to identify instances where subtle modifications in the input data (which are not instantaneously recognized) can lead to erroneous model predictions.\n\n\n\nA demonstration of fast adversarial example generation applied to GoogLeNet on ImageNet. By adding an imperceptibly small vector whose elements are equal to the sign of the elements of the gradient of the cost function with respect to the input, we can change GoogLeNet’s classification of the image.\n\n\n\nSource: Goodfellow et al. (2015), Explaining and Harnessing Adversarial Examples, ICLR.\n\nThe above example shows how a small perturbation to the image of a panda led to the model predicting the image as a gibbon with high confidence. This indicates that there may be certain patterns in the data which are not clearly seen by the human eye, but the model is relying on them to make predictions. Identifying these sensitivities/vulnerabilities are important to understand how a model is making its predictions.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#adversarial-stickers",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#adversarial-stickers",
    "title": "Generative Networks",
    "section": "Adversarial stickers",
    "text": "Adversarial stickers\n\n\n\nAdversarial stickers.\n\n\n\nSource: The Verge (2018), These stickers make computer vision software hallucinate things that aren’t there.\n\nThe above graphical illustration shows how adding a metal component changes the model predictions from Banana to toaster with high confidence.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#adversarial-text",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#adversarial-text",
    "title": "Generative Networks",
    "section": "Adversarial text",
    "text": "Adversarial text\nAdversarial attacks on text generation models help users get an understanding of the inner workings NLP models. This includes identifying input patterns that are critical to model predictions, and assessing performance of NLP models for robustness.\n“TextAttack 🐙 is a Python framework for adversarial attacks, data augmentation, and model training in NLP”\n\n\n\nDemo",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#deep-dream",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#deep-dream",
    "title": "Generative Networks",
    "section": "Deep Dream",
    "text": "Deep Dream\n\n\n\nDeep Dream is an image-modification program released by Google in 2015.\n\n\n\nSource: Wikipedia, DeepDream page.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#deepdream",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#deepdream",
    "title": "Generative Networks",
    "section": "DeepDream",
    "text": "DeepDream\n\nEven though many deep learning models are black boxes, convnets are quite interpretable via visualization. Some visualization techniques are: visualizing convnet outputs shows how convnet layers transform the input, visualizing convnet filters shows what visual patterns or concept each filter is receptive to, etc.\nThe activations of the first few layers of the network carries more information about the visual contents, while deeper layers encode higher, more abstract concepts.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#deepdream-1",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#deepdream-1",
    "title": "Generative Networks",
    "section": "DeepDream",
    "text": "DeepDream\n\nEach filter is receptive to a visual pattern. To visualize a convnet filter, gradient ascent is used to maximize the response of the filter. Gradient ascent maximize a loss function and moves the image in a direction that activate the filter more strongly to enhance its reading of the visual pattern.\nDeepDream maximizes the activation of the entire convnet layer rather than that of a specific filter, thus mixing together many visual patterns all at once.\nDeepDream starts with an existing image, latches on to preexisting visual patterns, distorting elements of the image in a somewhat artistic fashion.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#original",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#original",
    "title": "Generative Networks",
    "section": "Original",
    "text": "Original\n\n\n\nA sunny day on the Mornington peninsula.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#transformed",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#transformed",
    "title": "Generative Networks",
    "section": "Transformed",
    "text": "Transformed\n\n\n\nDeep-dreaming version.\n\n\n\nGenerated by Keras’ Deep Dream tutorial.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#goal-of-nst",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#goal-of-nst",
    "title": "Generative Networks",
    "section": "Goal of NST",
    "text": "Goal of NST\nWhat the model does:\n\nPreserve content by maintaining similar deeper layer activations between the original image and the generated image. The convnet should “see” both the original image and the generated image as containing the same things.\nPreserve style by maintaining similar correlations within activations for both low level layers and high-level layers. Feature correlations within a layer capture textures: the generated image and the style-reference image should share the same textures at different spatial scales.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#a-wanderer-in-greenland",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#a-wanderer-in-greenland",
    "title": "Generative Networks",
    "section": "A wanderer in Greenland",
    "text": "A wanderer in Greenland\n\n\nContent\n\n\n\nSome striking young hiker in Greenland.\n\n\n\nStyle\n\n\n\nWanderer above the Sea of Fog by Caspar David Friedrich.\n\n\n\n\n\nSource: Laub (2018), On Neural Style Transfer, Blog post.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#a-wanderer-in-greenland-ii",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#a-wanderer-in-greenland-ii",
    "title": "Generative Networks",
    "section": "A wanderer in Greenland II",
    "text": "A wanderer in Greenland II\n\n\n\n\n\nAnimation of NST in progress.\n\n\n\n\n\n\nOne result of NST.\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow would you make this faster for one specific style image?\n\n\n\nSource: Laub (2018), On Neural Style Transfer, Blog post.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#a-new-style-image",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#a-new-style-image",
    "title": "Generative Networks",
    "section": "A new style image",
    "text": "A new style image\n\n\n\nHokusai’s Great Wave off Kanagawa\n\n\n\nSource: Laub (2018), On Neural Style Transfer, Blog post.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#a-new-content-image",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#a-new-content-image",
    "title": "Generative Networks",
    "section": "A new content image",
    "text": "A new content image\n\n\n\nThe seascape in Qingdao\n\n\n\nSource: Laub (2018), On Neural Style Transfer, Blog post.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#another-neural-style-transfer",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#another-neural-style-transfer",
    "title": "Generative Networks",
    "section": "Another neural style transfer",
    "text": "Another neural style transfer\n\n\n\nThe seascape in Qingdao in the style of Hokusai’s Great Wave off Kanagawa\n\n\n\nSource: Laub (2018), On Neural Style Transfer, Blog post.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#why-is-this-important",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#why-is-this-important",
    "title": "Generative Networks",
    "section": "Why is this important?",
    "text": "Why is this important?\nTaking derivatives with respect to the input image can be a first step toward explainable AI for convolutional networks.\n\nSaliency maps\nGrad-CAM",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#autoencoder",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#autoencoder",
    "title": "Generative Networks",
    "section": "Autoencoder",
    "text": "Autoencoder\nAn autoencoder takes a data/image, maps it to a latent space via an encoder module, then decodes it back to an output with the same dimensions via a decoder module.\nThey are useful in learning latent representations of the data.\n\n\n\nSchematic of an autoencoder.\n\n\n\nSource: Marcus Lautier (2022).",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#autoencoder-ii",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#autoencoder-ii",
    "title": "Generative Networks",
    "section": "Autoencoder II",
    "text": "Autoencoder II\n\nAn autoencoder is trained by using the same image as both the input and the target, meaning an autoencoder learns to reconstruct the original inputs. Therefore it’s not supervised learning, but self-supervised learning.\nIf we impose constraints on the encoders to be low-dimensional and sparse, the input data will be compressed into fewer bits of information.\nLatent space is a place that stores low-dimensional representation of data. It can be used for data compression, where data is compressed to a point in a latent space.\nAn image can be compressed into a latent representation, which can then be reconstructed back to a slightly different image.\n\n\nFor image editing, an image can be projected onto a latent space and moved inside the latent space in a meaningful way (which means we modify its latent representation), before being mapped back to the image space. This will edit the image and allow us to generate images that have never been seen before.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#example-psam",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#example-psam",
    "title": "Generative Networks",
    "section": "Example: PSAM",
    "text": "Example: PSAM\nLoading the dataset off-screen (using Lecture 6 code).\n\n\n\nplt.imshow(X_train[0], cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nplt.imshow(X_train[42], cmap=\"gray\");",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#a-compression-game",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#a-compression-game",
    "title": "Generative Networks",
    "section": "A compression game",
    "text": "A compression game\nEncoding is the overall process of compressing an input with containing data in a high dimensional space to a low dimension space. Compressing is the action of identifying necessary information in the data (versus redundant data) and representing the input in a more concise form. The following slides show two different ways of representing the same data. The second representation is more concise (and smarter) than the first.\n\n\n\nplt.imshow(X_train[42], cmap=\"gray\");\nprint(img_width * img_height)\n\n6400\n\n\n\n\n\n\n\n\n\n\n\nA 4 with a curly foot, a flat line goes across the middle of the 4, two feet come off the bottom.\n\n96 characters\n\nA Dōng character, rotated counterclockwise 15 degrees.\n\n54 characters",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#make-a-basic-autoencoder",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#make-a-basic-autoencoder",
    "title": "Generative Networks",
    "section": "Make a basic autoencoder",
    "text": "Make a basic autoencoder\nThe following code is an example of constructing a basic autoencoder. The high-level idea here is to take an image, compress the information of the image from 6400 pixels to 400 pixels (encoding stage) and decode it back to the original image size (decoding stage). Note that we train the neural network keeping the input and the output the same.\n\nnum_hidden_layer = 400\nprint(f\"Compress from {img_height * img_width} pixels to {num_hidden_layer} latent variables.\")\n\nCompress from 6400 pixels to 400 latent variables.\n\n\n\n1random.seed(123)\n\nmodel = keras.models.Sequential([\n    layers.Input((img_height, img_width, 1)),\n2    layers.Rescaling(1./255),\n3    layers.Flatten(),\n4    layers.Dense(num_hidden_layer, \"relu\"),\n5    layers.Dense(img_height*img_width, \"sigmoid\"),\n6    layers.Reshape((img_height, img_width, 1)),\n7    layers.Rescaling(255),\n])\n\n8model.compile(\"adam\", \"mse\")\n9epochs = 1_000\nes = keras.callbacks.EarlyStopping(\n10    patience=5, restore_best_weights=True)\nmodel.fit(X_train, X_train, epochs=epochs, verbose=0,\n11    validation_data=(X_val, X_val), callbacks=es);\n\n\n1\n\nSets the random seed for reproducibility\n\n2\n\nScales the image input by the number of pixels so that the input is scaled to [0,1] range\n\n3\n\nReshapes the 2D input into a 1D representation\n\n4\n\nCondenses the information from 6400 variables to 400 latent variables (the encoding stage ends here)\n\n5\n\nConvers the condensed representation from 400 to 6400 again. Note that the sigmoid activation is used to ensure output is between [0,1]\n\n6\n\nReshapes the 1D representation to a 2D array\n\n7\n\nRescales the input information back to the actual input scaling by multiplying with 255 (this completes the decoding stage, and now the input is in its original shape)\n\n8\n\nCompiles the model with the loss function and the optimizer\n\n9\n\nSpecifies the number of epochs to run the algorithm\n\n10\n\nSpecifies the early stopping criteria. Here, the early stopping activates after 5 iterations with no improvement in the validation loss\n\n11\n\nFits the model specifying the train set, validation set, the number of epochs to run, and the early stopping criteria.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#the-model",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#the-model",
    "title": "Generative Networks",
    "section": "The model",
    "text": "The model\n\nmodel.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n rescaling (Rescaling)       (None, 80, 80, 1)         0         \n                                                                 \n flatten (Flatten)           (None, 6400)              0         \n                                                                 \n dense (Dense)               (None, 400)               2560400   \n                                                                 \n dense_1 (Dense)             (None, 6400)              2566400   \n                                                                 \n reshape (Reshape)           (None, 80, 80, 1)         0         \n                                                                 \n rescaling_1 (Rescaling)     (None, 80, 80, 1)         0         \n                                                                 \n=================================================================\nTotal params: 5126800 (19.56 MB)\nTrainable params: 5126800 (19.56 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\nmodel.evaluate(X_val, X_val, verbose=0)\n\n2263.939453125",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#some-recovered-image",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#some-recovered-image",
    "title": "Generative Networks",
    "section": "Some recovered image",
    "text": "Some recovered image\n\nX_val_rec = model.predict(X_val, verbose=0)\n\n\n\n\nplt.imshow(X_val[42], cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nplt.imshow(X_val_rec[42], cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nThe recovered image is not as sharp as the original image, however, we can see that the high-level representation of the original picture is reconstrcuted.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#invert-the-images",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#invert-the-images",
    "title": "Generative Networks",
    "section": "Invert the images",
    "text": "Invert the images\nAnother way to attempt the autoencoder would be to invert the colours of the image. Following example shows, how the colours in the images are swapped. The areas which were previously in white are now in black and vice versa. The motivation behind inverting the colours is to make the input more suited for the relu activation. relu returns zeros, and zero corresponds to the black colour. If the image has more black colour, there is a chance the neural network might train more efficiently. Hence we try inverting the colours as a preprocessing before we pass it through the encoding stage.\n\n\n\nplt.imshow(255 - X_train[0], cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nplt.imshow(255 - X_train[42], cmap=\"gray\");",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#try-inverting-the-images",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#try-inverting-the-images",
    "title": "Generative Networks",
    "section": "Try inverting the images",
    "text": "Try inverting the images\nFollowing code shows how the same code as before is implemented, but with an additional step for inverting the pixel values of the data before parsing it through the encoding step.\n\nrandom.seed(123)\n\nmodel = keras.models.Sequential([\n    layers.Input((img_height, img_width, 1)),\n    layers.Rescaling(1./255),\n1    layers.Lambda(lambda x: 1 - x),\n    layers.Flatten(),\n    layers.Dense(num_hidden_layer, \"relu\"),\n    layers.Dense(img_height*img_width, \"sigmoid\"),\n2    layers.Lambda(lambda x: 1 - x),\n    layers.Reshape((img_height, img_width, 1)),\n    layers.Rescaling(255),\n])\n\nmodel.compile(\"adam\", \"mse\")\nmodel.fit(X_train, X_train, epochs=epochs, verbose=0,\n    validation_data=(X_val, X_val), callbacks=es);\n\n\n1\n\nInverts the colours by mapping the function with x: 1-x\n\n2\n\nReverses the inversion to make sure the same input image is reconstructed",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#the-model-1",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#the-model-1",
    "title": "Generative Networks",
    "section": "The model",
    "text": "The model\n\nmodel.summary()\n\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n rescaling_2 (Rescaling)     (None, 80, 80, 1)         0         \n                                                                 \n lambda (Lambda)             (None, 80, 80, 1)         0         \n                                                                 \n flatten_1 (Flatten)         (None, 6400)              0         \n                                                                 \n dense_2 (Dense)             (None, 400)               2560400   \n                                                                 \n dense_3 (Dense)             (None, 6400)              2566400   \n                                                                 \n lambda_1 (Lambda)           (None, 6400)              0         \n                                                                 \n reshape_1 (Reshape)         (None, 80, 80, 1)         0         \n                                                                 \n rescaling_3 (Rescaling)     (None, 80, 80, 1)         0         \n                                                                 \n=================================================================\nTotal params: 5126800 (19.56 MB)\nTrainable params: 5126800 (19.56 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\nmodel.evaluate(X_val, X_val, verbose=0)\n\n2382.336669921875",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#some-recovered-image-1",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#some-recovered-image-1",
    "title": "Generative Networks",
    "section": "Some recovered image",
    "text": "Some recovered image\n\nX_val_rec = model.predict(X_val, verbose=0)\n\n\n\n\nplt.imshow(X_val[42], cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nplt.imshow(X_val_rec[42], cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nThe recovered image is not too different to the image from the previous example.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#cnn-enhanced-encoder",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#cnn-enhanced-encoder",
    "title": "Generative Networks",
    "section": "CNN-enhanced encoder",
    "text": "CNN-enhanced encoder\nTo further improve the process, we can try neural networks specialized for image processing. Here we use a Convolutional Neural Network lith convolutional and pooling layers. The following example shows how we first specify the encoder, and then the decoder. The two architectures are combined at the final stage.\n\n1random.seed(123)\n\n2encoder = keras.models.Sequential([\n    layers.Input((img_height, img_width, 1)),\n3    layers.Rescaling(1./255),\n4    layers.Lambda(lambda x: 1 - x),\n5    layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n6    layers.MaxPooling2D(),\n7    layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n    layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dense(num_hidden_layer, \"relu\")\n])\n\n\n1\n\nSets the random seed for reproducibility\n\n2\n\nStarts specifying the encoder\n\n3\n\nRescales the image pixel values to range between [0,1]\n\n4\n\nInverts the colours of the image\n\n5\n\nApplies a 2D convolutional layer with 16 filters, each of size 3 \\times 3, and having the same padding. same padding ensures that the output from the layer has the same heigh and width as the input\n\n6\n\nPerforms max-pooling to reduce the dimension of the feature space\n\n7\n\nCNN-enhanced decoder\n\n\n\n\n\ndecoder = keras.models.Sequential([\n    keras.Input(shape=(num_hidden_layer,)),\n    layers.Dense(20*20),\n    layers.Reshape((20, 20, 1)),\n    layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n    layers.UpSampling2D(),\n    layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n    layers.UpSampling2D(),\n    layers.Conv2D(1, 1, padding=\"same\", activation=\"relu\"),\n    layers.Lambda(lambda x: 1 - x),\n    layers.Rescaling(255),\n])\n\nmodel = keras.models.Sequential([encoder, decoder])\nmodel.compile(\"adam\", \"mse\")\nmodel.fit(X_train, X_train, epochs=epochs, verbose=0,\n    validation_data=(X_val, X_val), callbacks=es);",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#encoder-summary",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#encoder-summary",
    "title": "Generative Networks",
    "section": "Encoder summary",
    "text": "Encoder summary\n\nencoder.summary()\n\nModel: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n rescaling_4 (Rescaling)     (None, 80, 80, 1)         0         \n                                                                 \n lambda_2 (Lambda)           (None, 80, 80, 1)         0         \n                                                                 \n conv2d (Conv2D)             (None, 80, 80, 16)        160       \n                                                                 \n max_pooling2d (MaxPooling2  (None, 40, 40, 16)        0         \n D)                                                              \n                                                                 \n conv2d_1 (Conv2D)           (None, 40, 40, 32)        4640      \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 20, 20, 32)        0         \n g2D)                                                            \n                                                                 \n conv2d_2 (Conv2D)           (None, 20, 20, 64)        18496     \n                                                                 \n max_pooling2d_2 (MaxPoolin  (None, 10, 10, 64)        0         \n g2D)                                                            \n                                                                 \n flatten_2 (Flatten)         (None, 6400)              0         \n                                                                 \n dense_4 (Dense)             (None, 400)               2560400   \n                                                                 \n=================================================================\nTotal params: 2583696 (9.86 MB)\nTrainable params: 2583696 (9.86 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#decoder-summary",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#decoder-summary",
    "title": "Generative Networks",
    "section": "Decoder summary",
    "text": "Decoder summary\n\ndecoder.summary()\n\nModel: \"sequential_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_5 (Dense)             (None, 400)               160400    \n                                                                 \n reshape_2 (Reshape)         (None, 20, 20, 1)         0         \n                                                                 \n conv2d_3 (Conv2D)           (None, 20, 20, 128)       1280      \n                                                                 \n up_sampling2d (UpSampling2  (None, 40, 40, 128)       0         \n D)                                                              \n                                                                 \n conv2d_4 (Conv2D)           (None, 40, 40, 64)        73792     \n                                                                 \n up_sampling2d_1 (UpSamplin  (None, 80, 80, 64)        0         \n g2D)                                                            \n                                                                 \n conv2d_5 (Conv2D)           (None, 80, 80, 1)         65        \n                                                                 \n lambda_3 (Lambda)           (None, 80, 80, 1)         0         \n                                                                 \n rescaling_5 (Rescaling)     (None, 80, 80, 1)         0         \n                                                                 \n=================================================================\nTotal params: 235537 (920.07 KB)\nTrainable params: 235537 (920.07 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\nmodel.evaluate(X_val, X_val, verbose=0)\n\n2022.39990234375",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#some-recovered-image-2",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#some-recovered-image-2",
    "title": "Generative Networks",
    "section": "Some recovered image",
    "text": "Some recovered image\n\nX_val_rec = model.predict(X_val, verbose=0)\n\n\n\n\nplt.imshow(X_val[42], cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nplt.imshow(X_val_rec[42], cmap=\"gray\");",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#latent-space-vs-word-embedding",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#latent-space-vs-word-embedding",
    "title": "Generative Networks",
    "section": "Latent space vs word embedding",
    "text": "Latent space vs word embedding\n\nWe revisit the concept of word embedding, where words in the vocabulary are mapped into vector representations. Words with similar meaning should lie close to one another in the word-embedding space.\nLatent space contains low-dimensional representation of data. Data/Images that are similar should lie close in the latent space.\nThere are pre-trained word-embedding spaces such as those for English-language movie review, German-language legal documents, etc. Semantic relationships between words differ for different tasks. Similarly, the structure of latent spaces for different data sets (humans faces, animals, etc) are different.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#latent-space-vs-word-embedding-1",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#latent-space-vs-word-embedding-1",
    "title": "Generative Networks",
    "section": "Latent space vs word embedding",
    "text": "Latent space vs word embedding\n\nGiven a latent space of representations, or an embedding space, certain directions in the space may encode interesting axes of variation in the original data.\nA concept vector is a direction of variation in the data. For example there may be a smile vector such that if z is the latent representation of a face, then z+s is the representation of the same face, smiling. We can generate an image of the person smiling from this latent representation.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#intentionally-add-noise-to-inputs",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#intentionally-add-noise-to-inputs",
    "title": "Generative Networks",
    "section": "Intentionally add noise to inputs",
    "text": "Intentionally add noise to inputs\n\n\n\nmask = rnd.random(size=X_train.shape[1:]) &lt; 0.5\nplt.imshow(mask * (255 - X_train[0]), cmap=\"gray\");\n\n\n\n\n\n\n\n\n\n\nmask = rnd.random(size=X_train.shape[1:]) &lt; 0.5\nplt.imshow(mask * (255 - X_train[42]) * mask, cmap=\"gray\");",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#denoising-autoencoder",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#denoising-autoencoder",
    "title": "Generative Networks",
    "section": "Denoising autoencoder",
    "text": "Denoising autoencoder\nCan be used to do feature engineering for supervised learning problems\n\nIt is also possible to include input variables as outputs to infer missing values or just help the model “understand” the features – in fact the winning solution of a claims prediction Kaggle competition heavily used denoising autoencoders together with model stacking and ensembling – read more here.\n\nJacky Poon\n\nSource: Poon (2021), Multitasking Risk Pricing Using Deep Learning, Actuaries’ Analytical Cookbook.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#variational-autoencoder",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#variational-autoencoder",
    "title": "Generative Networks",
    "section": "Variational autoencoder",
    "text": "Variational autoencoder\n\nA slightly different sample from the distribution in the latent space will be decoded to a slightly different image. The stochasticity of this process improves robustness and forces the latent space to encode meaningful representation everywhere: every point in the latent space is decoded to a valid output. So the latent spaces of VAEs are continuous and highly-structured.\n\n\n\n\nSchematic of a variational autoencoder.\n\n\n\nSource: François Chollet (2021), Deep Learning with Python, Second Edition, Figure 12.17.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#vae-schematic-process",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#vae-schematic-process",
    "title": "Generative Networks",
    "section": "VAE schematic process",
    "text": "VAE schematic process\n\n\n\nKeras code for a VAE.\n\n\n\nSource: François Chollet (2021), Deep Learning with Python, Second Edition, Unnumbered listing in Chapter 12.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#focus-on-the-decoder",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#focus-on-the-decoder",
    "title": "Generative Networks",
    "section": "Focus on the decoder",
    "text": "Focus on the decoder\n\n\n\nSampling new artificial images from the latent space.\n\n\n\nSource: François Chollet (2021), Deep Learning with Python, Second Edition, Figure 12.13.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#exploring-the-mnist-latent-space",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#exploring-the-mnist-latent-space",
    "title": "Generative Networks",
    "section": "Exploring the MNIST latent space",
    "text": "Exploring the MNIST latent space\n\n\n\nExample of MNIST-like images generated from the latent space.\n\n\n\nSource: François Chollet (2021), Deep Learning with Python, Second Edition, Figure 12.18.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#recommended-viewing",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#recommended-viewing",
    "title": "Generative Networks",
    "section": "Recommended Viewing",
    "text": "Recommended Viewing\n\nBoth autoencoders and variational autoencoders aim to obtain latent representations of input data that carry same information but in a lower dimensional space. The difference between the two is that, autoencoders outputs the latent representations as vectors, while variational auto encoders first identifies the distribution of the input in the latent space, and then sample an observation from that as the vector. Autoencoders are better suited for dimensionality reduction and feature learning tasks. Variation autoencoders are better suited for generative modelling tasks and uncertainty estimation.",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-8-Generative-Networks/generative-networks.html#using-kerascv",
    "href": "Lecture-8-Generative-Networks/generative-networks.html#using-kerascv",
    "title": "Generative Networks",
    "section": "Using KerasCV",
    "text": "Using KerasCV",
    "crumbs": [
      "Module 8",
      "Generative Networks"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#interpretability-and-trust",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#interpretability-and-trust",
    "title": "Interpretability",
    "section": "Interpretability and Trust",
    "text": "Interpretability and Trust\nSuppose a neural network informs us to increase the premium for Bob.\n\nWhy are we getting such a conclusion from the neural network, and should we trust it?\nHow can we explain our pricing scheme to Bob and the regulators?\nShould we be concerned with moral hazards, discrimination, unfairness, and ethical affairs?\n\nWe need to trust the model to employ it! With interpretability, we can trust it!"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#interpretability-1",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#interpretability-1",
    "title": "Interpretability",
    "section": "Interpretability",
    "text": "Interpretability\n\nInterpretability Definition\n\nInterpretability refers to the ease with which one can understand and comprehend the model’s algorithm and predictions.\n\n\nInterpretability of black-box models can be crucial to ascertaining trust."
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#first-dimension-of-interpretability",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#first-dimension-of-interpretability",
    "title": "Interpretability",
    "section": "First Dimension of Interpretability",
    "text": "First Dimension of Interpretability\n\nInherent Interpretability\n\nThe model is interpretable by design.\n\n\n\nPost-hoc Interpretability\n\nThe model is not interpretable by design, but we can use other methods to explain the model."
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#second-dimension-of-interpretability",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#second-dimension-of-interpretability",
    "title": "Interpretability",
    "section": "Second Dimension of Interpretability",
    "text": "Second Dimension of Interpretability\nGlobal Interpretability:\n\nThe ability to understand how the model works.\nExample: how each feature impacts the overall mean prediction.\n\nLocal Interpretability:\n\nThe ability to interpret/understand each prediction.\nExample: how Bob’s mean prediction has increased the most."
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#trees-are-interpretable",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#trees-are-interpretable",
    "title": "Interpretability",
    "section": "Trees are interpretable!",
    "text": "Trees are interpretable!\n\nTrain prices"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#trees-are-interpretable-1",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#trees-are-interpretable-1",
    "title": "Interpretability",
    "section": "Trees are interpretable?",
    "text": "Trees are interpretable?\n\nFull train pricing"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#linear-models",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#linear-models",
    "title": "Interpretability",
    "section": "Linear models",
    "text": "Linear models\nA GLM has the form\n\n\\hat{y} = g^{-1}\\bigl( \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p \\bigr)\n\nwhere \\beta_0, \\dots, \\beta_p are the model parameters.\nGlobal & local interpretations are easy to obtain."
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#localglmnet",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#localglmnet",
    "title": "Interpretability",
    "section": "LocalGLMNet",
    "text": "LocalGLMNet\nImagine: \n\\hat{y_i} = g^{-1}\\bigl( \\beta_0(\\boldsymbol{x}_i) + \\beta_1(\\boldsymbol{x}_i) x_{i1} + \\dots + \\beta_p(\\boldsymbol{x}_i) x_{ip} \\bigr)\n\nA GLM with local parameters \\beta_0(\\boldsymbol{x}_i), \\dots, \\beta_p(\\boldsymbol{x}_i) for each observation \\boldsymbol{x}_i.\nThe local parameters are the output of a neural network."
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#permutation-importance",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#permutation-importance",
    "title": "Interpretability",
    "section": "Permutation importance",
    "text": "Permutation importance\n\nInputs: fitted model m, tabular dataset D.\nCompute the reference score s of the model m on data D (for instance the accuracy for a classifier or the R^2 for a regressor).\nFor each feature j (column of D):\n\nFor each repetition k in {1, \\dots, K}:\n\nRandomly shuffle column j of dataset D to generate a corrupted version of the data named \\tilde{D}_{k,j}.\nCompute the score s_{k,j} of model m on corrupted data \\tilde{D}_{k,j}.\n\nCompute importance i_j for feature f_j defined as:\n i_j = s - \\frac{1}{K} \\sum_{k=1}^{K} s_{k,j} \n\n\n\nSource: scikit-learn documentation, permutation_importance function."
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#permutation-importance-1",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#permutation-importance-1",
    "title": "Interpretability",
    "section": "Permutation importance",
    "text": "Permutation importance\n\ndef permutation_test(model, X, y, num_reps=1, seed=42):\n    \"\"\"\n    Run the permutation test for variable importance.\n    Returns matrix of shape (X.shape[1], len(model.evaluate(X, y))).\n    \"\"\"\n    rnd.seed(seed)\n    scores = []    \n\n    for j in range(X.shape[1]):\n        original_column = np.copy(X[:, j])\n        col_scores = []\n\n        for r in range(num_reps):\n            rnd.shuffle(X[:,j])\n            col_scores.append(model.evaluate(X, y, verbose=0))\n\n        scores.append(np.mean(col_scores, axis=0))\n        X[:,j] = original_column\n    \n    return np.array(scores)"
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#lime",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#lime",
    "title": "Interpretability",
    "section": "LIME",
    "text": "LIME\nLocal Interpretable Model-agnostic Explanations employs an interpretable surrogate model to explain locally how the black-box model makes predictions for individual instances.\nE.g. a black-box model predicts Bob’s premium as the highest among all policyholders. LIME uses an interpretable model (a linear regression) to explain how Bob’s features influence the black-box model’s prediction.\n\nCf. “Why Should I Trust You?”: Explaining the Predictions of Any Classifier."
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#globally-vs.-locally-faithful",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#globally-vs.-locally-faithful",
    "title": "Interpretability",
    "section": "Globally vs. Locally Faithful",
    "text": "Globally vs. Locally Faithful\n\nGlobally Faithful\n\nThe interpretable model’s explanations accurately reflect the behaviour of the black-box model across the entire input space.\n\nLocally Faithful\n\nThe interpretable model’s explanations accurately reflect the behaviour of the black-box model for a specific instance.\n\n\nLIME aims to construct an interpretable model that mimics the black-box model’s behaviour in a locally faithful manner."
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#lime-algorithm",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#lime-algorithm",
    "title": "Interpretability",
    "section": "LIME Algorithm",
    "text": "LIME Algorithm\nSuppose we want to explain the instance \\boldsymbol{x}_{\\text{Bob}}=(1, 2, 0.5).\n\nGenerate perturbed examples of \\boldsymbol{x}_{\\text{Bob}} and use the trained gamma MDN f to make predictions: \n\\begin{align*}\n  \\boldsymbol{x}^{'(1)}_{\\text{Bob}} &= (1.1, 1.9, 0.6), \\quad f\\big(\\boldsymbol{x}^{'(1)}_{\\text{Bob}}\\big)=34000 \\\\\n  \\boldsymbol{x}^{'(2)}_{\\text{Bob}} &= (0.8, 2.1, 0.4), \\quad f\\big(\\boldsymbol{x}^{'(2)}_{\\text{Bob}}\\big)=31000 \\\\\n  &\\vdots \\quad \\quad \\quad \\quad\\quad \\quad\\quad \\quad\\quad \\quad \\quad \\vdots\n\\end{align*} We can then construct a dataset of N_{\\text{Examples}} perturbed examples: \\mathcal{D}_{\\text{LIME}} = \\big(\\big\\{\\boldsymbol{x}^{'(i)}_{\\text{Bob}},f\\big(\\boldsymbol{x}^{'(i)}_{\\text{Bob}}\\big)\\big\\}\\big)_{i=0}^{N_{\\text{Examples}}}."
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#lime-algorithm-1",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#lime-algorithm-1",
    "title": "Interpretability",
    "section": "LIME Algorithm",
    "text": "LIME Algorithm\n\nFit an interpretable model g, i.e., a linear regression using \\mathcal{D}_{\\text{LIME}} and the following loss function: \\mathcal{L}_{\\text{LIME}}(f,g,\\pi_{\\boldsymbol{x}_{\\text{Bob}}})=\\sum_{i=1}^{N_{\\text{Examples}}}\\pi_{\\boldsymbol{x}_{\\text{Bob}}}\\big(\\boldsymbol{x}^{'(i)}_{\\text{Bob}}\\big)\\cdot \\bigg(f\\big(\\boldsymbol{x}^{'(i)}_{\\text{Bob}}\\big)-g\\big(\\boldsymbol{x}^{'(i)}_{\\text{Bob}}\\big)\\bigg)^2, where \\pi_{\\boldsymbol{x}_{\\text{Bob}}}\\big(\\boldsymbol{x}^{'(i)}_{\\text{Bob}}\\big) represents the distance from the perturbed example \\boldsymbol{x}^{'(i)}_{\\text{Bob}} to the instance to be explained \\boldsymbol{x}_{\\text{Bob}}."
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#explaining-to-bob",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#explaining-to-bob",
    "title": "Interpretability",
    "section": "“Explaining” to Bob",
    "text": "“Explaining” to Bob\n\n\n\n\nThe bold red cross is the instance being explained. LIME samples instances (grey nodes), gets predictions using f (gamma MDN) and weighs them by the proximity to the instance being explained (represented here by size). The dashed line g is the learned local explanation."
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#shap-values",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#shap-values",
    "title": "Interpretability",
    "section": "SHAP Values",
    "text": "SHAP Values\nThe SHapley Additive exPlanations (SHAP) value helps to quantify the contribution of each feature to the prediction for a specific instance.\nThe SHAP value for the jth feature is defined as \\begin{align*}\n\\text{SHAP}^{(j)}(\\boldsymbol{x}) &=\n\\sum_{U\\subset \\{1, ..., p\\} \\backslash \\{j\\}} \\frac{1}{p}\n\\binom{p-1}{|U|}^{-1}\n\\big(\\mathbb{E}[Y| \\boldsymbol{x}^{(U\\cup \\{j\\})}] - \\mathbb{E}[Y|\\boldsymbol{x}^{(U)}]\\big),\n\\end{align*}\n where p is the number of features. A positive SHAP value indicates that the variable increases the prediction value.\n\nReference: Lundberg & Lee (2017), A Unified Approach to Interpreting Model Predictions, Advances in Neural Information Processing Systems, 30."
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.slides.html#grad-cam",
    "href": "Lecture-9-Advanced-Topics/interpretability.slides.html#grad-cam",
    "title": "Interpretability",
    "section": "Grad-CAM",
    "text": "Grad-CAM\n\n\n\n\n\nOriginal image\n\n\n\n\n\n\nGrad-CAM\n\n\n\n\n\nCf. Chollet (2021), Deep Learning with Python, Section 9.4.3."
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html",
    "href": "Lecture-9-Advanced-Topics/interpretability.html",
    "title": "Interpretability",
    "section": "",
    "text": "Interpretability on a high-level refers to understanding how a model works. Understanding how a model works is very important for decision making. Traditional statistical methods like linear regression and generalized linear regressions are inherently interpretable because we can see and understand how different variables impact the model predictions collectively and individually. In contrast, deep learning algorithms do not readily provide insights into how variables contributed to the predictions. They are composed of multiple layers of interconnected nodes that learn different representations of data. Hence, it is not clear how inputs directly contributed to the outputs. This makes neural networks less interpretable. This is not very desirable, especially in situations which demand making explanations. As such, there is active discussion going on about how we can make less interpretable models more interpretable so that we start trusting these models more.\n\n\nSuppose a neural network informs us to increase the premium for Bob.\n\nWhy are we getting such a conclusion from the neural network, and should we trust it?\nHow can we explain our pricing scheme to Bob and the regulators?\nShould we be concerned with moral hazards, discrimination, unfairness, and ethical affairs?\n\nWe need to trust the model to employ it! With interpretability, we can trust it!\n\n\n\n\nInterpretability Definition\n\nInterpretability refers to the ease with which one can understand and comprehend the model’s algorithm and predictions.\n\n\nInterpretability of black-box models can be crucial to ascertaining trust.\n\n\n\n\nInherent Interpretability\n\nThe model is interpretable by design.\n\n\nModels with inherent interpretability generally have a simple model architecture where the relationships between inputs and outputs are straightforward. This makes it easy to understand and comprehend model’s inner workings and its predictions. As a result, decision making processes convenient. Examples for models with inherent interpretability include linear regression models, generalized linear regression models and decision trees.\n\nPost-hoc Interpretability\n\nThe model is not interpretable by design, but we can use other methods to explain the model.\n\n\nPost-hoc interpretability refers to applying various techniques to understand how the model makes its predictions after the model is trained. Post-hoc interpretability is useful for understanding predictions coming from complex models (less interpretable models) such as neural networks, random forests and gradient boosting trees.\n\n\n\nGlobal Interpretability:\n\nThe ability to understand how the model works.\nExample: how each feature impacts the overall mean prediction.\n\nGlobal Interpretability focuses on understanding the model’s decision-making process as a whole. Global interpretability takes in to account the entire dataset. These techniques will try to look at general patterns related how input data drives the output in general. Examples for techniques include global feature importance method and permutation importance methods.\nLocal Interpretability:\n\nThe ability to interpret/understand each prediction.\nExample: how Bob’s mean prediction has increased the most.\n\nLocal Interpretability focuses on understanding the model’s decision-making for a specific input observation. These techniques will try to look at how different input features contributed to the output.",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#interpretability-and-trust",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#interpretability-and-trust",
    "title": "Interpretability",
    "section": "",
    "text": "Suppose a neural network informs us to increase the premium for Bob.\n\nWhy are we getting such a conclusion from the neural network, and should we trust it?\nHow can we explain our pricing scheme to Bob and the regulators?\nShould we be concerned with moral hazards, discrimination, unfairness, and ethical affairs?\n\nWe need to trust the model to employ it! With interpretability, we can trust it!",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#interpretability-1",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#interpretability-1",
    "title": "Interpretability",
    "section": "",
    "text": "Interpretability Definition\n\nInterpretability refers to the ease with which one can understand and comprehend the model’s algorithm and predictions.\n\n\nInterpretability of black-box models can be crucial to ascertaining trust.",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#first-dimension-of-interpretability",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#first-dimension-of-interpretability",
    "title": "Interpretability",
    "section": "",
    "text": "Inherent Interpretability\n\nThe model is interpretable by design.\n\n\nModels with inherent interpretability generally have a simple model architecture where the relationships between inputs and outputs are straightforward. This makes it easy to understand and comprehend model’s inner workings and its predictions. As a result, decision making processes convenient. Examples for models with inherent interpretability include linear regression models, generalized linear regression models and decision trees.\n\nPost-hoc Interpretability\n\nThe model is not interpretable by design, but we can use other methods to explain the model.\n\n\nPost-hoc interpretability refers to applying various techniques to understand how the model makes its predictions after the model is trained. Post-hoc interpretability is useful for understanding predictions coming from complex models (less interpretable models) such as neural networks, random forests and gradient boosting trees.",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#second-dimension-of-interpretability",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#second-dimension-of-interpretability",
    "title": "Interpretability",
    "section": "",
    "text": "Global Interpretability:\n\nThe ability to understand how the model works.\nExample: how each feature impacts the overall mean prediction.\n\nGlobal Interpretability focuses on understanding the model’s decision-making process as a whole. Global interpretability takes in to account the entire dataset. These techniques will try to look at general patterns related how input data drives the output in general. Examples for techniques include global feature importance method and permutation importance methods.\nLocal Interpretability:\n\nThe ability to interpret/understand each prediction.\nExample: how Bob’s mean prediction has increased the most.\n\nLocal Interpretability focuses on understanding the model’s decision-making for a specific input observation. These techniques will try to look at how different input features contributed to the output.",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#trees-are-interpretable",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#trees-are-interpretable",
    "title": "Interpretability",
    "section": "Trees are interpretable!",
    "text": "Trees are interpretable!\n\n\n\nTrain prices",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#trees-are-interpretable-1",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#trees-are-interpretable-1",
    "title": "Interpretability",
    "section": "Trees are interpretable?",
    "text": "Trees are interpretable?\n\n\n\nFull train pricing",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#linear-models",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#linear-models",
    "title": "Interpretability",
    "section": "Linear models",
    "text": "Linear models\nA GLM has the form\n\n\\hat{y} = g^{-1}\\bigl( \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p \\bigr)\n\nwhere \\beta_0, \\dots, \\beta_p are the model parameters.\nGlobal & local interpretations are easy to obtain.\nThe above GLM representation provides a clear interpretation of how a marginal change in a variable x can contribute to a change in the mean of the output. This makes GLM inherently interpretable.",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#localglmnet",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#localglmnet",
    "title": "Interpretability",
    "section": "LocalGLMNet",
    "text": "LocalGLMNet\nImagine: \n\\hat{y_i} = g^{-1}\\bigl( \\beta_0(\\boldsymbol{x}_i) + \\beta_1(\\boldsymbol{x}_i) x_{i1} + \\dots + \\beta_p(\\boldsymbol{x}_i) x_{ip} \\bigr)\n\nA GLM with local parameters \\beta_0(\\boldsymbol{x}_i), \\dots, \\beta_p(\\boldsymbol{x}_i) for each observation \\boldsymbol{x}_i.\nThe local parameters are the output of a neural network.\nHere, \\beta_p’s are the neurons from the output layer. First, we define a Feed Foward Neural Network using an input layer, several hidden layers and an output layer. The number of neurons in the output layer must be equal to the number of inputs. Thereafter, we define a skip connection from the input layer directly to the output layer, and merge them using scaler multiplication. Thereafter, the neural network returns the coefficients of the GLM fitted for each individual. We then train the model with the response variable.",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#permutation-importance",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#permutation-importance",
    "title": "Interpretability",
    "section": "Permutation importance",
    "text": "Permutation importance\n\nInputs: fitted model m, tabular dataset D.\nCompute the reference score s of the model m on data D (for instance the accuracy for a classifier or the R^2 for a regressor).\nFor each feature j (column of D):\n\nFor each repetition k in {1, \\dots, K}:\n\nRandomly shuffle column j of dataset D to generate a corrupted version of the data named \\tilde{D}_{k,j}.\nCompute the score s_{k,j} of model m on corrupted data \\tilde{D}_{k,j}.\n\nCompute importance i_j for feature f_j defined as:\n i_j = s - \\frac{1}{K} \\sum_{k=1}^{K} s_{k,j} \n\n\n\nSource: scikit-learn documentation, permutation_importance function.",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#permutation-importance-1",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#permutation-importance-1",
    "title": "Interpretability",
    "section": "Permutation importance",
    "text": "Permutation importance\n\ndef permutation_test(model, X, y, num_reps=1, seed=42):\n    \"\"\"\n    Run the permutation test for variable importance.\n    Returns matrix of shape (X.shape[1], len(model.evaluate(X, y))).\n    \"\"\"\n    rnd.seed(seed)\n    scores = []    \n\n    for j in range(X.shape[1]):\n        original_column = np.copy(X[:, j])\n        col_scores = []\n\n        for r in range(num_reps):\n            rnd.shuffle(X[:,j])\n            col_scores.append(model.evaluate(X, y, verbose=0))\n\n        scores.append(np.mean(col_scores, axis=0))\n        X[:,j] = original_column\n    \n    return np.array(scores)",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#lime",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#lime",
    "title": "Interpretability",
    "section": "LIME",
    "text": "LIME\nLocal Interpretable Model-agnostic Explanations employs an interpretable surrogate model to explain locally how the black-box model makes predictions for individual instances.\nE.g. a black-box model predicts Bob’s premium as the highest among all policyholders. LIME uses an interpretable model (a linear regression) to explain how Bob’s features influence the black-box model’s prediction.\n\nCf. “Why Should I Trust You?”: Explaining the Predictions of Any Classifier.",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#globally-vs.-locally-faithful",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#globally-vs.-locally-faithful",
    "title": "Interpretability",
    "section": "Globally vs. Locally Faithful",
    "text": "Globally vs. Locally Faithful\n\nGlobally Faithful\n\nThe interpretable model’s explanations accurately reflect the behaviour of the black-box model across the entire input space.\n\nLocally Faithful\n\nThe interpretable model’s explanations accurately reflect the behaviour of the black-box model for a specific instance.\n\n\nLIME aims to construct an interpretable model that mimics the black-box model’s behaviour in a locally faithful manner.",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#lime-algorithm",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#lime-algorithm",
    "title": "Interpretability",
    "section": "LIME Algorithm",
    "text": "LIME Algorithm\nSuppose we want to explain the instance \\boldsymbol{x}_{\\text{Bob}}=(1, 2, 0.5).\n\nGenerate perturbed examples of \\boldsymbol{x}_{\\text{Bob}} and use the trained gamma MDN f to make predictions: \n\\begin{align*}\n  \\boldsymbol{x}^{'(1)}_{\\text{Bob}} &= (1.1, 1.9, 0.6), \\quad f\\big(\\boldsymbol{x}^{'(1)}_{\\text{Bob}}\\big)=34000 \\\\\n  \\boldsymbol{x}^{'(2)}_{\\text{Bob}} &= (0.8, 2.1, 0.4), \\quad f\\big(\\boldsymbol{x}^{'(2)}_{\\text{Bob}}\\big)=31000 \\\\\n  &\\vdots \\quad \\quad \\quad \\quad\\quad \\quad\\quad \\quad\\quad \\quad \\quad \\vdots\n\\end{align*} We can then construct a dataset of N_{\\text{Examples}} perturbed examples: \\mathcal{D}_{\\text{LIME}} = \\big(\\big\\{\\boldsymbol{x}^{'(i)}_{\\text{Bob}},f\\big(\\boldsymbol{x}^{'(i)}_{\\text{Bob}}\\big)\\big\\}\\big)_{i=0}^{N_{\\text{Examples}}}.",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#lime-algorithm-1",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#lime-algorithm-1",
    "title": "Interpretability",
    "section": "LIME Algorithm",
    "text": "LIME Algorithm\n\nFit an interpretable model g, i.e., a linear regression using \\mathcal{D}_{\\text{LIME}} and the following loss function: \\mathcal{L}_{\\text{LIME}}(f,g,\\pi_{\\boldsymbol{x}_{\\text{Bob}}})=\\sum_{i=1}^{N_{\\text{Examples}}}\\pi_{\\boldsymbol{x}_{\\text{Bob}}}\\big(\\boldsymbol{x}^{'(i)}_{\\text{Bob}}\\big)\\cdot \\bigg(f\\big(\\boldsymbol{x}^{'(i)}_{\\text{Bob}}\\big)-g\\big(\\boldsymbol{x}^{'(i)}_{\\text{Bob}}\\big)\\bigg)^2, where \\pi_{\\boldsymbol{x}_{\\text{Bob}}}\\big(\\boldsymbol{x}^{'(i)}_{\\text{Bob}}\\big) represents the distance from the perturbed example \\boldsymbol{x}^{'(i)}_{\\text{Bob}} to the instance to be explained \\boldsymbol{x}_{\\text{Bob}}.",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#explaining-to-bob",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#explaining-to-bob",
    "title": "Interpretability",
    "section": "“Explaining” to Bob",
    "text": "“Explaining” to Bob\n\n\n\n\nThe bold red cross is the instance being explained. LIME samples instances (grey nodes), gets predictions using f (gamma MDN) and weighs them by the proximity to the instance being explained (represented here by size). The dashed line g is the learned local explanation.",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#shap-values",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#shap-values",
    "title": "Interpretability",
    "section": "SHAP Values",
    "text": "SHAP Values\nThe SHapley Additive exPlanations (SHAP) value helps to quantify the contribution of each feature to the prediction for a specific instance.\nThe SHAP value for the jth feature is defined as \\begin{align*}\n\\text{SHAP}^{(j)}(\\boldsymbol{x}) &=\n\\sum_{U\\subset \\{1, ..., p\\} \\backslash \\{j\\}} \\frac{1}{p}\n\\binom{p-1}{|U|}^{-1}\n\\big(\\mathbb{E}[Y| \\boldsymbol{x}^{(U\\cup \\{j\\})}] - \\mathbb{E}[Y|\\boldsymbol{x}^{(U)}]\\big),\n\\end{align*}\n where p is the number of features. A positive SHAP value indicates that the variable increases the prediction value.\n\nReference: Lundberg & Lee (2017), A Unified Approach to Interpreting Model Predictions, Advances in Neural Information Processing Systems, 30.",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  },
  {
    "objectID": "Lecture-9-Advanced-Topics/interpretability.html#grad-cam",
    "href": "Lecture-9-Advanced-Topics/interpretability.html#grad-cam",
    "title": "Interpretability",
    "section": "Grad-CAM",
    "text": "Grad-CAM\n\n\n\n\n\nOriginal image\n\n\n\n\n\n\nGrad-CAM\n\n\n\n\n\nCf. Chollet (2021), Deep Learning with Python, Section 9.4.3.",
    "crumbs": [
      "Module 9",
      "Interpretability"
    ]
  }
]