<!DOCTYPE html>
<html lang="en"><head>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-contrib/reveal-auto-agenda-0.0.3/reveal-auto-agenda.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.4.554">

  <meta name="author" content="Eric Dong &amp; Patrick Laub">
  <title>AI for Actuaries - Distributional Regression</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {  background-color: #e9ecef; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #0040ff; font-weight: bold; } /* Alert */
    code span.an { color: #4090c0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #336699; } /* Attribute */
    code span.bn { color: #0033a0; } /* BaseN */
    code span.bu { color: #0055cc; } /* BuiltIn */
    code span.cf { color: #0055cc; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #002080; } /* Constant */
    code span.co { color: #4090c0; font-style: italic; } /* Comment */
    code span.cv { color: #4090c0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #3060a0; font-style: italic; } /* Documentation */
    code span.dt { color: #0044bb; } /* DataType */
    code span.dv { color: #0033a0; } /* DecVal */
    code span.er { color: #0040ff; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #0033a0; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #0055cc; font-weight: bold; } /* Import */
    code span.in { color: #4090c0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #0055cc; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #0055cc; } /* Other */
    code span.pp { color: #336699; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #336699; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #4090c0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto.css">
  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
  
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Distributional Regression</h1>
  <p class="subtitle">ACTL3143 &amp; ACTL5111 Deep Learning for Actuaries</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Eric Dong &amp; Patrick Laub 
</div>
</div>
</div>

</section>
<section>
<section id="uncertainty" class="title-slide slide level1 agenda-slide center" data-visibility="uncounted">
<h1>Uncertainty</h1>
<div class="agenda-heading">
<p>Lecture Outline</p>
</div>
<div class="agenda">
<ul>
<li><div class="agenda-active">
<p>Uncertainty</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Aleatoric Uncertainty</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Epistemic Uncertainty</p>
</div></li>
</ul>
</div>
</section>
<section id="quiz" class="slide level2">
<h2>Quiz</h2>
<p>Question: <em>If you decide to predict the claim amount of Bob using a deep learning model, which source(s) of uncertainty are you confronting?</em></p>
<ol type="1">
<li>The inherent variability of the data-generating process.</li>
<li>Parameter error.</li>
<li>Model error.</li>
<li>Data uncertainty.</li>
<li>All of the above.</li>
</ol>
</section>
<section id="answer" class="slide level2">
<h2>Answer</h2>
<p>All of the above!</p>
<p>There are two major types of uncertainty in statistical or machine learning:</p>
<ul>
<li>Aleatoric uncertainty</li>
<li>Epistemic uncertainty</li>
</ul>
<p>Since there is no consensus on the definitions of aleatoric and epistemic uncertainty, we provide the most acknowledged definitions in the following slides.</p>
</section>
<section id="aleatoric-uncertainty" class="slide level2">
<h2>Aleatoric Uncertainty</h2>
<dl>
<dt>Qualitative Definition</dt>
<dd>
<p><em>Aleatoric uncertainty refers to the statistical variability and inherent noise with data distribution that modelling cannot explain.</em></p>
</dd>
<dt>Quantitative Definition</dt>
<dd>
<p><span class="math display">\text{Ale}(Y|\boldsymbol{x}) = \mathbb{V}[Y|\boldsymbol{x}],</span>i.e., if <span class="math inline">Y|\boldsymbol{x} \sim \mathcal{N}(\mu, \sigma^2)</span>, the aleatoric uncertainty would be <span class="math inline">\sigma^2</span>. Simply, it is the conditional variance of the response variable <span class="math inline">Y</span> given features/covariates <span class="math inline">\boldsymbol{x}</span>.</p>
</dd>
</dl>
</section>
<section id="epistemic-uncertainty" class="slide level2">
<h2>Epistemic Uncertainty</h2>
<dl>
<dt>Qualitative Definition</dt>
<dd>
<p><em>Epistemic uncertainty refers to the lack of knowledge, limited data information, parameter errors and model errors.</em></p>
</dd>
<dt>Quantitative Definition</dt>
<dd>
<p><span class="math display">\text{Epi}(Y|\boldsymbol{x}) = \text{Uncertainty}(Y|\boldsymbol{x}) - \text{Ale}(Y|\boldsymbol{x}),</span></p>
</dd>
</dl>
<p>i.e., the total uncertainty subtracting the aleatoric uncertainty <span class="math inline">\mathbb{V}[Y|\boldsymbol{x}]</span> would be the epistemic uncertainty.</p>
</section>
<section id="uncertainty-1" class="slide level2">
<h2>Uncertainty</h2>
<p>Let’s go back to the question at the beginning:</p>
<p><em>If you decide to predict the claim amount of an individual using a deep learning model, which source(s) of uncertainty are you dealing with?</em></p>
<ol type="1">
<li>The inherent variability of the data-generating process <span class="math inline">\rightarrow</span> aleatoric uncertainty.</li>
<li>Parameter error <span class="math inline">\rightarrow</span> epistemic uncertainty.</li>
<li>Model error <span class="math inline">\rightarrow</span> epistemic uncertainty.</li>
<li>Data uncertainty <span class="math inline">\rightarrow</span> epistemic uncertainty.</li>
</ol>
</section>
<section id="code-data" class="slide level2">
<h2>Code: Data</h2>
<div id="9faf734c" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a></a>sev_df <span class="op">=</span> pd.read_csv(<span class="st">'freMTPL2sev.csv'</span>)</span>
<span id="cb1-3"><a></a>freq_df <span class="op">=</span> pd.read_csv(<span class="st">'freMTPL2freq.csv'</span>)</span>
<span id="cb1-4"><a></a></span>
<span id="cb1-5"><a></a><span class="co"># Create a copy of freq dataframe without 'claimfreq' column</span></span>
<span id="cb1-6"><a></a>freq_without_claimfreq <span class="op">=</span> freq_df.drop(columns<span class="op">=</span>[<span class="st">'ClaimNb'</span>])</span>
<span id="cb1-7"><a></a></span>
<span id="cb1-8"><a></a><span class="co"># Merge severity dataframe with freq_without_claimfreq dataframe</span></span>
<span id="cb1-9"><a></a>new_sev_df <span class="op">=</span> pd.merge(sev_df, freq_without_claimfreq, on<span class="op">=</span><span class="st">'IDpol'</span>, </span>
<span id="cb1-10"><a></a>                                                      how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb1-11"><a></a>new_sev_df <span class="op">=</span> new_sev_df.dropna()</span>
<span id="cb1-12"><a></a>new_sev_df <span class="op">=</span> new_sev_df.drop(<span class="st">"IDpol"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-13"><a></a>new_sev_df[:<span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">ClaimAmount</th>
<th data-quarto-table-cell-role="th">Exposure</th>
<th data-quarto-table-cell-role="th">VehPower</th>
<th data-quarto-table-cell-role="th">VehAge</th>
<th data-quarto-table-cell-role="th">DrivAge</th>
<th data-quarto-table-cell-role="th">BonusMalus</th>
<th data-quarto-table-cell-role="th">VehBrand</th>
<th data-quarto-table-cell-role="th">VehGas</th>
<th data-quarto-table-cell-role="th">Area</th>
<th data-quarto-table-cell-role="th">Density</th>
<th data-quarto-table-cell-role="th">Region</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>995.20</td>
<td>0.59</td>
<td>11.0</td>
<td>0.0</td>
<td>39.0</td>
<td>56.0</td>
<td>B12</td>
<td>Diesel</td>
<td>D</td>
<td>778.0</td>
<td>Picardie</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1128.12</td>
<td>0.95</td>
<td>4.0</td>
<td>1.0</td>
<td>49.0</td>
<td>50.0</td>
<td>B12</td>
<td>Regular</td>
<td>E</td>
<td>2354.0</td>
<td>Ile-de-France</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
</section>
<section id="code-preprocessing" class="slide level2">
<h2>Code: Preprocessing</h2>
<div id="41c42775" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb2-2"><a></a>  new_sev_df.drop(<span class="st">"ClaimAmount"</span>, axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb2-3"><a></a>  new_sev_df[<span class="st">"ClaimAmount"</span>],</span>
<span id="cb2-4"><a></a>  random_state<span class="op">=</span><span class="dv">2023</span>)</span>
<span id="cb2-5"><a></a></span>
<span id="cb2-6"><a></a><span class="co"># Reset each index to start at 0 again.</span></span>
<span id="cb2-7"><a></a>X_train <span class="op">=</span> X_train.reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-8"><a></a>X_test <span class="op">=</span> X_test.reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-9"><a></a>y_train <span class="op">=</span> y_train.reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-10"><a></a>y_test <span class="op">=</span> y_test.reset_index(drop<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="code-preprocessing-1" class="slide level2">
<h2>Code: Preprocessing</h2>
<div id="d99e5b98" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a><span class="co"># Transformation</span></span>
<span id="cb3-2"><a></a>ct <span class="op">=</span> make_column_transformer(</span>
<span id="cb3-3"><a></a>  (OrdinalEncoder(), [<span class="st">"VehBrand"</span>, <span class="st">"Region"</span>, <span class="st">"Area"</span>, <span class="st">"VehGas"</span>]),</span>
<span id="cb3-4"><a></a>  remainder<span class="op">=</span>StandardScaler(),</span>
<span id="cb3-5"><a></a>   verbose_feature_names_out<span class="op">=</span><span class="va">False</span></span>
<span id="cb3-6"><a></a>)</span>
<span id="cb3-7"><a></a></span>
<span id="cb3-8"><a></a><span class="co"># We don't apply entity embedding </span></span>
<span id="cb3-9"><a></a>X_train_ct <span class="op">=</span> ct.fit_transform(X_train)</span>
<span id="cb3-10"><a></a>X_test_ct <span class="op">=</span> ct.transform(X_test)</span>
<span id="cb3-11"><a></a>X_train <span class="op">=</span> X_train_ct.drop([<span class="st">"VehBrand"</span>, <span class="st">"Region"</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-12"><a></a>X_test <span class="op">=</span> X_test_ct.drop([<span class="st">"VehBrand"</span>, <span class="st">"Region"</span>], axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><span class="math inline">\texttt{VehGas=1}</span> if the car gas is regular.</li>
<li><span class="math inline">\texttt{Area=0}</span> represents the rural area, and <span class="math inline">\texttt{Area=5}</span> represents the urban center.</li>
</ul>
</section>
<section id="histogram-of-the-claimamount" class="slide level2">
<h2>Histogram of the <code>ClaimAmount</code></h2>
<div id="a89131d7" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a>plt.hist(y_train[y_train <span class="op">&lt;</span> <span class="dv">5000</span>], bins<span class="op">=</span><span class="dv">30</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="distributional-regression_files/figure-revealjs/cell-7-output-1.png" class="r-stretch"></section></section>
<section>
<section id="aleatoric-uncertainty-1" class="title-slide slide level1 agenda-slide center" data-visibility="uncounted">
<h1>Aleatoric Uncertainty</h1>
<div class="agenda-heading">
<p>Lecture Outline</p>
</div>
<div class="agenda">
<ul>
<li><div class="agenda-inactive agenda-pre-active">
<p>Uncertainty</p>
</div></li>
<li><div class="agenda-active">
<p>Aleatoric Uncertainty</p>
</div></li>
<li><div class="agenda-inactive agenda-post-active">
<p>Epistemic Uncertainty</p>
</div></li>
</ul>
</div>
</section>
<section id="glm" class="slide level2">
<h2>GLM</h2>
<p>The generalised linear model (GLM) is a statistical regression model that estimates the conditional mean of the response variable <span class="math inline">Y</span> given an instance <span class="math inline">\boldsymbol{x}</span> via a link function <span class="math inline">g</span>: <span class="math display">
    \mathbb{E}[Y|\boldsymbol{x}]
    = \mu(\boldsymbol{x}; \boldsymbol{\beta}_{\text{GLM}})
    = g^{-1} \big(\big \langle \boldsymbol{\beta}_{\text{GLM}}, \boldsymbol{x} \big \rangle\big),
</span> where</p>
<ul>
<li><span class="math inline">\boldsymbol{x} \in \mathbb{R}^{d_{\boldsymbol{x}}}</span> is the vector of explanatory variables, with <span class="math inline">d_{\boldsymbol{x}}</span> denoting its dimension.</li>
<li><span class="math inline">\boldsymbol{\beta}_{\text{GLM}}</span> represents the vector of regression coefficients.</li>
<li><span class="math inline">\langle \boldsymbol{a}, \boldsymbol{b}\rangle</span> represents the inner product of <span class="math inline">\boldsymbol{a}</span> and <span class="math inline">\boldsymbol{b}</span>.</li>
</ul>
</section>
<section id="gamma-glm" class="slide level2">
<h2>Gamma GLM</h2>
<p>Suppose a fitted gamma GLM model has</p>
<ul>
<li>a log link function <span class="math inline">g(x)=\log(x)</span> and</li>
<li>regression coefficients <span class="math inline">\boldsymbol{\beta}_{\text{GLM}}=(\beta_0, \beta_1, \beta_2, \beta_3)</span>.</li>
</ul>
<p>Then, it estimates the conditional mean of <span class="math inline">Y</span> given a new instance <span class="math inline">\boldsymbol{x}=(1, x_1, x_2, x_3)</span> as follows: <span class="math display">
    \mathbb{E}[Y|\boldsymbol{x}]=g^{-1}(\langle \boldsymbol{\beta}_{\text{GLM}}, \boldsymbol{x}\rangle)=\exp\big(\beta_0+ \beta_1x_1+\beta_2x_2+\beta_3x_3\big).
</span></p>
<p>A GLM can model any other exponential family distribution using an appropriate link function <span class="math inline">g</span>.</p>
</section>
<section id="loss-function-for-a-gamma-glm" class="slide level2">
<h2>“Loss Function” for a Gamma GLM</h2>
<p>If <span class="math inline">Y|\boldsymbol{x}</span> is a gamma r.v., we can parameterise its density by its mean <span class="math inline">\mu(\boldsymbol{x}; \boldsymbol{\beta})</span> and dispersion parameter <span class="math inline">\phi</span>: <span class="math display">
    f_{Y|\boldsymbol{X}}(y|\boldsymbol{x}, \boldsymbol{\beta}, \phi)
    = \frac{(\mu (\boldsymbol{x}; \boldsymbol{\beta})\cdot \phi)^{-1/\phi}}{{\Gamma(1/\phi)}} \cdot y^{1/\phi - 1} \cdot \mathrm{e}^{-y/(\mu (\boldsymbol{x}; \boldsymbol{\beta})\cdot\phi)}.
</span> The “loss function” for a gamma GLM is typically the negative log-likelihood (NLL): <span class="math display">
    \sum_{i=1}^{N}-\log f_{Y|\boldsymbol{X}}(y_i|\boldsymbol{x}_i, \boldsymbol{\beta},\phi)
    \propto \sum_{i=1}^{N}\log \mu (\boldsymbol{x}_i; \boldsymbol{\beta})+\frac{y_i}{\mu (\boldsymbol{x}_i; \boldsymbol{\beta})} + \text{const},
</span> i.e., we ignore the dispersion parameter <span class="math inline">\phi</span> while estimating the regression coefficients.</p>
</section>
<section id="fitting-steps" class="slide level2">
<h2>Fitting Steps</h2>
<p>Step 1. Use the advanced second derivative iterative method to find the regression coefficients: <span class="math display">
    \boldsymbol{\beta}_{\text{GLM}} = \underset{\boldsymbol{\beta}}{\text{arg min}} \ \sum_{i=1}^{N}\log \mu (\boldsymbol{x}_i; \boldsymbol{\beta})+\frac{y_i}{\mu (\boldsymbol{x}_i; \boldsymbol{\beta})}
</span></p>
<p>Step 2. Estimate the dispersion parameter: <span class="math display">
    \phi_{\text{GLM}}=\frac{1}{N-d_{\boldsymbol{x}}}\sum_{i=1}^{N}\frac{(y_i-\mu(\boldsymbol{x}_i; \boldsymbol{\beta}_{\text{GLM}} ))^2}{\mu(\boldsymbol{x}_i; \boldsymbol{\beta}_{\text{GLM}} )^2}
</span></p>
</section>
<section id="code-gamma-glm" class="slide level2">
<h2>Code: Gamma GLM</h2>
<p>In Python, we can fit a gamma GLM as follows:</p>
<div id="380d6482" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb5-2"><a></a></span>
<span id="cb5-3"><a></a><span class="co"># Add a column of ones to include an intercept in the model</span></span>
<span id="cb5-4"><a></a>X_train_design <span class="op">=</span> sm.add_constant(X_train)</span>
<span id="cb5-5"><a></a></span>
<span id="cb5-6"><a></a><span class="co"># Create a Gamma GLM with a log link function</span></span>
<span id="cb5-7"><a></a>gamma_GLM <span class="op">=</span> sm.GLM(y_train, X_train_design,                   </span>
<span id="cb5-8"><a></a>            family<span class="op">=</span>sm.families.Gamma(sm.families.links.Log()))</span>
<span id="cb5-9"><a></a></span>
<span id="cb5-10"><a></a><span class="co"># Fit the model</span></span>
<span id="cb5-11"><a></a>gamma_GLM <span class="op">=</span> gamma_GLM.fit()</span>
<span id="cb5-12"><a></a></span>
<span id="cb5-13"><a></a><span class="co"># Dispersion Parameter</span></span>
<span id="cb5-14"><a></a>mus <span class="op">=</span> gamma_GLM.predict(X_train_design)</span>
<span id="cb5-15"><a></a>residuals <span class="op">=</span> mus<span class="op">-</span>y_train</span>
<span id="cb5-16"><a></a>variance <span class="op">=</span> mus<span class="op">**</span><span class="dv">2</span></span>
<span id="cb5-17"><a></a>dof <span class="op">=</span> (<span class="bu">len</span>(y_train)<span class="op">-</span>X_train.shape[<span class="dv">1</span>])</span>
<span id="cb5-18"><a></a>phi_GLM <span class="op">=</span>  np.sum(residuals<span class="op">**</span><span class="dv">2</span><span class="op">/</span>variance)<span class="op">/</span>dof</span>
<span id="cb5-19"><a></a><span class="bu">print</span>(phi_GLM)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>59.6306232357824</code></pre>
</div>
</div>
</section>
<section id="cann" class="slide level2">
<h2>CANN</h2>
<p>The Combined Actuarial Neural Network is a novel actuarial neural network architecture proposed by Schelldorfer and Wüthrich (2019). We summarise the CANN approach as follows:</p>
<ul>
<li>Find the coefficients <span class="math inline">\boldsymbol{\beta}_{\text{GLM}}</span> of the GLM with a link function <span class="math inline">g(\cdot)</span>.</li>
<li>Find the weights <span class="math inline">\boldsymbol{w}_{\text{CANN}}</span> of a neural network <span class="math inline">\mathcal{M}_{\text{CANN}}:\mathbb{R}^{d_{\boldsymbol{x}}}\to\mathbb{R}</span>.</li>
<li>Given a new instance <span class="math inline">\boldsymbol{x}</span>, we have <span class="math display">\mathbb{E}[Y|\boldsymbol{x}] = g^{-1}\Big( \langle\boldsymbol{\beta}_{\text{GLM}}, \boldsymbol{x}\rangle + \mathcal{M}_{\text{CANN}}(\boldsymbol{x};\boldsymbol{w}_{\text{CANN}})\Big).</span></li>
</ul>
</section>
<section id="architecture" class="slide level2">
<h2>Architecture</h2>

<img data-src="./CANN.png" class="r-stretch quarto-figure-center"><p class="caption"><span style="color:darkblue;">Figure</span>: CANN approach.</p></section>
<section id="code-architecture" class="slide level2">
<h2>Code: Architecture</h2>
<div id="aae9edf5" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a></a>gamma_GLM.params</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>const         7.786576
Area         -0.073226
VehGas        0.082292
                ...   
DrivAge      -0.022147
BonusMalus    0.157204
Density       0.010539
Length: 9, dtype: float64</code></pre>
</div>
</div>
<div id="5611f9bc" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a></a><span class="co"># Ensure reproducibility</span></span>
<span id="cb9-2"><a></a>random.seed(<span class="dv">1</span>)<span class="op">;</span> tf.random.set_seed(<span class="dv">1</span>)</span>
<span id="cb9-3"><a></a></span>
<span id="cb9-4"><a></a><span class="co"># Pre-defined constants</span></span>
<span id="cb9-5"><a></a>glm_weights <span class="op">=</span> gamma_GLM.params.iloc[<span class="dv">1</span>:]</span>
<span id="cb9-6"><a></a>glm_bias <span class="op">=</span> gamma_GLM.params.iloc[<span class="dv">0</span>]</span>
<span id="cb9-7"><a></a></span>
<span id="cb9-8"><a></a><span class="co"># Define model inputs</span></span>
<span id="cb9-9"><a></a>inputs <span class="op">=</span> Input(shape<span class="op">=</span>X_train.shape[<span class="dv">1</span>:])</span>
<span id="cb9-10"><a></a></span>
<span id="cb9-11"><a></a><span class="co"># Non-trainable GLM linear part</span></span>
<span id="cb9-12"><a></a>glm_logmu <span class="op">=</span> Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'linear'</span>, trainable<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-13"><a></a>                     kernel_initializer<span class="op">=</span>Constant(glm_weights),</span>
<span id="cb9-14"><a></a>                     bias_initializer<span class="op">=</span>Constant(glm_bias))(inputs)</span>
<span id="cb9-15"><a></a></span>
<span id="cb9-16"><a></a><span class="co"># Neural network layers</span></span>
<span id="cb9-17"><a></a>x <span class="op">=</span> Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(inputs)</span>
<span id="cb9-18"><a></a>x <span class="op">=</span> Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb9-19"><a></a>cann_logmu <span class="op">=</span> Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'linear'</span>)(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="code-loss-function" class="slide level2">
<h2>Code: Loss Function</h2>
<div id="b6e7718b" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a></a><span class="co"># Combine GLM and CANN estimates</span></span>
<span id="cb10-2"><a></a>CANN <span class="op">=</span> Model(inputs, Concatenate(axis<span class="op">=</span><span class="dv">1</span>)([cann_logmu, glm_logmu]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We need to customise the loss function for CANN.</p>
<div id="c333d7a4" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a></a><span class="kw">def</span> CANN_negative_log_likelihood(y_true, y_pred):</span>
<span id="cb11-2"><a></a>    <span class="co">#the new mean estimate</span></span>
<span id="cb11-3"><a></a>    CANN_logmu <span class="op">=</span> y_pred[:, <span class="dv">0</span>]</span>
<span id="cb11-4"><a></a>    GLM_logmu <span class="op">=</span> y_pred[:, <span class="dv">1</span>]</span>
<span id="cb11-5"><a></a>    mu <span class="op">=</span> tf.math.exp(CANN_logmu <span class="op">+</span> GLM_logmu)</span>
<span id="cb11-6"><a></a></span>
<span id="cb11-7"><a></a>    <span class="co"># Compute the negative log likelihood of the Gamma distribution</span></span>
<span id="cb11-8"><a></a>    nll <span class="op">=</span> tf.reduce_mean(CANN_logmu <span class="op">+</span> GLM_logmu <span class="op">+</span> y_true<span class="op">/</span>mu)</span>
<span id="cb11-9"><a></a>    </span>
<span id="cb11-10"><a></a>    <span class="cf">return</span> nll</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="code-model-training" class="slide level2">
<h2>Code: Model Training</h2>
<div id="385c35da" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a></a>CANN.compile(optimizer<span class="op">=</span><span class="st">"adam"</span>, loss<span class="op">=</span>CANN_negative_log_likelihood)</span>
<span id="cb12-2"><a></a>hist <span class="op">=</span> CANN.fit(X_train, y_train,</span>
<span id="cb12-3"><a></a>    epochs<span class="op">=</span><span class="dv">300</span>, </span>
<span id="cb12-4"><a></a>    callbacks<span class="op">=</span>[EarlyStopping(patience<span class="op">=</span><span class="dv">30</span>)],  </span>
<span id="cb12-5"><a></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb12-6"><a></a>    batch_size<span class="op">=</span><span class="dv">64</span>, </span>
<span id="cb12-7"><a></a>    validation_split<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Find the dispersion parameter.</p>
<div id="66c918b2" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a></a>mus <span class="op">=</span> np.exp(np.sum(CANN.predict(X_train, verbose<span class="op">=</span><span class="dv">0</span>), axis <span class="op">=</span> <span class="dv">1</span>))</span>
<span id="cb13-2"><a></a>residuals <span class="op">=</span> mus<span class="op">-</span>y_train</span>
<span id="cb13-3"><a></a>variance <span class="op">=</span> mus<span class="op">**</span><span class="dv">2</span></span>
<span id="cb13-4"><a></a>dof <span class="op">=</span> (<span class="bu">len</span>(y_train)<span class="op">-</span>X_train.shape[<span class="dv">1</span>])</span>
<span id="cb13-5"><a></a>phi_CANN <span class="op">=</span>  np.sum(residuals<span class="op">**</span><span class="dv">2</span><span class="op">/</span>variance) <span class="op">/</span> dof</span>
<span id="cb13-6"><a></a><span class="bu">print</span>(phi_CANN)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>98.60976911896634</code></pre>
</div>
</div>
</section>
<section id="mixture-distribution" class="slide level2">
<h2>Mixture Distribution</h2>
<p>Given a finite set of resulting random variables <span class="math inline">(Y_1, ..., Y_{K})</span>, one can generate a multinomial random variable <span class="math inline">Y\sim \text{Multinomial}(1, \boldsymbol{\pi})</span>. Meanwhile, <span class="math inline">Y</span> can be regarded as a mixture of <span class="math inline">Y_1, ..., Y_{K}</span>, i.e., <span class="math display">
  Y = \begin{cases}
      Y_1 &amp; \text{w.p. } \pi_1, \\
      \vdots &amp; \vdots\\
      Y_K &amp; \text{w.p. } \pi_K, \\
  \end{cases}
</span> where we define a set of finite set of weights <span class="math inline">\boldsymbol{\pi}=(\pi_{1} ..., \pi_{K})</span> such that <span class="math inline">\pi_k \ge 0</span> for <span class="math inline">k \in \{1, ..., K\}</span> and <span class="math inline">\sum_{k=1}^{K}\pi_k=1</span>.</p>
</section>
<section id="mixture-distribution-1" class="slide level2">
<h2>Mixture Distribution</h2>
<p>Let <span class="math inline">f_{Y_k|\boldsymbol{X}}</span> and <span class="math inline">F_{Y_k|\boldsymbol{X}}</span> be the probability density function and the cumulative density function, respectively, of <span class="math inline">Y_k|\boldsymbol{X}</span> for all <span class="math inline">k\in \{1, ..., K\}</span>. The random variable <span class="math inline">Y|\boldsymbol{X}</span>, which mixes <span class="math inline">Y_k|\boldsymbol{X}</span>’s with weights <span class="math inline">\pi_k</span>’s, has the density function <span class="math display">
    f_{Y|\boldsymbol{X}}(y|\boldsymbol{x}) = \sum_{k=1}^{K}\pi_k(\boldsymbol{x}) f_{k}(y|\boldsymbol{x}),
</span> and the cumulative density function <span class="math display">
    F_{Y|\boldsymbol{X}}(y|\boldsymbol{x}) = \sum_{k=1}^{K}\pi_k(\boldsymbol{x}) F_{k}(y|\boldsymbol{x}).
</span></p>
</section>
<section id="mixture-density-network" class="slide level2">
<h2>Mixture Density Network</h2>
<p>A mixture density network (MDN) <span class="math inline">\mathcal{M}_{\boldsymbol{w}^*}</span> outputs each distribution component’s mixing weights and parameters of <span class="math inline">Y</span> given the input features <span class="math inline">\boldsymbol{x}</span>, i.e., <span class="math display">
    \mathcal{M}_{\boldsymbol{w}^*}(\boldsymbol{x})=(\boldsymbol{\pi}(\boldsymbol{x};\boldsymbol{w}^*), \boldsymbol{\theta}(\boldsymbol{x};\boldsymbol{w}^*)),
</span> where <span class="math inline">\boldsymbol{w}^*</span> is the networks’ weights found by minimising the following negative log-likelihood loss function <span class="math display">
    \mathcal{L}(\mathcal{D}, \boldsymbol{\theta})= - \sum_{i=1}^{N} \log f_{Y|\boldsymbol{x}}(y_i|\boldsymbol{x}, \boldsymbol{w}^*),
</span> where <span class="math inline">\mathcal{D}=\{(\boldsymbol{x}_i,y_i)\}_{i=1}^{N}</span> is the training dataset.</p>
</section>
<section id="mixture-density-network-1" class="slide level2">
<h2>Mixture Density Network</h2>

<img data-src="./MDN.png" class="r-stretch quarto-figure-center"><p class="caption"><span style="color:darkblue;">Figure</span>: An MDN that outputs the parameters for a <span class="math inline">K</span> component mixture distribution. <span class="math inline">\boldsymbol{\theta}_k(\boldsymbol{x}; \boldsymbol{w}^*)= (\theta_{k,1}(\boldsymbol{x}; \boldsymbol{w}^*), ..., \theta_{k,|\boldsymbol{\theta}_k|}(\boldsymbol{x}; \boldsymbol{w}^*))</span> consists of the parameter estimates for the <span class="math inline">k</span>th mixture component.</p></section>
<section id="model-specification" class="slide level2">
<h2>Model Specification</h2>
<p>Suppose there are two types of claims:</p>
<ul>
<li>Type I: <span class="math inline">Y_1|\boldsymbol{x}\sim \text{Gamma}(\alpha_1(\boldsymbol{x}), \beta_1(\boldsymbol{x}))</span> and,</li>
<li>Type II: <span class="math inline">Y_2|\boldsymbol{x}\sim \text{Gamma}(\alpha_2(\boldsymbol{x}), \beta_2(\boldsymbol{x}))</span>.</li>
</ul>
<p>The density of the actual claim amount <span class="math inline">Y|\boldsymbol{x}</span> follows <span class="math display">
    \begin{align*}
        f_{Y|\boldsymbol{X}}(y|\boldsymbol{x})
        &amp;= \pi_1(\boldsymbol{x})\cdot \frac{\beta_1(\boldsymbol{x})^{\alpha_1(\boldsymbol{x})}}{\Gamma(\alpha_1(\boldsymbol{x}))}\mathrm{e}^{-\beta_1(\boldsymbol{x})y}y^{\alpha_1(\boldsymbol{x})-1} \\
        &amp;\quad + (1-\pi_1(\boldsymbol{x}))\cdot \frac{\beta_2(\boldsymbol{x})^{\alpha_2(\boldsymbol{x})}}{\Gamma(\alpha_2(\boldsymbol{x}))}\mathrm{e}^{-\beta_2(\boldsymbol{x})y}y^{\alpha_2(\boldsymbol{x})-1}.
    \end{align*}
</span> where <span class="math inline">\pi_1(\boldsymbol{x})</span> is the probability of a Type I claim given <span class="math inline">\boldsymbol{x}</span>.</p>
</section>
<section id="output" class="slide level2">
<h2>Output</h2>
<p>The aim is to find the optimum weights <span class="math display">
    \boldsymbol{w}^* = \underset{w}{\text{arg min}} \ \mathcal{L}(\mathcal{D}, \boldsymbol{w})
</span> for the Gamma mixture density network <span class="math inline">\mathcal{M}_{\boldsymbol{w}^*}</span> that outputs the mixing weights, shapes and scales of <span class="math inline">Y</span> given the input features <span class="math inline">\boldsymbol{x}</span>, i.e., <span class="math display">
    \begin{align*}
        \mathcal{M}_{\boldsymbol{w}^*}(\boldsymbol{x})
        = ( &amp;\pi_1(\boldsymbol{x}; \boldsymbol{w}^*),
             \pi_2(\boldsymbol{x}; \boldsymbol{w}^*), \\
            &amp;\alpha_1(\boldsymbol{x}; \boldsymbol{w}^*),
            \alpha_2(\boldsymbol{x}; \boldsymbol{w}^*),\\
            &amp;\beta_1(\boldsymbol{x}; \boldsymbol{w}^*),
            \beta_2(\boldsymbol{x}; \boldsymbol{w}^*)
        ).
    \end{align*}
</span></p>
</section>
<section id="architecture-1" class="slide level2">
<h2>Architecture</h2>

<img data-src="./Gamma_MDN.png" class="r-stretch quarto-figure-center"><p class="caption"><span style="color:darkblue;">Figure</span>: We demonstrate the structure of a gamma MDN that outputs the parameters for a gamma mixture with two components.</p></section>
<section id="code-architecture-1" class="slide level2">
<h2>Code: Architecture</h2>
<p>The following code resembles the architecture of the architecture of the gamma MDN from the previous slide.</p>
<div id="49ffa236" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a></a><span class="co"># Ensure reproducibility</span></span>
<span id="cb15-2"><a></a>random.seed(<span class="dv">1</span>)<span class="op">;</span> tf.random.set_seed(<span class="dv">1</span>)</span>
<span id="cb15-3"><a></a></span>
<span id="cb15-4"><a></a>inputs <span class="op">=</span> Input(shape<span class="op">=</span>X_train.shape[<span class="dv">1</span>:])</span>
<span id="cb15-5"><a></a></span>
<span id="cb15-6"><a></a><span class="co"># Two hidden layers </span></span>
<span id="cb15-7"><a></a>x <span class="op">=</span> Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(inputs)</span>
<span id="cb15-8"><a></a>x <span class="op">=</span> Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb15-9"><a></a></span>
<span id="cb15-10"><a></a>pis <span class="op">=</span> Dense(<span class="dv">2</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)(x) <span class="co">#mixing weights</span></span>
<span id="cb15-11"><a></a>alphas <span class="op">=</span> Dense(<span class="dv">2</span>, activation<span class="op">=</span><span class="st">'exponential'</span>)(x) <span class="co">#shape parameters</span></span>
<span id="cb15-12"><a></a>betas <span class="op">=</span> Dense(<span class="dv">2</span>, activation<span class="op">=</span><span class="st">'exponential'</span>)(x) <span class="co">#scale parameters</span></span>
<span id="cb15-13"><a></a></span>
<span id="cb15-14"><a></a><span class="co"># `y_pred` will now have 6 columns</span></span>
<span id="cb15-15"><a></a>gamma_mdn <span class="op">=</span> Model(inputs, Concatenate(axis<span class="op">=</span><span class="dv">1</span>)([pis, alphas, betas]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="loss-function" class="slide level2">
<h2>Loss Function</h2>
<p>The negative log-likelihood loss function is given by</p>
<p><span class="math display">
    \mathcal{L}(\mathcal{D}, \boldsymbol{w})
    = - \sum_{i=1}^{N} \log \  f_{Y|\boldsymbol{x}}(y_i|\boldsymbol{x}, \boldsymbol{w})
</span> where the <span class="math inline">f_{Y|\boldsymbol{x}}(y_i|\boldsymbol{x}, \boldsymbol{w})</span> is defined by <span class="math display">
\begin{align*}
    &amp;\pi_1(\boldsymbol{x};\boldsymbol{w})\cdot \frac{\beta_1(\boldsymbol{x};\boldsymbol{w})^{\alpha_1(\boldsymbol{x};\boldsymbol{w})}}{\Gamma(\alpha_1(\boldsymbol{x};\boldsymbol{w}))}\mathrm{e}^{-\beta_1(\boldsymbol{x};\boldsymbol{w})y}y^{\alpha_1(\boldsymbol{x};\boldsymbol{w})-1} \\
    &amp; \quad + (1-\pi_1(\boldsymbol{x};\boldsymbol{w}))\cdot \frac{\beta_2(\boldsymbol{x};\boldsymbol{w})^{\alpha_2(\boldsymbol{x};\boldsymbol{w})}}{\Gamma(\alpha_2(\boldsymbol{x};\boldsymbol{w}))}\mathrm{e}^{-\beta_2(\boldsymbol{x};\boldsymbol{w})y}y^{\alpha_2(\boldsymbol{x};\boldsymbol{w})-1}
\end{align*}
</span></p>
</section>
<section id="code-loss-function-1" class="slide level2">
<h2>Code: Loss Function</h2>
<p>We employ functions from <code>tensorflow_probability</code> to code the loss function for the gamma MDN. The <code>MixtureSameFamily</code> function facilitates defining a mixture distribution all components from the same distribution but have different parametrization.</p>
<div id="93dca82c" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a></a><span class="im">import</span> tensorflow_probability <span class="im">as</span> tfp</span>
<span id="cb16-2"><a></a>tfd <span class="op">=</span> tfp.distributions</span>
<span id="cb16-3"><a></a>K <span class="op">=</span> <span class="dv">2</span> <span class="co"># number of mixture components</span></span>
<span id="cb16-4"><a></a></span>
<span id="cb16-5"><a></a><span class="kw">def</span> gamma_mixture_NLL(y_true, y_pred):                                      </span>
<span id="cb16-6"><a></a>    K <span class="op">=</span> y_pred.shape[<span class="dv">1</span>] <span class="op">//</span> <span class="dv">3</span></span>
<span id="cb16-7"><a></a>    pis <span class="op">=</span>  y_pred[:, :K]                                                    </span>
<span id="cb16-8"><a></a>    alphas <span class="op">=</span> y_pred[:, K:<span class="dv">2</span><span class="op">*</span>K]                                               </span>
<span id="cb16-9"><a></a>    betas <span class="op">=</span> y_pred[:, <span class="dv">2</span><span class="op">*</span>K:<span class="dv">3</span><span class="op">*</span>K]                                              </span>
<span id="cb16-10"><a></a></span>
<span id="cb16-11"><a></a>    <span class="co"># The mixture distribution is a MixtureSameFamily distribution</span></span>
<span id="cb16-12"><a></a>    mixture_distribution <span class="op">=</span> tfd.MixtureSameFamily(</span>
<span id="cb16-13"><a></a>        mixture_distribution<span class="op">=</span>tfd.Categorical(probs<span class="op">=</span>pis),</span>
<span id="cb16-14"><a></a>        components_distribution<span class="op">=</span>tfd.Gamma(alphas, betas))</span>
<span id="cb16-15"><a></a></span>
<span id="cb16-16"><a></a>    <span class="co"># The loss is the negative log-likelihood of the data</span></span>
<span id="cb16-17"><a></a>    <span class="cf">return</span> <span class="op">-</span>mixture_distribution.log_prob(y_true)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="code-model-training-1" class="slide level2">
<h2>Code: Model Training</h2>
<div id="ab116b53" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a></a><span class="co"># Employ the loss function from previous slide</span></span>
<span id="cb17-2"><a></a>gamma_mdn.compile(optimizer<span class="op">=</span><span class="st">"adam"</span>, loss<span class="op">=</span>gamma_mixture_NLL)</span>
<span id="cb17-3"><a></a></span>
<span id="cb17-4"><a></a>hist <span class="op">=</span> gamma_mdn.fit(X_train, y_train,</span>
<span id="cb17-5"><a></a>    epochs<span class="op">=</span><span class="dv">300</span>, </span>
<span id="cb17-6"><a></a>    callbacks<span class="op">=</span>[EarlyStopping(patience<span class="op">=</span><span class="dv">30</span>)],  </span>
<span id="cb17-7"><a></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb17-8"><a></a>    batch_size<span class="op">=</span><span class="dv">64</span>, </span>
<span id="cb17-9"><a></a>    validation_split<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="proper-scoring-rules" class="slide level2">
<h2>Proper Scoring Rules</h2>
<dl>
<dt>Definition</dt>
<dd>
<p><em>The scoring rule</em> <span class="math inline">S : \mathcal{F} \times \mathbb{R} \to \bar{\mathbb{R}}</span> is proper relative to the class <span class="math inline">\mathcal{F}</span> if <span class="math display">
S(G, G)\le S(F, G)
</span> for all <span class="math inline">F,G\in \mathcal{F}</span>. It is strictly proper if equality holds only if <span class="math inline">F = G</span>.</p>
</dd>
</dl>
<p>Examples:</p>
<ul>
<li>Logarithmic Score (NLL)</li>
<li>Continuous Ranked Probability Score (CRPS)</li>
</ul>
</section>
<section id="proper-scoring-rules-1" class="slide level2">
<h2>Proper Scoring Rules</h2>
<dl>
<dt>Logarithmic Score (NLL)</dt>
<dd>
<p>The logarithmic score is defined as <span class="math display">
    \mathrm{LogS}(f, y) = - \log f(y),
</span> where <span class="math inline">f</span> is the predictive density.</p>
</dd>
<dt>Continuous Ranked Probability Score (CRPS)</dt>
<dd>
<p>The continuous ranked probability score is defined as <span class="math display">
    \mathrm{crps}(F, y) = \int_{-\infty}^{\infty} (F(t) - {1}_{t\ge y})^2 \ \mathrm{d}t,
</span> where <span class="math inline">F</span> is the cumulative distribution function.</p>
</dd>
</dl>
</section>
<section id="code-nll" class="slide level2">
<h2>Code: NLL</h2>
<div id="8d04bd15" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a></a><span class="im">from</span> scipy.stats <span class="im">import</span> gamma</span>
<span id="cb18-2"><a></a></span>
<span id="cb18-3"><a></a><span class="kw">def</span> gamma_nll(mean, dispersion, y):</span>
<span id="cb18-4"><a></a>    <span class="co"># Calculate shape and scale parameters from mean and dispersion</span></span>
<span id="cb18-5"><a></a>    shape <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> dispersion<span class="op">;</span> scale <span class="op">=</span> mean <span class="op">*</span> dispersion</span>
<span id="cb18-6"><a></a></span>
<span id="cb18-7"><a></a>    <span class="co"># Create a gamma distribution object</span></span>
<span id="cb18-8"><a></a>    gamma_dist <span class="op">=</span> gamma(a<span class="op">=</span>shape, scale<span class="op">=</span>scale)</span>
<span id="cb18-9"><a></a>    </span>
<span id="cb18-10"><a></a>    <span class="cf">return</span> <span class="op">-</span>np.mean(gamma_dist.logpdf(y))</span>
<span id="cb18-11"><a></a></span>
<span id="cb18-12"><a></a><span class="co"># GLM</span></span>
<span id="cb18-13"><a></a>X_test_design <span class="op">=</span> sm.add_constant(X_test)</span>
<span id="cb18-14"><a></a>mus <span class="op">=</span> gamma_GLM.predict(X_test_design)</span>
<span id="cb18-15"><a></a>NLL_GLM <span class="op">=</span> gamma_nll(mus, phi_GLM, y_test)</span>
<span id="cb18-16"><a></a></span>
<span id="cb18-17"><a></a><span class="co"># CANN</span></span>
<span id="cb18-18"><a></a>mus <span class="op">=</span> np.exp(np.sum(CANN.predict(X_test, verbose<span class="op">=</span><span class="dv">0</span>), axis <span class="op">=</span> <span class="dv">1</span>))</span>
<span id="cb18-19"><a></a>NLL_CANN <span class="op">=</span> gamma_nll(mus, phi_CANN, y_test)</span>
<span id="cb18-20"><a></a></span>
<span id="cb18-21"><a></a><span class="co"># MDN</span></span>
<span id="cb18-22"><a></a>NLL_MDN <span class="op">=</span> gamma_mdn.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="model-comparisons" class="slide level2">
<h2>Model Comparisons</h2>
<div id="f1b1a1a4" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a></a><span class="bu">print</span>(<span class="ss">f'GLM: </span><span class="sc">{</span>round(NLL_GLM, <span class="dv">2</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb19-2"><a></a><span class="bu">print</span>(<span class="ss">f'CANN: </span><span class="sc">{</span>round(NLL_CANN, <span class="dv">2</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb19-3"><a></a><span class="bu">print</span>(<span class="ss">f'MDN: </span><span class="sc">{</span>round(NLL_MDN, <span class="dv">2</span>)<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>GLM: 11.02
CANN: 11.5
MDN: 8.67</code></pre>
</div>
</div>
</section></section>
<section>
<section id="epistemic-uncertainty-1" class="title-slide slide level1 agenda-slide center" data-visibility="uncounted">
<h1>Epistemic Uncertainty</h1>
<div class="agenda-heading">
<p>Lecture Outline</p>
</div>
<div class="agenda">
<ul>
<li><div class="agenda-inactive agenda-pre-active">
<p>Uncertainty</p>
</div></li>
<li><div class="agenda-inactive agenda-pre-active">
<p>Aleatoric Uncertainty</p>
</div></li>
<li><div class="agenda-active">
<p>Epistemic Uncertainty</p>
</div></li>
</ul>
</div>
</section>
<section id="dropout" class="slide level2">
<h2>Dropout</h2>

<img data-src="./dropout.png" class="r-stretch quarto-figure-center"><p class="caption">An example of neurons dropped during training.</p><div class="footer">
<p>Sources: Marcus Lautier (2022).</p>
</div>
</section>
<section id="dropout-quote-1" class="slide level2">
<h2>Dropout quote #1</h2>
<blockquote>
<p>It’s surprising at first that this destructive technique works at all. Would a company perform better if its employees were told to toss a coin every morning to decide whether or not to go to work? Well, who knows; perhaps it would! The company would be forced to adapt its organization; it could not rely on any single person to work the coffee machine or perform any other critical tasks, so this expertise would have to be spread across several people. Employees would have to learn to cooperate with many of their coworkers, not just a handful of them.</p>
</blockquote>
<div class="footer">
<p>Source: Aurélien Géron (2019), <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>, 2nd Edition, p.&nbsp;366</p>
</div>
</section>
<section id="dropout-quote-2" class="slide level2">
<h2>Dropout quote #2</h2>
<blockquote>
<p>The company would become much more resilient. If one person quit, it wouldn’t make much of a difference. It’s unclear whether this idea would actually work for companies, but it certainly does for neural networks. Neurons trained with dropout cannot co-adapt with their neighboring neurons; they have to be as useful as possible on their own. They also cannot rely excessively on just a few input neurons; they must pay attention to each of their input neurons. They end up being less sensitive to slight changes in the inputs. In the end, you get a more robust network that generalizes better.</p>
</blockquote>
<div class="footer">
<p>Source: Aurélien Géron (2019), <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em>, 2nd Edition, p.&nbsp;366</p>
</div>
</section>
<section id="code-dropout" class="slide level2">
<h2>Code: Dropout</h2>
<p>Dropout is just another layer in Keras.</p>
<div id="b4f42a23" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a></a><span class="im">from</span> tf_keras.layers <span class="im">import</span> Dropout</span>
<span id="cb21-2"><a></a><span class="co"># Ensure reproducibility</span></span>
<span id="cb21-3"><a></a>random.seed(<span class="dv">2</span>)<span class="op">;</span> tf.random.set_seed(<span class="dv">2</span>)</span>
<span id="cb21-4"><a></a></span>
<span id="cb21-5"><a></a>model <span class="op">=</span> Sequential([</span>
<span id="cb21-6"><a></a>    Dense(<span class="dv">30</span>, activation<span class="op">=</span><span class="st">"leaky_relu"</span>, name<span class="op">=</span><span class="st">"hidden1"</span>),</span>
<span id="cb21-7"><a></a>    Dropout(<span class="fl">0.2</span>),</span>
<span id="cb21-8"><a></a>    Dense(<span class="dv">30</span>, activation<span class="op">=</span><span class="st">"leaky_relu"</span>, name<span class="op">=</span><span class="st">"hidden2"</span>),</span>
<span id="cb21-9"><a></a>    Dropout(<span class="fl">0.2</span>),</span>
<span id="cb21-10"><a></a>    Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">"exponential"</span>, name<span class="op">=</span><span class="st">"output"</span>)</span>
<span id="cb21-11"><a></a>])</span>
<span id="cb21-12"><a></a></span>
<span id="cb21-13"><a></a>model.compile(<span class="st">"adam"</span>, <span class="st">"mse"</span>)</span>
<span id="cb21-14"><a></a>model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">4</span>, verbose<span class="op">=</span><span class="dv">0</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="code-dropout-after-training" class="slide level2">
<h2>Code: Dropout after training</h2>
<p>Making predictions is the same as any other model:</p>
<div class="columns">
<div class="column">
<div id="7255dfbe" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a></a>model.predict(X_test.head(<span class="dv">3</span>),</span>
<span id="cb22-2"><a></a>                  verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>array([[ 53.365997],
       [149.5073  ],
       [ 84.2315  ]], dtype=float32)</code></pre>
</div>
</div>
</div><div class="column">
<div id="915a0320" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a></a>model.predict(X_test.head(<span class="dv">3</span>),</span>
<span id="cb24-2"><a></a>                  verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>array([[ 53.365997],
       [149.5073  ],
       [ 84.2315  ]], dtype=float32)</code></pre>
</div>
</div>
</div>
</div>
<p>We can make the model think it is still training:</p>
<div class="columns">
<div class="column">
<div id="e1fa1993" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a></a>model(X_test.head(<span class="dv">3</span>).to_numpy(),</span>
<span id="cb26-2"><a></a>    training<span class="op">=</span><span class="va">True</span>).numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>array([[ 45.215286],
       [506.83798 ],
       [ 80.71608 ]], dtype=float32)</code></pre>
</div>
</div>
</div><div class="column">
<div id="362d3e76" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a></a>model(X_test.head(<span class="dv">3</span>).to_numpy(),</span>
<span id="cb28-2"><a></a>    training<span class="op">=</span><span class="va">True</span>).numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>array([[170.87773],
       [140.37846],
       [231.01816]], dtype=float32)</code></pre>
</div>
</div>
</div>
</div>
</section>
<section id="dropout-limitation" class="slide level2">
<h2>Dropout Limitation</h2>
<ul>
<li>Increased Training Time: Since dropout introduces noise into the training process, it can make the training process slower.</li>
<li>Sensitivity to Dropout Rates: the performance of dropout is highly dependent on the chosen dropout rate.</li>
<li>Uncertainty Quantification: the dropout can only provide a crude approximation to the theoretically justified Bayesian approach in terms of quantifying uncertainty.</li>
</ul>
</section>
<section id="bayesian-neural-network" class="slide level2">
<h2>Bayesian Neural Network</h2>
<p>The weights <span class="math inline">\boldsymbol{w}</span> of a Bayesian neural network (BNN) have their posterior distribution: <span class="math display">p(\boldsymbol{w}|\mathcal{D})\propto \mathcal{L}(\mathcal{D}|\boldsymbol{w})p(\boldsymbol{w})</span> according to the Bayes’ theorem.</p>
<ul>
<li><span class="math inline">\mathcal{L}(\mathcal{D}|\boldsymbol{w})</span> represents the likelihood of data given the weights.</li>
<li><span class="math inline">p(\boldsymbol{w})</span> represents the density of the prior distribution of the weights.</li>
</ul>
</section>
<section id="tractability-of-posterior-distribution" class="slide level2">
<h2>Tractability of Posterior Distribution</h2>
<p>Let <span class="math inline">\boldsymbol{\theta}_0=(\boldsymbol{\mu}_{\boldsymbol{w}_0},\boldsymbol{\sigma}_{\boldsymbol{w}_0})</span> be the parameters of the prior distribution of weights: <span class="math display">
    \boldsymbol{w}\sim \mathcal{N}(\boldsymbol{\mu}_{\boldsymbol{w}_0},\boldsymbol{\sigma}_{\boldsymbol{w}_0}).
</span> The derivation of the true posterior <span class="math display">
    p(\boldsymbol{w}|\mathcal{D})
    \propto \mathcal{L}(\mathcal{D}|\boldsymbol{w})p(\boldsymbol{w})
</span> is non-trivial due to the complexity of the model. We cannot compute the true posterior distribution efficiently.</p>
</section>
<section id="variational-approximation" class="slide level2">
<h2>Variational Approximation</h2>
<p>The variational approximation is a potential solution. Intuitively, we approximate the true posterior distribution with a variational distribution that is more tractable: <span class="math display">
    \underbrace{p(\boldsymbol{w}|\mathcal{D})}_{\text{True Posterior Distribution}}\approx \underbrace{q(\boldsymbol{w}|\boldsymbol{\theta})}_{\text{Variational Distribution}}
    \sim\mathcal{N}(\boldsymbol{\mu}_{\boldsymbol{w}},\boldsymbol{\sigma}_{\boldsymbol{w}}),
</span> i.e., a normal distribution with parameters <span class="math inline">\boldsymbol{\theta}= (\boldsymbol{\mu}_{\boldsymbol{w}},\boldsymbol{\sigma}_{\boldsymbol{w}})</span> is used to approximate the true posterior distribution of <span class="math inline">\boldsymbol{w}|\mathcal{D}</span>.</p>
</section>
<section id="demonstration" class="slide level2">
<h2>Demonstration</h2>

<img data-src="./VA.png" class="r-stretch quarto-figure-center"><p class="caption"><span style="color:darkblue;">Figure</span>: The idea is to use the <span style="color:blue;">blue</span> curve (variational distribution) to approximate the <span style="color:purple;">purple</span> curve (true posterior).</p></section>
<section id="code-variational-layers" class="slide level2">
<h2>Code: Variational Layers</h2>
<div id="caa073a0" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a></a><span class="im">import</span> tensorflow_probability <span class="im">as</span> tfp</span>
<span id="cb30-2"><a></a>tfd <span class="op">=</span> tfp.distributions</span>
<span id="cb30-3"><a></a></span>
<span id="cb30-4"><a></a><span class="kw">def</span> prior(kernel_size, bias_size, dtype<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb30-5"><a></a>    n <span class="op">=</span> kernel_size <span class="op">+</span> bias_size</span>
<span id="cb30-6"><a></a>    <span class="cf">return</span> <span class="kw">lambda</span> t: tfd.Independent(</span>
<span id="cb30-7"><a></a>        tfd.Normal(loc<span class="op">=</span>tf.zeros(n, dtype<span class="op">=</span>dtype),</span>
<span id="cb30-8"><a></a>                   scale<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb30-9"><a></a>                   reinterpreted_batch_ndims<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb30-10"><a></a></span>
<span id="cb30-11"><a></a><span class="kw">def</span> posterior(kernel_size, bias_size, dtype<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb30-12"><a></a>    n <span class="op">=</span> kernel_size <span class="op">+</span> bias_size</span>
<span id="cb30-13"><a></a>    <span class="cf">return</span> Sequential([</span>
<span id="cb30-14"><a></a>      tfp.layers.VariableLayer(<span class="dv">2</span> <span class="op">*</span> n, dtype<span class="op">=</span>dtype),</span>
<span id="cb30-15"><a></a>      tfp.layers.DistributionLambda(<span class="kw">lambda</span> t: tfd.Independent(</span>
<span id="cb30-16"><a></a>          tfd.Normal(loc<span class="op">=</span>t[..., :n],</span>
<span id="cb30-17"><a></a>                     scale<span class="op">=</span><span class="fl">1e-5</span> <span class="op">+</span> tf.nn.softplus(<span class="fl">0.01</span> <span class="op">*</span> t[..., n:])),</span>
<span id="cb30-18"><a></a>          reinterpreted_batch_ndims<span class="op">=</span><span class="dv">1</span>)),</span>
<span id="cb30-19"><a></a>    ])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="architecture-2" class="slide level2">
<h2>Architecture</h2>

<img data-src="./BNN_raw.png" class="r-stretch quarto-figure-center"><p class="caption"><span style="color:darkblue;">Figure</span>: We demonstrate the typical structure of a Bayesian neural network (BNN).</p><div class="footer">
<p>Source: Blundell et al.&nbsp;(2015), Weight Uncertainty in Neural Networks.</p>
</div>
</section>
<section id="loss-function-1" class="slide level2">
<h2>Loss Function</h2>
<p>The KL divergence between the true posterior and variational distribution is given by: <span class="math display">
    D_{\text{KL}}\left[q(\boldsymbol{w}|\boldsymbol{\theta}) || p(\boldsymbol{w}|\mathcal{D})\right]
    =\mathbb{E}_{\boldsymbol{w} \sim q(\boldsymbol{w}|\boldsymbol{\theta})}\left[\log\left(\frac{q(\boldsymbol{w}|\boldsymbol{\theta})}{p(\boldsymbol{w}|\mathcal{D})}\right) \right]
</span> After some algebra, we acknowledge the final representation: <span class="math display">
\begin{align*}
    D_{\text{KL}}\left[q(\boldsymbol{w}|\boldsymbol{\theta}) || p(\boldsymbol{w}|\mathcal{D})\right]
    &amp;=\underbrace{D_{\text{KL}}\left[{q(\boldsymbol{w}|\boldsymbol{\theta})} || {p(\boldsymbol{w})}\right]}_{{\text{Complexity Loss}}}  \underbrace{-\mathbb{E}_{\boldsymbol{w} \sim q(\boldsymbol{w}|\boldsymbol{\theta})}\left[\log{p(\mathcal{D}|\boldsymbol{w})}\right]}_{{\text{Error Loss}}} \\
    &amp; \quad\quad\quad\quad\quad\quad+  \ \text{const}.
\end{align*}
</span></p>
</section>
<section id="evaluation-of-loss" class="slide level2">
<h2>Evaluation of Loss</h2>
<p>In practice, we estimate loss function <span class="math display">
    \mathcal{L}(\mathcal{D}, \boldsymbol{\theta})
    =\underbrace{D_{\text{KL}}\left[{q(\boldsymbol{w}|\boldsymbol{\theta})} || {p(\boldsymbol{w})}\right]}_{{\text{Complexity Loss}}}  \underbrace{-\mathbb{E}_{\boldsymbol{w} \sim q(\boldsymbol{w}|\boldsymbol{\theta})}\left[\log{p(\mathcal{D}|\boldsymbol{w})}\right]}_{{\text{Error Loss}}}
</span> through Monte Carlo estimates <span class="math display">
   \mathcal{L}(\mathcal{D}, \boldsymbol{\theta})\approx\frac{1}{M}\sum_{m=1}^{M}\underbrace{\log\Bigg({\frac{q\left(\boldsymbol{w}^{(m)}|\boldsymbol{\theta}^{(m)}\right) }{ p\left(\boldsymbol{w}^{(m)}\right)}}\Bigg)}_{\text{Complexity Loss}}
   \underbrace{-\log{p\left(\mathcal{D}|\boldsymbol{w}^{(m)}\right)}}_{\text{Error Loss}}
</span> where <span class="math inline">\left\{\boldsymbol{w}^{(m)}\right\}_{m=1}^{M}</span> are random samples of <span class="math inline">\boldsymbol{w}|\boldsymbol{\theta}</span>.</p>
</section>
<section id="bayesian-gamma-loss" class="slide level2">
<h2>“Bayesian-Gamma” Loss</h2>
<p>If the output consists of the shape and scale parameter of a gamma distribution, the loss function would be <span class="math display">
    \mathcal{L}(\mathcal{D}, \boldsymbol{\theta})\approx\frac{1}{M}\sum_{m=1}^{M}\underbrace{\log\Bigg({\frac{q\left(\boldsymbol{w}^{(m)}|\boldsymbol{\theta}^{(m)}\right) }{ p\left(\boldsymbol{w}^{(m)}\right)}}\Bigg)}_{\text{Complexity Loss}}
   \underbrace{-\sum_{i=1}^{N}\log \ f(y_i|\boldsymbol{x}_i,\boldsymbol{w}^{(m)})}_{\text{Error Loss}},
</span> where <span class="math inline">f(y_i|\boldsymbol{x}_i,\boldsymbol{w}^{(m)})</span> denotes the density value of <span class="math inline">y_i</span> given <span class="math inline">\boldsymbol{x}_i</span>, under the <span class="math inline">m</span>th Monte Carlo sample <span class="math inline">\boldsymbol{w}^{(m)}</span>, i.e., <span class="math display">
    f(y_i|\boldsymbol{x}_i,\boldsymbol{w}^{(m)})=\frac{\beta(\boldsymbol{x};\boldsymbol{w}^{(m)})^{\alpha(\boldsymbol{x};\boldsymbol{w}^{(m)})}}{\Gamma(\alpha(\boldsymbol{x}^{(m)};\boldsymbol{w}^{(m)}))}\mathrm{e}^{-\beta(\boldsymbol{x};\boldsymbol{w}^{(m)})y}y^{\alpha(\boldsymbol{x};\boldsymbol{w}^{(m)})-1}.
</span></p>
</section>
<section id="architecture-3" class="slide level2">
<h2>Architecture</h2>

<img data-src="./Bayesian_Gamma.png" class="r-stretch quarto-figure-center"><p class="caption"><span style="color:darkblue;">Figure</span>: The output of our Bayesian neural network now consists of the shape parameter <span class="math inline">\alpha(\boldsymbol{x}; \boldsymbol{w})</span> and the scale parameter <span class="math inline">\beta(\boldsymbol{x}; \boldsymbol{w})</span>.</p></section>
<section id="code-architecture-2" class="slide level2">
<h2>Code: Architecture</h2>
<p>The <code>tfp.layers</code> allows us to extract the parameters from the output, which is a gamma distribution object.</p>
<div id="46c9bff3" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a></a><span class="co"># Ensure reproducibility</span></span>
<span id="cb31-2"><a></a>random.seed(<span class="dv">1</span>)<span class="op">;</span> tf.random.set_seed(<span class="dv">1</span>)</span>
<span id="cb31-3"><a></a></span>
<span id="cb31-4"><a></a>inputs <span class="op">=</span> Input(shape<span class="op">=</span>X_train.shape[<span class="dv">1</span>:])</span>
<span id="cb31-5"><a></a></span>
<span id="cb31-6"><a></a><span class="co"># DenseVariational layer</span></span>
<span id="cb31-7"><a></a>x <span class="op">=</span> tfp.layers.DenseVariational(<span class="dv">64</span>, posterior, prior,</span>
<span id="cb31-8"><a></a>                kl_weight<span class="op">=</span><span class="dv">1</span><span class="op">/</span>X_train.shape[<span class="dv">0</span>])(inputs)</span>
<span id="cb31-9"><a></a>outputs <span class="op">=</span> Dense(<span class="dv">2</span>, activation <span class="op">=</span> <span class="st">'softplus'</span>)(x)</span>
<span id="cb31-10"><a></a></span>
<span id="cb31-11"><a></a><span class="co"># Construct the Gamma distribution on the last layer</span></span>
<span id="cb31-12"><a></a>distributions <span class="op">=</span> tfp.layers.DistributionLambda(</span>
<span id="cb31-13"><a></a>      <span class="kw">lambda</span> t: tfd.Gamma(concentration<span class="op">=</span>t[..., <span class="dv">0</span>:<span class="dv">1</span>], </span>
<span id="cb31-14"><a></a>                          rate<span class="op">=</span>t[..., <span class="dv">1</span>:<span class="dv">2</span>]))(outputs)</span>
<span id="cb31-15"><a></a><span class="co"># Define the model</span></span>
<span id="cb31-16"><a></a>gamma_bnn <span class="op">=</span> Model(inputs, distributions)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="code-loss-function-and-training" class="slide level2">
<h2>Code: Loss Function and Training</h2>
<div id="2d918362" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a></a><span class="kw">def</span> gamma_loss(y_true, y_pred):</span>
<span id="cb32-2"><a></a>    <span class="cf">return</span> <span class="op">-</span>y_pred.log_prob(y_true)</span>
<span id="cb32-3"><a></a></span>
<span id="cb32-4"><a></a><span class="co"># Then use the loss function when compiling the model</span></span>
<span id="cb32-5"><a></a>gamma_bnn.compile(optimizer<span class="op">=</span>tf_keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">0.001</span>),</span>
<span id="cb32-6"><a></a>                loss<span class="op">=</span>gamma_loss)</span>
<span id="cb32-7"><a></a></span>
<span id="cb32-8"><a></a>hist <span class="op">=</span> gamma_bnn.fit(X_train, y_train,</span>
<span id="cb32-9"><a></a>    epochs<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb32-10"><a></a>    callbacks<span class="op">=</span>[EarlyStopping(patience<span class="op">=</span><span class="dv">30</span>)],</span>
<span id="cb32-11"><a></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb32-12"><a></a>    batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb32-13"><a></a>    validation_split<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="code-output-sampling" class="slide level2">
<h2>Code: Output Sampling</h2>
<p>In practice, we can further increase the number of samples.</p>
<div id="bde10f00" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a></a><span class="co"># Define the number of samples</span></span>
<span id="cb33-2"><a></a>n_samples <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb33-3"><a></a></span>
<span id="cb33-4"><a></a><span class="co"># Store all predictions in a list</span></span>
<span id="cb33-5"><a></a>alphas <span class="op">=</span> []<span class="op">;</span> betas <span class="op">=</span> []</span>
<span id="cb33-6"><a></a></span>
<span id="cb33-7"><a></a><span class="co"># Run the model `n_samples` times and store the predicted parameters</span></span>
<span id="cb33-8"><a></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_samples):</span>
<span id="cb33-9"><a></a>  <span class="co"># Predict the distributions</span></span>
<span id="cb33-10"><a></a>  predicted_distributions <span class="op">=</span> gamma_bnn(X_test[<span class="dv">9</span>:<span class="dv">10</span>].values)</span>
<span id="cb33-11"><a></a>  <span class="co"># Get the parameters</span></span>
<span id="cb33-12"><a></a>  alphas.append(predicted_distributions.concentration.numpy())</span>
<span id="cb33-13"><a></a>  betas.append(predicted_distributions.rate.numpy())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="sampled-density-functions" class="slide level2">
<h2>Sampled Density Functions</h2>

<img data-src="distributional-regression_files/figure-revealjs/cell-29-output-1.png" class="r-stretch"><p>We plot some of the sampled posterior density functions. The variability of the sampled density functions is one critical consideration for epistemic uncertainty.</p>
</section>
<section id="uncertainty-quantification-uq" class="slide level2">
<h2>Uncertainty Quantification (UQ)</h2>
<p>We analyse the total variance formula: <span class="math display">
\begin{align*}
    \mathbb{V}[Y]&amp;=\mathbb{E}[\mathbb{V}[Y|\boldsymbol{x}]] + \mathbb{V}[\mathbb{E}[Y|\boldsymbol{x}]]\\
    &amp;\approx \underbrace{\frac{1}{M}\sum_{m=1}^{M}\mathbb{V}\big[Y|\boldsymbol{x},\boldsymbol{w}^{(m)}\big]}_{\text{Aleatoric}} \\
    &amp;\quad \quad +\underbrace{\frac{1}{M}\sum_{m=1}^{M}\bigg(\mathbb{E}\big[Y|\boldsymbol{x},\boldsymbol{w}^{(m)}\big]-\frac{1}{M}\sum_{m=1}^{M}\mathbb{E}\big[Y|\boldsymbol{x},\boldsymbol{w}^{(m)}\big]\bigg)^2}_{\text{Epistemic}},
\end{align*}
</span> where <span class="math inline">M</span> is the number of posterior samples generated.</p>
</section>
<section id="code-applying-uq" class="slide level2">
<h2>Code: Applying UQ</h2>
<div id="ea796719" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a></a><span class="co"># Convert to numpy array for easier manipulation</span></span>
<span id="cb34-2"><a></a>alphas <span class="op">=</span> np.array(alphas)<span class="op">;</span> betas <span class="op">=</span> np.array(betas)</span>
<span id="cb34-3"><a></a></span>
<span id="cb34-4"><a></a><span class="co"># Aleatoric uncertainty: Mean of the variances of the predicted Gamma distributions</span></span>
<span id="cb34-5"><a></a>aleatoric_uncertainty <span class="op">=</span> np.mean(alphas<span class="op">/</span>betas<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb34-6"><a></a></span>
<span id="cb34-7"><a></a><span class="co"># Epistemic uncertainty: Variance of the means of the model's predictions</span></span>
<span id="cb34-8"><a></a>epistemic_uncertainty <span class="op">=</span> np.var(alphas<span class="op">/</span>betas)</span>
<span id="cb34-9"><a></a></span>
<span id="cb34-10"><a></a><span class="bu">print</span>(<span class="ss">f"Aleatoric uncertainty: </span><span class="sc">{</span>aleatoric_uncertainty<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb34-11"><a></a><span class="bu">print</span>(<span class="ss">f"Epistemic uncertainty: </span><span class="sc">{</span>epistemic_uncertainty<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Aleatoric uncertainty: 12227515.0
Epistemic uncertainty: 1425106.75</code></pre>
</div>
</div>
</section>
<section id="deep-ensembles" class="slide level2">
<h2>Deep Ensembles</h2>
<p>Lakshminarayanan et al.&nbsp;(2017) proposed deep ensembles as another prominent approach to obtaining epistemic uncertainty. Such a technique can be an alternative to BNNs. It’s simple to implement and requires very little hyperparameter tuning.</p>
<p>We summarise the deep ensemble approach for uncertainty quantification as follows:</p>
<ol type="1">
<li>Train <span class="math inline">D</span> neural networks with different random weights initialisations independently in parallel. The trained weights are <span class="math inline">\boldsymbol{w}^{(1)}, ..., \boldsymbol{w}^{(D)}</span> .</li>
</ol>
</section>
<section id="code-deep-ensembles-i" class="slide level2">
<h2>Code: Deep Ensembles I</h2>
<div id="d0677b74" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a></a>K <span class="op">=</span> <span class="dv">1</span> <span class="co"># number of mixtures</span></span>
<span id="cb36-2"><a></a></span>
<span id="cb36-3"><a></a><span class="kw">def</span> MDN_DE(num_ensembles):</span>
<span id="cb36-4"><a></a>  models <span class="op">=</span> []</span>
<span id="cb36-5"><a></a>  <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(num_ensembles):</span>
<span id="cb36-6"><a></a>    <span class="co"># Ensure reproducibility</span></span>
<span id="cb36-7"><a></a>    random.seed(k)<span class="op">;</span> tf.random.set_seed(k)</span>
<span id="cb36-8"><a></a>    inputs <span class="op">=</span> Input(shape<span class="op">=</span>X_train.shape[<span class="dv">1</span>:])</span>
<span id="cb36-9"><a></a></span>
<span id="cb36-10"><a></a>    <span class="co"># Two hidden layers </span></span>
<span id="cb36-11"><a></a>    x <span class="op">=</span> Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(inputs)</span>
<span id="cb36-12"><a></a>    x <span class="op">=</span> Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb36-13"><a></a></span>
<span id="cb36-14"><a></a>    pis <span class="op">=</span> Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)(x) <span class="co"># mixing weights</span></span>
<span id="cb36-15"><a></a>    alphas <span class="op">=</span> Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'softplus'</span>)(x) <span class="co"># shape parameters</span></span>
<span id="cb36-16"><a></a>    betas <span class="op">=</span> Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'softplus'</span>)(x) <span class="co"># scale parameters</span></span>
<span id="cb36-17"><a></a></span>
<span id="cb36-18"><a></a>    <span class="co"># Concatenate by columns: `y_pred` will now have 6 columns</span></span>
<span id="cb36-19"><a></a>    gamma_mdn_new <span class="op">=</span> Model(inputs, Concatenate(axis<span class="op">=</span><span class="dv">1</span>)([pis, alphas, betas]))</span>
<span id="cb36-20"><a></a>    gamma_mdn_new.compile(optimizer<span class="op">=</span><span class="st">"adam"</span>,</span>
<span id="cb36-21"><a></a>                          loss<span class="op">=</span>gamma_mixture_NLL)</span>
<span id="cb36-22"><a></a>    gamma_mdn_new.fit(X_train, y_train,</span>
<span id="cb36-23"><a></a>        epochs<span class="op">=</span><span class="dv">100</span>, callbacks<span class="op">=</span>[EarlyStopping(patience<span class="op">=</span><span class="dv">10</span>)],  </span>
<span id="cb36-24"><a></a>        verbose<span class="op">=</span><span class="dv">0</span>, batch_size<span class="op">=</span><span class="dv">64</span>, validation_split<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb36-25"><a></a>    models.append(gamma_mdn_new)</span>
<span id="cb36-26"><a></a></span>
<span id="cb36-27"><a></a>  <span class="cf">return</span>(models)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="code-deep-ensembles-ii" class="slide level2">
<h2>Code: Deep Ensembles II</h2>
<ol start="2" type="1">
<li>For a new instance <span class="math inline">\boldsymbol{x}</span>, obtain <span class="math display">\Big\{\big(\mathbb{E}\big[Y|\boldsymbol{x},\boldsymbol{w}^{(d)}\big],\mathbb{V}\big[Y|\boldsymbol{x},\boldsymbol{w}^{(d)}\big]\big)\Big\}_{d=1}^{D},</span></li>
</ol>
<div id="c0260df1" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a></a>D <span class="op">=</span> <span class="dv">10</span> <span class="co"># number of MDNs</span></span>
<span id="cb37-2"><a></a>MDN_models <span class="op">=</span> MDN_DE(D)</span>
<span id="cb37-3"><a></a></span>
<span id="cb37-4"><a></a><span class="co"># Store all predictions in a list</span></span>
<span id="cb37-5"><a></a>weights <span class="op">=</span> [<span class="dv">0</span>]<span class="op">*</span>D<span class="op">;</span> alphas <span class="op">=</span> [<span class="dv">0</span>]<span class="op">*</span>D<span class="op">;</span> betas <span class="op">=</span> [<span class="dv">0</span>]<span class="op">*</span>D</span>
<span id="cb37-6"><a></a></span>
<span id="cb37-7"><a></a><span class="co"># Store the parameters</span></span>
<span id="cb37-8"><a></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(D):</span>
<span id="cb37-9"><a></a>  weights[i], alphas[i], betas[i] <span class="op">=</span> MDN_models[i].predict(X_test[<span class="dv">9</span>:<span class="dv">10</span>], verbose<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>]</span>
<span id="cb37-10"><a></a></span>
<span id="cb37-11"><a></a><span class="co"># Predict the means and variances</span></span>
<span id="cb37-12"><a></a>means <span class="op">=</span> np.array(alphas)<span class="op">/</span>np.array(betas)</span>
<span id="cb37-13"><a></a>variances <span class="op">=</span> np.array(alphas)<span class="op">/</span>np.array(betas)<span class="op">**</span><span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="code-deep-ensembles-iii" class="slide level2">
<h2>Code: Deep Ensembles III</h2>
<ol start="3" type="1">
<li>Apply the variance decomposition <span class="math display">
    \mathbb{V}[Y]=\mathbb{E}[\mathbb{V}[Y|\boldsymbol{x}]] + \mathbb{V}[\mathbb{E}[Y|\boldsymbol{x}]]
</span></li>
</ol>
<div id="b5b70e20" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a></a>aleatoric_uncertainty <span class="op">=</span> np.mean(variances)</span>
<span id="cb38-2"><a></a>epistemic_uncertainty <span class="op">=</span> np.var(means)</span>
<span id="cb38-3"><a></a></span>
<span id="cb38-4"><a></a><span class="bu">print</span>(<span class="ss">f"Aleatoric uncertainty: </span><span class="sc">{</span>aleatoric_uncertainty<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb38-5"><a></a><span class="bu">print</span>(<span class="ss">f"Epistemic uncertainty: </span><span class="sc">{</span>epistemic_uncertainty<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Aleatoric uncertainty: 75940600.0
Epistemic uncertainty: 16657899.0</code></pre>
</div>
</div>
</section>
<section id="package-versions" class="slide level2 appendix" data-visibility="uncounted">
<h2>Package Versions</h2>
<div id="c072e7f0" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a></a><span class="im">from</span> watermark <span class="im">import</span> watermark</span>
<span id="cb40-2"><a></a><span class="bu">print</span>(watermark(python<span class="op">=</span><span class="va">True</span>, packages<span class="op">=</span><span class="st">"keras,matplotlib,numpy,pandas,seaborn,scipy,torch,tensorflow,tensorflow_probability,tf_keras"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Python implementation: CPython
Python version       : 3.11.9
IPython version      : 8.24.0

keras                 : 3.3.3
matplotlib            : 3.9.0
numpy                 : 1.26.4
pandas                : 2.2.2
seaborn               : 0.13.2
scipy                 : 1.11.0
torch                 : 2.0.1
tensorflow            : 2.16.1
tensorflow_probability: 0.24.0
tf_keras              : 2.16.0
</code></pre>
</div>
</div>
</section>
<section id="glossary" class="slide level2 appendix" data-visibility="uncounted">
<h2>Glossary</h2>
<div class="columns">
<div class="column">
<ul>
<li>aleatoric and epistemic uncertainty</li>
<li>Bayesian neural network</li>
<li>deep ensembles</li>
<li>dropout</li>
<li>CANN</li>
<li>GLM</li>
</ul>
</div><div class="column">
<ul>
<li>MDN</li>
<li>mixture distribution</li>
<li>posterior sampling</li>
<li>proper scoring rule</li>
<li>uncertainty quantification</li>
<li>variational approximation</li>
</ul>
</div>
</div>

<div class="quarto-auto-generated-content">
<p><img src="../unsw-logo.png" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true,"boardmarkerWidth":4,"grid":false,"background":["rgba(255,255,255,0.0)","https://github.com/rajgoel/reveal.js-plugins/raw/master/chalkboard/img/blackboard.png"]},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1000,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
            // Handle positioning of the toggle
        window.addEventListener(
          "resize",
          throttle(() => {
            elRect = undefined;
            if (selectedAnnoteEl) {
              selectCodeLines(selectedAnnoteEl);
            }
          }, 10)
        );
        function throttle(fn, ms) {
        let throttle = false;
        let timer;
          return (...args) => {
            if(!throttle) { // first call gets through
                fn.apply(this, args);
                throttle = true;
            } else { // all the others get throttled
                if(timer) clearTimeout(timer); // cancel #2
                timer = setTimeout(() => {
                  fn.apply(this, args);
                  timer = throttle = false;
                }, ms);
            }
          };
        }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>