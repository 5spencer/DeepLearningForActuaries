<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Patrick Laub">

<title>AI for Actuaries - Distributional Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../Advanced-Topics/interpretability.html" rel="next">
<link href="../Labs/backpropagation-lab.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../Distributional-Regression/distributional-regression.html">Module 7</a></li><li class="breadcrumb-item"><a href="../Distributional-Regression/distributional-regression.html">Distributional Regression</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">AI for Actuaries</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Module 1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Artificial-Intelligence/course-overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Artificial-Intelligence/artificial-intelligence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Artificial Intelligence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Artificial-Intelligence/python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/python-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: Intro Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/python-for-data-science-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: Python for Data Science</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Exercises/chess-ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercise: Chess AI</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Module 2</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Tabular-Data/deep-learning-keras.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deep Learning with Keras</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Tabular-Data/categorical-variables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Categorical Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Tabular-Data/classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Tabular-Data/project.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project Details</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/matplotlib-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: Matplotlib</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Exercises/victorian-crash-severity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercise: Victorian Car Crash Severity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Exercises/french-motor-frequency.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercise: French Motor Claim Frequency</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Module 3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Computer-Vision/computer-vision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Computer Vision</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/latex-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: Markdown</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Exercises/hurricane-damage.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercise: Aerial Photos of Hurricane Damage</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Module 4</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Natural-Language-Processing/natural-language-processing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Natural Language Processing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Exercises/police-reports.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercise: Police Reports of US Car Crashes</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Module 5</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Time-Series-And-Recurrent-Neural-Networks/time-series-and-rnns.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Time Series &amp; Recurrent Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Exercises/sydney-airport-temperature.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercise: Sydney Temperature Forecasting</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">Module 6</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Advanced-Tabular-Data/advanced-tabular-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Tabular Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Advanced-Tabular-Data/optimisation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Optimisation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/forward-pass-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: Forward Pass</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/optimisation-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: Optimisation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/backpropagation-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: Backpropagation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">Module 7</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Distributional-Regression/distributional-regression.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Distributional Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Advanced-Topics/interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interpretability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Labs/distributional-regression-lab.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab: Distributional Regression</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">Module 8</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Generative-Networks/generative-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Generative Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Generative-Networks/gans.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Generative Adversarial Networks</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
 <span class="menu-text">Module 9</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Advanced-Topics/next-steps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Next Steps</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#traditional-regression" id="toc-traditional-regression" class="nav-link active" data-scroll-target="#traditional-regression">Traditional Regression</a>
  <ul class="collapse">
  <li><a href="#traditional-regression-1" id="toc-traditional-regression-1" class="nav-link" data-scroll-target="#traditional-regression-1">Traditional Regression</a></li>
  <li><a href="#visualising-the-distribution-of-each-y" id="toc-visualising-the-distribution-of-each-y" class="nav-link" data-scroll-target="#visualising-the-distribution-of-each-y">Visualising the distribution of each <span class="math inline">Y</span></a></li>
  <li><a href="#the-probabilistic-view" id="toc-the-probabilistic-view" class="nav-link" data-scroll-target="#the-probabilistic-view">The probabilistic view</a></li>
  <li><a href="#the-predicted-distributions" id="toc-the-predicted-distributions" class="nav-link" data-scroll-target="#the-predicted-distributions">The predicted distributions</a></li>
  <li><a href="#the-machine-learning-view" id="toc-the-machine-learning-view" class="nav-link" data-scroll-target="#the-machine-learning-view">The machine learning view</a></li>
  <li><a href="#generalised-linear-model-glm" id="toc-generalised-linear-model-glm" class="nav-link" data-scroll-target="#generalised-linear-model-glm">Generalised Linear Model (GLM)</a></li>
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link" data-scroll-target="#logistic-regression">Logistic regression</a></li>
  <li><a href="#binary-cross-entropy-loss" id="toc-binary-cross-entropy-loss" class="nav-link" data-scroll-target="#binary-cross-entropy-loss">Binary cross-entropy loss</a></li>
  <li><a href="#poisson-regression" id="toc-poisson-regression" class="nav-link" data-scroll-target="#poisson-regression">Poisson regression</a></li>
  <li><a href="#poisson-loss" id="toc-poisson-loss" class="nav-link" data-scroll-target="#poisson-loss">Poisson loss</a></li>
  <li><a href="#gamma-regression" id="toc-gamma-regression" class="nav-link" data-scroll-target="#gamma-regression">Gamma regression</a></li>
  <li><a href="#gamma-loss" id="toc-gamma-loss" class="nav-link" data-scroll-target="#gamma-loss">Gamma loss</a></li>
  <li><a href="#why-do-actuaries-use-glms" id="toc-why-do-actuaries-use-glms" class="nav-link" data-scroll-target="#why-do-actuaries-use-glms">Why do actuaries use GLMs?</a></li>
  </ul></li>
  <li><a href="#stochastic-forecasts" id="toc-stochastic-forecasts" class="nav-link" data-scroll-target="#stochastic-forecasts">Stochastic Forecasts</a>
  <ul class="collapse">
  <li><a href="#stock-price-forecasting" id="toc-stock-price-forecasting" class="nav-link" data-scroll-target="#stock-price-forecasting">Stock price forecasting</a></li>
  <li><a href="#noisy-auto-regressive-forecast" id="toc-noisy-auto-regressive-forecast" class="nav-link" data-scroll-target="#noisy-auto-regressive-forecast">Noisy auto-regressive forecast</a></li>
  <li><a href="#original-forecast" id="toc-original-forecast" class="nav-link" data-scroll-target="#original-forecast">Original forecast</a></li>
  <li><a href="#with-noise" id="toc-with-noise" class="nav-link" data-scroll-target="#with-noise">With noise</a></li>
  <li><a href="#with-noise-1" id="toc-with-noise-1" class="nav-link" data-scroll-target="#with-noise-1">With noise</a></li>
  <li><a href="#with-noise-2" id="toc-with-noise-2" class="nav-link" data-scroll-target="#with-noise-2">With noise</a></li>
  <li><a href="#many-noisy-forecasts" id="toc-many-noisy-forecasts" class="nav-link" data-scroll-target="#many-noisy-forecasts">Many noisy forecasts</a></li>
  <li><a href="#prediction-intervals" id="toc-prediction-intervals" class="nav-link" data-scroll-target="#prediction-intervals">95% “prediction intervals”</a></li>
  <li><a href="#residuals" id="toc-residuals" class="nav-link" data-scroll-target="#residuals">Residuals</a></li>
  <li><a href="#q-q-plot-and-p-p-plot" id="toc-q-q-plot-and-p-p-plot" class="nav-link" data-scroll-target="#q-q-plot-and-p-p-plot">Q-Q plot and P-P plot</a></li>
  </ul></li>
  <li><a href="#glms-and-neural-networks" id="toc-glms-and-neural-networks" class="nav-link" data-scroll-target="#glms-and-neural-networks">GLMs and Neural Networks</a>
  <ul class="collapse">
  <li><a href="#code-data" id="toc-code-data" class="nav-link" data-scroll-target="#code-data">Code: Data</a></li>
  <li><a href="#code-preprocessing" id="toc-code-preprocessing" class="nav-link" data-scroll-target="#code-preprocessing">Code: Preprocessing</a></li>
  <li><a href="#code-preprocessing-1" id="toc-code-preprocessing-1" class="nav-link" data-scroll-target="#code-preprocessing-1">Code: Preprocessing</a></li>
  <li><a href="#histogram-of-the-claimamount" id="toc-histogram-of-the-claimamount" class="nav-link" data-scroll-target="#histogram-of-the-claimamount">Histogram of the <code>ClaimAmount</code></a></li>
  <li><a href="#gamma-glm" id="toc-gamma-glm" class="nav-link" data-scroll-target="#gamma-glm">Gamma GLM</a></li>
  <li><a href="#gamma-glm-loss" id="toc-gamma-glm-loss" class="nav-link" data-scroll-target="#gamma-glm-loss">Gamma GLM loss</a></li>
  <li><a href="#fitting-steps" id="toc-fitting-steps" class="nav-link" data-scroll-target="#fitting-steps">Fitting Steps</a></li>
  <li><a href="#code-gamma-glm" id="toc-code-gamma-glm" class="nav-link" data-scroll-target="#code-gamma-glm">Code: Gamma GLM</a></li>
  <li><a href="#ann-can-feed-into-a-glm" id="toc-ann-can-feed-into-a-glm" class="nav-link" data-scroll-target="#ann-can-feed-into-a-glm">ANN can feed into a GLM</a></li>
  </ul></li>
  <li><a href="#combined-actuarial-neural-network" id="toc-combined-actuarial-neural-network" class="nav-link" data-scroll-target="#combined-actuarial-neural-network">Combined Actuarial Neural Network</a>
  <ul class="collapse">
  <li><a href="#cann" id="toc-cann" class="nav-link" data-scroll-target="#cann">CANN</a></li>
  <li><a href="#architecture" id="toc-architecture" class="nav-link" data-scroll-target="#architecture">Architecture</a></li>
  <li><a href="#code-architecture" id="toc-code-architecture" class="nav-link" data-scroll-target="#code-architecture">Code: Architecture</a></li>
  <li><a href="#code-loss-function" id="toc-code-loss-function" class="nav-link" data-scroll-target="#code-loss-function">Code: Loss Function</a></li>
  <li><a href="#code-model-training" id="toc-code-model-training" class="nav-link" data-scroll-target="#code-model-training">Code: Model Training</a></li>
  </ul></li>
  <li><a href="#mixture-density-network" id="toc-mixture-density-network" class="nav-link" data-scroll-target="#mixture-density-network">Mixture Density Network</a>
  <ul class="collapse">
  <li><a href="#mixture-distribution" id="toc-mixture-distribution" class="nav-link" data-scroll-target="#mixture-distribution">Mixture Distribution</a></li>
  <li><a href="#mixture-distribution-1" id="toc-mixture-distribution-1" class="nav-link" data-scroll-target="#mixture-distribution-1">Mixture Distribution</a></li>
  <li><a href="#mixture-density-network-1" id="toc-mixture-density-network-1" class="nav-link" data-scroll-target="#mixture-density-network-1">Mixture Density Network</a></li>
  <li><a href="#mixture-density-network-2" id="toc-mixture-density-network-2" class="nav-link" data-scroll-target="#mixture-density-network-2">Mixture Density Network</a></li>
  <li><a href="#model-specification" id="toc-model-specification" class="nav-link" data-scroll-target="#model-specification">Model Specification</a></li>
  <li><a href="#output" id="toc-output" class="nav-link" data-scroll-target="#output">Output</a></li>
  <li><a href="#architecture-1" id="toc-architecture-1" class="nav-link" data-scroll-target="#architecture-1">Architecture</a></li>
  <li><a href="#code-architecture-1" id="toc-code-architecture-1" class="nav-link" data-scroll-target="#code-architecture-1">Code: Architecture</a></li>
  <li><a href="#loss-function" id="toc-loss-function" class="nav-link" data-scroll-target="#loss-function">Loss Function</a></li>
  <li><a href="#code-loss-function-1" id="toc-code-loss-function-1" class="nav-link" data-scroll-target="#code-loss-function-1">Code: Loss Function</a></li>
  <li><a href="#code-model-training-1" id="toc-code-model-training-1" class="nav-link" data-scroll-target="#code-model-training-1">Code: Model Training</a></li>
  </ul></li>
  <li><a href="#metrics-for-distributional-regression" id="toc-metrics-for-distributional-regression" class="nav-link" data-scroll-target="#metrics-for-distributional-regression">Metrics for Distributional Regression</a>
  <ul class="collapse">
  <li><a href="#proper-scoring-rules" id="toc-proper-scoring-rules" class="nav-link" data-scroll-target="#proper-scoring-rules">Proper Scoring Rules</a></li>
  <li><a href="#proper-scoring-rules-1" id="toc-proper-scoring-rules-1" class="nav-link" data-scroll-target="#proper-scoring-rules-1">Proper Scoring Rules</a></li>
  <li><a href="#code-nll" id="toc-code-nll" class="nav-link" data-scroll-target="#code-nll">Code: NLL</a></li>
  <li><a href="#model-comparisons" id="toc-model-comparisons" class="nav-link" data-scroll-target="#model-comparisons">Model Comparisons</a></li>
  </ul></li>
  <li><a href="#aleatoric-and-epistemic-uncertainty" id="toc-aleatoric-and-epistemic-uncertainty" class="nav-link" data-scroll-target="#aleatoric-and-epistemic-uncertainty">Aleatoric and Epistemic Uncertainty</a>
  <ul class="collapse">
  <li><a href="#categories-of-uncertainty" id="toc-categories-of-uncertainty" class="nav-link" data-scroll-target="#categories-of-uncertainty">Categories of uncertainty</a></li>
  <li><a href="#aleatoric-uncertainty" id="toc-aleatoric-uncertainty" class="nav-link" data-scroll-target="#aleatoric-uncertainty">Aleatoric Uncertainty</a></li>
  <li><a href="#epistemic-uncertainty" id="toc-epistemic-uncertainty" class="nav-link" data-scroll-target="#epistemic-uncertainty">Epistemic Uncertainty</a></li>
  <li><a href="#sources-of-uncertainty" id="toc-sources-of-uncertainty" class="nav-link" data-scroll-target="#sources-of-uncertainty">Sources of uncertainty</a></li>
  
  
  
  
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="distributional-regression.slides.html"><i class="bi bi-file-slides"></i>RevealJS</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../Distributional-Regression/distributional-regression.html">Module 7</a></li><li class="breadcrumb-item"><a href="../Distributional-Regression/distributional-regression.html">Distributional Regression</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Distributional Regression</h1>
<p class="subtitle lead">ACTL3143 &amp; ACTL5111 Deep Learning for Actuaries</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Patrick Laub </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="acknowledgments" class="level4">
<h4 class="anchored" data-anchor-id="acknowledgments">Acknowledgments</h4>
<p>Thanks to Eric Dong for making the original version of these slides.</p>
<div id="f51cad18" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Show the package imports</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy.random <span class="im">as</span> rnd</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> set_config</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>set_config(transform_output<span class="op">=</span><span class="st">"pandas"</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tf_keras</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tf_keras.callbacks <span class="im">import</span> EarlyStopping</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tf_keras.layers <span class="im">import</span> Dense</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tf_keras.models <span class="im">import</span> Sequential</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tf_keras.layers <span class="im">import</span> Input, Dense, Concatenate</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tf_keras.models <span class="im">import</span> Model</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tf_keras.initializers <span class="im">import</span> Constant</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> make_column_transformer</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OrdinalEncoder</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="traditional-regression" class="level2" data-visibility="uncounted">
<h2 data-visibility="uncounted" class="anchored" data-anchor-id="traditional-regression">Traditional Regression</h2>
<section id="traditional-regression-1" class="level3">
<h3 class="anchored" data-anchor-id="traditional-regression-1">Traditional Regression</h3>
<p>Multiple linear regression assumes the data-generating process is</p>
<p><span class="math display">Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \ldots + \beta_p x_{ip} + \varepsilon</span></p>
<p>where <span class="math inline">\varepsilon \sim \mathcal{N}(0, \sigma^2)</span>.</p>
<p>We estimate the coefficients <span class="math inline">\beta_0, \beta_1, \ldots, \beta_p</span> by minimising the sum of squared residuals or mean squared error</p>
<p><span class="math display">\text{RSS} := \sum_{i=1}^n (y_i - \hat{y}_i)^2
, \quad \text{MSE} := \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2 ,
</span></p>
<p>where <span class="math inline">\hat{y}_i</span> is the predicted value for the <span class="math inline">i</span>th observation.</p>
</section>
<section id="visualising-the-distribution-of-each-y" class="level3">
<h3 class="anchored" data-anchor-id="visualising-the-distribution-of-each-y">Visualising the distribution of each <span class="math inline">Y</span></h3>
<div id="0135e919" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate sample data for linear regression</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>np.random.shuffle(X)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>beta_0 <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>beta_1 <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> beta_0 <span class="op">+</span> beta_1 <span class="op">*</span> X <span class="op">+</span> np.random.normal(scale<span class="op">=</span><span class="dv">2</span>, size<span class="op">=</span>X.shape)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a simple linear regression model</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>coefficients <span class="op">=</span> np.polyfit(X, y, <span class="dv">1</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>predicted_y <span class="op">=</span> np.polyval(coefficients, X)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data points and the fitted line</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>plt.scatter(X, y, label<span class="op">=</span><span class="st">'Data Points'</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>plt.plot(X, predicted_y, color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Fitted Line'</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw the normal distribution bell curve sideways at each data point</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(X)):</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> predicted_y[i]</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> <span class="dv">2</span>  <span class="co"># Assuming a standard deviation for the normal distribution</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    y_values <span class="op">=</span> np.linspace(mu <span class="op">-</span> <span class="dv">4</span><span class="op">*</span>sigma, mu <span class="op">+</span> <span class="dv">4</span><span class="op">*</span>sigma, <span class="dv">100</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    x_values <span class="op">=</span> stats.norm.pdf(y_values, mu, sigma) <span class="op">+</span> X[i]</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    plt.plot(x_values, y_values, color<span class="op">=</span><span class="st">'blue'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'$x$'</span>)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'$y$'</span>)</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="distributional-regression_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="the-probabilistic-view" class="level3">
<h3 class="anchored" data-anchor-id="the-probabilistic-view">The probabilistic view</h3>
<p><span class="math display">Y_i \sim \mathcal{N}(\mu_i, \sigma^2)</span></p>
<p>where <span class="math inline">\mu_i = \beta_0 + \beta_1 x_{i1} + \ldots + \beta_p x_{ip}</span>, and the <span class="math inline">\sigma^2</span> is known.</p>
<p>The <span class="math inline">\mathcal{N}(\mu, \sigma^2)</span> normal distribution has p.d.f.</p>
<p><span class="math display">f(y) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y - \mu)^2}{2\sigma^2}\right) .</span></p>
<p>The likelihood function is</p>
<p><span class="math display">
L(\boldsymbol{\beta}) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y_i - \mu_i)^2}{2\sigma^2}\right)
</span> <span class="math display">
\Rightarrow \ell(\boldsymbol{\beta}) = -\frac{n}{2}\log(2\pi) - \frac{n}{2}\log(\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i - \mu_i)^2 .
</span></p>
<p>Perform maximum likelihood estimation to find <span class="math inline">\boldsymbol{\beta}</span>.</p>
</section>
<section id="the-predicted-distributions" class="level3">
<h3 class="anchored" data-anchor-id="the-predicted-distributions">The predicted distributions</h3>
<div id="3edfaddf" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> np.polyval(coefficients, X[:<span class="dv">4</span>])</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">4</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="fl">5.0</span>, <span class="fl">3.0</span>))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>x_min <span class="op">=</span> y_pred[:<span class="dv">4</span>].min() <span class="op">-</span> <span class="dv">4</span><span class="op">*</span>sigma</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>x_max <span class="op">=</span> y_pred[:<span class="dv">4</span>].max() <span class="op">+</span> <span class="dv">4</span><span class="op">*</span>sigma</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>x_grid <span class="op">=</span> np.linspace(x_min, x_max, <span class="dv">100</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot each normal distribution with different means vertically</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axes):</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> y_pred[i]</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    y_grid <span class="op">=</span> stats.norm.pdf(x_grid, mu, sigma)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    ax.plot(x_grid, y_grid)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="ss">f'$f(y ; </span><span class="ch">\\</span><span class="ss">boldsymbol</span><span class="ch">{{</span><span class="ss">x</span><span class="ch">}}</span><span class="ss">_</span><span class="ch">{{</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ch">}}</span><span class="ss">)$'</span>)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    ax.set_xticks([y_pred[i]], labels<span class="op">=</span>[<span class="vs">r'$\mu_{'</span> <span class="op">+</span> <span class="bu">str</span>(i<span class="op">+</span><span class="dv">1</span>) <span class="op">+</span> <span class="vs">r'}$'</span>])</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="distributional-regression_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="the-machine-learning-view" class="level3">
<h3 class="anchored" data-anchor-id="the-machine-learning-view">The machine learning view</h3>
<p>The negative log-likelihood <span class="math inline">\text{NLL}(\boldsymbol{\beta}) := -\ell(\boldsymbol{\beta})</span> is to be minimised:</p>
<p><span class="math display">
\text{NLL}(\boldsymbol{\beta})
= \frac{n}{2}\log(2\pi) + \frac{n}{2}\log(\sigma^2) + \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i - \mu_i)^2 .
</span></p>
<p>As <span class="math inline">\sigma^2</span> is fixed, minimising NLL is equivalent to minimising MSE:</p>
<p><span class="math display">
\begin{aligned}
\widehat{\boldsymbol{\beta}}
&amp;= \underset{\boldsymbol{\beta}}{\operatorname{arg\,min}}\,\, \text{NLL}(\boldsymbol{\beta}) \\
&amp;= \underset{\boldsymbol{\beta}}{\operatorname{arg\,min}}\,\, \frac{n}{2}\log(2\pi) + \frac{n}{2}\log(\sigma^2) + \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i - \mu_i)^2 \\
&amp;= \underset{\boldsymbol{\beta}}{\operatorname{arg\,min}}\,\, \frac{1}{n} \sum_{i=1}^n \Bigl( y_i - \hat{y}_i(\boldsymbol{x}_i; \boldsymbol{\beta}) \Bigr)^2 \\
&amp;= \underset{\boldsymbol{\beta}}{\operatorname{arg\,min}}\,\, \text{MSE}\bigl( \boldsymbol{y}, \hat{\boldsymbol{y}}(\boldsymbol{\mathbf{X}}; \boldsymbol{\beta}) \bigr).
\end{aligned}
</span></p>
</section>
<section id="generalised-linear-model-glm" class="level3">
<h3 class="anchored" data-anchor-id="generalised-linear-model-glm">Generalised Linear Model (GLM)</h3>
<p>The GLM is often characterised by the mean prediction:</p>
<p><span class="math display">
\mu(\boldsymbol{x}; \boldsymbol{\beta}) = g^{-1} \left(\left\langle \boldsymbol{\beta}, \boldsymbol{x} \right\rangle\right)
</span></p>
<p>where <span class="math inline">g</span> is the link function.</p>
<p>Common GLM distributions for the response variable include:</p>
<ul>
<li>Normal distribution with identity link (just MLR)</li>
<li>Bernoulli distribution with logit link (logistic regression)</li>
<li>Poisson distribution with log link (Poisson regression)</li>
<li>Gamma distribution with log link</li>
</ul>
</section>
<section id="logistic-regression" class="level3">
<h3 class="anchored" data-anchor-id="logistic-regression">Logistic regression</h3>
<p>A Bernoulli distribution with parameter <span class="math inline">p</span> has p.m.f.</p>
<p><span class="math display">
f(y)\ =\ \begin{cases}
p &amp; \text{if } y = 1 \\
1 - p &amp; \text{if } y = 0
\end{cases}
\ =\ p^y (1 - p)^{1 - y}.
</span></p>
<p>Our model is <span class="math inline">Y|\boldsymbol{X}=\boldsymbol{x}</span> follows a Bernoulli distribution with parameter</p>
<p><span class="math display">
\mu(\boldsymbol{x}; \boldsymbol{\beta}) = \frac{1}{1 + \exp\left(-\left\langle \boldsymbol{\beta}, \boldsymbol{x} \right\rangle\right)} = \mathbb{P}(Y=1|\boldsymbol{X}=\boldsymbol{x}).
</span></p>
<p>The likelihood function, using <span class="math inline">\mu_i := \mu(\boldsymbol{x}_i; \boldsymbol{\beta})</span>, is</p>
<p><span class="math display">
L(\boldsymbol{\beta})
\ =\ \prod_{i=1}^n \begin{cases}
\mu_i &amp; \text{if } y_i = 1 \\
1 - \mu_i &amp; \text{if } y_i = 0
\end{cases}
\ =\ \prod_{i=1}^n \mu_i^{y_i} (1 - \mu_i)^{1 - y_i} .
</span></p>
</section>
<section id="binary-cross-entropy-loss" class="level3">
<h3 class="anchored" data-anchor-id="binary-cross-entropy-loss">Binary cross-entropy loss</h3>
<p><span class="math display">
L(\boldsymbol{\beta}) = \prod_{i=1}^n \mu_i^{y_i} (1 - \mu_i)^{1 - y_i}
\Rightarrow \ell(\boldsymbol{\beta}) = \sum_{i=1}^n \Bigl( y_i \log(\mu_i) + (1 - y_i) \log(1 - \mu_i) \Bigr).
</span></p>
<p>The negative log-likelihood is</p>
<p><span class="math display">
\text{NLL}(\boldsymbol{\beta}) = -\sum_{i=1}^n \Bigl( y_i \log(\mu_i) + (1 - y_i) \log(1 - \mu_i) \Bigr).
</span></p>
<p>The binary cross-entropy loss is identical: <span class="math display">
\text{BCE}(\boldsymbol{y}, \boldsymbol{\mu}) = -\sum_{i=1}^n \Bigl( y_i \log(\mu_i) + (1 - y_i) \log(1 - \mu_i) \Bigr).
</span></p>
</section>
<section id="poisson-regression" class="level3">
<h3 class="anchored" data-anchor-id="poisson-regression">Poisson regression</h3>
<p>A Poisson distribution with rate <span class="math inline">\lambda</span> has p.m.f. <span class="math display">
f(y) = \frac{\lambda^y \exp(-\lambda)}{y!}.
</span></p>
<p>Our model is <span class="math inline">Y|\boldsymbol{X}=\boldsymbol{x}</span> is Poisson distributed with parameter</p>
<p><span class="math display">
\mu(\boldsymbol{x}; \boldsymbol{\beta}) = \exp\left(\left\langle \boldsymbol{\beta}, \boldsymbol{x} \right\rangle\right) .
</span></p>
<p>The likelihood function is</p>
<p><span class="math display">
L(\boldsymbol{\beta}) = \prod_{i=1}^n \frac{ \mu_i^{y_i} \exp(-\mu_i) }{y_i!}
</span> <span class="math display">
\Rightarrow \ell(\boldsymbol{\beta}) = \sum_{i=1}^n \Bigl( -\mu_i + y_i \log(\mu_i) - \log(y_i!) \Bigr).
</span></p>
</section>
<section id="poisson-loss" class="level3">
<h3 class="anchored" data-anchor-id="poisson-loss">Poisson loss</h3>
<p>The negative log-likelihood is</p>
<p><span class="math display">
\text{NLL}(\boldsymbol{\beta}) = \sum_{i=1}^n \Bigl( \mu_i - y_i \log(\mu_i) + \log(y_i!) \Bigr) .
</span></p>
<p>The Poisson loss is</p>
<p><span class="math display">
\text{Poisson}(\boldsymbol{y}, \boldsymbol{\mu}) = \sum_{i=1}^n \Bigl( \mu_i - y_i \log(\mu_i) \Bigr).
</span></p>
</section>
<section id="gamma-regression" class="level3">
<h3 class="anchored" data-anchor-id="gamma-regression">Gamma regression</h3>
<p>A gamma distribution with mean <span class="math inline">\mu</span> and dispersion <span class="math inline">\phi</span> has p.d.f. <span class="math display">
f(y; \mu, \phi) = \frac{(\mu \phi)^{-\frac{1}{\phi}}}{\Gamma\left(\frac{1}{\phi}\right)} y^{\frac{1}{\phi} - 1} \mathrm{e}^{-\frac{y}{\mu \phi}}
</span></p>
<p>Our model is <span class="math inline">Y|\boldsymbol{X}=\boldsymbol{x}</span> is gamma distributed with a dispersion of <span class="math inline">\phi</span> and a mean of <span class="math inline">\mu(\boldsymbol{x}; \boldsymbol{\beta}) = \exp\left(\left\langle \boldsymbol{\beta}, \boldsymbol{x} \right\rangle\right)</span>.</p>
<p>The likelihood function is <span class="math display">
L(\boldsymbol{\beta}) = \prod_{i=1}^n \frac{(\mu_i \phi)^{-\frac{1}{\phi}}}{\Gamma\left(\frac{1}{\phi}\right)} y_i^{\frac{1}{\phi} - 1} \exp\left(-\frac{y_i}{\mu_i \phi}\right)
</span></p>
<p><span class="math display">
\Rightarrow \ell(\boldsymbol{\beta}) = \sum_{i=1}^n \left[ -\frac{1}{\phi} \log(\mu_i \phi) - \log \Gamma\left(\frac{1}{\phi}\right) + \left(\frac{1}{\phi} - 1\right) \log(y_i) - \frac{y_i}{\mu_i \phi} \right].
</span></p>
</section>
<section id="gamma-loss" class="level3">
<h3 class="anchored" data-anchor-id="gamma-loss">Gamma loss</h3>
<p>The negative log-likelihood is</p>
<p><span class="math display">
\text{NLL}(\boldsymbol{\beta}) = \sum_{i=1}^n \left[ \frac{1}{\phi} \log(\mu_i \phi) + \log \Gamma\left(\frac{1}{\phi}\right) - \left(\frac{1}{\phi} - 1\right) \log(y_i) + \frac{y_i}{\mu_i \phi} \right].
</span></p>
<p>Since <span class="math inline">\phi</span> is a nuisance parameter <span class="math display">
\text{NLL}(\boldsymbol{\beta})
= \sum_{i=1}^n \left[ \frac{1}{\phi} \log(\mu_i) + \frac{y_i}{\mu_i \phi} \right] + \text{const}
\propto \sum_{i=1}^n \left[ \log(\mu_i) + \frac{y_i}{\mu_i} \right].
</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>As <span class="math inline">\log(\mu_i) = \log(y_i) - \log(y_i / \mu_i)</span>, we could write an alternative version <span class="math display">
\text{NLL}(\boldsymbol{\beta})
\propto \sum_{i=1}^n \left[ \log(y_i) - \log\Bigl(\frac{y_i}{\mu_i}\Bigr) + \frac{y_i}{\mu_i} \right]
\propto \sum_{i=1}^n \left[ \frac{y_i}{\mu_i} - \log\Bigl(\frac{y_i}{\mu_i}\Bigr) \right].
</span></p>
</div>
</div>
</section>
<section id="why-do-actuaries-use-glms" class="level3">
<h3 class="anchored" data-anchor-id="why-do-actuaries-use-glms">Why do actuaries use GLMs?</h3>
<ul>
<li>GLMs are interpretable.</li>
<li>GLMs are flexible (can handle different types of response variables).</li>
<li>We get the full distribution of the response variable, not just the mean.</li>
</ul>
<p>This last point is particularly important for analysing worst-case scenarios.</p>
</section>
</section>
<section id="stochastic-forecasts" class="level2" data-visibility="uncounted">
<h2 data-visibility="uncounted" class="anchored" data-anchor-id="stochastic-forecasts">Stochastic Forecasts</h2>
<section id="stock-price-forecasting" class="level3">
<h3 class="anchored" data-anchor-id="stock-price-forecasting">Stock price forecasting</h3>
<div id="5d4163c3" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lagged_timeseries(df, target, window<span class="op">=</span><span class="dv">30</span>):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    lagged <span class="op">=</span> pd.DataFrame()</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(window, <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        lagged[<span class="ss">f"T-</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>] <span class="op">=</span> df[target].shift(i)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    lagged[<span class="st">"T"</span>] <span class="op">=</span> df[target].values</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> lagged</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>stocks <span class="op">=</span> pd.read_csv(<span class="st">"../Time-Series-And-Recurrent-Neural-Networks/aus_fin_stocks.csv"</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>stocks[<span class="st">"Date"</span>] <span class="op">=</span> pd.to_datetime(stocks[<span class="st">"Date"</span>])</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>stocks <span class="op">=</span> stocks.set_index(<span class="st">"Date"</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> stocks.pop(<span class="st">"ASX200"</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>stock <span class="op">=</span> stocks[[<span class="st">"CBA"</span>]]</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>stock <span class="op">=</span> stock.ffill()</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>df_lags <span class="op">=</span> lagged_timeseries(stock, <span class="st">"CBA"</span>, <span class="dv">40</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data in time</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> df_lags.loc[:<span class="st">"2018"</span>]</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>X_val <span class="op">=</span> df_lags.loc[<span class="st">"2019"</span>]</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> df_lags.loc[<span class="st">"2020"</span>:]</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove any with NAs and split into X and y</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train.dropna()</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>X_val <span class="op">=</span> X_val.dropna()</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X_test.dropna()</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> X_train.pop(<span class="st">"T"</span>)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>y_val <span class="op">=</span> X_val.pop(<span class="st">"T"</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> X_test.pop(<span class="st">"T"</span>)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train <span class="op">/</span> <span class="dv">100</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>X_val <span class="op">=</span> X_val <span class="op">/</span> <span class="dv">100</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X_test <span class="op">/</span> <span class="dv">100</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> y_train <span class="op">/</span> <span class="dv">100</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>y_val <span class="op">=</span> y_val <span class="op">/</span> <span class="dv">100</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> y_test <span class="op">/</span> <span class="dv">100</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> LinearRegression()</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>lr.fit(X_train, y_train)<span class="op">;</span></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>stocks.plot()</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Stock Price"</span>)</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"upper center"</span>, bbox_to_anchor<span class="op">=</span>(<span class="fl">0.5</span>, <span class="op">-</span><span class="fl">0.5</span>), ncol<span class="op">=</span><span class="dv">4</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="distributional-regression_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="noisy-auto-regressive-forecast" class="level3">
<h3 class="anchored" data-anchor-id="noisy-auto-regressive-forecast">Noisy auto-regressive forecast</h3>
<div id="037bf5a2" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> noisy_autoregressive_forecast(model, X_val, sigma, suppress<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Generate a multi-step forecast using the given model.</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    multi_step <span class="op">=</span> pd.Series(index<span class="op">=</span>X_val.index, name<span class="op">=</span><span class="st">"Multi Step"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize the input data for forecasting</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    input_data <span class="op">=</span> X_val.iloc[<span class="dv">0</span>].values.reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(multi_step)):</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ensure input_data has the correct feature names</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        input_df <span class="op">=</span> pd.DataFrame(input_data, columns<span class="op">=</span>X_val.columns)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> suppress:</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>            next_value <span class="op">=</span> model.predict(input_df, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>            next_value <span class="op">=</span> model.predict(input_df)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        next_value <span class="op">+=</span> np.random.normal(<span class="dv">0</span>, sigma)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        multi_step.iloc[i] <span class="op">=</span> next_value</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Append that prediction to the input for the next forecast</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">+</span> <span class="dv">1</span> <span class="op">&lt;</span> <span class="bu">len</span>(multi_step):</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>            input_data <span class="op">=</span> np.append(input_data[:, <span class="dv">1</span>:], next_value).reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> multi_step</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="original-forecast" class="level3">
<h3 class="anchored" data-anchor-id="original-forecast">Original forecast</h3>
<div id="2e595e93" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>lr_forecast <span class="op">=</span> noisy_autoregressive_forecast(lr, X_val, <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="15273020" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>stock.loc[lr_forecast.index, <span class="st">"AR Linear"</span>] <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> lr_forecast</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_forecasts(stock):</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    stock.loc[<span class="st">"2018-12"</span>:<span class="st">"2019"</span>].plot()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    plt.axvline(<span class="st">"2019"</span>, color<span class="op">=</span><span class="st">"black"</span>, linestyle<span class="op">=</span><span class="st">"--"</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Stock Price"</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    plt.legend(loc<span class="op">=</span><span class="st">"center left"</span>, bbox_to_anchor<span class="op">=</span>(<span class="dv">1</span>, <span class="fl">0.5</span>))</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>plot_forecasts(stock)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="distributional-regression_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="20e8eb7e" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> y_train <span class="op">-</span> lr.predict(X_train)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> np.std(residuals)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="with-noise" class="level3">
<h3 class="anchored" data-anchor-id="with-noise">With noise</h3>
<div id="9b2457a4" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>lr_noisy_forecast <span class="op">=</span> noisy_autoregressive_forecast(lr, X_val, sigma)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cdc66ff3" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>stock.loc[lr_noisy_forecast.index, <span class="st">"AR Noisy Linear"</span>] <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> lr_noisy_forecast</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>plot_forecasts(stock)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="distributional-regression_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="with-noise-1" class="level3" data-visibility="uncounted">
<h3 data-visibility="uncounted" class="anchored" data-anchor-id="with-noise-1">With noise</h3>
<div id="98e6e74f" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">2</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>lr_noisy_forecast <span class="op">=</span> noisy_autoregressive_forecast(lr, X_val, sigma)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="ba14a54e" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>stock.loc[lr_noisy_forecast.index, <span class="st">"AR Noisy Linear"</span>] <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> lr_noisy_forecast</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>plot_forecasts(stock)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="distributional-regression_files/figure-html/cell-14-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="with-noise-2" class="level3" data-visibility="uncounted">
<h3 data-visibility="uncounted" class="anchored" data-anchor-id="with-noise-2">With noise</h3>
<div id="0245a371" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">3</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>lr_noisy_forecast <span class="op">=</span> noisy_autoregressive_forecast(lr, X_val, sigma)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="1ea4a315" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>stock.loc[lr_noisy_forecast.index, <span class="st">"AR Noisy Linear"</span>] <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> lr_noisy_forecast</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>plot_forecasts(stock)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="distributional-regression_files/figure-html/cell-16-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="many-noisy-forecasts" class="level3" data-visibility="uncounted">
<h3 data-visibility="uncounted" class="anchored" data-anchor-id="many-noisy-forecasts">Many noisy forecasts</h3>
<div id="68f181fa" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>num_forecasts <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>forecasts <span class="op">=</span> []</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_forecasts):</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    forecasts.append(noisy_autoregressive_forecast(lr, X_val, sigma) <span class="op">*</span> <span class="dv">100</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>noisy_forecasts <span class="op">=</span> pd.concat(forecasts, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>noisy_forecasts.index <span class="op">=</span> X_val.index</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="e5a671db" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>noisy_forecasts.loc[<span class="st">"2018-12"</span>:<span class="st">"2019"</span>].plot(legend<span class="op">=</span><span class="va">False</span>, alpha<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Stock Price"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="distributional-regression_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="prediction-intervals" class="level3">
<h3 class="anchored" data-anchor-id="prediction-intervals">95% “prediction intervals”</h3>
<div id="f0a66fce" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate quantiles for the forecasts</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>lower_quantile <span class="op">=</span> noisy_forecasts.quantile(<span class="fl">0.025</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>upper_quantile <span class="op">=</span> noisy_forecasts.quantile(<span class="fl">0.975</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>mean_forecast <span class="op">=</span> noisy_forecasts.mean(axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="5adb3126" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the mean forecast</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">3</span>))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>plt.plot(stock.loc[<span class="st">"2018-12"</span>:<span class="st">"2019"</span>].index, stock.loc[<span class="st">"2018-12"</span>:<span class="st">"2019"</span>][<span class="st">"CBA"</span>], label<span class="op">=</span><span class="st">"CBA"</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>plt.plot(mean_forecast, label<span class="op">=</span><span class="st">"Mean"</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the quantile-based shaded area</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>plt.fill_between(mean_forecast.index, </span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>                 lower_quantile, </span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>                 upper_quantile, </span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>                 color<span class="op">=</span><span class="st">"grey"</span>, alpha<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot settings</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>plt.axvline(pd.Timestamp(<span class="st">"2019-01-01"</span>), color<span class="op">=</span><span class="st">"black"</span>, linestyle<span class="op">=</span><span class="st">"--"</span>)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"center left"</span>, bbox_to_anchor<span class="op">=</span>(<span class="dv">1</span>, <span class="fl">0.5</span>))</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Date"</span>)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Stock Price"</span>)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="distributional-regression_files/figure-html/cell-20-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="residuals" class="level3">
<h3 class="anchored" data-anchor-id="residuals">Residuals</h3>
<div class="columns">
<div class="column">
<div id="4249f447" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> lr.predict(X_train)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> y_train <span class="op">-</span> y_pred</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">-=</span> np.mean(residuals)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">/=</span> np.std(residuals)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>stats.shapiro(residuals)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/plaub/miniconda3/envs/ai2024/lib/python3.11/site-packages/scipy/stats/_morestats.py:1882: UserWarning: p-value may not be accurate for N &gt; 5000.
  warnings.warn("p-value may not be accurate for N &gt; 5000.")</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>ShapiroResult(statistic=0.9038059115409851, pvalue=0.0)</code></pre>
</div>
</div>
<div class="fragment callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Probably should model the log-returns instead of the stock prices.</p>
</div>
</div>
</div><div class="column">
<div id="f7a957c1" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>plt.hist(residuals, bins<span class="op">=</span><span class="dv">40</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">100</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>plt.xlim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>plt.plot(x, stats.norm.pdf(x, <span class="dv">0</span>, <span class="dv">1</span>))<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="distributional-regression_files/figure-html/cell-23-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="q-q-plot-and-p-p-plot" class="level3" data-visibility="uncounted">
<h3 data-visibility="uncounted" class="anchored" data-anchor-id="q-q-plot-and-p-p-plot">Q-Q plot and P-P plot</h3>
<div class="columns">
<div class="column">
<div id="adefbe24" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>sm.qqplot(residuals, line<span class="op">=</span><span class="st">"45"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="distributional-regression_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</div><div class="column">
<div id="1ffc62fd" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>sm.ProbPlot(residuals).ppplot(line<span class="op">=</span><span class="st">"45"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="distributional-regression_files/figure-html/cell-25-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="glms-and-neural-networks" class="level2" data-visibility="uncounted">
<h2 data-visibility="uncounted" class="anchored" data-anchor-id="glms-and-neural-networks">GLMs and Neural Networks</h2>
<section id="code-data" class="level3">
<h3 class="anchored" data-anchor-id="code-data">Code: Data</h3>
<div id="bd4a64ac" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="annotated-cell-18"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-18-1"><a href="#annotated-cell-18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-18" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-18-2" class="code-annotation-target"><a href="#annotated-cell-18-2" aria-hidden="true" tabindex="-1"></a>sev_df <span class="op">=</span> pd.read_csv(<span class="st">'freMTPL2sev.csv'</span>)</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-18" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-18-3" class="code-annotation-target"><a href="#annotated-cell-18-3" aria-hidden="true" tabindex="-1"></a>freq_df <span class="op">=</span> pd.read_csv(<span class="st">'freMTPL2freq.csv'</span>)</span>
<span id="annotated-cell-18-4"><a href="#annotated-cell-18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-18-5"><a href="#annotated-cell-18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a copy of freq dataframe without 'claimfreq' column</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-18" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-18-6" class="code-annotation-target"><a href="#annotated-cell-18-6" aria-hidden="true" tabindex="-1"></a>freq_without_claimfreq <span class="op">=</span> freq_df.drop(columns<span class="op">=</span>[<span class="st">'ClaimNb'</span>])</span>
<span id="annotated-cell-18-7"><a href="#annotated-cell-18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-18-8"><a href="#annotated-cell-18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge severity dataframe with freq_without_claimfreq dataframe</span></span>
<span id="annotated-cell-18-9"><a href="#annotated-cell-18-9" aria-hidden="true" tabindex="-1"></a>new_sev_df <span class="op">=</span> pd.merge(sev_df, freq_without_claimfreq, on<span class="op">=</span><span class="st">'IDpol'</span>, </span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-18" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-18-10" class="code-annotation-target"><a href="#annotated-cell-18-10" aria-hidden="true" tabindex="-1"></a>                                                      how<span class="op">=</span><span class="st">'left'</span>)</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-18" data-target-annotation="5" onclick="event.preventDefault();">5</a><span id="annotated-cell-18-11" class="code-annotation-target"><a href="#annotated-cell-18-11" aria-hidden="true" tabindex="-1"></a>new_sev_df <span class="op">=</span> new_sev_df.dropna()</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-18" data-target-annotation="6" onclick="event.preventDefault();">6</a><span id="annotated-cell-18-12" class="code-annotation-target"><a href="#annotated-cell-18-12" aria-hidden="true" tabindex="-1"></a>new_sev_df <span class="op">=</span> new_sev_df.drop(<span class="st">"IDpol"</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-18" data-target-annotation="7" onclick="event.preventDefault();">7</a><span id="annotated-cell-18-13" class="code-annotation-target"><a href="#annotated-cell-18-13" aria-hidden="true" tabindex="-1"></a>new_sev_df[:<span class="dv">2</span>]</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-18" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-18" data-code-lines="2" data-code-annotation="1">Imports <code>freMTPL2sev.csv</code> dataset</span>
</dd>
<dt data-target-cell="annotated-cell-18" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-18" data-code-lines="3" data-code-annotation="2">Imports <code>freMTPL2freq.csv</code> dataset</span>
</dd>
<dt data-target-cell="annotated-cell-18" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-18" data-code-lines="6" data-code-annotation="3">Drops <code>ClaimNb</code> column</span>
</dd>
<dt data-target-cell="annotated-cell-18" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-18" data-code-lines="10" data-code-annotation="4">Merges the two datasets ,<code>sev_df</code> and <code>freq_without_claimfreq</code> by matching the <code>IDpol</code> column. Assigning <code>how='left'</code> ensures that all rows from the left dataset <code>sev_df</code> is considered, and only the matching columns from <code>freq_without_claimfreq</code> are selected</span>
</dd>
<dt data-target-cell="annotated-cell-18" data-target-annotation="5">5</dt>
<dd>
<span data-code-cell="annotated-cell-18" data-code-lines="11" data-code-annotation="5">Drops missing values or/and NAN values</span>
</dd>
<dt data-target-cell="annotated-cell-18" data-target-annotation="6">6</dt>
<dd>
<span data-code-cell="annotated-cell-18" data-code-lines="12" data-code-annotation="6">Drops the <code>IDpol</code> column from <code>new_sev_df</code></span>
</dd>
<dt data-target-cell="annotated-cell-18" data-target-annotation="7">7</dt>
<dd>
<span data-code-cell="annotated-cell-18" data-code-lines="13" data-code-annotation="7">Retrieves first two rows of the dataset</span>
</dd>
</dl>
</div>
<div class="cell-output cell-output-display" data-execution_count="26">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">ClaimAmount</th>
<th data-quarto-table-cell-role="th">Exposure</th>
<th data-quarto-table-cell-role="th">VehPower</th>
<th data-quarto-table-cell-role="th">VehAge</th>
<th data-quarto-table-cell-role="th">DrivAge</th>
<th data-quarto-table-cell-role="th">BonusMalus</th>
<th data-quarto-table-cell-role="th">VehBrand</th>
<th data-quarto-table-cell-role="th">VehGas</th>
<th data-quarto-table-cell-role="th">Area</th>
<th data-quarto-table-cell-role="th">Density</th>
<th data-quarto-table-cell-role="th">Region</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>995.20</td>
<td>0.59</td>
<td>11.0</td>
<td>0.0</td>
<td>39.0</td>
<td>56.0</td>
<td>B12</td>
<td>Diesel</td>
<td>D</td>
<td>778.0</td>
<td>Picardie</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1128.12</td>
<td>0.95</td>
<td>4.0</td>
<td>1.0</td>
<td>49.0</td>
<td>50.0</td>
<td>B12</td>
<td>Regular</td>
<td>E</td>
<td>2354.0</td>
<td>Ile-de-France</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
</section>
<section id="code-preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="code-preprocessing">Code: Preprocessing</h3>
<p>Next we carry out some basic preprocessing</p>
<div id="fdc041c7" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  new_sev_df.drop(<span class="st">"ClaimAmount"</span>, axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  new_sev_df[<span class="st">"ClaimAmount"</span>],</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  random_state<span class="op">=</span><span class="dv">2023</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Reset each index to start at 0 again.</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train.reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X_test.reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> y_train.reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> y_test.reset_index(drop<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="code-preprocessing-1" class="level3">
<h3 class="anchored" data-anchor-id="code-preprocessing-1">Code: Preprocessing</h3>
<p>Next we define the column transfer. The column transfer first applies ordinal encoding to <code>VehBrand</code>, <code>Region</code>, <code>Area</code> and <code>VehGas</code> variables, and applies standard scaling to all remaining numerical values. Next we fit the defined column transfer to the training set. The fitted transformation is then applied on both training and test sets. (Note that the fitting is only carried out on the train set and the same fit is applied to both train, validation and test sets.)</p>
<p>Since this task does not apply entity embeddings, <code>VehBrand</code> and <code>Region</code> variables are dropped from the dataframe.</p>
<div id="47d93e45" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>ct <span class="op">=</span> make_column_transformer(</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  (OrdinalEncoder(), [<span class="st">"Area"</span>, <span class="st">"VehGas"</span>]),</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  (<span class="st">"drop"</span>, [<span class="st">"VehBrand"</span>, <span class="st">"Region"</span>]),</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  remainder<span class="op">=</span>StandardScaler(),</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>  verbose_feature_names_out<span class="op">=</span><span class="va">False</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> ct.fit_transform(X_train)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> ct.transform(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><span class="math inline">\texttt{VehGas=1}</span> if the car gas is regular.</li>
<li><span class="math inline">\texttt{Area=0}</span> represents the rural area, and <span class="math inline">\texttt{Area=5}</span> represents the urban center.</li>
</ul>
</section>
<section id="histogram-of-the-claimamount" class="level3">
<h3 class="anchored" data-anchor-id="histogram-of-the-claimamount">Histogram of the <code>ClaimAmount</code></h3>
<p>Plotting the empirical distribution of the target variable help us get an understanding of the inherent variability associated with the data.</p>
<div id="a05264e0" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>plt.hist(y_train[y_train <span class="op">&lt;</span> <span class="dv">5000</span>], bins<span class="op">=</span><span class="dv">30</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="distributional-regression_files/figure-html/cell-30-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The following section illustrates how embedding a GLM in a neural network architecture can help us quantify the uncertainty relating to the predictions coming from the neural network. The idea is to first fit a GLM, and use the predictions from the GLM and predictions from the neural network part to define a custom loss function. This embedding presents an opportunity to compute the dispersion parameter <span class="math inline">\phi_{CANN}</span> for the neural network. </p>
<p>The idea of GLM is to find a linear combination of independent variables <span class="math inline">\boldsymbol{x}</span> and coefficients <span class="math inline">\boldsymbol{\beta}</span>, apply a non-linear transformation (<span class="math inline">g^{-1}</span>) to that linear combination and set it equal to conditional mean of the response variable <span class="math inline">Y</span> given an instance <span class="math inline">\boldsymbol{x}</span>. The non-linear transformation provides added flexibility.</p>
</section>
<section id="gamma-glm" class="level3">
<h3 class="anchored" data-anchor-id="gamma-glm">Gamma GLM</h3>
<p>Suppose a fitted gamma GLM model has</p>
<ul>
<li>a log link function <span class="math inline">g(x)=\log(x)</span> and</li>
<li>regression coefficients <span class="math inline">\boldsymbol{\beta}=(\beta_0, \beta_1, \beta_2, \beta_3)</span>.</li>
</ul>
<p>Then, it estimates the conditional mean of <span class="math inline">Y</span> given a new instance <span class="math inline">\boldsymbol{x}=(1, x_1, x_2, x_3)</span> as follows: <span class="math display">
    \mathbb{E}[Y|\boldsymbol{X}=\boldsymbol{x}]=g^{-1}(\langle \boldsymbol{\beta}, \boldsymbol{x}\rangle)=\exp\big(\beta_0+ \beta_1x_1+\beta_2x_2+\beta_3x_3\big).
</span></p>
<p>A GLM can model any other exponential family distribution using an appropriate link function <span class="math inline">g</span>.</p>
</section>
<section id="gamma-glm-loss" class="level3">
<h3 class="anchored" data-anchor-id="gamma-glm-loss">Gamma GLM loss</h3>
<p>If <span class="math inline">Y|\boldsymbol{X}=\boldsymbol{x}</span> is a gamma r.v. with mean <span class="math inline">\mu(\boldsymbol{x}; \boldsymbol{\beta})</span> and dispersion parameter <span class="math inline">\phi</span>, we can minimise the negative log-likelihood (NLL) <span class="math display">
    \text{NLL} \propto \sum_{i=1}^{n}\log \mu (\boldsymbol{x}_i; \boldsymbol{\beta})+\frac{y_i}{\mu (\boldsymbol{x}_i; \boldsymbol{\beta})} + \text{const},
</span> i.e., we ignore the dispersion parameter <span class="math inline">\phi</span> while estimating the regression coefficients.</p>
</section>
<section id="fitting-steps" class="level3">
<h3 class="anchored" data-anchor-id="fitting-steps">Fitting Steps</h3>
<p>Step 1. Use the advanced second derivative iterative method to find the regression coefficients: <span class="math display">
    \widehat{\boldsymbol{\beta}} = \underset{\boldsymbol{\beta}}{\text{arg\,min}} \ \sum_{i=1}^{n}\log \mu (\boldsymbol{x}_i; \boldsymbol{\beta})+\frac{y_i}{\mu (\boldsymbol{x}_i; \boldsymbol{\beta})}
</span></p>
<p>Step 2. Estimate the dispersion parameter: <span class="math display">
    \phi = \frac{1}{n-p}\sum_{i=1}^{n}\frac{(y_i-\mu(\boldsymbol{x}_i; \boldsymbol{\beta} ))^2}{\mu(\boldsymbol{x}_i; \boldsymbol{\beta} )^2}
</span></p>
</section>
<section id="code-gamma-glm" class="level3">
<h3 class="anchored" data-anchor-id="code-gamma-glm">Code: Gamma GLM</h3>
<p>In Python, we can fit a gamma GLM as follows:</p>
<div id="dbffcd13" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a column of ones to include an intercept in the model</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>X_train_design <span class="op">=</span> sm.add_constant(X_train)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a Gamma GLM with a log link function</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>gamma_glm <span class="op">=</span> sm.GLM(y_train, X_train_design,                   </span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>            family<span class="op">=</span>sm.families.Gamma(sm.families.links.Log()))</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>gamma_glm <span class="op">=</span> gamma_glm.fit()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="columns">
<div class="column">
<div id="fa826ff7" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>gamma_glm.params</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>const         7.786576
Area         -0.073226
VehGas        0.082292
                ...   
DrivAge      -0.022147
BonusMalus    0.157204
Density       0.010539
Length: 9, dtype: float64</code></pre>
</div>
</div>
</div><div class="column">
<div id="b706b525" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Dispersion Parameter</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>mus <span class="op">=</span> gamma_glm.predict(X_train_design)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> y_train <span class="op">-</span> mus</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>variance <span class="op">=</span> mus<span class="op">**</span><span class="dv">2</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>dof <span class="op">=</span> (<span class="bu">len</span>(y_train)<span class="op">-</span>X_train.shape[<span class="dv">1</span>])</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>phi_glm <span class="op">=</span>  np.sum(residuals<span class="op">**</span><span class="dv">2</span><span class="op">/</span>variance)<span class="op">/</span>dof</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(phi_glm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>59.6306232357824</code></pre>
</div>
</div>
</div>
</div>
<p>The above example of fitting a Gamma distribution assumes a constant dispersion, meaning that, the dispersion of claim amount is constant for all policyholders. If we believe that the constant dispersion assumption is quite strong, we can use a double GLM model. Fitting a GLM is the traditional way of modelling a claim amount.</p>
</section>
<section id="ann-can-feed-into-a-glm" class="level3">
<h3 class="anchored" data-anchor-id="ann-can-feed-into-a-glm">ANN can feed into a GLM</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="richman-glm-and-ann.png" class="img-fluid figure-img"></p>
<figcaption>Combining GLM &amp; ANN.</figcaption>
</figure>
</div>
<div class="footer">
<p>Source: Ronald Richman (2022), Mind the Gap - Safely Incorporating Deep Learning Models into the Actuarial Toolkit, IFoA seminar, Slide 14.</p>
</div>
</section>
</section>
<section id="combined-actuarial-neural-network" class="level2" data-visibility="uncounted">
<h2 data-visibility="uncounted" class="anchored" data-anchor-id="combined-actuarial-neural-network">Combined Actuarial Neural Network</h2>
<section id="cann" class="level3">
<h3 class="anchored" data-anchor-id="cann">CANN</h3>
<p>The Combined Actuarial Neural Network is a novel actuarial neural network architecture proposed by Schelldorfer and Wüthrich (2019). We summarise the CANN approach as follows:</p>
<ul>
<li>Find the coefficients <span class="math inline">\boldsymbol{\beta}</span> of the GLM with a link function <span class="math inline">g(\cdot)</span>.</li>
<li>Find the weights <span class="math inline">\boldsymbol{w}_{\text{CANN}}</span> of a neural network <span class="math inline">\mathcal{M}_{\text{CANN}}:\mathbb{R}^{p}\to\mathbb{R}</span>.</li>
<li>Given a new instance <span class="math inline">\boldsymbol{x}</span>, we have <span class="math display">\mathbb{E}[Y|\boldsymbol{X}=\boldsymbol{x}] = g^{-1}\Big( \langle\boldsymbol{\beta}, \boldsymbol{x}\rangle + \mathcal{M}_{\text{CANN}}(\boldsymbol{x};\boldsymbol{w}_{\text{CANN}})\Big).</span></li>
</ul>
</section>
<section id="architecture" class="level3">
<h3 class="anchored" data-anchor-id="architecture">Architecture</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="CANN.png" class="img-fluid figure-img"></p>
<figcaption>CANN approach.</figcaption>
</figure>
</div>
</section>
<section id="code-architecture" class="level3">
<h3 class="anchored" data-anchor-id="code-architecture">Code: Architecture</h3>
<div id="d847b4fa" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="annotated-cell-23"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-23-1"><a href="#annotated-cell-23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure reproducibility</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-23" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-23-2" class="code-annotation-target"><a href="#annotated-cell-23-2" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">1</span>)<span class="op">;</span> tf.random.set_seed(<span class="dv">1</span>)</span>
<span id="annotated-cell-23-3"><a href="#annotated-cell-23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-23-4"><a href="#annotated-cell-23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Pre-defined constants</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-23" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-23-5" class="code-annotation-target"><a href="#annotated-cell-23-5" aria-hidden="true" tabindex="-1"></a>glm_weights <span class="op">=</span> gamma_glm.params.iloc[<span class="dv">1</span>:].values</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-23" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-23-6" class="code-annotation-target"><a href="#annotated-cell-23-6" aria-hidden="true" tabindex="-1"></a>glm_bias <span class="op">=</span> gamma_glm.params.iloc[<span class="dv">0</span>]</span>
<span id="annotated-cell-23-7"><a href="#annotated-cell-23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-23-8"><a href="#annotated-cell-23-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Define model inputs</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-23" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-23-9" class="code-annotation-target"><a href="#annotated-cell-23-9" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> Input(shape<span class="op">=</span>X_train.shape[<span class="dv">1</span>:])</span>
<span id="annotated-cell-23-10"><a href="#annotated-cell-23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-23-11"><a href="#annotated-cell-23-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Non-trainable GLM linear part</span></span>
<span id="annotated-cell-23-12"><a href="#annotated-cell-23-12" aria-hidden="true" tabindex="-1"></a>glm_logmu <span class="op">=</span> Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'linear'</span>, trainable<span class="op">=</span><span class="va">False</span>,</span>
<span id="annotated-cell-23-13"><a href="#annotated-cell-23-13" aria-hidden="true" tabindex="-1"></a>                     kernel_initializer<span class="op">=</span>Constant(glm_weights),</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-23" data-target-annotation="5" onclick="event.preventDefault();">5</a><span id="annotated-cell-23-14" class="code-annotation-target"><a href="#annotated-cell-23-14" aria-hidden="true" tabindex="-1"></a>                     bias_initializer<span class="op">=</span>Constant(glm_bias))(inputs)</span>
<span id="annotated-cell-23-15"><a href="#annotated-cell-23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-23-16"><a href="#annotated-cell-23-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Neural network layers</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-23" data-target-annotation="6" onclick="event.preventDefault();">6</a><span id="annotated-cell-23-17" class="code-annotation-target"><a href="#annotated-cell-23-17" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(inputs)</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-23" data-target-annotation="7" onclick="event.preventDefault();">7</a><span id="annotated-cell-23-18" class="code-annotation-target"><a href="#annotated-cell-23-18" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-23" data-target-annotation="8" onclick="event.preventDefault();">8</a><span id="annotated-cell-23-19" class="code-annotation-target"><a href="#annotated-cell-23-19" aria-hidden="true" tabindex="-1"></a>cann_logmu <span class="op">=</span> Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'linear'</span>)(x)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-23" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-23" data-code-lines="2" data-code-annotation="1">Sets the random seed for reproducibility</span>
</dd>
<dt data-target-cell="annotated-cell-23" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-23" data-code-lines="5" data-code-annotation="2">Stores weights computed from GLM in <code>glm_weights</code></span>
</dd>
<dt data-target-cell="annotated-cell-23" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-23" data-code-lines="6" data-code-annotation="3">Stores bias computed from GLM in <code>glm_bias</code></span>
</dd>
<dt data-target-cell="annotated-cell-23" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-23" data-code-lines="9" data-code-annotation="4">Specifies the model input features</span>
</dd>
<dt data-target-cell="annotated-cell-23" data-target-annotation="5">5</dt>
<dd>
<span data-code-cell="annotated-cell-23" data-code-lines="14" data-code-annotation="5">Adds a <code>Dense</code> layer with just one neuron, to store the model output from the GLM. The linear activation is used to make sure that the output is a linear combination of inputs. The weights are set to be non-trainable, hence the values obtained during GLM fitting will not change during the neural network training process. <code>kernel_initializer=Constant(glm_weights)</code> and <code>bias_initializer=Constant(glm_bias)</code> ensures that weights are initialized with the optimal values estimated from GLM fit.</span>
</dd>
<dt data-target-cell="annotated-cell-23" data-target-annotation="6">6</dt>
<dd>
<span data-code-cell="annotated-cell-23" data-code-lines="17" data-code-annotation="6">Adds another <code>Dense</code> layer</span>
</dd>
<dt data-target-cell="annotated-cell-23" data-target-annotation="7">7</dt>
<dd>
<span data-code-cell="annotated-cell-23" data-code-lines="18" data-code-annotation="7">Adds another <code>Dense</code> layer</span>
</dd>
<dt data-target-cell="annotated-cell-23" data-target-annotation="8">8</dt>
<dd>
<span data-code-cell="annotated-cell-23" data-code-lines="19" data-code-annotation="8">Adds the output layer with linear activation</span>
</dd>
</dl>
</div>
</div>
</section>
<section id="code-loss-function" class="level3">
<h3 class="anchored" data-anchor-id="code-loss-function">Code: Loss Function</h3>
<div id="1cc08ceb" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="annotated-cell-24"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-24-1"><a href="#annotated-cell-24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine GLM and CANN estimates</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-24" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-24-2" class="code-annotation-target"><a href="#annotated-cell-24-2" aria-hidden="true" tabindex="-1"></a>cann <span class="op">=</span> Model(inputs, Concatenate(axis<span class="op">=</span><span class="dv">1</span>)([cann_logmu, glm_logmu]))</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-24" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-24" data-code-lines="2" data-code-annotation="1">Since the output of the model is evaluated by combining the output from both branches, the model is constructed by concatenating outputs from <code>cann_logmu</code> and <code>glm_logmu</code>. Note that there are two predicted values, one predicted value from the <code>glm_logmu</code> component and the other coming from the <code>cann_logmu</code> component.</span>
</dd>
</dl>
</div>
</div>
<p>We need to customise the loss function for CANN.</p>
<div id="80f5e4c1" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="annotated-cell-25"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-25-1"><a href="#annotated-cell-25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cann_negative_log_likelihood(y_true, y_pred):</span>
<span id="annotated-cell-25-2"><a href="#annotated-cell-25-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The new mean estimate</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-25" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-25-3" class="code-annotation-target"><a href="#annotated-cell-25-3" aria-hidden="true" tabindex="-1"></a>    cann_logmu <span class="op">=</span> y_pred[:, <span class="dv">0</span>]</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-25" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-25-4" class="code-annotation-target"><a href="#annotated-cell-25-4" aria-hidden="true" tabindex="-1"></a>    glm_logmu <span class="op">=</span> y_pred[:, <span class="dv">1</span>]</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-25" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-25-5" class="code-annotation-target"><a href="#annotated-cell-25-5" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> tf.math.exp(cann_logmu <span class="op">+</span> glm_logmu)</span>
<span id="annotated-cell-25-6"><a href="#annotated-cell-25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-25-7"><a href="#annotated-cell-25-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the negative log likelihood of the Gamma distribution</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-25" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-25-8" class="code-annotation-target"><a href="#annotated-cell-25-8" aria-hidden="true" tabindex="-1"></a>    nll <span class="op">=</span> tf.reduce_mean(cann_logmu <span class="op">+</span> glm_logmu <span class="op">+</span> y_true<span class="op">/</span>mu)</span>
<span id="annotated-cell-25-9"><a href="#annotated-cell-25-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="annotated-cell-25-10"><a href="#annotated-cell-25-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> nll</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-25" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-25" data-code-lines="3" data-code-annotation="1">Stores the first column of the <code>y_pred</code> matrix as <code>cann_logmu</code> (the prediction from the CANN)</span>
</dd>
<dt data-target-cell="annotated-cell-25" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-25" data-code-lines="4" data-code-annotation="2">Stores the second column of the <code>y_pred</code> matrix as <code>glm_logmu</code> (the prediction from the glm)</span>
</dd>
<dt data-target-cell="annotated-cell-25" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-25" data-code-lines="5" data-code-annotation="3">Computes the exponential of the sum of them as <code>mu</code></span>
</dd>
<dt data-target-cell="annotated-cell-25" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-25" data-code-lines="8" data-code-annotation="4">Computes the negative log likelihood of a Gamma distribution where <span class="math inline">\log(\mu)</span> is now the sum <code>cann_logmu + glm_logmu</code></span>
</dd>
</dl>
</div>
</div>
</section>
<section id="code-model-training" class="level3">
<h3 class="anchored" data-anchor-id="code-model-training">Code: Model Training</h3>
<div id="10fd0c64" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="annotated-cell-26"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><a class="code-annotation-anchor" data-target-cell="annotated-cell-26" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-26-1" class="code-annotation-target"><a href="#annotated-cell-26-1" aria-hidden="true" tabindex="-1"></a>cann.compile(optimizer<span class="op">=</span><span class="st">"adam"</span>, loss<span class="op">=</span>cann_negative_log_likelihood)</span>
<span id="annotated-cell-26-2"><a href="#annotated-cell-26-2" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> cann.fit(X_train, y_train,</span>
<span id="annotated-cell-26-3"><a href="#annotated-cell-26-3" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">100</span>, </span>
<span id="annotated-cell-26-4"><a href="#annotated-cell-26-4" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>[EarlyStopping(patience<span class="op">=</span><span class="dv">10</span>)],  </span>
<span id="annotated-cell-26-5"><a href="#annotated-cell-26-5" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="annotated-cell-26-6"><a href="#annotated-cell-26-6" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">64</span>, </span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-26" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-26-7" class="code-annotation-target"><a href="#annotated-cell-26-7" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span><span class="fl">0.2</span>)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-26" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-26" data-code-lines="1" data-code-annotation="1">Compiles the model with adam optimizer and the custom loss function</span>
</dd>
<dt data-target-cell="annotated-cell-26" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-26" data-code-lines="7" data-code-annotation="2">Fits the model (with a validation split defined inside the fit function)</span>
</dd>
</dl>
</div>
</div>
<p>Find the dispersion parameter.</p>
<div id="181fc5b8" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>mus <span class="op">=</span> np.exp(np.sum(cann.predict(X_train, verbose<span class="op">=</span><span class="dv">0</span>), axis <span class="op">=</span> <span class="dv">1</span>))</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> y_train <span class="op">-</span> mus</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>variance <span class="op">=</span> mus<span class="op">**</span><span class="dv">2</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>dof <span class="op">=</span> (<span class="bu">len</span>(y_train)<span class="op">-</span>X_train.shape[<span class="dv">1</span>])</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>phi_cann <span class="op">=</span> np.sum(residuals<span class="op">**</span><span class="dv">2</span><span class="op">/</span>variance) <span class="op">/</span> dof</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(phi_cann)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>86.69498963886436</code></pre>
</div>
</div>
</section>
</section>
<section id="mixture-density-network" class="level2" data-visibility="uncounted">
<h2 data-visibility="uncounted" class="anchored" data-anchor-id="mixture-density-network">Mixture Density Network</h2>
<section id="mixture-distribution" class="level3">
<h3 class="anchored" data-anchor-id="mixture-distribution">Mixture Distribution</h3>
<p>One intuitive way to capture uncertainty using neural networks would be to estimate the parameters of the target distribution, instead of predicting the value it self. For example, suppose we want to predict <span class="math inline">y</span> coming from a Gaussian distribution. Most common method would be to predict <span class="math inline">(\hat{y})</span> directly using a single neuron at the output layer. Another possible way would be to estimate the parameters (<span class="math inline">\mu</span> and <span class="math inline">\sigma</span>) of the <span class="math inline">y</span> distribution using 2 neurons at the output layer. Estimating parameters of the distribution instead of point estimates for <span class="math inline">y</span> can help us get an idea about the uncertainty. However, assuming distributional properties at times could be too restrictive. For example, it is possible that the actual distribution of <span class="math inline">y</span> values is bimodal or multi modal. In such situations, assuming a mixture distribution is more intuitive.</p>
<p>Given a finite set of resulting random variables <span class="math inline">(Y_1, \ldots, Y_{K})</span>, one can generate a multinomial random variable <span class="math inline">Y\sim \text{Multinomial}(1, \boldsymbol{\pi})</span>. Meanwhile, <span class="math inline">Y</span> can be regarded as a mixture of <span class="math inline">Y_1, \ldots, Y_{K}</span>, i.e., <span class="math display">
  Y = \begin{cases}
      Y_1 &amp; \text{w.p. } \pi_1, \\
      \vdots &amp; \vdots\\
      Y_K &amp; \text{w.p. } \pi_K, \\
  \end{cases}
</span> where we define a set of finite set of weights <span class="math inline">\boldsymbol{\pi}=(\pi_{1} \ldots, \pi_{K})</span> such that <span class="math inline">\pi_k \ge 0</span> for <span class="math inline">k \in \{1, \ldots, K\}</span> and <span class="math inline">\sum_{k=1}^{K}\pi_k=1</span>.</p>
</section>
<section id="mixture-distribution-1" class="level3">
<h3 class="anchored" data-anchor-id="mixture-distribution-1">Mixture Distribution</h3>
<p>Let <span class="math inline">f_{Y_k|\boldsymbol{X}}</span> and <span class="math inline">F_{Y_k|\boldsymbol{X}}</span> be the p.d.f. and the c.d.f of <span class="math inline">Y_k|\boldsymbol{X}</span> for all <span class="math inline">k \in \{1, \ldots, K\}</span>.</p>
<p>The random variable <span class="math inline">Y|\boldsymbol{X}</span>, which mixes <span class="math inline">Y_k|\boldsymbol{X}</span>’s with weights <span class="math inline">\pi_k</span>’s, has the density function <span class="math display">
    f_{Y|\boldsymbol{X}}(y|\boldsymbol{x}) = \sum_{k=1}^{K}\pi_k(\boldsymbol{x}) f_{k}(y|\boldsymbol{x}),
</span> and the cumulative density function <span class="math display">
    F_{Y|\boldsymbol{X}}(y|\boldsymbol{x}) = \sum_{k=1}^{K}\pi_k(\boldsymbol{x}) F_{k}(y|\boldsymbol{x}).
</span></p>
</section>
<section id="mixture-density-network-1" class="level3">
<h3 class="anchored" data-anchor-id="mixture-density-network-1">Mixture Density Network</h3>
<p>A mixture density network (MDN) <span class="math inline">\mathcal{M}_{\boldsymbol{w}^*}</span> outputs each distribution component’s mixing weights and parameters of <span class="math inline">Y</span> given the input features <span class="math inline">\boldsymbol{x}</span>, i.e., <span class="math display">
    \mathcal{M}_{\boldsymbol{w}^*}(\boldsymbol{x})=(\boldsymbol{\pi}(\boldsymbol{x};\boldsymbol{w}^*), \boldsymbol{\theta}(\boldsymbol{x};\boldsymbol{w}^*)),
</span> where <span class="math inline">\boldsymbol{w}^*</span> is the networks’ weights found by minimising the following negative log-likelihood loss function <span class="math display">
    \mathcal{L}(\mathcal{D}, \boldsymbol{\theta})= - \sum_{i=1}^{n} \log f_{Y|\boldsymbol{X}}(y_i|\boldsymbol{x}, \boldsymbol{w}^*),
</span> where <span class="math inline">\mathcal{D}=\{(\boldsymbol{x}_i,y_i)\}_{i=1}^{n}</span> is the training dataset.</p>
</section>
<section id="mixture-density-network-2" class="level3">
<h3 class="anchored" data-anchor-id="mixture-density-network-2">Mixture Density Network</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="MDN.png" class="img-fluid figure-img"></p>
<figcaption>An MDN that outputs the parameters for a <span class="math inline">K</span> component mixture distribution. <span class="math inline">\boldsymbol{\theta}_k(\boldsymbol{x}; \boldsymbol{w}^*)= (\theta_{k,1}(\boldsymbol{x}; \boldsymbol{w}^*), \ldots, \theta_{k,|\boldsymbol{\theta}_k|}(\boldsymbol{x}; \boldsymbol{w}^*))</span> consists of the parameter estimates for the <span class="math inline">k</span>th mixture component.</figcaption>
</figure>
</div>
</section>
<section id="model-specification" class="level3">
<h3 class="anchored" data-anchor-id="model-specification">Model Specification</h3>
<p>Suppose there are two types of claims:</p>
<ul>
<li>Type I: <span class="math inline">Y_1|\boldsymbol{X}=\boldsymbol{x}\sim \text{Gamma}(\alpha_1(\boldsymbol{x}), \beta_1(\boldsymbol{x}))</span> and,</li>
<li>Type II: <span class="math inline">Y_2|\boldsymbol{X}=\boldsymbol{x}\sim \text{Gamma}(\alpha_2(\boldsymbol{x}), \beta_2(\boldsymbol{x}))</span>.</li>
</ul>
<p>The density of the actual claim amount <span class="math inline">Y|\boldsymbol{X}=\boldsymbol{x}</span> follows <span class="math display">
    \begin{align*}
        f_{Y|\boldsymbol{X}}(y|\boldsymbol{x})
        &amp;= \pi_1(\boldsymbol{x})\cdot \frac{\beta_1(\boldsymbol{x})^{\alpha_1(\boldsymbol{x})}}{\Gamma(\alpha_1(\boldsymbol{x}))}\mathrm{e}^{-\beta_1(\boldsymbol{x})y}y^{\alpha_1(\boldsymbol{x})-1} \\
        &amp;\quad + (1-\pi_1(\boldsymbol{x}))\cdot \frac{\beta_2(\boldsymbol{x})^{\alpha_2(\boldsymbol{x})}}{\Gamma(\alpha_2(\boldsymbol{x}))}\mathrm{e}^{-\beta_2(\boldsymbol{x})y}y^{\alpha_2(\boldsymbol{x})-1}.
    \end{align*}
</span> where <span class="math inline">\pi_1(\boldsymbol{x})</span> is the probability of a Type I claim given <span class="math inline">\boldsymbol{x}</span>.</p>
</section>
<section id="output" class="level3">
<h3 class="anchored" data-anchor-id="output">Output</h3>
<p>The aim is to find the optimum weights <span class="math display">
    \boldsymbol{w}^* = \underset{w}{\text{arg\,min}} \ \mathcal{L}(\mathcal{D}, \boldsymbol{w})
</span> for the Gamma mixture density network <span class="math inline">\mathcal{M}_{\boldsymbol{w}^*}</span> that outputs the mixing weights, shapes and scales of <span class="math inline">Y</span> given the input features <span class="math inline">\boldsymbol{x}</span>, i.e., <span class="math display">
    \begin{align*}
        \mathcal{M}_{\boldsymbol{w}^*}(\boldsymbol{x})
        = ( &amp;\pi_1(\boldsymbol{x}; \boldsymbol{w}^*),
             \pi_2(\boldsymbol{x}; \boldsymbol{w}^*), \\
            &amp;\alpha_1(\boldsymbol{x}; \boldsymbol{w}^*),
            \alpha_2(\boldsymbol{x}; \boldsymbol{w}^*),\\
            &amp;\beta_1(\boldsymbol{x}; \boldsymbol{w}^*),
            \beta_2(\boldsymbol{x}; \boldsymbol{w}^*)
        ).
    \end{align*}
</span></p>
</section>
<section id="architecture-1" class="level3">
<h3 class="anchored" data-anchor-id="architecture-1">Architecture</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Gamma_MDN.png" class="img-fluid figure-img"></p>
<figcaption>We demonstrate the structure of a gamma MDN that outputs the parameters for a gamma mixture with two components.</figcaption>
</figure>
</div>
</section>
<section id="code-architecture-1" class="level3">
<h3 class="anchored" data-anchor-id="code-architecture-1">Code: Architecture</h3>
<p>The following code resembles the architecture of the architecture of the gamma MDN from the previous slide.</p>
<div id="f1f25bad" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="annotated-cell-28"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-28-1"><a href="#annotated-cell-28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure reproducibility</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-28" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-28-2" class="code-annotation-target"><a href="#annotated-cell-28-2" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">1</span>)<span class="op">;</span> tf.random.set_seed(<span class="dv">1</span>)</span>
<span id="annotated-cell-28-3"><a href="#annotated-cell-28-3" aria-hidden="true" tabindex="-1"></a></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-28" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-28-4" class="code-annotation-target"><a href="#annotated-cell-28-4" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> Input(shape<span class="op">=</span>X_train.shape[<span class="dv">1</span>:])</span>
<span id="annotated-cell-28-5"><a href="#annotated-cell-28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-28-6"><a href="#annotated-cell-28-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Two hidden layers </span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-28" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-28-7" class="code-annotation-target"><a href="#annotated-cell-28-7" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(inputs)</span>
<span id="annotated-cell-28-8"><a href="#annotated-cell-28-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="annotated-cell-28-9"><a href="#annotated-cell-28-9" aria-hidden="true" tabindex="-1"></a></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-28" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-28-10" class="code-annotation-target"><a href="#annotated-cell-28-10" aria-hidden="true" tabindex="-1"></a>pis <span class="op">=</span> Dense(<span class="dv">2</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)(x) <span class="co"># Mixing weights</span></span>
<span id="annotated-cell-28-11"><a href="#annotated-cell-28-11" aria-hidden="true" tabindex="-1"></a>alphas <span class="op">=</span> Dense(<span class="dv">2</span>, activation<span class="op">=</span><span class="st">'exponential'</span>)(x) <span class="co"># Shape parameters</span></span>
<span id="annotated-cell-28-12"><a href="#annotated-cell-28-12" aria-hidden="true" tabindex="-1"></a>betas <span class="op">=</span> Dense(<span class="dv">2</span>, activation<span class="op">=</span><span class="st">'exponential'</span>)(x) <span class="co"># Scale parameters</span></span>
<span id="annotated-cell-28-13"><a href="#annotated-cell-28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-28-14"><a href="#annotated-cell-28-14" aria-hidden="true" tabindex="-1"></a><span class="co"># `y_pred` will now have 6 columns</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-28" data-target-annotation="5" onclick="event.preventDefault();">5</a><span id="annotated-cell-28-15" class="code-annotation-target"><a href="#annotated-cell-28-15" aria-hidden="true" tabindex="-1"></a>gamma_mdn <span class="op">=</span> Model(inputs, Concatenate(axis<span class="op">=</span><span class="dv">1</span>)([pis, alphas, betas]))</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-28" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-28" data-code-lines="2" data-code-annotation="1">Sets the random seeds for reproducibility</span>
</dd>
<dt data-target-cell="annotated-cell-28" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-28" data-code-lines="4" data-code-annotation="2">Defines the input layer with the number of neurons being equal to the number of input features</span>
</dd>
<dt data-target-cell="annotated-cell-28" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-28" data-code-lines="7" data-code-annotation="3">Specifies the hidden layers of the neural network</span>
</dd>
<dt data-target-cell="annotated-cell-28" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-28" data-code-lines="10" data-code-annotation="4">Specifies the neurons of the output layer. Here, <code>softmax</code> is used for <span class="math inline">\pi</span> values as they must sum up to 1. <code>exponential</code> activation is used for both <span class="math inline">\alpha</span>’s and <span class="math inline">\beta</span>’s as they must be non-negative.</span>
</dd>
<dt data-target-cell="annotated-cell-28" data-target-annotation="5">5</dt>
<dd>
<span data-code-cell="annotated-cell-28" data-code-lines="15" data-code-annotation="5">Defines the model by specifying the inputs and outputs</span>
</dd>
</dl>
</div>
</div>
</section>
<section id="loss-function" class="level3">
<h3 class="anchored" data-anchor-id="loss-function">Loss Function</h3>
<p>The negative log-likelihood loss function is given by</p>
<p><span class="math display">
    \mathcal{L}(\mathcal{D}, \boldsymbol{w})
    = - \sum_{i=1}^{n} \log \  f_{Y|\boldsymbol{X}}(y_i|\boldsymbol{x}, \boldsymbol{w})
</span> where the <span class="math inline">f_{Y|\boldsymbol{X}}(y_i|\boldsymbol{x}, \boldsymbol{w})</span> is defined by <span class="math display">
\begin{align*}
    &amp;\pi_1(\boldsymbol{x};\boldsymbol{w})\cdot \frac{\beta_1(\boldsymbol{x};\boldsymbol{w})^{\alpha_1(\boldsymbol{x};\boldsymbol{w})}}{\Gamma(\alpha_1(\boldsymbol{x};\boldsymbol{w}))}\mathrm{e}^{-\beta_1(\boldsymbol{x};\boldsymbol{w})y}y^{\alpha_1(\boldsymbol{x};\boldsymbol{w})-1} \\
    &amp; \quad + (1-\pi_1(\boldsymbol{x};\boldsymbol{w}))\cdot \frac{\beta_2(\boldsymbol{x};\boldsymbol{w})^{\alpha_2(\boldsymbol{x};\boldsymbol{w})}}{\Gamma(\alpha_2(\boldsymbol{x};\boldsymbol{w}))}\mathrm{e}^{-\beta_2(\boldsymbol{x};\boldsymbol{w})y}y^{\alpha_2(\boldsymbol{x};\boldsymbol{w})-1}
\end{align*}
</span></p>
</section>
<section id="code-loss-function-1" class="level3">
<h3 class="anchored" data-anchor-id="code-loss-function-1">Code: Loss Function</h3>
<p>We employ functions from <code>tensorflow_probability</code> to code the loss function for the gamma MDN. The <code>MixtureSameFamily</code> function facilitates defining a mixture distribution all components from the same distribution but have different parametrization.</p>
<div id="e33e210a" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="annotated-cell-29"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><a class="code-annotation-anchor" data-target-cell="annotated-cell-29" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-29-1" class="code-annotation-target"><a href="#annotated-cell-29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow_probability <span class="im">as</span> tfp</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-29" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-29-2" class="code-annotation-target"><a href="#annotated-cell-29-2" aria-hidden="true" tabindex="-1"></a>tfd <span class="op">=</span> tfp.distributions</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-29" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-29-3" class="code-annotation-target"><a href="#annotated-cell-29-3" aria-hidden="true" tabindex="-1"></a>K <span class="op">=</span> <span class="dv">2</span> <span class="co"># number of mixture components</span></span>
<span id="annotated-cell-29-4"><a href="#annotated-cell-29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-29-5"><a href="#annotated-cell-29-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gamma_mixture_nll(y_true, y_pred):                                      </span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-29" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-29-6" class="code-annotation-target"><a href="#annotated-cell-29-6" aria-hidden="true" tabindex="-1"></a>    K <span class="op">=</span> y_pred.shape[<span class="dv">1</span>] <span class="op">//</span> <span class="dv">3</span></span>
<span id="annotated-cell-29-7"><a href="#annotated-cell-29-7" aria-hidden="true" tabindex="-1"></a>    pis <span class="op">=</span>  y_pred[:, :K]                                                    </span>
<span id="annotated-cell-29-8"><a href="#annotated-cell-29-8" aria-hidden="true" tabindex="-1"></a>    alphas <span class="op">=</span> y_pred[:, K:<span class="dv">2</span><span class="op">*</span>K]                                               </span>
<span id="annotated-cell-29-9"><a href="#annotated-cell-29-9" aria-hidden="true" tabindex="-1"></a>    betas <span class="op">=</span> y_pred[:, <span class="dv">2</span><span class="op">*</span>K:<span class="dv">3</span><span class="op">*</span>K]                                              </span>
<span id="annotated-cell-29-10"><a href="#annotated-cell-29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-29-11"><a href="#annotated-cell-29-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The mixture distribution is a MixtureSameFamily distribution</span></span>
<span id="annotated-cell-29-12"><a href="#annotated-cell-29-12" aria-hidden="true" tabindex="-1"></a>    mixture_distribution <span class="op">=</span> tfd.MixtureSameFamily(</span>
<span id="annotated-cell-29-13"><a href="#annotated-cell-29-13" aria-hidden="true" tabindex="-1"></a>        mixture_distribution<span class="op">=</span>tfd.Categorical(probs<span class="op">=</span>pis),</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-29" data-target-annotation="5" onclick="event.preventDefault();">5</a><span id="annotated-cell-29-14" class="code-annotation-target"><a href="#annotated-cell-29-14" aria-hidden="true" tabindex="-1"></a>        components_distribution<span class="op">=</span>tfd.Gamma(alphas, betas))</span>
<span id="annotated-cell-29-15"><a href="#annotated-cell-29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-29-16"><a href="#annotated-cell-29-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The loss is the negative log-likelihood of the data</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-29" data-target-annotation="6" onclick="event.preventDefault();">6</a><span id="annotated-cell-29-17" class="code-annotation-target"><a href="#annotated-cell-29-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>mixture_distribution.log_prob(y_true)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-29" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-29" data-code-lines="1" data-code-annotation="1">Imports <code>tfp</code> class from <code>tensorflow_probability</code></span>
</dd>
<dt data-target-cell="annotated-cell-29" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-29" data-code-lines="2" data-code-annotation="2">Stores statistical distributions in the <code>tfp</code> class as <code>tfd</code></span>
</dd>
<dt data-target-cell="annotated-cell-29" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-29" data-code-lines="3" data-code-annotation="3">Specifies the number of components in the mixture model</span>
</dd>
<dt data-target-cell="annotated-cell-29" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-29" data-code-lines="6" data-code-annotation="4">Extracts predicted values for all model components and stores them in separate matrices</span>
</dd>
<dt data-target-cell="annotated-cell-29" data-target-annotation="5">5</dt>
<dd>
<span data-code-cell="annotated-cell-29" data-code-lines="14" data-code-annotation="5">Specifies the mixture distribution using computed model components</span>
</dd>
<dt data-target-cell="annotated-cell-29" data-target-annotation="6">6</dt>
<dd>
<span data-code-cell="annotated-cell-29" data-code-lines="17" data-code-annotation="6">Use the fitted model to calculate negative log likelihood given the observed data</span>
</dd>
</dl>
</div>
</div>
</section>
<section id="code-model-training-1" class="level3">
<h3 class="anchored" data-anchor-id="code-model-training-1">Code: Model Training</h3>
<div id="1f210753" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="annotated-cell-30"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-30-1"><a href="#annotated-cell-30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Employ the loss function from previous slide</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-30" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-30-2" class="code-annotation-target"><a href="#annotated-cell-30-2" aria-hidden="true" tabindex="-1"></a>gamma_mdn.compile(optimizer<span class="op">=</span><span class="st">"adam"</span>, loss<span class="op">=</span>gamma_mixture_nll)</span>
<span id="annotated-cell-30-3"><a href="#annotated-cell-30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-30-4"><a href="#annotated-cell-30-4" aria-hidden="true" tabindex="-1"></a>hist <span class="op">=</span> gamma_mdn.fit(X_train, y_train,</span>
<span id="annotated-cell-30-5"><a href="#annotated-cell-30-5" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">100</span>, </span>
<span id="annotated-cell-30-6"><a href="#annotated-cell-30-6" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>[EarlyStopping(patience<span class="op">=</span><span class="dv">10</span>)],  </span>
<span id="annotated-cell-30-7"><a href="#annotated-cell-30-7" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">0</span>,</span>
<span id="annotated-cell-30-8"><a href="#annotated-cell-30-8" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">64</span>, </span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-30" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-30-9" class="code-annotation-target"><a href="#annotated-cell-30-9" aria-hidden="true" tabindex="-1"></a>    validation_split<span class="op">=</span><span class="fl">0.2</span>)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-30" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-30" data-code-lines="2" data-code-annotation="1">Compiles the model using <code>adam</code> optimizer and the <code>gamma_mixture_nll</code> (negative log likelihood) as the loss function</span>
</dd>
<dt data-target-cell="annotated-cell-30" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-30" data-code-lines="9" data-code-annotation="2">Fits the model using the training data, with a validation split</span>
</dd>
</dl>
</div>
</div>
</section>
</section>
<section id="metrics-for-distributional-regression" class="level2" data-visibility="uncounted">
<h2 data-visibility="uncounted" class="anchored" data-anchor-id="metrics-for-distributional-regression">Metrics for Distributional Regression</h2>
<section id="proper-scoring-rules" class="level3">
<h3 class="anchored" data-anchor-id="proper-scoring-rules">Proper Scoring Rules</h3>
<p>Proper scoring rules provide a summary measure for the performance of the probabilistic predictions. They are useful in comparing performances across models.</p>
<dl>
<dt>Definition</dt>
<dd>
<p><em>The scoring rule</em> <span class="math inline">S : \mathcal{F} \times \mathbb{R} \to \bar{\mathbb{R}}</span> is proper relative to the class <span class="math inline">\mathcal{F}</span> if <span class="math display">
S(G, G)\le S(F, G)
</span> for all <span class="math inline">F,G\in \mathcal{F}</span>. It is strictly proper if equality holds only if <span class="math inline">F = G</span>.</p>
</dd>
</dl>
<p>Examples:</p>
<ul>
<li>Logarithmic Score (NLL)</li>
<li>Continuous Ranked Probability Score (CRPS)</li>
</ul>
</section>
<section id="proper-scoring-rules-1" class="level3">
<h3 class="anchored" data-anchor-id="proper-scoring-rules-1">Proper Scoring Rules</h3>
<dl>
<dt>Logarithmic Score (NLL)</dt>
<dd>
<p>The logarithmic score is defined as <span class="math display">
    \mathrm{LogS}(f, y) = - \log f(y),
</span> where <span class="math inline">f</span> is the predictive density.</p>
</dd>
<dt>Continuous Ranked Probability Score (CRPS)</dt>
<dd>
<p>The continuous ranked probability score is defined as <span class="math display">
    \mathrm{crps}(F, y) = \int_{-\infty}^{\infty} (F(t) - {1}_{t\ge y})^2 \ \mathrm{d}t,
</span> where <span class="math inline">F</span> is the cumulative distribution function.</p>
</dd>
</dl>
</section>
<section id="code-nll" class="level3">
<h3 class="anchored" data-anchor-id="code-nll">Code: NLL</h3>
<div id="98a1b06a" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> gamma</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gamma_nll(mean, dispersion, y):</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate shape and scale parameters from mean and dispersion</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    shape <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> dispersion<span class="op">;</span> scale <span class="op">=</span> mean <span class="op">*</span> dispersion</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a gamma distribution object</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    gamma_dist <span class="op">=</span> gamma(a<span class="op">=</span>shape, scale<span class="op">=</span>scale)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>np.mean(gamma_dist.logpdf(y))</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a><span class="co"># GLM</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>X_test_design <span class="op">=</span> sm.add_constant(X_test)</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>mus <span class="op">=</span> gamma_glm.predict(X_test_design)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>nll_glm <span class="op">=</span> gamma_nll(mus, phi_glm, y_test)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="co"># CANN</span></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>mus <span class="op">=</span> np.exp(np.sum(cann.predict(X_test, verbose<span class="op">=</span><span class="dv">0</span>), axis <span class="op">=</span> <span class="dv">1</span>))</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>nll_cann <span class="op">=</span> gamma_nll(mus, phi_cann, y_test)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a><span class="co"># MDN</span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>nll_mdn <span class="op">=</span> gamma_mdn.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="model-comparisons" class="level3">
<h3 class="anchored" data-anchor-id="model-comparisons">Model Comparisons</h3>
<div id="06f7c827" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'GLM: </span><span class="sc">{</span>round(nll_glm, <span class="dv">2</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'CANN: </span><span class="sc">{</span>round(nll_cann, <span class="dv">2</span>)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'MDN: </span><span class="sc">{</span>round(nll_mdn, <span class="dv">2</span>)<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>GLM: 11.02
CANN: 11.38
MDN: 8.67</code></pre>
</div>
</div>
<p>The above results show that MDN provides the lowest value for the Logarithmic Score (NLL). Low values for NLL indicate better calibration. One possible reason for the better performance of the MDN model (compared to the Gamma model) is the added flexibility from multiple modelling components. The multiple modelling components in the MDN model, together, can capture the inherent variation in the data better.</p>
</section>
</section>
<section id="aleatoric-and-epistemic-uncertainty" class="level2" data-visibility="uncounted">
<h2 data-visibility="uncounted" class="anchored" data-anchor-id="aleatoric-and-epistemic-uncertainty">Aleatoric and Epistemic Uncertainty</h2>
<p>Uncertainty in deep learning refers to the level of doubt one would have about the predictions made by an AI-driven algorithm. Identifying and quantifying different sources of uncertainty that could exist in AI-driven algorithms is therefore important to ensure a credible application.</p>
<section id="categories-of-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="categories-of-uncertainty">Categories of uncertainty</h3>
<p>There are two major categories of uncertainty in statistical or machine learning:</p>
<ul>
<li>Aleatoric uncertainty</li>
<li>Epistemic uncertainty</li>
</ul>
<p>Since there is no consensus on the definitions of aleatoric and epistemic uncertainty, we provide the most acknowledged definitions in the following slides.</p>
</section>
<section id="aleatoric-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="aleatoric-uncertainty">Aleatoric Uncertainty</h3>
<p>Aleatoric uncertainty refers to the inherent variability associated with the data generating process. Among many ways to capture the aleatoric uncertainty, (i) combining with probabilistic models and (ii) considering mixture models are two useful methods to quantify the inherent variability.</p>
<dl>
<dt>Qualitative Definition</dt>
<dd>
<p><em>Aleatoric uncertainty refers to the statistical variability and inherent noise with data distribution that modelling cannot explain.</em></p>
</dd>
<dt>Quantitative Definition</dt>
<dd>
<p><span class="math display">\text{Ale}(Y|\boldsymbol{X}=\boldsymbol{x}) = \mathbb{V}[Y|\boldsymbol{X}=\boldsymbol{x}],</span>i.e., if <span class="math inline">Y|\boldsymbol{X}=\boldsymbol{x} \sim \mathcal{N}(\mu, \sigma^2)</span>, the aleatoric uncertainty would be <span class="math inline">\sigma^2</span>. Simply, it is the conditional variance of the response variable <span class="math inline">Y</span> given features/covariates <span class="math inline">\boldsymbol{x}</span>.</p>
</dd>
</dl>
</section>
<section id="epistemic-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="epistemic-uncertainty">Epistemic Uncertainty</h3>
<dl>
<dt>Qualitative Definition</dt>
<dd>
<p><em>Epistemic uncertainty refers to the lack of knowledge, limited data information, parameter errors and model errors.</em></p>
</dd>
<dt>Quantitative Definition</dt>
<dd>
<p><span class="math display">\text{Epi}(Y|\boldsymbol{X}=\boldsymbol{x}) = \text{Uncertainty}(Y|\boldsymbol{X}=\boldsymbol{x}) - \text{Ale}(Y|\boldsymbol{X}=\boldsymbol{x}),</span></p>
</dd>
</dl>
<p>i.e., the total uncertainty subtracting the aleatoric uncertainty <span class="math inline">\mathbb{V}[Y|\boldsymbol{X}=\boldsymbol{x}]</span> would be the epistemic uncertainty.</p>
</section>
<section id="sources-of-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="sources-of-uncertainty">Sources of uncertainty</h3>
<p>There are many sources of uncertainty in statistical or machine learning models. Parameter error stems primarily due to lack of data. Model error stems from assuming wrong distributional properties of the data. Data uncertainty arises due to the lack of confidence we may have about the quality of the collected data. Noisy data, inconsistent data, data with missing values or data with missing important variables can result in data uncertainty.</p>
<p><em>If you decide to predict the claim amount of an individual using a deep learning model, which source(s) of uncertainty are you dealing with?</em></p>
<ol type="1">
<li>The inherent variability of the data-generating process <span class="math inline">\rightarrow</span> aleatoric uncertainty.</li>
<li>Parameter error <span class="math inline">\rightarrow</span> epistemic uncertainty.</li>
<li>Model error <span class="math inline">\rightarrow</span> epistemic uncertainty.</li>
<li>Data uncertainty <span class="math inline">\rightarrow</span> epistemic uncertainty.</li>
</ol>
</section>




</section>

<div id="quarto-appendix" class="default"><section id="notation" class="level3 appendix" data-visibility="uncounted"><h2 class="anchored quarto-appendix-heading">Notation</h2><div class="quarto-appendix-contents">

<ul>
<li>scalars are denoted by lowercase letters, e.g., <span class="math inline">y</span>,</li>
<li>vectors are denoted by bold lowercase letters, e.g., <span class="math display">\boldsymbol{y} = (y_1, \ldots, y_n) ,</span></li>
<li>random variables are denoted by capital letters, e.g., <span class="math inline">Y</span></li>
<li>random vectors are denoted by bold capital letters, e.g., <span class="math display">\boldsymbol{X} = (X_1, \ldots, X_p) ,</span></li>
<li>matrices are denoted by bold uppercase non-italics letters, e.g., <span class="math display">\mathbf{X} = \begin{pmatrix} x_{11} &amp; \cdots &amp; x_{1p} \\ \vdots &amp; \ddots &amp; \vdots \\ x_{n1} &amp; \cdots &amp; x_{np} \end{pmatrix} .</span></li>
</ul>
</div></section><section id="regression-notation" class="level3 appendix" data-visibility="uncounted"><h2 class="anchored quarto-appendix-heading">Regression notation</h2><div class="quarto-appendix-contents">

<ul>
<li><span class="math inline">n</span> is the number of observations, <span class="math inline">p</span> is the number of features,</li>
<li>the true coefficients are <span class="math inline">\boldsymbol{\beta} = (\beta_0, \beta_1, \ldots, \beta_p)</span>,</li>
<li><span class="math inline">\beta_0</span> is the intercept, <span class="math inline">\beta_1, \ldots, \beta_p</span> are the coefficients,</li>
<li><span class="math inline">\widehat{\boldsymbol{\beta}}</span> is the estimated coefficient vector,</li>
<li><span class="math inline">\boldsymbol{x}_i = (1, x_{i1}, x_{i2}, \ldots, x_{ip})</span> is the feature vector for the <span class="math inline">i</span>th observation,</li>
<li><span class="math inline">y_i</span> is the response variable for the <span class="math inline">i</span>th observation,</li>
<li><span class="math inline">\hat{y}_i</span> is the predicted value for the <span class="math inline">i</span>th observation,</li>
<li>probability density functions (p.d.f.), probability mass functions (p.m.f.), cumulative distribution functions (c.d.f.).</li>
</ul>
</div></section><section id="package-versions" class="level3 appendix" data-visibility="uncounted"><h2 class="anchored quarto-appendix-heading">Package Versions</h2><div class="quarto-appendix-contents">

<div id="45a97616" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> watermark <span class="im">import</span> watermark</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(watermark(python<span class="op">=</span><span class="va">True</span>, packages<span class="op">=</span><span class="st">"keras,matplotlib,numpy,pandas,seaborn,scipy,torch,tensorflow,tensorflow_probability,tf_keras"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Python implementation: CPython
Python version       : 3.11.9
IPython version      : 8.24.0

keras                 : 3.3.3
matplotlib            : 3.9.0
numpy                 : 1.26.4
pandas                : 2.2.2
seaborn               : 0.13.2
scipy                 : 1.11.0
torch                 : 2.3.1
tensorflow            : 2.16.1
tensorflow_probability: 0.24.0
tf_keras              : 2.16.0
</code></pre>
</div>
</div>
</div></section><section id="glossary" class="level3 appendix" data-visibility="uncounted"><h2 class="anchored quarto-appendix-heading">Glossary</h2><div class="quarto-appendix-contents">

<div class="columns">
<div class="column">
<ul>
<li>aleatoric and epistemic uncertainty</li>
<li>deep ensembles</li>
<li>CANN</li>
<li>GLM</li>
</ul>
</div><div class="column">
<ul>
<li>MDN</li>
<li>mixture distribution</li>
<li>posterior sampling</li>
<li>proper scoring rule</li>
</ul>
</div>
</div>


</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../Labs/backpropagation-lab.html" class="pagination-link" aria-label="Lab: Backpropagation">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Lab: Backpropagation</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../Advanced-Topics/interpretability.html" class="pagination-link" aria-label="Interpretability">
        <span class="nav-page-text">Interpretability</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>