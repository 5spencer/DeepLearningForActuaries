---
title: Examinable Topics for Revision
---

## Exam details

- Exam is on Inspera
- Open book
- No handwritten answers, maybe have a calculator handy
- You'll have __1.5 hours__ to complete plus 15 mins reading
- Complete the IT preparation checklist (MFA, speed test, read policies)

## Lecture 1: AI

::: columns
::: column
- artificial intelligence
- artificial intelligence vs machine learning
- classification problem
- ~~Deep Blue~~
- labelled/unlabelled data
:::
::: column
- machine learning
- ~~minimax algorithm~~
- pseudocode
- regression problem
- targets
:::
:::

## Lecture 1: Python

::: columns
::: column

- default arguments
- dictionaries
- f-strings
- function definitions
- ~~Google Colaboratory~~
- ~~`help`~~
- list
:::
::: column
- ~~`pip install ...`~~
- `range`
- slicing
- tuple
- ~~`type`~~
- whitespace indentation
- zero-indexing
:::
:::

## Lecture 2: Deep Learning {.smaller}

::: columns
::: column
- activations, activation function
- artificial neural network
- biases (in neurons)
- callbacks
- cost/loss function
- deep/shallow network, network depth
- dense or fully-connected layer
- early stopping
- epoch
- feed-forward neural network
:::
::: column
- ~~Keras, Tensorflow, PyTorch~~
- ~~matplotlib, seaborn~~
- neural network architecture
- overfitting
- ~~perceptron~~
- ReLU activation
- representation learning
- training/validation/test split
- universal approximation theorem
- weights (in a neuron)
:::
:::

## Tutorial 2: Forward Pass

::: columns
::: column
- batches, batch size
- forward pass of network
- gradient-based learning
:::
::: column
- learning rate
- stochastic (mini-batch) gradient descent
:::
:::

## Lecture 3: Mixed Topics

::: columns
:::: column
**Categorical Variables**

- entity embeddings
- Input layer
- Keras functional API
- nominal variables
- ordinal variables
- Reshape layer
- skip connection
- wide & deep network
::::
:::: column
**Classification**

- accuracy
- confusion matrix
- cross-entropy loss
- metrics
- sigmoid activation
- sofmax activation
::::
:::

## Lecture 4: Computer Vision

::: columns
::: column
- channels
- computer vision
- convolutional layer & CNN
- error analysis
- filter/kernel
:::
::: column
- flatten layer
- max pooling
- MNIST
- stride
- tensor (rank, dimension)
:::
:::

## Tutorial 4: Backpropagation

- backpropagation
- partial derivatives

## Lecture 5: Natural Language

::: columns
:::: column
- bag of words
- lemmatization
- one-hot embedding
- stop words
::::
:::: column
- vocabulary
- word embeddings/vectors
- word2vec
::::
:::

## Week 6: Uncertainy Quantification

::: columns
::: column
- aleatoric and epistemic uncertainty
- Bayesian neural network
- deep ensembles
- dropout
- ensemble model
- CANN
- GLM
:::
::: column
- MDN
- mixture distribution
- Monte Carlo dropout
- posterior sampling
- ~~proper scoring rule~~
- uncertainty quantification
- ~~variational approximation~~
:::
:::

## Lecture 7: Recurrent Networks

- GRU
- LSTM
- recurrent neural networks
- SimpleRNN

## Lecture 8: Transfer Learning

::: columns
:::: column
- ~~AlexNet, GoogLeNet, Inception~~
- ImageNet
::::
:::: column
- fine-tuning
- transfer learning
::::
:::

## Lecture 8-9: Generative Networks

::: columns
:::: column
- autoencoder (~~variational~~)
- beam search
- bias
- ~~ChatGPT (& RLHF)~~
- ~~DeepDream~~
- ~~generative adversarial networks~~
- greedy sampling
::::
:::: column
- ~~Hugging Face~~
- language model
- latent space
- ~~neural style transfer~~
- softmax temperature
- stochastic sampling
::::
:::

## Lecture 9: Interpretability

- global interpretability
- ~~Grad-CAM~~
- inherent interpretability
- LIME
- local interpretability
- permutation importance
- post-hoc interpretability
- ~~SHAP values~~

## StoryWalls

1. ~~Go AI: Basic Python~~
2. Sydney Temperature Forecasting: Basic MLP
3. Victorian Crash Severity: Classification & entity-embedding
4. [Hurricane damage](https://colab.research.google.com/drive/1WX3UQ9pLfHYiUXZ8o5DcAOQj6-AGdo5M?usp=sharing): Convolutional neural networks and hyperparameter tuning
5. US Police reports: NLP with bag-of-words, TF-IDF, permutation importance
6. Health Insurance Premiums: Uncertainty Quantification
7. ~~Generative networks experimenting~~


<script defer>
    // Remove the highlight.js class for the 'compile', 'min', 'max'
    // as there's a bug where they are treated like the Python built-in
    // global functions but we only ever see it as methods like
    // 'model.compile()' or 'predictions.max()'
    buggyBuiltIns = ["abs", "compile", "eval", "min", "max", "round", "sum"];

    document.querySelectorAll('.bu').forEach((elem) => {
        if (buggyBuiltIns.includes(elem.innerHTML)) {
            elem.classList.remove('bu');
        }
    })

    var registerRevealCallbacks = function() {
        Reveal.on('overviewshown', event => {
            document.querySelector(".line.right").hidden = true;
        });
        Reveal.on('overviewhidden', event => {
            document.querySelector(".line.right").hidden = false;
        });
    };
</script>
