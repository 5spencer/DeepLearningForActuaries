# Stroke Prediction {background-image="unsw-yellow-shape.png" data-visibility="uncounted"}

## The data {.smaller}

Dataset source: [Kaggle Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset).

```{python}
data = pd.read_csv("stroke.csv")
data.head()
```

## Split the data

First, look for missing values.
```{python}
numberMissing = data.isna().sum()
numberMissing[numberMissing > 0]
```

```{python}
features = data.drop(["id", "stroke"], axis=1)
target = data["stroke"]

X_main, X_test, y_main, y_test = train_test_split(
    features, target, test_size=0.2, random_state=7)
X_train, X_val, y_train, y_val = train_test_split(
    X_main, y_main, test_size=0.25, random_state=12)

X_train.shape, X_val.shape, X_test.shape
```

## What values do we see in the data?

::: columns
::: column
```{python}
X_train["gender"].value_counts()
```

```{python}
X_train["ever_married"].value_counts()
```

```{python}
X_train["Residence_type"].value_counts()
```
:::
::: column
```{python}
X_train["work_type"].value_counts()
```

```{python}
X_train["smoking_status"].value_counts()
```
:::
:::

## Preprocess the columns individually

::: {.smaller}
Take categorical columns $\hookrightarrow$ one-hot vectors,
binary columns $\hookrightarrow$ do nothing, continuous columns $\hookrightarrow$ impute NaNs & standardise.
:::

```{python}
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline
from sklearn.impute import SimpleImputer

catVars =  ["gender", "ever_married", "Residence_type",
    "work_type", "smoking_status"]

ct = make_column_transformer(
  (OneHotEncoder(handle_unknown="ignore"), catVars),
  ("passthrough", ["hypertension", "heart_disease"]),
  remainder=make_pipeline(SimpleImputer(), StandardScaler())
)

X_train_ct = ct.fit_transform(X_train)
X_val_ct = ct.transform(X_val); X_test_ct = ct.transform(X_test)

numNANs = np.sum(np.isnan(X_train_ct)) + np.sum(np.isnan(X_val_ct)) + np.sum(np.isnan(X_test_ct))
f"The training set has shape {X_train_ct.shape} & there are now {numNANs} NANs in the data."
```

## Handling unseen categories

::: columns
::: column
```{python}
X_train["gender"].value_counts()
```
:::
::: column
```{python}
X_val["gender"].value_counts()
```
:::
:::

::: columns
::: column
```{python}
ind = np.argmax(X_val["gender"] == "Other")
X_val.iloc[ind-1:ind+3][["gender"]]
```
:::
::: column
```{python}
X_val_ct[ind-1:ind+3,:2]
```

::: {.callout-note}
Note, when you pass a DataFrame to `sklearn`, it gives you back a `numpy` array.
:::
:::
:::

## Setup a binary classification model

```{python}
def create_model(seed=42):
    random.seed(seed)
    model = Sequential()
    model.add(Dense(32, "leaky_relu", input_shape=X_train_ct.shape[1:]))
    model.add(Dense(16, "leaky_relu"))
    model.add(Dense(1, "sigmoid"))
    return model
```

```{python}
model = create_model()
model.summary(print_fn=skip_empty)
```

## Add metrics, compile, and fit

```{python}
model = create_model()

pr_auc = tf.keras.metrics.AUC(curve="PR", name="pr_auc")
model.compile(optimizer="adam", loss="BinaryCrossentropy",
    metrics=["accuracy", "AUC", pr_auc])

es = EarlyStopping(patience=50, restore_best_weights=True,
    monitor="val_pr_auc", verbose=1)
model.fit(X_train_ct, y_train, callbacks=[es], epochs=1_000, verbose=0,
  validation_data=(X_val_ct, y_val));
```

::: columns
::: column
```{python}
model.evaluate(X_val_ct, y_val, verbose=0)
```
:::
::: column
:::
:::

## Try overweighting the minority class

```{python}
model = create_model()

pr_auc = tf.keras.metrics.AUC(curve="PR", name="pr_auc")
model.compile(optimizer="adam", loss="BinaryCrossentropy",
    metrics=["accuracy", "AUC", pr_auc])

es = EarlyStopping(patience=50, restore_best_weights=True,
    monitor="val_pr_auc", verbose=1)
model.fit(X_train_ct, y_train, callbacks=[es], epochs=1_000, verbose=0,
  validation_data=(X_val_ct, y_val), class_weight={0: 1, 1: 10});
```

::: columns
::: column
```{python}
model.evaluate(X_val_ct, y_val, verbose=0)
```
:::
::: column
::: fragment
```{python}
model.evaluate(X_test_ct, y_test, verbose=0)
```
:::
:::
:::

## Classification Metrics {.smaller}

```{python}
from sklearn.metrics import confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay
y_pred = model.predict(X_test_ct, verbose=0)
```

::: columns
::: column
```{python}
RocCurveDisplay.from_predictions(y_test, y_pred, name="");
```
:::
::: column
```{python}
PrecisionRecallDisplay.from_predictions(y_test, y_pred, name=""); plt.legend(loc="upper right");
```
:::
:::

::: columns
::: column
```{python}
y_pred_stroke = y_pred > 0.5
confusion_matrix(y_test, y_pred_stroke)
```
:::
::: column
```{python}
y_pred_stroke = y_pred > 0.3
confusion_matrix(y_test, y_pred_stroke)
```
:::
:::
