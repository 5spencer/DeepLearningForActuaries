---
title: "Artificial Intelligence and Deep Learning Models for Actuarial Applications"
subtitle: "Lecture slides from UNSW's ACTL3143 & ACTL5111 courses"
author: Dr Patrick Laub
format:
  html: default
---

# Overview

These are the lecture slides from my recent "Artificial Intelligence and Deep Learning Models for Actuarial Applications" courses (coded ACTL3143 & ACTL5111) at UNSW.
They can be used to see what topics I covered in these courses.
The slides are not intended to be used to learn deep learning from scratch.
For that, you need to attend the lectures & complete the assessment.

# Lecture Materials

<!-- - [Course Overview](/Lecture-1-Artificial-Intelligence/course-overview.html) ([slides](/Lecture-1-Artificial-Intelligence/course-overview.pdf)) -->
<!-- - [Artificial Intelligence](/Lecture-1-Artificial-Intelligence/artificial-intelligence.html) ([slides](/Lecture-1-Artificial-Intelligence/artificial-intelligence.pdf)) -->
- [Python](/Lecture-1-Artificial-Intelligence/python.html) ([slides](/Lecture-1-Artificial-Intelligence/python.pdf))
- [Deep Learning with Keras](/Lecture-2-Deep-Learning-Keras/deep-learning-keras.html) ([slides](/Lecture-2-Deep-Learning-Keras/deep-learning-keras.pdf))
<!-- - [Project](/Lecture-2-Deep-Learning-Keras/project.html) ([slides](/Lecture-2-Deep-Learning-Keras/project.pdf)) -->
- [Categorical Variables](/Lecture-3-Tabular-Data/categorical-variables.html) ([slides](/Lecture-3-Tabular-Data/categorical-variables.pdf))
- [Classification](/Lecture-3-Tabular-Data/classification.html) ([slides](/Lecture-3-Tabular-Data/classification.pdf))
- [Computer Vision](/Lecture-4-Computer-Vision/computer-vision.html) ([slides](/Lecture-4-Computer-Vision/computer-vision.pdf))
- [Natural Language Processing](/Lecture-5-Natural-Language-Processing/natural-language-processing.html) ([slides](/Lecture-5-Natural-Language-Processing/natural-language-processing.pdf))
- [Uncertainty Quantification](/Lecture-6-Uncertainty-Quantification/uncertainty-quantification.html) ([slides](/Lecture-6-Uncertainty-Quantification/uncertainty-quantification.pdf))
- [Recurrent Networks and Time Series](/Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.html) ([slides](/Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.pdf))
- [Generative Networks](/Lecture-8-Generative-Networks/generative-networks.html) ([slides](/Lecture-8-Generative-Networks/generative-networks.pdf))
- [Generative Adversarial Networks](/Lecture-8-Generative-Networks/gans.html) ([slides](/Lecture-8-Generative-Networks/gans.pdf))
- [Interpretability](/Lecture-9-Advanced-Topics/interpretability.html) ([slides](/Lecture-9-Advanced-Topics/interpretability.pdf))

<!-- 
# List of Topics Covered

## [Lecture 1: Python](/Lecture-1-Artificial-Intelligence/python.qmd)

::: columns
::: column

- default arguments
- dictionaries
- f-strings
- function definitions
- Google Colaboratory
- `help`
- list
:::
::: column
- `pip install ...`
- `range`
- slicing
- tuple
- `type`
- whitespace indentation
- zero-indexing
:::
:::

## [Lecture 2: Deep Learning](/Lecture-2-Deep-Learning-Keras/deep-learning-keras.qmd)

::: columns
::: column
- activations, activation function
- artificial neural network
- biases (in neurons)
- callbacks
- cost/loss function
- deep/shallow network, network depth
- dense or fully-connected layer
- early stopping
- epoch
- feed-forward neural network
:::
::: column
- Keras, Tensorflow, PyTorch
- matplotlib, seaborn
- neural network architecture
- overfitting
- perceptron
- ReLU activation
- representation learning
- training/validation/test split
- universal approximation theorem
- weights (in a neuron)
:::
:::

## Tutorial 2: Forward Pass

::: columns
::: column
- batches, batch size
- forward pass of network
- gradient-based learning
:::
::: column
- learning rate
- stochastic (mini-batch) gradient descent
:::
:::

## [Lecture 3: Tabular Data](/Lecture-3-Tabular-Data/categorical-variables.qmd)

::: columns
:::: column
**Categorical Variables**

- entity embeddings
- Input layer
- Keras functional API
- nominal variables
- ordinal variables
- Reshape layer
- skip connection
- wide & deep network
::::
:::: column
**Classification**

- accuracy
- confusion matrix
- cross-entropy loss
- metrics
- sigmoid activation
- sofmax activation
::::
:::

## [Lecture 4: Computer Vision](/Lecture-4-Computer-Vision/computer-vision.qmd)

::: columns
::: column
- AlexNet, GoogLeNet, Inception
- channels
- computer vision
- convolutional layer & CNN
- error analysis
- fine-tuning
- filter/kernel
:::
::: column
- flatten layer
- ImageNet
- max pooling
- MNIST
- stride
- tensor (rank, dimension)
- transfer learning
:::
:::

## Tutorial 4: Backpropagation

- backpropagation
- partial derivatives

## [Lecture 5: Natural Language Processing](/Lecture-5-Natural-Language-Processing/natural-language-processing.qmd)

::: columns
:::: column
- bag of words
- lemmatization
- one-hot embedding
- stop words
::::
:::: column
- vocabulary
- word embeddings/vectors
- word2vec
::::
:::

## [Lecture 6: Uncertainy Quantification](/Lecture-6-Uncertainty-Quantification/uncertainty-quantification.qmd)

::: columns
::: column
- aleatoric and epistemic uncertainty
- Bayesian neural network
- deep ensembles
- dropout
- ensemble model
- CANN
- GLM
:::
::: column
- MDN
- mixture distribution
- Monte Carlo dropout
- posterior sampling
- proper scoring rule
- uncertainty quantification
- variational approximation
:::
:::

## [Lecture 7: Recurrent Networks and Time Series](/Lecture-7-Recurrent-Neural-Networks-And-Time-Series/rnns-and-time-series.qmd)

- GRU
- LSTM
- recurrent neural networks
- SimpleRNN

## [Lecture 8: Generative Networks](/Lecture-8-Generative-Networks/generative-networks.qmd)


## Lecture 8-9: Generative Networks

::: columns
:::: column
- autoencoder (variational)
- beam search
- bias
- ChatGPT (& RLHF)
- DeepDream
- generative adversarial networks
- greedy sampling
::::
:::: column
- Hugging Face
- language model
- latent space
- neural style transfer
- softmax temperature
- stochastic sampling
::::
:::

## [Lecture 9: Interpretability](/Lecture-9-Advanced-Topics/interpretability.qmd)

- global interpretability
- Grad-CAM
- inherent interpretability
- LIME
- local interpretability
- permutation importance
- post-hoc interpretability
- SHAP values
-->

# Contributors

- Tian (Eric) Dong
- Michael Jacinto
- Hang Nguyen
- Marcus Lautier
- Gayani Thalagoda

# Copyright

Patrick Laub
