---
title: Course Overview
subtitle: ACTL3143 & ACTL5111 Deep Learning for Actuaries
author: Dr Patrick Laub
format:
  revealjs:
    theme: [serif, custom.scss]
    controls: true
    controls-tutorial: true
    logo: unsw-logo.svg
    footer: "Slides: [Dr Patrick Laub](https://pat-laub.github.io) (@PatrickLaub)."
    title-slide-attributes:
      data-background-image: unsw-yellow-shape.png
      data-background-size: contain !important
    transition: none
    slide-number: c/t
    strip-comments: true
    preview-links: false
    margin: 0.12
    width: 1000
    chalkboard:
      boardmarker-width: 6
      grid: false
      background:
        - "rgba(255,255,255,0.0)"
        - "https://github.com/rajgoel/reveal.js-plugins/raw/master/chalkboard/img/blackboard.png"
    include-before: <div class="line right"></div>
    include-after: <script>registerRevealCallbacks();</script>
highlight-style: breeze
jupyter: python3
execute:
  keep-ipynb: true
  echo: true
---

# Course Overview {background-image="unsw-yellow-shape.png"}

## Your lecturer

My name is Patrick Laub.
My background:

- Bachelor in Software engineering / Mathematics (UQ)
- PhD in Applied Probability (Denmark & UQ)
- Post-doc in Lyon, France
- Post-doc in Melbourne, Australia
- Lecturer here since January

## Course objectives

<br>

Artificial intelligence and _deep learning_ for actuaries.

You will be able to:

- explain common neural network architectures,
- create deep learning models (in Keras) to solve actuarial data science problems,
- gain experience with practical computational tools (e.g. Python).

<!-- At the end: not 100% AI Engineer (need more practice), but have foundation / can be an informed user. -->

## AI vs ML vs DL

![The Venn diagram of AI, ML, and DL.](AI-vs-ML-vs-Deep-Learning.png)

::: footer
Source: Edureka (2020), [AI Vs Machine Learning Vs Deep Learning Edureka](https://www.edureka.co/blog/ai-vs-machine-learning-vs-deep-learning).
:::

## Lecture plans

::: columns
::: column

1. Artificial Intelligence
2. Deep Learning with Keras
3. (**PH**) Mathematics of Deep Learning
4. Regularisation and Hyperparameter Tuning
5. **Guest lecture** & Recurrent Neural Networks

:::
::: column

6. _Away for flexibility week_
7. Computer Vision
8. Natural Language Processing
9. Generative Networks
10. Deep Reinforcement Learning

In Week 3, attend/watch on Tuesday.
:::
:::

## Contact hours

<br>

The lectures are scheduled as 2.5 hours each week.
This is a 2 hour traditional lecture, and a 0.5 hour tutorial.

<br>

The tutorials will cover practical Python and computational topics which are useful for deep learning.

<br>

Office hours can be arranged if needed.

## Assessment & StoryWall

1. StoryWall (30%)
2. Project (40%)
3. Exam (30%)

StoryWall #0 is a introduction due on June 3 worth 2%.

StoryWall #1 to #9 are 4% each, with the best 7 of 9 being counted.
Each is pass/fail.

Questions released on a Monday and *normally* due the following Monday.

## A complete deep learning project

Individual project over the term.
You will:

- specify a *supervised learning* problem,
- collect and clean the data,
- perform an exploratory data analysis (EDA),
- create a simple (non-deep learning) benchmark model,
- fit two different deep learning architectures,
- perform hyperparameter tuning,
- write a discussion of the results.

## The template {auto-animate=true}

Richman & Wüthrich (2019), [Lee and Carter go Machine Learning: Recurrent Neural Networks](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3441030), SSRN

Problem: predict Swiss mortality rates.

::: columns
::: column

Data collection: Human mortality database.

Benchmark: Lee-Carter model.

DL models: RNNs (LSTM & GRU).

:::
::: column

![](lee-carter-go-ml-raw-mortality.png)

:::
:::

## Modify the template {auto-animate=true}

Richman & Wüthrich (2019), [Lee and Carter go Machine Learning: Recurrent Neural Networks](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3441030), SSRN

Problem: predict ~~Swiss~~ _another country's_ mortality rates.

::: columns
::: column

Data collection: Human mortality database.

Benchmark: Lee-Carter model.

DL models: ~~RNNs (LSTM & GRU)~~ _FC & RNN_, or _FC & CNN_ etc.

:::
::: column

![](lee-carter-go-ml-raw-mortality.png)

:::
:::


## Project deliverables

<br>

The deliverables for the project will include:

1. draft due at noon on July 1 (10%),
2. recorded presentation due at noon on July 22 (15%),
3. final report due at noon on August 1 (15%).

## Project draft (10%)

Draft should show that you have:

- specified your supervised learning problem,
- collected and cleaned the data,
- performed a basic exploratory data analysis,
- create a simple (non-deep learning) benchmark model.

Email me a PDF by **noon on July 1**, no late submissions.

::: {.callout-tip}
Later in the project you will fit two different deep learning architectures.
Consider the _wide & deep_ architecture from later in this lecture.
:::


## Exam

The exam will test the concepts presented in the lectures.
For example, you will be expected to:

- provide definitions for various deep learning terminology,
- suggest neural network designs to solve risk and actuarial problems,
- give advice to mock deep learning engineers whose projects have hit common roadblocks,
- find/explain common bugs in deep learning Python code.

## Copying code...

::: columns
::: {.column width="70%"}

If you copy, tag it:
```python
# Suppress endless warnings from Keras.
# Source: https://stackoverflow.com/a/38645250
import tensorflow as tf
tf.get_logger().setLevel('INFO')
```

Even if you then edit it a little:
```python
# Create a basic Convolutional Network.
# Adapted from: https://www.tensorflow.org/tutorials/images/cnn
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3),
    activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10))
```
:::
::: {.column width="30%"}
![Recommended reading.](copying-pasting-stack-overflow.png)
:::
:::

::: footer
Source: Anonymous (2016), [Essential Copying and Pasting from Stack Overflow](https://github.com/dmnhut/read/raw/master/essential-copying-and-pasting-from-stack-overflow.pdf).
:::


# Project {background-image="unsw-yellow-shape.png" data-visibility="uncounted"}

## Project components

<br>

1. Draft (10% pass/fail).
2. Recorded presentation due at noon on July 22 (15%).
3. Final report due at noon on August 1 (15%).

## Presentation 

Create a 3–5 minute recording covering:

1. the problem you are investigating,
2. the source of the data, 
3. the deep learning approaches you are using, and
4. preliminary results you have (table of metrics).

**Deliverable**: YouTube link (public or unlisted) to a special StoryWall page.
Presentations will be "public" to the class.

<br>

_Suggestions_: aim to be fully public and give peer feedback.

## Presentation marking scheme

- **Content** (6%): did you cover the four points on previous slide?
- **Style** (6%): are your slides/figures professional and do they enhance the presentation?
- **Delivery** (3%): is the presentation interesting and within the time limit?

::: {.callout-tip}
It is a critical skill to be able to condense a complicated project into a short pitch.
The project report is where you will give us all the details.
:::

## Last presentation tips

- Each project is different, you decide which parts to focus on. E.g. source of data may simply be "Human Mortality Database".
- Not necessary to film yourself.
- Nice to _briefly_ show the data (look at my lecture slides for example).
- Don't go overboard on EDA. Mention the _most important_ 1--2 facts (if any!) about the data. E.g. imbalanced classes for classification.
- You can avoid adding UNSW / the course code to your presentation.

## Report requirements

You are asked to cover the four requirements in the draft, and also:

- fit two different deep learning architectures,
- perform hyperparameter tuning,
- write a discussion of the results and any potential ethical concerns.

**Deliverable**: Report (PDF file), Jupyter Notebook, and dataset (e.g. CSV or ZIP file).
Submission not public, probably to Moodle.

## Report marking criteria

- **Content** (8%): did you cover the seven points in the ML workflow?
- **Style** (5%): does your report look professional, are your plots/tables useful and unpixelated, do you have spelling or grammar errors, are you within the page limit, and is the text easy to read? 
- **Code** (2%): is your code clean and well-commented, have useless cells been pruned, does it give errors when the "Run All" button is pressed?

Unlike StoryWall, _avoid screenshots & code in the report_.

## Some comments on the report

- **Focus on deep learning**: I'm most interested in seeing your ability to use and explain your neural networks.
For example, your mastery of the Lee--Carter model is less important to demonstrate.
- **Hyperparameter tuning**: The tuning is one significant change from the weekly StoryWall tasks.
Add a table (for each neural network) showing (at least) two hyperparameters that you tuned.
- **Use appendices**: If you run out of space, use appendices which are not counted in the page limit.
E.g., the less urgent parts of your EDA can go in here.


<script defer>
    var registerRevealCallbacks = function() {
        Reveal.on('overviewshown', event => {
            document.querySelector(".line.right").hidden = true;
        });
        Reveal.on('overviewhidden', event => {
            document.querySelector(".line.right").hidden = false;
        });
    };
</script>